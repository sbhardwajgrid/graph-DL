{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/sbhardwaj/Documents/GraphNodeClassification')\n",
    "\n",
    "from src.models.models import GCN , MLP , mlp_GCN , n2vnet\n",
    "from src.models.training import weighted_BCE , train_mlp , test_mlp , train_gcn , test_gcn , train_n2v , test_n2v\n",
    "from src.data.data_loader import DBLP_dataset\n",
    "from src.utilities.utils import acc , recall , save_model\n",
    "import os\n",
    "import node2vec\n",
    "\n",
    "import torch\n",
    "import copy\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select GPS device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps device found!\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"mps device found!\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge sampling experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gcn_logger = logging.getLogger('gcn')\n",
    "# mlp_logger = logging.getLogger('mlp')\n",
    "mlp_gcn_logger = logging.getLogger('mlp_gcn')\n",
    "n2vnet_logger = logging.getLogger(\"n2vnet\")\n",
    "\n",
    "# gcn_logger.setLevel(logging.INFO)\n",
    "# mlp_logger.setLevel(logging.INFO)\n",
    "mlp_gcn_logger.setLevel(logging.INFO)\n",
    "n2vnet_logger.setLevel(logging.INFO)\n",
    "\n",
    "# file_handler_gcn = logging.FileHandler(f'../src/logs/es_expt/gcn_{run}.log' , mode=\"w\")\n",
    "# file_handler_mlp = logging.FileHandler(f'../src/logs/es_expt/mlp_{run}.log' , mode=\"w\")\n",
    "file_handler_mlp_gcn = logging.FileHandler(f\"../src/logs/es_expt/mlp_gcn_{run}.log\" , mode=\"w\")\n",
    "file_handler_n2vnet = logging.FileHandler(f\"../src/logs/es_expt/n2vnet_{run}.log\" , mode=\"w\")\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "# file_handler_gcn.setFormatter(formatter)\n",
    "# file_handler_mlp.setFormatter(formatter)\n",
    "file_handler_mlp_gcn.setFormatter(formatter)\n",
    "file_handler_n2vnet.setFormatter(formatter)\n",
    "\n",
    "# gcn_logger.addHandler(file_handler_gcn)\n",
    "# mlp_logger.addHandler(file_handler_mlp)\n",
    "mlp_gcn_logger.addHandler(file_handler_mlp_gcn)\n",
    "n2vnet_logger.addHandler(file_handler_n2vnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root': '/Users/sbhardwaj/Documents/GraphNodeClassification/data',\n",
       " 'raw_filenames': ['graph_edges.txt', '5000_communities.txt'],\n",
       " 'expt': 'edge_sampling',\n",
       " 'processed_filenames': ['data_es_0.pt',\n",
       "  'data_es_1.pt',\n",
       "  'data_es_2.pt',\n",
       "  'data_es_3.pt']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader_args = {\n",
    "    \"root\":os.path.abspath(\"..\")+\"/data\",\n",
    "    \"raw_filenames\":[\"graph_edges.txt\" , \"5000_communities.txt\"],\n",
    "    \"expt\":\"edge_sampling\",\n",
    "    \"processed_filenames\":[\"data_es_0.pt\" , \"data_es_1.pt\" , \"data_es_2.pt\" , \"data_es_3.pt\" ]\n",
    "}\n",
    "\n",
    "dataloader_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf59c30cb2fd4bf48b7ae72d5a49e3fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/13169 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 100/100 [00:27<00:00,  3.58it/s]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "d_es = DBLP_dataset(root = dataloader_args[\"root\"] , raw_filenames = dataloader_args[\"raw_filenames\"] ,\n",
    "                    expt = dataloader_args[\"expt\"], processed_filenames = dataloader_args[\"processed_filenames\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[13169, 21], edge_index=[2, 57621], y=[13169, 200], dtype=torch.float32, g=Graph with 13169 nodes and 22226 edges, train_mask=[13169], val_mask=[13169], test_mask=[13169])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = d_es[0].to(device)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'device': device(type='mps'),\n",
       " 'num_layers': 4,\n",
       " 'hidden_dim': 16,\n",
       " 'dropout': 0.2,\n",
       " 'lr': 0.005,\n",
       " 'epochs': 1000}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcn_args = {\n",
    "    'device': device,\n",
    "    'num_layers': 4,\n",
    "    'hidden_dim': 16,\n",
    "    'dropout': 0.2,\n",
    "    'lr': 0.005,\n",
    "    'epochs': 1000,\n",
    "}\n",
    "\n",
    "gcn_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN model number of parameters: 4392\n"
     ]
    }
   ],
   "source": [
    "gcn_model = GCN(data.x.shape[1] , gcn_args['hidden_dim'] , data.y.shape[1] , gcn_args['num_layers'] , gcn_args['dropout']).to(device)\n",
    "\n",
    "total_params_GCN = sum(\n",
    "\tparam.numel() for param in gcn_model.parameters()\n",
    ")\n",
    "print(\"GCN model number of parameters:\" , total_params_GCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (convs): ModuleList(\n",
       "    (0): GCNConv(21, 16)\n",
       "    (1-2): 2 x GCNConv(16, 16)\n",
       "    (3): GCNConv(16, 200)\n",
       "  )\n",
       "  (bns): ModuleList(\n",
       "    (0-2): 3 x BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (output): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train GCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loc(\"mps_not_equal\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/4e1473ee-9f66-11ee-8daf-cedaeb4cabe2/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":253:0)): error: 'anec.not_equal_zero' op Invalid configuration for the following reasons: Tensor dimensions N1D1C1H1W57621 are not within supported range, N[1-65536]D[1-16384]C[1-65536]H[1-16384]W[1-16384].\n",
      "loc(\"mps_select\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/4e1473ee-9f66-11ee-8daf-cedaeb4cabe2/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":294:0)): error: 'anec.not_equal_zero' op Invalid configuration for the following reasons: Tensor dimensions N1D1C1H1W57621 are not within supported range, N[1-65536]D[1-16384]C[1-65536]H[1-16384]W[1-16384].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 23739.2793, Recall: 51.17%, Acc: 58.27% Test: 50.59%\n",
      "Epoch: 02, Loss: 23315.8574, Recall: 52.65%, Acc: 62.44% Test: 52.14%\n",
      "Epoch: 03, Loss: 22862.6445, Recall: 55.92%, Acc: 66.55% Test: 56.14%\n",
      "Epoch: 04, Loss: 22489.4609, Recall: 59.28%, Acc: 70.47% Test: 58.88%\n",
      "Epoch: 05, Loss: 22117.9434, Recall: 62.21%, Acc: 73.96% Test: 61.54%\n",
      "Epoch: 06, Loss: 21773.3789, Recall: 65.15%, Acc: 76.88% Test: 64.35%\n",
      "Epoch: 07, Loss: 21416.9219, Recall: 68.85%, Acc: 79.26% Test: 67.16%\n",
      "Epoch: 08, Loss: 21087.9375, Recall: 70.89%, Acc: 81.13% Test: 69.08%\n",
      "Epoch: 09, Loss: 20755.8281, Recall: 72.33%, Acc: 82.58% Test: 70.56%\n",
      "Epoch: 10, Loss: 20455.6855, Recall: 73.09%, Acc: 83.75% Test: 71.67%\n",
      "Epoch: 11, Loss: 20158.3828, Recall: 73.52%, Acc: 84.75% Test: 72.49%\n",
      "Epoch: 12, Loss: 19872.5938, Recall: 73.96%, Acc: 85.53% Test: 73.22%\n",
      "Epoch: 13, Loss: 19628.7969, Recall: 74.23%, Acc: 86.17% Test: 73.08%\n",
      "Epoch: 14, Loss: 19354.3828, Recall: 74.32%, Acc: 86.69% Test: 73.15%\n",
      "Epoch: 15, Loss: 19126.6602, Recall: 74.61%, Acc: 87.13% Test: 73.22%\n",
      "Epoch: 16, Loss: 18895.8398, Recall: 74.96%, Acc: 87.49% Test: 73.45%\n",
      "Epoch: 17, Loss: 18689.6250, Recall: 75.23%, Acc: 87.78% Test: 73.82%\n",
      "Epoch: 18, Loss: 18468.5000, Recall: 75.51%, Acc: 88.03% Test: 73.96%\n",
      "Epoch: 19, Loss: 18291.0117, Recall: 75.75%, Acc: 88.21% Test: 74.19%\n",
      "Epoch: 20, Loss: 18107.2012, Recall: 76.00%, Acc: 88.35% Test: 74.41%\n",
      "Epoch: 21, Loss: 17923.5488, Recall: 76.14%, Acc: 88.46% Test: 74.48%\n",
      "Epoch: 22, Loss: 17770.2930, Recall: 76.19%, Acc: 88.56% Test: 74.56%\n",
      "Epoch: 23, Loss: 17638.7090, Recall: 76.32%, Acc: 88.65% Test: 74.70%\n",
      "Epoch: 24, Loss: 17467.2188, Recall: 76.47%, Acc: 88.74% Test: 74.85%\n",
      "Epoch: 25, Loss: 17359.5605, Recall: 76.61%, Acc: 88.82% Test: 75.15%\n",
      "Epoch: 26, Loss: 17234.6172, Recall: 76.88%, Acc: 88.90% Test: 75.44%\n",
      "Epoch: 27, Loss: 17125.1992, Recall: 76.94%, Acc: 88.97% Test: 75.81%\n",
      "Epoch: 28, Loss: 17004.3574, Recall: 77.08%, Acc: 89.05% Test: 75.89%\n",
      "Epoch: 29, Loss: 16892.4629, Recall: 77.24%, Acc: 89.12% Test: 75.89%\n",
      "Epoch: 30, Loss: 16792.5078, Recall: 77.40%, Acc: 89.18% Test: 75.96%\n",
      "Epoch: 31, Loss: 16726.8672, Recall: 77.50%, Acc: 89.23% Test: 76.04%\n",
      "Epoch: 32, Loss: 16647.6094, Recall: 77.66%, Acc: 89.28% Test: 76.18%\n",
      "Epoch: 33, Loss: 16564.2539, Recall: 77.86%, Acc: 89.33% Test: 76.33%\n",
      "Epoch: 34, Loss: 16466.7422, Recall: 78.04%, Acc: 89.39% Test: 76.78%\n",
      "Epoch: 35, Loss: 16414.2578, Recall: 78.21%, Acc: 89.44% Test: 76.92%\n",
      "Epoch: 36, Loss: 16333.9961, Recall: 78.40%, Acc: 89.50% Test: 77.14%\n",
      "Epoch: 37, Loss: 16271.3740, Recall: 78.75%, Acc: 89.55% Test: 77.51%\n",
      "Epoch: 38, Loss: 16200.4824, Recall: 78.96%, Acc: 89.60% Test: 77.59%\n",
      "Epoch: 39, Loss: 16139.1582, Recall: 79.14%, Acc: 89.66% Test: 77.74%\n",
      "Epoch: 40, Loss: 16090.3477, Recall: 79.40%, Acc: 89.72% Test: 77.96%\n",
      "Epoch: 41, Loss: 16020.7441, Recall: 79.55%, Acc: 89.78% Test: 78.40%\n",
      "Epoch: 42, Loss: 15965.6123, Recall: 79.72%, Acc: 89.84% Test: 78.48%\n",
      "Epoch: 43, Loss: 15922.2344, Recall: 79.96%, Acc: 89.89% Test: 78.77%\n",
      "Epoch: 44, Loss: 15862.4209, Recall: 80.21%, Acc: 89.95% Test: 79.14%\n",
      "Epoch: 45, Loss: 15805.0547, Recall: 80.63%, Acc: 90.00% Test: 79.66%\n",
      "Epoch: 46, Loss: 15773.2812, Recall: 81.24%, Acc: 90.05% Test: 80.25%\n",
      "Epoch: 47, Loss: 15712.1699, Recall: 81.78%, Acc: 90.11% Test: 80.70%\n",
      "Epoch: 48, Loss: 15665.9453, Recall: 82.17%, Acc: 90.17% Test: 80.99%\n",
      "Epoch: 49, Loss: 15614.2949, Recall: 82.40%, Acc: 90.22% Test: 81.36%\n",
      "Epoch: 50, Loss: 15580.3398, Recall: 82.64%, Acc: 90.29% Test: 81.66%\n",
      "Epoch: 51, Loss: 15558.4707, Recall: 82.86%, Acc: 90.35% Test: 81.88%\n",
      "Epoch: 52, Loss: 15478.8594, Recall: 83.13%, Acc: 90.41% Test: 82.03%\n",
      "Epoch: 53, Loss: 15438.0645, Recall: 83.35%, Acc: 90.46% Test: 82.10%\n",
      "Epoch: 54, Loss: 15421.5488, Recall: 83.60%, Acc: 90.51% Test: 82.32%\n",
      "Epoch: 55, Loss: 15364.8574, Recall: 83.90%, Acc: 90.56% Test: 82.62%\n",
      "Epoch: 56, Loss: 15318.3096, Recall: 84.16%, Acc: 90.61% Test: 82.69%\n",
      "Epoch: 57, Loss: 15298.2109, Recall: 84.38%, Acc: 90.65% Test: 83.06%\n",
      "Epoch: 58, Loss: 15250.8359, Recall: 84.61%, Acc: 90.69% Test: 83.28%\n",
      "Epoch: 59, Loss: 15216.5928, Recall: 84.83%, Acc: 90.74% Test: 83.36%\n",
      "Epoch: 60, Loss: 15166.1689, Recall: 85.07%, Acc: 90.78% Test: 83.65%\n",
      "Epoch: 61, Loss: 15129.3525, Recall: 85.29%, Acc: 90.83% Test: 84.10%\n",
      "Epoch: 62, Loss: 15109.5195, Recall: 85.51%, Acc: 90.87% Test: 84.39%\n",
      "Epoch: 63, Loss: 15098.6006, Recall: 85.77%, Acc: 90.92% Test: 84.54%\n",
      "Epoch: 64, Loss: 15058.0117, Recall: 85.99%, Acc: 90.96% Test: 84.54%\n",
      "Epoch: 65, Loss: 15027.9727, Recall: 86.28%, Acc: 91.00% Test: 84.69%\n",
      "Epoch: 66, Loss: 15012.6914, Recall: 86.67%, Acc: 91.03% Test: 85.06%\n",
      "Epoch: 67, Loss: 14966.0127, Recall: 86.82%, Acc: 91.06% Test: 85.21%\n",
      "Epoch: 68, Loss: 14930.3037, Recall: 86.98%, Acc: 91.09% Test: 85.50%\n",
      "Epoch: 69, Loss: 14906.2168, Recall: 87.14%, Acc: 91.12% Test: 85.58%\n",
      "Epoch: 70, Loss: 14881.3857, Recall: 87.42%, Acc: 91.15% Test: 85.65%\n",
      "Epoch: 71, Loss: 14816.1816, Recall: 87.65%, Acc: 91.18% Test: 85.58%\n",
      "Epoch: 72, Loss: 14813.8984, Recall: 87.80%, Acc: 91.21% Test: 85.95%\n",
      "Epoch: 73, Loss: 14814.3037, Recall: 87.94%, Acc: 91.25% Test: 86.24%\n",
      "Epoch: 74, Loss: 14752.0283, Recall: 88.16%, Acc: 91.28% Test: 86.32%\n",
      "Epoch: 75, Loss: 14706.5498, Recall: 88.46%, Acc: 91.32% Test: 86.76%\n",
      "Epoch: 76, Loss: 14686.9492, Recall: 88.67%, Acc: 91.36% Test: 87.35%\n",
      "Epoch: 77, Loss: 14667.7148, Recall: 88.84%, Acc: 91.40% Test: 87.35%\n",
      "Epoch: 78, Loss: 14637.2344, Recall: 88.88%, Acc: 91.44% Test: 87.57%\n",
      "Epoch: 79, Loss: 14610.7383, Recall: 89.03%, Acc: 91.48% Test: 87.72%\n",
      "Epoch: 80, Loss: 14567.2930, Recall: 89.07%, Acc: 91.52% Test: 87.80%\n",
      "Epoch: 81, Loss: 14541.0371, Recall: 89.18%, Acc: 91.56% Test: 87.94%\n",
      "Epoch: 82, Loss: 14525.1611, Recall: 89.30%, Acc: 91.60% Test: 88.09%\n",
      "Epoch: 83, Loss: 14521.7939, Recall: 89.43%, Acc: 91.65% Test: 88.17%\n",
      "Epoch: 84, Loss: 14496.6338, Recall: 89.57%, Acc: 91.70% Test: 88.24%\n",
      "Epoch: 85, Loss: 14458.0938, Recall: 89.66%, Acc: 91.74% Test: 88.31%\n",
      "Epoch: 86, Loss: 14441.5820, Recall: 89.78%, Acc: 91.79% Test: 88.54%\n",
      "Epoch: 87, Loss: 14400.1699, Recall: 89.83%, Acc: 91.84% Test: 88.61%\n",
      "Epoch: 88, Loss: 14426.7090, Recall: 89.88%, Acc: 91.88% Test: 88.68%\n",
      "Epoch: 89, Loss: 14385.4980, Recall: 89.93%, Acc: 91.92% Test: 88.76%\n",
      "Epoch: 90, Loss: 14353.1084, Recall: 89.99%, Acc: 91.96% Test: 88.76%\n",
      "Epoch: 91, Loss: 14328.4062, Recall: 90.12%, Acc: 92.00% Test: 88.76%\n",
      "Epoch: 92, Loss: 14343.1484, Recall: 90.24%, Acc: 92.04% Test: 88.91%\n",
      "Epoch: 93, Loss: 14296.5625, Recall: 90.30%, Acc: 92.09% Test: 88.91%\n",
      "Epoch: 94, Loss: 14250.6104, Recall: 90.41%, Acc: 92.12% Test: 88.98%\n",
      "Epoch: 95, Loss: 14243.1953, Recall: 90.43%, Acc: 92.17% Test: 88.98%\n",
      "Epoch: 96, Loss: 14249.1338, Recall: 90.49%, Acc: 92.21% Test: 89.13%\n",
      "Epoch: 97, Loss: 14220.3086, Recall: 90.57%, Acc: 92.25% Test: 89.20%\n",
      "Epoch: 98, Loss: 14216.0938, Recall: 90.66%, Acc: 92.29% Test: 89.35%\n",
      "Epoch: 99, Loss: 14150.0049, Recall: 90.80%, Acc: 92.33% Test: 89.42%\n",
      "Epoch: 100, Loss: 14126.4961, Recall: 90.90%, Acc: 92.38% Test: 89.57%\n",
      "Epoch: 101, Loss: 14144.8164, Recall: 91.14%, Acc: 92.42% Test: 89.94%\n",
      "Epoch: 102, Loss: 14090.6758, Recall: 91.34%, Acc: 92.46% Test: 90.09%\n",
      "Epoch: 103, Loss: 14108.7139, Recall: 91.51%, Acc: 92.49% Test: 90.24%\n",
      "Epoch: 104, Loss: 14099.0684, Recall: 91.76%, Acc: 92.52% Test: 90.38%\n",
      "Epoch: 105, Loss: 14022.0088, Recall: 91.88%, Acc: 92.55% Test: 90.61%\n",
      "Epoch: 106, Loss: 14047.9229, Recall: 92.04%, Acc: 92.58% Test: 90.75%\n",
      "Epoch: 107, Loss: 14020.9102, Recall: 92.16%, Acc: 92.60% Test: 90.75%\n",
      "Epoch: 108, Loss: 14002.5176, Recall: 92.24%, Acc: 92.63% Test: 91.05%\n",
      "Epoch: 109, Loss: 13974.0352, Recall: 92.40%, Acc: 92.66% Test: 91.12%\n",
      "Epoch: 110, Loss: 13952.3828, Recall: 92.48%, Acc: 92.70% Test: 91.12%\n",
      "Epoch: 111, Loss: 13952.5684, Recall: 92.64%, Acc: 92.73% Test: 91.12%\n",
      "Epoch: 112, Loss: 13967.0283, Recall: 92.73%, Acc: 92.76% Test: 91.20%\n",
      "Epoch: 113, Loss: 13943.0059, Recall: 92.81%, Acc: 92.78% Test: 91.12%\n",
      "Epoch: 114, Loss: 13874.8262, Recall: 92.86%, Acc: 92.81% Test: 91.12%\n",
      "Epoch: 115, Loss: 13897.8125, Recall: 92.89%, Acc: 92.84% Test: 91.12%\n",
      "Epoch: 116, Loss: 13891.9346, Recall: 92.94%, Acc: 92.86% Test: 91.20%\n",
      "Epoch: 117, Loss: 13852.2793, Recall: 92.95%, Acc: 92.88% Test: 91.20%\n",
      "Epoch: 118, Loss: 13859.2773, Recall: 93.01%, Acc: 92.90% Test: 91.42%\n",
      "Epoch: 119, Loss: 13826.6484, Recall: 93.14%, Acc: 92.93% Test: 91.64%\n",
      "Epoch: 120, Loss: 13813.0342, Recall: 93.17%, Acc: 92.96% Test: 91.86%\n",
      "Epoch: 121, Loss: 13812.6543, Recall: 93.25%, Acc: 92.99% Test: 91.72%\n",
      "Epoch: 122, Loss: 13797.1016, Recall: 93.34%, Acc: 93.04% Test: 91.86%\n",
      "Epoch: 123, Loss: 13750.6914, Recall: 93.34%, Acc: 93.07% Test: 91.79%\n",
      "Epoch: 124, Loss: 13797.9980, Recall: 93.43%, Acc: 93.10% Test: 91.94%\n",
      "Epoch: 125, Loss: 13737.8701, Recall: 93.48%, Acc: 93.13% Test: 92.01%\n",
      "Epoch: 126, Loss: 13751.6514, Recall: 93.51%, Acc: 93.16% Test: 92.01%\n",
      "Epoch: 127, Loss: 13716.6641, Recall: 93.54%, Acc: 93.20% Test: 92.01%\n",
      "Epoch: 128, Loss: 13676.7168, Recall: 93.52%, Acc: 93.24% Test: 92.01%\n",
      "Epoch: 129, Loss: 13686.6621, Recall: 93.55%, Acc: 93.28% Test: 92.01%\n",
      "Epoch: 130, Loss: 13690.5742, Recall: 93.59%, Acc: 93.32% Test: 92.01%\n",
      "Epoch: 131, Loss: 13678.8418, Recall: 93.61%, Acc: 93.35% Test: 92.01%\n",
      "Epoch: 132, Loss: 13648.6934, Recall: 93.73%, Acc: 93.38% Test: 92.01%\n",
      "Epoch: 133, Loss: 13645.0156, Recall: 93.80%, Acc: 93.41% Test: 92.09%\n",
      "Epoch: 134, Loss: 13620.8887, Recall: 93.97%, Acc: 93.43% Test: 92.16%\n",
      "Epoch: 135, Loss: 13594.0977, Recall: 93.99%, Acc: 93.46% Test: 92.16%\n",
      "Epoch: 136, Loss: 13615.1641, Recall: 94.03%, Acc: 93.48% Test: 92.23%\n",
      "Epoch: 137, Loss: 13606.2539, Recall: 94.06%, Acc: 93.49% Test: 92.31%\n",
      "Epoch: 138, Loss: 13562.8564, Recall: 94.16%, Acc: 93.51% Test: 92.38%\n",
      "Epoch: 139, Loss: 13578.6582, Recall: 94.16%, Acc: 93.52% Test: 92.31%\n",
      "Epoch: 140, Loss: 13571.9678, Recall: 94.18%, Acc: 93.54% Test: 92.38%\n",
      "Epoch: 141, Loss: 13554.1357, Recall: 94.28%, Acc: 93.56% Test: 92.46%\n",
      "Epoch: 142, Loss: 13550.6895, Recall: 94.30%, Acc: 93.57% Test: 92.60%\n",
      "Epoch: 143, Loss: 13549.1602, Recall: 94.34%, Acc: 93.58% Test: 92.60%\n",
      "Epoch: 144, Loss: 13514.5430, Recall: 94.44%, Acc: 93.59% Test: 92.60%\n",
      "Epoch: 145, Loss: 13472.6641, Recall: 94.47%, Acc: 93.61% Test: 92.60%\n",
      "Epoch: 146, Loss: 13534.0996, Recall: 94.53%, Acc: 93.62% Test: 92.60%\n",
      "Epoch: 147, Loss: 13525.2207, Recall: 94.59%, Acc: 93.63% Test: 92.60%\n",
      "Epoch: 148, Loss: 13491.4111, Recall: 94.65%, Acc: 93.66% Test: 92.60%\n",
      "Epoch: 149, Loss: 13506.1621, Recall: 94.66%, Acc: 93.67% Test: 92.60%\n",
      "Epoch: 150, Loss: 13491.3770, Recall: 94.63%, Acc: 93.69% Test: 92.60%\n",
      "Epoch: 151, Loss: 13461.5488, Recall: 94.66%, Acc: 93.71% Test: 92.60%\n",
      "Epoch: 152, Loss: 13430.5566, Recall: 94.66%, Acc: 93.73% Test: 92.60%\n",
      "Epoch: 153, Loss: 13403.4219, Recall: 94.66%, Acc: 93.76% Test: 92.60%\n",
      "Epoch: 154, Loss: 13411.6318, Recall: 94.65%, Acc: 93.78% Test: 92.75%\n",
      "Epoch: 155, Loss: 13421.2334, Recall: 94.69%, Acc: 93.82% Test: 92.75%\n",
      "Epoch: 156, Loss: 13391.7539, Recall: 94.69%, Acc: 93.85% Test: 92.75%\n",
      "Epoch: 157, Loss: 13362.4902, Recall: 94.68%, Acc: 93.88% Test: 92.83%\n",
      "Epoch: 158, Loss: 13354.6855, Recall: 94.69%, Acc: 93.91% Test: 92.83%\n",
      "Epoch: 159, Loss: 13378.3574, Recall: 94.69%, Acc: 93.95% Test: 92.90%\n",
      "Epoch: 160, Loss: 13334.3389, Recall: 94.75%, Acc: 93.98% Test: 92.97%\n",
      "Epoch: 161, Loss: 13336.6523, Recall: 94.78%, Acc: 94.01% Test: 92.90%\n",
      "Epoch: 162, Loss: 13376.6953, Recall: 94.79%, Acc: 94.05% Test: 92.90%\n",
      "Epoch: 163, Loss: 13343.9092, Recall: 94.82%, Acc: 94.08% Test: 92.90%\n",
      "Epoch: 164, Loss: 13336.7822, Recall: 94.87%, Acc: 94.10% Test: 92.97%\n",
      "Epoch: 165, Loss: 13321.7490, Recall: 94.90%, Acc: 94.12% Test: 93.05%\n",
      "Epoch: 166, Loss: 13327.3105, Recall: 94.91%, Acc: 94.14% Test: 93.12%\n",
      "Epoch: 167, Loss: 13312.1260, Recall: 95.00%, Acc: 94.15% Test: 93.12%\n",
      "Epoch: 168, Loss: 13293.0273, Recall: 95.02%, Acc: 94.16% Test: 93.27%\n",
      "Epoch: 169, Loss: 13298.3125, Recall: 95.02%, Acc: 94.18% Test: 93.20%\n",
      "Epoch: 170, Loss: 13282.4590, Recall: 95.09%, Acc: 94.20% Test: 93.20%\n",
      "Epoch: 171, Loss: 13266.4688, Recall: 95.15%, Acc: 94.21% Test: 93.27%\n",
      "Epoch: 172, Loss: 13258.5469, Recall: 95.25%, Acc: 94.22% Test: 93.27%\n",
      "Epoch: 173, Loss: 13237.6895, Recall: 95.26%, Acc: 94.23% Test: 93.27%\n",
      "Epoch: 174, Loss: 13279.9600, Recall: 95.32%, Acc: 94.25% Test: 93.34%\n",
      "Epoch: 175, Loss: 13274.8242, Recall: 95.34%, Acc: 94.27% Test: 93.49%\n",
      "Epoch: 176, Loss: 13250.7773, Recall: 95.39%, Acc: 94.28% Test: 93.57%\n",
      "Epoch: 177, Loss: 13230.8145, Recall: 95.48%, Acc: 94.30% Test: 93.64%\n",
      "Epoch: 178, Loss: 13229.6973, Recall: 95.52%, Acc: 94.31% Test: 93.71%\n",
      "Epoch: 179, Loss: 13182.2412, Recall: 95.54%, Acc: 94.32% Test: 93.71%\n",
      "Epoch: 180, Loss: 13205.3164, Recall: 95.54%, Acc: 94.34% Test: 93.79%\n",
      "Epoch: 181, Loss: 13183.5117, Recall: 95.56%, Acc: 94.35% Test: 93.86%\n",
      "Epoch: 182, Loss: 13172.8320, Recall: 95.56%, Acc: 94.38% Test: 93.86%\n",
      "Epoch: 183, Loss: 13188.3379, Recall: 95.60%, Acc: 94.40% Test: 93.86%\n",
      "Epoch: 184, Loss: 13166.2598, Recall: 95.57%, Acc: 94.42% Test: 93.93%\n",
      "Epoch: 185, Loss: 13175.2227, Recall: 95.53%, Acc: 94.44% Test: 93.93%\n",
      "Epoch: 186, Loss: 13150.3906, Recall: 95.53%, Acc: 94.46% Test: 93.93%\n",
      "Epoch: 187, Loss: 13169.4336, Recall: 95.51%, Acc: 94.49% Test: 93.86%\n",
      "Epoch: 188, Loss: 13179.7520, Recall: 95.54%, Acc: 94.51% Test: 94.01%\n",
      "Epoch: 189, Loss: 13163.1680, Recall: 95.55%, Acc: 94.53% Test: 94.16%\n",
      "Epoch: 190, Loss: 13159.8057, Recall: 95.53%, Acc: 94.54% Test: 94.08%\n",
      "Epoch: 191, Loss: 13125.5410, Recall: 95.56%, Acc: 94.54% Test: 94.08%\n",
      "Epoch: 192, Loss: 13137.8682, Recall: 95.57%, Acc: 94.54% Test: 94.08%\n",
      "Epoch: 193, Loss: 13135.6797, Recall: 95.56%, Acc: 94.54% Test: 94.16%\n",
      "Epoch: 194, Loss: 13168.2637, Recall: 95.59%, Acc: 94.54% Test: 94.23%\n",
      "Epoch: 195, Loss: 13086.1543, Recall: 95.57%, Acc: 94.55% Test: 94.23%\n",
      "Epoch: 196, Loss: 13074.4229, Recall: 95.60%, Acc: 94.56% Test: 94.23%\n",
      "Epoch: 197, Loss: 13067.2754, Recall: 95.73%, Acc: 94.57% Test: 94.53%\n",
      "Epoch: 198, Loss: 13104.3633, Recall: 95.80%, Acc: 94.58% Test: 94.45%\n",
      "Epoch: 199, Loss: 13070.8984, Recall: 95.87%, Acc: 94.60% Test: 94.53%\n",
      "Epoch: 200, Loss: 13102.3691, Recall: 95.88%, Acc: 94.62% Test: 94.53%\n",
      "Epoch: 201, Loss: 13045.7266, Recall: 95.89%, Acc: 94.64% Test: 94.53%\n",
      "Epoch: 202, Loss: 13057.9121, Recall: 95.92%, Acc: 94.65% Test: 94.53%\n",
      "Epoch: 203, Loss: 13082.5273, Recall: 95.93%, Acc: 94.66% Test: 94.53%\n",
      "Epoch: 204, Loss: 13064.8135, Recall: 95.94%, Acc: 94.68% Test: 94.53%\n",
      "Epoch: 205, Loss: 13065.0322, Recall: 95.95%, Acc: 94.69% Test: 94.53%\n",
      "Epoch: 206, Loss: 13012.8223, Recall: 95.99%, Acc: 94.70% Test: 94.45%\n",
      "Epoch: 207, Loss: 13003.7051, Recall: 95.99%, Acc: 94.71% Test: 94.38%\n",
      "Epoch: 208, Loss: 13058.7129, Recall: 96.00%, Acc: 94.72% Test: 94.38%\n",
      "Epoch: 209, Loss: 13027.0801, Recall: 96.00%, Acc: 94.74% Test: 94.30%\n",
      "Epoch: 210, Loss: 13038.8535, Recall: 96.04%, Acc: 94.75% Test: 94.30%\n",
      "Epoch: 211, Loss: 12979.7266, Recall: 96.01%, Acc: 94.77% Test: 94.30%\n",
      "Epoch: 212, Loss: 13002.1777, Recall: 96.01%, Acc: 94.79% Test: 94.30%\n",
      "Epoch: 213, Loss: 13035.9492, Recall: 95.98%, Acc: 94.80% Test: 94.30%\n",
      "Epoch: 214, Loss: 13004.1445, Recall: 95.97%, Acc: 94.82% Test: 94.30%\n",
      "Epoch: 215, Loss: 12985.7402, Recall: 95.98%, Acc: 94.83% Test: 94.30%\n",
      "Epoch: 216, Loss: 13027.3281, Recall: 95.98%, Acc: 94.85% Test: 94.30%\n",
      "Epoch: 217, Loss: 12947.4023, Recall: 96.01%, Acc: 94.87% Test: 94.30%\n",
      "Epoch: 218, Loss: 13005.9658, Recall: 96.04%, Acc: 94.88% Test: 94.30%\n",
      "Epoch: 219, Loss: 12977.7676, Recall: 96.04%, Acc: 94.89% Test: 94.30%\n",
      "Epoch: 220, Loss: 12965.8262, Recall: 96.04%, Acc: 94.90% Test: 94.23%\n",
      "Epoch: 221, Loss: 12954.2334, Recall: 96.07%, Acc: 94.92% Test: 94.38%\n",
      "Epoch: 222, Loss: 12956.3848, Recall: 96.08%, Acc: 94.94% Test: 94.38%\n",
      "Epoch: 223, Loss: 12950.8682, Recall: 96.08%, Acc: 94.96% Test: 94.45%\n",
      "Epoch: 224, Loss: 12952.6426, Recall: 96.09%, Acc: 94.98% Test: 94.45%\n",
      "Epoch: 225, Loss: 12975.2646, Recall: 96.12%, Acc: 94.99% Test: 94.45%\n",
      "Epoch: 226, Loss: 12957.7422, Recall: 96.11%, Acc: 94.99% Test: 94.45%\n",
      "Epoch: 227, Loss: 12917.0117, Recall: 96.11%, Acc: 95.00% Test: 94.53%\n",
      "Epoch: 228, Loss: 12913.2139, Recall: 96.10%, Acc: 95.02% Test: 94.53%\n",
      "Epoch: 229, Loss: 12942.0664, Recall: 96.09%, Acc: 95.02% Test: 94.53%\n",
      "Epoch: 230, Loss: 12925.0811, Recall: 96.11%, Acc: 95.03% Test: 94.53%\n",
      "Epoch: 231, Loss: 12960.7578, Recall: 96.16%, Acc: 95.04% Test: 94.67%\n",
      "Epoch: 232, Loss: 12909.9727, Recall: 96.21%, Acc: 95.04% Test: 94.60%\n",
      "Epoch: 233, Loss: 12916.9844, Recall: 96.22%, Acc: 95.06% Test: 94.67%\n",
      "Epoch: 234, Loss: 12892.4053, Recall: 96.23%, Acc: 95.07% Test: 94.67%\n",
      "Epoch: 235, Loss: 12892.9023, Recall: 96.25%, Acc: 95.08% Test: 94.75%\n",
      "Epoch: 236, Loss: 12911.8057, Recall: 96.27%, Acc: 95.09% Test: 94.75%\n",
      "Epoch: 237, Loss: 12917.8330, Recall: 96.27%, Acc: 95.10% Test: 94.75%\n",
      "Epoch: 238, Loss: 12918.4189, Recall: 96.26%, Acc: 95.11% Test: 94.75%\n",
      "Epoch: 239, Loss: 12888.7637, Recall: 96.25%, Acc: 95.12% Test: 94.67%\n",
      "Epoch: 240, Loss: 12880.1953, Recall: 96.24%, Acc: 95.13% Test: 94.67%\n",
      "Epoch: 241, Loss: 12857.6738, Recall: 96.24%, Acc: 95.14% Test: 94.75%\n",
      "Epoch: 242, Loss: 12891.1660, Recall: 96.25%, Acc: 95.15% Test: 94.75%\n",
      "Epoch: 243, Loss: 12865.2129, Recall: 96.25%, Acc: 95.15% Test: 94.75%\n",
      "Epoch: 244, Loss: 12897.2412, Recall: 96.25%, Acc: 95.15% Test: 94.75%\n",
      "Epoch: 245, Loss: 12859.5078, Recall: 96.25%, Acc: 95.15% Test: 94.75%\n",
      "Epoch: 246, Loss: 12874.1973, Recall: 96.21%, Acc: 95.16% Test: 94.75%\n",
      "Epoch: 247, Loss: 12884.7676, Recall: 96.25%, Acc: 95.15% Test: 94.90%\n",
      "Epoch: 248, Loss: 12888.2891, Recall: 96.30%, Acc: 95.16% Test: 94.90%\n",
      "Epoch: 249, Loss: 12852.7852, Recall: 96.35%, Acc: 95.16% Test: 94.90%\n",
      "Epoch: 250, Loss: 12870.4482, Recall: 96.37%, Acc: 95.17% Test: 94.97%\n",
      "Epoch: 251, Loss: 12846.8730, Recall: 96.38%, Acc: 95.18% Test: 95.04%\n",
      "Epoch: 252, Loss: 12860.0059, Recall: 96.40%, Acc: 95.17% Test: 95.04%\n",
      "Epoch: 253, Loss: 12852.6582, Recall: 96.45%, Acc: 95.17% Test: 95.12%\n",
      "Epoch: 254, Loss: 12854.2441, Recall: 96.45%, Acc: 95.17% Test: 95.12%\n",
      "Epoch: 255, Loss: 12838.6826, Recall: 96.44%, Acc: 95.17% Test: 95.04%\n",
      "Epoch: 256, Loss: 12812.5801, Recall: 96.48%, Acc: 95.17% Test: 95.04%\n",
      "Epoch: 257, Loss: 12844.3496, Recall: 96.49%, Acc: 95.18% Test: 95.04%\n",
      "Epoch: 258, Loss: 12832.1367, Recall: 96.50%, Acc: 95.18% Test: 94.97%\n",
      "Epoch: 259, Loss: 12838.3457, Recall: 96.50%, Acc: 95.17% Test: 94.90%\n",
      "Epoch: 260, Loss: 12840.7188, Recall: 96.50%, Acc: 95.17% Test: 94.97%\n",
      "Epoch: 261, Loss: 12812.0332, Recall: 96.48%, Acc: 95.17% Test: 94.97%\n",
      "Epoch: 262, Loss: 12821.2480, Recall: 96.49%, Acc: 95.16% Test: 94.97%\n",
      "Epoch: 263, Loss: 12818.8643, Recall: 96.50%, Acc: 95.17% Test: 94.97%\n",
      "Epoch: 264, Loss: 12833.7168, Recall: 96.47%, Acc: 95.18% Test: 94.97%\n",
      "Epoch: 265, Loss: 12811.2773, Recall: 96.44%, Acc: 95.18% Test: 94.90%\n",
      "Epoch: 266, Loss: 12804.9775, Recall: 96.45%, Acc: 95.19% Test: 94.90%\n",
      "Epoch: 267, Loss: 12791.6348, Recall: 96.45%, Acc: 95.20% Test: 94.90%\n",
      "Epoch: 268, Loss: 12822.5889, Recall: 96.45%, Acc: 95.21% Test: 94.90%\n",
      "Epoch: 269, Loss: 12774.0762, Recall: 96.44%, Acc: 95.22% Test: 94.97%\n",
      "Epoch: 270, Loss: 12767.9043, Recall: 96.46%, Acc: 95.24% Test: 94.97%\n",
      "Epoch: 271, Loss: 12742.6406, Recall: 96.45%, Acc: 95.26% Test: 95.04%\n",
      "Epoch: 272, Loss: 12797.0645, Recall: 96.47%, Acc: 95.28% Test: 95.04%\n",
      "Epoch: 273, Loss: 12765.7910, Recall: 96.47%, Acc: 95.29% Test: 95.04%\n",
      "Epoch: 274, Loss: 12792.9746, Recall: 96.46%, Acc: 95.31% Test: 95.04%\n",
      "Epoch: 275, Loss: 12790.8838, Recall: 96.48%, Acc: 95.31% Test: 94.97%\n",
      "Epoch: 276, Loss: 12802.2422, Recall: 96.50%, Acc: 95.32% Test: 94.97%\n",
      "Epoch: 277, Loss: 12774.2168, Recall: 96.51%, Acc: 95.33% Test: 95.04%\n",
      "Epoch: 278, Loss: 12761.9756, Recall: 96.51%, Acc: 95.34% Test: 94.97%\n",
      "Epoch: 279, Loss: 12784.8213, Recall: 96.52%, Acc: 95.35% Test: 94.97%\n",
      "Epoch: 280, Loss: 12779.0762, Recall: 96.54%, Acc: 95.35% Test: 94.97%\n",
      "Epoch: 281, Loss: 12768.0312, Recall: 96.55%, Acc: 95.36% Test: 94.97%\n",
      "Epoch: 282, Loss: 12772.9053, Recall: 96.55%, Acc: 95.36% Test: 95.04%\n",
      "Epoch: 283, Loss: 12756.1436, Recall: 96.56%, Acc: 95.37% Test: 95.04%\n",
      "Epoch: 284, Loss: 12754.3223, Recall: 96.56%, Acc: 95.37% Test: 95.04%\n",
      "Epoch: 285, Loss: 12723.0586, Recall: 96.57%, Acc: 95.38% Test: 95.04%\n",
      "Epoch: 286, Loss: 12754.7988, Recall: 96.56%, Acc: 95.39% Test: 94.97%\n",
      "Epoch: 287, Loss: 12728.4473, Recall: 96.55%, Acc: 95.40% Test: 94.97%\n",
      "Epoch: 288, Loss: 12751.7051, Recall: 96.55%, Acc: 95.41% Test: 94.97%\n",
      "Epoch: 289, Loss: 12746.5430, Recall: 96.55%, Acc: 95.41% Test: 94.97%\n",
      "Epoch: 290, Loss: 12726.5820, Recall: 96.55%, Acc: 95.41% Test: 94.97%\n",
      "Epoch: 291, Loss: 12725.2930, Recall: 96.52%, Acc: 95.41% Test: 94.97%\n",
      "Epoch: 292, Loss: 12751.1143, Recall: 96.55%, Acc: 95.40% Test: 94.97%\n",
      "Epoch: 293, Loss: 12733.9414, Recall: 96.55%, Acc: 95.40% Test: 94.97%\n",
      "Epoch: 294, Loss: 12744.5615, Recall: 96.56%, Acc: 95.41% Test: 94.97%\n",
      "Epoch: 295, Loss: 12729.0156, Recall: 96.56%, Acc: 95.41% Test: 94.97%\n",
      "Epoch: 296, Loss: 12672.6641, Recall: 96.56%, Acc: 95.42% Test: 94.97%\n",
      "Epoch: 297, Loss: 12717.2705, Recall: 96.54%, Acc: 95.44% Test: 94.97%\n",
      "Epoch: 298, Loss: 12717.9629, Recall: 96.54%, Acc: 95.46% Test: 94.97%\n",
      "Epoch: 299, Loss: 12746.9258, Recall: 96.54%, Acc: 95.47% Test: 94.97%\n",
      "Epoch: 300, Loss: 12745.7734, Recall: 96.55%, Acc: 95.50% Test: 94.97%\n",
      "Epoch: 301, Loss: 12727.0830, Recall: 96.56%, Acc: 95.52% Test: 94.97%\n",
      "Epoch: 302, Loss: 12706.9844, Recall: 96.56%, Acc: 95.55% Test: 94.97%\n",
      "Epoch: 303, Loss: 12749.9092, Recall: 96.55%, Acc: 95.56% Test: 95.04%\n",
      "Epoch: 304, Loss: 12726.8721, Recall: 96.52%, Acc: 95.58% Test: 95.04%\n",
      "Epoch: 305, Loss: 12700.3281, Recall: 96.53%, Acc: 95.59% Test: 94.97%\n",
      "Epoch: 306, Loss: 12719.5723, Recall: 96.53%, Acc: 95.59% Test: 95.04%\n",
      "Epoch: 307, Loss: 12683.0508, Recall: 96.53%, Acc: 95.59% Test: 95.12%\n",
      "Epoch: 308, Loss: 12657.4395, Recall: 96.54%, Acc: 95.60% Test: 95.12%\n",
      "Epoch: 309, Loss: 12678.6553, Recall: 96.57%, Acc: 95.61% Test: 95.12%\n",
      "Epoch: 310, Loss: 12661.6367, Recall: 96.60%, Acc: 95.62% Test: 95.12%\n",
      "Epoch: 311, Loss: 12709.1895, Recall: 96.66%, Acc: 95.63% Test: 95.19%\n",
      "Epoch: 312, Loss: 12687.3877, Recall: 96.66%, Acc: 95.64% Test: 95.19%\n",
      "Epoch: 313, Loss: 12625.8965, Recall: 96.66%, Acc: 95.64% Test: 95.19%\n",
      "Epoch: 314, Loss: 12682.1230, Recall: 96.63%, Acc: 95.65% Test: 95.19%\n",
      "Epoch: 315, Loss: 12696.2012, Recall: 96.64%, Acc: 95.66% Test: 95.19%\n",
      "Epoch: 316, Loss: 12687.5527, Recall: 96.64%, Acc: 95.66% Test: 95.12%\n",
      "Epoch: 317, Loss: 12665.2598, Recall: 96.62%, Acc: 95.66% Test: 95.12%\n",
      "Epoch: 318, Loss: 12700.7979, Recall: 96.62%, Acc: 95.65% Test: 95.12%\n",
      "Epoch: 319, Loss: 12651.6934, Recall: 96.64%, Acc: 95.64% Test: 95.04%\n",
      "Epoch: 320, Loss: 12626.2285, Recall: 96.64%, Acc: 95.63% Test: 94.97%\n",
      "Epoch: 321, Loss: 12650.8594, Recall: 96.64%, Acc: 95.63% Test: 94.97%\n",
      "Epoch: 322, Loss: 12678.8525, Recall: 96.62%, Acc: 95.63% Test: 94.90%\n",
      "Epoch: 323, Loss: 12650.0449, Recall: 96.63%, Acc: 95.63% Test: 94.90%\n",
      "Epoch: 324, Loss: 12675.7568, Recall: 96.62%, Acc: 95.64% Test: 94.90%\n",
      "Epoch: 325, Loss: 12631.0264, Recall: 96.58%, Acc: 95.64% Test: 95.04%\n",
      "Epoch: 326, Loss: 12657.5986, Recall: 96.59%, Acc: 95.66% Test: 94.97%\n",
      "Epoch: 327, Loss: 12653.4531, Recall: 96.61%, Acc: 95.68% Test: 94.97%\n",
      "Epoch: 328, Loss: 12645.3398, Recall: 96.73%, Acc: 95.69% Test: 95.04%\n",
      "Epoch: 329, Loss: 12617.5889, Recall: 96.76%, Acc: 95.71% Test: 94.97%\n",
      "Epoch: 330, Loss: 12630.6660, Recall: 96.75%, Acc: 95.72% Test: 95.04%\n",
      "Epoch: 331, Loss: 12648.0059, Recall: 96.78%, Acc: 95.72% Test: 95.19%\n",
      "Epoch: 332, Loss: 12652.4414, Recall: 96.79%, Acc: 95.72% Test: 95.19%\n",
      "Epoch: 333, Loss: 12626.3848, Recall: 96.80%, Acc: 95.72% Test: 95.12%\n",
      "Epoch: 334, Loss: 12620.4121, Recall: 96.82%, Acc: 95.72% Test: 95.12%\n",
      "Epoch: 335, Loss: 12617.9590, Recall: 96.80%, Acc: 95.72% Test: 95.12%\n",
      "Epoch: 336, Loss: 12623.9297, Recall: 96.84%, Acc: 95.72% Test: 95.19%\n",
      "Epoch: 337, Loss: 12633.1914, Recall: 96.84%, Acc: 95.71% Test: 95.19%\n",
      "Epoch: 338, Loss: 12628.6250, Recall: 96.90%, Acc: 95.70% Test: 95.49%\n",
      "Epoch: 339, Loss: 12639.6416, Recall: 96.92%, Acc: 95.70% Test: 95.56%\n",
      "Epoch: 340, Loss: 12592.7021, Recall: 96.87%, Acc: 95.70% Test: 95.64%\n",
      "Epoch: 341, Loss: 12604.5137, Recall: 96.87%, Acc: 95.70% Test: 95.56%\n",
      "Epoch: 342, Loss: 12624.7012, Recall: 96.87%, Acc: 95.71% Test: 95.49%\n",
      "Epoch: 343, Loss: 12635.8008, Recall: 96.87%, Acc: 95.72% Test: 95.49%\n",
      "Epoch: 344, Loss: 12576.7773, Recall: 96.87%, Acc: 95.72% Test: 95.49%\n",
      "Epoch: 345, Loss: 12590.4395, Recall: 96.88%, Acc: 95.74% Test: 95.49%\n",
      "Epoch: 346, Loss: 12597.5547, Recall: 96.91%, Acc: 95.75% Test: 95.49%\n",
      "Epoch: 347, Loss: 12580.2051, Recall: 96.91%, Acc: 95.76% Test: 95.49%\n",
      "Epoch: 348, Loss: 12581.6113, Recall: 96.90%, Acc: 95.76% Test: 95.49%\n",
      "Epoch: 349, Loss: 12603.6035, Recall: 96.91%, Acc: 95.76% Test: 95.49%\n",
      "Epoch: 350, Loss: 12593.9707, Recall: 96.95%, Acc: 95.76% Test: 95.49%\n",
      "Epoch: 351, Loss: 12620.9414, Recall: 97.02%, Acc: 95.77% Test: 95.49%\n",
      "Epoch: 352, Loss: 12558.8877, Recall: 97.02%, Acc: 95.77% Test: 95.49%\n",
      "Epoch: 353, Loss: 12561.8691, Recall: 97.02%, Acc: 95.78% Test: 95.49%\n",
      "Epoch: 354, Loss: 12592.3652, Recall: 97.03%, Acc: 95.78% Test: 95.49%\n",
      "Epoch: 355, Loss: 12570.7529, Recall: 97.02%, Acc: 95.79% Test: 95.56%\n",
      "Epoch: 356, Loss: 12596.6982, Recall: 97.02%, Acc: 95.79% Test: 95.56%\n",
      "Epoch: 357, Loss: 12575.9785, Recall: 97.01%, Acc: 95.79% Test: 95.49%\n",
      "Epoch: 358, Loss: 12567.1973, Recall: 97.01%, Acc: 95.80% Test: 95.49%\n",
      "Epoch: 359, Loss: 12561.3281, Recall: 97.02%, Acc: 95.80% Test: 95.49%\n",
      "Epoch: 360, Loss: 12562.8926, Recall: 97.03%, Acc: 95.81% Test: 95.49%\n",
      "Epoch: 361, Loss: 12520.1768, Recall: 97.03%, Acc: 95.82% Test: 95.41%\n",
      "Epoch: 362, Loss: 12573.9893, Recall: 97.02%, Acc: 95.83% Test: 95.49%\n",
      "Epoch: 363, Loss: 12578.1445, Recall: 97.03%, Acc: 95.83% Test: 95.41%\n",
      "Epoch: 364, Loss: 12505.0879, Recall: 97.05%, Acc: 95.84% Test: 95.41%\n",
      "Epoch: 365, Loss: 12559.1250, Recall: 97.04%, Acc: 95.85% Test: 95.41%\n",
      "Epoch: 366, Loss: 12503.6104, Recall: 97.04%, Acc: 95.86% Test: 95.41%\n",
      "Epoch: 367, Loss: 12545.4707, Recall: 97.02%, Acc: 95.87% Test: 95.34%\n",
      "Epoch: 368, Loss: 12543.4004, Recall: 96.99%, Acc: 95.88% Test: 95.34%\n",
      "Epoch: 369, Loss: 12565.4668, Recall: 96.99%, Acc: 95.88% Test: 95.34%\n",
      "Epoch: 370, Loss: 12527.6133, Recall: 96.99%, Acc: 95.89% Test: 95.41%\n",
      "Epoch: 371, Loss: 12556.1211, Recall: 97.00%, Acc: 95.89% Test: 95.41%\n",
      "Epoch: 372, Loss: 12522.6162, Recall: 96.98%, Acc: 95.89% Test: 95.41%\n",
      "Epoch: 373, Loss: 12520.9326, Recall: 96.98%, Acc: 95.90% Test: 95.49%\n",
      "Epoch: 374, Loss: 12512.9131, Recall: 96.99%, Acc: 95.90% Test: 95.49%\n",
      "Epoch: 375, Loss: 12524.6973, Recall: 97.00%, Acc: 95.90% Test: 95.49%\n",
      "Epoch: 376, Loss: 12540.3125, Recall: 97.05%, Acc: 95.89% Test: 95.41%\n",
      "Epoch: 377, Loss: 12517.6025, Recall: 97.10%, Acc: 95.89% Test: 95.49%\n",
      "Epoch: 378, Loss: 12500.5000, Recall: 97.11%, Acc: 95.88% Test: 95.49%\n",
      "Epoch: 379, Loss: 12537.8672, Recall: 97.13%, Acc: 95.87% Test: 95.49%\n",
      "Epoch: 380, Loss: 12503.7168, Recall: 97.13%, Acc: 95.87% Test: 95.41%\n",
      "Epoch: 381, Loss: 12528.2266, Recall: 97.13%, Acc: 95.87% Test: 95.41%\n",
      "Epoch: 382, Loss: 12490.8818, Recall: 97.15%, Acc: 95.87% Test: 95.56%\n",
      "Epoch: 383, Loss: 12529.2969, Recall: 97.13%, Acc: 95.86% Test: 95.49%\n",
      "Epoch: 384, Loss: 12480.3174, Recall: 97.12%, Acc: 95.86% Test: 95.49%\n",
      "Epoch: 385, Loss: 12525.3301, Recall: 97.12%, Acc: 95.87% Test: 95.49%\n",
      "Epoch: 386, Loss: 12487.4258, Recall: 97.12%, Acc: 95.87% Test: 95.56%\n",
      "Epoch: 387, Loss: 12521.0469, Recall: 97.11%, Acc: 95.88% Test: 95.64%\n",
      "Epoch: 388, Loss: 12489.7715, Recall: 97.12%, Acc: 95.89% Test: 95.64%\n",
      "Epoch: 389, Loss: 12525.9941, Recall: 97.12%, Acc: 95.91% Test: 95.64%\n",
      "Epoch: 390, Loss: 12531.8340, Recall: 97.11%, Acc: 95.92% Test: 95.64%\n",
      "Epoch: 391, Loss: 12469.9492, Recall: 97.11%, Acc: 95.93% Test: 95.71%\n",
      "Epoch: 392, Loss: 12546.7227, Recall: 97.13%, Acc: 95.94% Test: 95.71%\n",
      "Epoch: 393, Loss: 12466.8428, Recall: 97.13%, Acc: 95.96% Test: 95.71%\n",
      "Epoch: 394, Loss: 12512.4629, Recall: 97.13%, Acc: 95.97% Test: 95.78%\n",
      "Epoch: 395, Loss: 12494.5898, Recall: 97.13%, Acc: 95.97% Test: 95.78%\n",
      "Epoch: 396, Loss: 12463.5234, Recall: 97.14%, Acc: 95.98% Test: 95.78%\n",
      "Epoch: 397, Loss: 12481.7588, Recall: 97.16%, Acc: 95.99% Test: 95.78%\n",
      "Epoch: 398, Loss: 12501.8926, Recall: 97.16%, Acc: 95.99% Test: 95.78%\n",
      "Epoch: 399, Loss: 12490.5713, Recall: 97.15%, Acc: 95.98% Test: 95.78%\n",
      "Epoch: 400, Loss: 12531.0879, Recall: 97.15%, Acc: 95.98% Test: 95.78%\n",
      "Epoch: 401, Loss: 12507.5420, Recall: 97.17%, Acc: 95.98% Test: 95.78%\n",
      "Epoch: 402, Loss: 12487.1787, Recall: 97.16%, Acc: 95.98% Test: 95.71%\n",
      "Epoch: 403, Loss: 12493.5781, Recall: 97.16%, Acc: 95.97% Test: 95.71%\n",
      "Epoch: 404, Loss: 12533.2832, Recall: 97.16%, Acc: 95.96% Test: 95.78%\n",
      "Epoch: 405, Loss: 12464.3828, Recall: 97.16%, Acc: 95.95% Test: 95.78%\n",
      "Epoch: 406, Loss: 12475.7012, Recall: 97.18%, Acc: 95.95% Test: 95.78%\n",
      "Epoch: 407, Loss: 12488.3516, Recall: 97.17%, Acc: 95.95% Test: 95.71%\n",
      "Epoch: 408, Loss: 12479.9346, Recall: 97.17%, Acc: 95.95% Test: 95.56%\n",
      "Epoch: 409, Loss: 12523.0605, Recall: 97.19%, Acc: 95.96% Test: 95.56%\n",
      "Epoch: 410, Loss: 12499.6250, Recall: 97.19%, Acc: 95.96% Test: 95.56%\n",
      "Epoch: 411, Loss: 12489.3506, Recall: 97.21%, Acc: 95.96% Test: 95.56%\n",
      "Epoch: 412, Loss: 12527.5967, Recall: 97.21%, Acc: 95.96% Test: 95.56%\n",
      "Epoch: 413, Loss: 12497.5928, Recall: 97.19%, Acc: 95.95% Test: 95.56%\n",
      "Epoch: 414, Loss: 12454.8301, Recall: 97.19%, Acc: 95.94% Test: 95.41%\n",
      "Epoch: 415, Loss: 12438.1182, Recall: 97.18%, Acc: 95.94% Test: 95.56%\n",
      "Epoch: 416, Loss: 12441.8887, Recall: 97.21%, Acc: 95.94% Test: 95.64%\n",
      "Epoch: 417, Loss: 12481.2666, Recall: 97.21%, Acc: 95.94% Test: 95.64%\n",
      "Epoch: 418, Loss: 12463.2334, Recall: 97.23%, Acc: 95.95% Test: 95.71%\n",
      "Epoch: 419, Loss: 12479.6562, Recall: 97.24%, Acc: 95.96% Test: 95.86%\n",
      "Epoch: 420, Loss: 12459.5176, Recall: 97.24%, Acc: 95.96% Test: 95.86%\n",
      "Epoch: 421, Loss: 12496.3135, Recall: 97.24%, Acc: 95.97% Test: 95.86%\n",
      "Epoch: 422, Loss: 12428.3994, Recall: 97.24%, Acc: 95.98% Test: 95.86%\n",
      "Epoch: 423, Loss: 12497.9551, Recall: 97.23%, Acc: 95.99% Test: 95.86%\n",
      "Epoch: 424, Loss: 12458.7725, Recall: 97.24%, Acc: 96.00% Test: 95.93%\n",
      "Epoch: 425, Loss: 12471.8975, Recall: 97.23%, Acc: 96.02% Test: 95.93%\n",
      "Epoch: 426, Loss: 12455.5127, Recall: 97.24%, Acc: 96.03% Test: 95.86%\n",
      "Epoch: 427, Loss: 12454.5020, Recall: 97.26%, Acc: 96.05% Test: 95.86%\n",
      "Epoch: 428, Loss: 12457.9473, Recall: 97.25%, Acc: 96.07% Test: 95.78%\n",
      "Epoch: 429, Loss: 12464.5078, Recall: 97.26%, Acc: 96.08% Test: 95.78%\n",
      "Epoch: 430, Loss: 12459.8867, Recall: 97.24%, Acc: 96.10% Test: 95.86%\n",
      "Epoch: 431, Loss: 12474.7500, Recall: 97.24%, Acc: 96.11% Test: 95.86%\n",
      "Epoch: 432, Loss: 12511.0859, Recall: 97.23%, Acc: 96.12% Test: 95.86%\n",
      "Epoch: 433, Loss: 12426.7852, Recall: 97.19%, Acc: 96.13% Test: 95.71%\n",
      "Epoch: 434, Loss: 12468.5498, Recall: 97.20%, Acc: 96.13% Test: 95.64%\n",
      "Epoch: 435, Loss: 12441.4238, Recall: 97.19%, Acc: 96.13% Test: 95.64%\n",
      "Epoch: 436, Loss: 12445.7129, Recall: 97.21%, Acc: 96.13% Test: 95.64%\n",
      "Epoch: 437, Loss: 12420.1504, Recall: 97.23%, Acc: 96.13% Test: 95.64%\n",
      "Epoch: 438, Loss: 12460.1855, Recall: 97.24%, Acc: 96.13% Test: 95.64%\n",
      "Epoch: 439, Loss: 12457.5215, Recall: 97.24%, Acc: 96.13% Test: 95.64%\n",
      "Epoch: 440, Loss: 12439.3418, Recall: 97.27%, Acc: 96.12% Test: 95.56%\n",
      "Epoch: 441, Loss: 12419.8242, Recall: 97.28%, Acc: 96.12% Test: 95.56%\n",
      "Epoch: 442, Loss: 12438.4951, Recall: 97.28%, Acc: 96.11% Test: 95.56%\n",
      "Epoch: 443, Loss: 12425.3379, Recall: 97.29%, Acc: 96.11% Test: 95.56%\n",
      "Epoch: 444, Loss: 12443.2920, Recall: 97.31%, Acc: 96.11% Test: 95.49%\n",
      "Epoch: 445, Loss: 12441.0215, Recall: 97.32%, Acc: 96.10% Test: 95.49%\n",
      "Epoch: 446, Loss: 12454.0508, Recall: 97.33%, Acc: 96.09% Test: 95.56%\n",
      "Epoch: 447, Loss: 12457.7988, Recall: 97.33%, Acc: 96.09% Test: 95.64%\n",
      "Epoch: 448, Loss: 12436.0117, Recall: 97.34%, Acc: 96.10% Test: 95.78%\n",
      "Epoch: 449, Loss: 12402.0566, Recall: 97.35%, Acc: 96.11% Test: 95.78%\n",
      "Epoch: 450, Loss: 12428.4492, Recall: 97.34%, Acc: 96.11% Test: 95.86%\n",
      "Epoch: 451, Loss: 12393.4209, Recall: 97.32%, Acc: 96.12% Test: 95.78%\n",
      "Epoch: 452, Loss: 12380.9082, Recall: 97.32%, Acc: 96.13% Test: 95.71%\n",
      "Epoch: 453, Loss: 12434.7754, Recall: 97.32%, Acc: 96.13% Test: 95.71%\n",
      "Epoch: 454, Loss: 12409.0303, Recall: 97.33%, Acc: 96.14% Test: 95.71%\n",
      "Epoch: 455, Loss: 12391.2461, Recall: 97.34%, Acc: 96.14% Test: 95.78%\n",
      "Epoch: 456, Loss: 12401.6592, Recall: 97.36%, Acc: 96.16% Test: 95.71%\n",
      "Epoch: 457, Loss: 12423.1523, Recall: 97.36%, Acc: 96.17% Test: 95.71%\n",
      "Epoch: 458, Loss: 12435.1787, Recall: 97.34%, Acc: 96.17% Test: 95.78%\n",
      "Epoch: 459, Loss: 12413.8760, Recall: 97.35%, Acc: 96.18% Test: 95.78%\n",
      "Epoch: 460, Loss: 12396.7227, Recall: 97.34%, Acc: 96.18% Test: 95.86%\n",
      "Epoch: 461, Loss: 12446.7168, Recall: 97.33%, Acc: 96.19% Test: 95.78%\n",
      "Epoch: 462, Loss: 12404.0098, Recall: 97.35%, Acc: 96.19% Test: 95.86%\n",
      "Epoch: 463, Loss: 12407.3115, Recall: 97.34%, Acc: 96.18% Test: 95.86%\n",
      "Epoch: 464, Loss: 12405.6406, Recall: 97.34%, Acc: 96.18% Test: 95.93%\n",
      "Epoch: 465, Loss: 12410.5654, Recall: 97.34%, Acc: 96.18% Test: 95.93%\n",
      "Epoch: 466, Loss: 12394.5098, Recall: 97.36%, Acc: 96.17% Test: 95.93%\n",
      "Epoch: 467, Loss: 12390.4082, Recall: 97.36%, Acc: 96.17% Test: 95.86%\n",
      "Epoch: 468, Loss: 12378.3604, Recall: 97.36%, Acc: 96.16% Test: 95.78%\n",
      "Epoch: 469, Loss: 12396.6777, Recall: 97.40%, Acc: 96.16% Test: 95.71%\n",
      "Epoch: 470, Loss: 12373.2500, Recall: 97.41%, Acc: 96.16% Test: 95.71%\n",
      "Epoch: 471, Loss: 12405.8857, Recall: 97.41%, Acc: 96.16% Test: 95.71%\n",
      "Epoch: 472, Loss: 12380.6758, Recall: 97.39%, Acc: 96.16% Test: 95.71%\n",
      "Epoch: 473, Loss: 12364.3613, Recall: 97.41%, Acc: 96.16% Test: 95.71%\n",
      "Epoch: 474, Loss: 12391.6797, Recall: 97.42%, Acc: 96.16% Test: 95.71%\n",
      "Epoch: 475, Loss: 12377.9688, Recall: 97.41%, Acc: 96.16% Test: 95.71%\n",
      "Epoch: 476, Loss: 12382.1797, Recall: 97.40%, Acc: 96.16% Test: 95.64%\n",
      "Epoch: 477, Loss: 12346.9844, Recall: 97.40%, Acc: 96.16% Test: 95.64%\n",
      "Epoch: 478, Loss: 12377.9473, Recall: 97.39%, Acc: 96.16% Test: 95.71%\n",
      "Epoch: 479, Loss: 12365.5332, Recall: 97.38%, Acc: 96.16% Test: 95.64%\n",
      "Epoch: 480, Loss: 12375.8652, Recall: 97.41%, Acc: 96.16% Test: 95.71%\n",
      "Epoch: 481, Loss: 12361.7070, Recall: 97.43%, Acc: 96.16% Test: 95.78%\n",
      "Epoch: 482, Loss: 12429.2402, Recall: 97.44%, Acc: 96.16% Test: 95.78%\n",
      "Epoch: 483, Loss: 12371.1436, Recall: 97.45%, Acc: 96.17% Test: 95.78%\n",
      "Epoch: 484, Loss: 12377.6670, Recall: 97.46%, Acc: 96.17% Test: 95.71%\n",
      "Epoch: 485, Loss: 12400.8418, Recall: 97.44%, Acc: 96.18% Test: 95.64%\n",
      "Epoch: 486, Loss: 12384.7988, Recall: 97.44%, Acc: 96.18% Test: 95.64%\n",
      "Epoch: 487, Loss: 12392.0254, Recall: 97.41%, Acc: 96.20% Test: 95.64%\n",
      "Epoch: 488, Loss: 12399.7891, Recall: 97.40%, Acc: 96.20% Test: 95.86%\n",
      "Epoch: 489, Loss: 12389.5625, Recall: 97.43%, Acc: 96.21% Test: 95.86%\n",
      "Epoch: 490, Loss: 12399.3203, Recall: 97.41%, Acc: 96.22% Test: 95.86%\n",
      "Epoch: 491, Loss: 12358.3320, Recall: 97.39%, Acc: 96.24% Test: 95.86%\n",
      "Epoch: 492, Loss: 12359.3486, Recall: 97.37%, Acc: 96.25% Test: 95.78%\n",
      "Epoch: 493, Loss: 12355.5527, Recall: 97.37%, Acc: 96.26% Test: 95.78%\n",
      "Epoch: 494, Loss: 12380.4395, Recall: 97.38%, Acc: 96.27% Test: 95.78%\n",
      "Epoch: 495, Loss: 12369.4180, Recall: 97.39%, Acc: 96.27% Test: 95.71%\n",
      "Epoch: 496, Loss: 12363.4609, Recall: 97.39%, Acc: 96.27% Test: 95.71%\n",
      "Epoch: 497, Loss: 12373.5410, Recall: 97.41%, Acc: 96.27% Test: 95.71%\n",
      "Epoch: 498, Loss: 12360.8496, Recall: 97.40%, Acc: 96.26% Test: 95.64%\n",
      "Epoch: 499, Loss: 12371.4336, Recall: 97.39%, Acc: 96.26% Test: 95.64%\n",
      "Epoch: 500, Loss: 12385.9512, Recall: 97.37%, Acc: 96.25% Test: 95.64%\n",
      "Epoch: 501, Loss: 12353.6562, Recall: 97.37%, Acc: 96.25% Test: 95.64%\n",
      "Epoch: 502, Loss: 12357.6982, Recall: 97.38%, Acc: 96.24% Test: 95.56%\n",
      "Epoch: 503, Loss: 12361.3740, Recall: 97.38%, Acc: 96.24% Test: 95.56%\n",
      "Epoch: 504, Loss: 12354.5332, Recall: 97.38%, Acc: 96.24% Test: 95.56%\n",
      "Epoch: 505, Loss: 12400.1191, Recall: 97.38%, Acc: 96.23% Test: 95.64%\n",
      "Epoch: 506, Loss: 12325.2383, Recall: 97.38%, Acc: 96.23% Test: 95.64%\n",
      "Epoch: 507, Loss: 12376.0781, Recall: 97.38%, Acc: 96.23% Test: 95.64%\n",
      "Epoch: 508, Loss: 12359.6914, Recall: 97.39%, Acc: 96.24% Test: 95.56%\n",
      "Epoch: 509, Loss: 12347.5801, Recall: 97.39%, Acc: 96.26% Test: 95.49%\n",
      "Epoch: 510, Loss: 12339.2920, Recall: 97.40%, Acc: 96.27% Test: 95.49%\n",
      "Epoch: 511, Loss: 12361.8828, Recall: 97.40%, Acc: 96.28% Test: 95.56%\n",
      "Epoch: 512, Loss: 12328.9590, Recall: 97.38%, Acc: 96.28% Test: 95.56%\n",
      "Epoch: 513, Loss: 12353.1152, Recall: 97.38%, Acc: 96.29% Test: 95.56%\n",
      "Epoch: 514, Loss: 12364.1221, Recall: 97.39%, Acc: 96.30% Test: 95.56%\n",
      "Epoch: 515, Loss: 12315.5352, Recall: 97.39%, Acc: 96.31% Test: 95.56%\n",
      "Epoch: 516, Loss: 12344.0098, Recall: 97.40%, Acc: 96.32% Test: 95.56%\n",
      "Epoch: 517, Loss: 12358.4414, Recall: 97.40%, Acc: 96.32% Test: 95.64%\n",
      "Epoch: 518, Loss: 12347.8896, Recall: 97.41%, Acc: 96.32% Test: 95.64%\n",
      "Epoch: 519, Loss: 12341.0518, Recall: 97.43%, Acc: 96.32% Test: 95.64%\n",
      "Epoch: 520, Loss: 12367.3066, Recall: 97.41%, Acc: 96.31% Test: 95.64%\n",
      "Epoch: 521, Loss: 12376.5166, Recall: 97.41%, Acc: 96.30% Test: 95.71%\n",
      "Epoch: 522, Loss: 12335.8438, Recall: 97.41%, Acc: 96.30% Test: 95.71%\n",
      "Epoch: 523, Loss: 12363.8154, Recall: 97.42%, Acc: 96.30% Test: 95.71%\n",
      "Epoch: 524, Loss: 12328.1709, Recall: 97.41%, Acc: 96.30% Test: 95.71%\n",
      "Epoch: 525, Loss: 12351.5381, Recall: 97.40%, Acc: 96.30% Test: 95.71%\n",
      "Epoch: 526, Loss: 12341.8799, Recall: 97.42%, Acc: 96.31% Test: 95.71%\n",
      "Epoch: 527, Loss: 12354.7783, Recall: 97.44%, Acc: 96.32% Test: 95.71%\n",
      "Epoch: 528, Loss: 12325.6895, Recall: 97.51%, Acc: 96.32% Test: 95.78%\n",
      "Epoch: 529, Loss: 12347.3193, Recall: 97.50%, Acc: 96.32% Test: 95.71%\n",
      "Epoch: 530, Loss: 12312.2695, Recall: 97.51%, Acc: 96.33% Test: 95.71%\n",
      "Epoch: 531, Loss: 12322.9180, Recall: 97.51%, Acc: 96.34% Test: 95.71%\n",
      "Epoch: 532, Loss: 12340.5781, Recall: 97.51%, Acc: 96.35% Test: 95.71%\n",
      "Epoch: 533, Loss: 12312.6270, Recall: 97.53%, Acc: 96.35% Test: 95.71%\n",
      "Epoch: 534, Loss: 12316.5283, Recall: 97.52%, Acc: 96.35% Test: 95.71%\n",
      "Epoch: 535, Loss: 12324.6846, Recall: 97.51%, Acc: 96.34% Test: 95.71%\n",
      "Epoch: 536, Loss: 12314.8691, Recall: 97.50%, Acc: 96.34% Test: 95.71%\n",
      "Epoch: 537, Loss: 12329.3457, Recall: 97.50%, Acc: 96.33% Test: 95.71%\n",
      "Epoch: 538, Loss: 12353.8770, Recall: 97.50%, Acc: 96.33% Test: 95.71%\n",
      "Epoch: 539, Loss: 12297.4053, Recall: 97.50%, Acc: 96.32% Test: 95.64%\n",
      "Epoch: 540, Loss: 12308.0518, Recall: 97.51%, Acc: 96.33% Test: 95.64%\n",
      "Epoch: 541, Loss: 12328.2891, Recall: 97.51%, Acc: 96.33% Test: 95.64%\n",
      "Epoch: 542, Loss: 12312.6270, Recall: 97.52%, Acc: 96.33% Test: 95.71%\n",
      "Epoch: 543, Loss: 12332.4873, Recall: 97.51%, Acc: 96.32% Test: 95.71%\n",
      "Epoch: 544, Loss: 12320.1777, Recall: 97.51%, Acc: 96.33% Test: 95.78%\n",
      "Epoch: 545, Loss: 12333.1270, Recall: 97.52%, Acc: 96.33% Test: 95.71%\n",
      "Epoch: 546, Loss: 12339.1230, Recall: 97.52%, Acc: 96.33% Test: 95.64%\n",
      "Epoch: 547, Loss: 12324.7314, Recall: 97.53%, Acc: 96.34% Test: 95.64%\n",
      "Epoch: 548, Loss: 12321.8154, Recall: 97.52%, Acc: 96.34% Test: 95.64%\n",
      "Epoch: 549, Loss: 12278.1758, Recall: 97.54%, Acc: 96.35% Test: 95.64%\n",
      "Epoch: 550, Loss: 12304.5137, Recall: 97.54%, Acc: 96.36% Test: 95.64%\n",
      "Epoch: 551, Loss: 12312.8896, Recall: 97.55%, Acc: 96.36% Test: 95.71%\n",
      "Epoch: 552, Loss: 12324.3164, Recall: 97.56%, Acc: 96.36% Test: 95.71%\n",
      "Epoch: 553, Loss: 12356.8574, Recall: 97.56%, Acc: 96.35% Test: 95.78%\n",
      "Epoch: 554, Loss: 12337.6699, Recall: 97.57%, Acc: 96.34% Test: 95.78%\n",
      "Epoch: 555, Loss: 12301.6875, Recall: 97.57%, Acc: 96.34% Test: 95.86%\n",
      "Epoch: 556, Loss: 12335.2041, Recall: 97.58%, Acc: 96.34% Test: 95.86%\n",
      "Epoch: 557, Loss: 12305.8584, Recall: 97.59%, Acc: 96.34% Test: 95.86%\n",
      "Epoch: 558, Loss: 12325.5938, Recall: 97.57%, Acc: 96.35% Test: 95.78%\n",
      "Epoch: 559, Loss: 12291.1045, Recall: 97.55%, Acc: 96.36% Test: 95.78%\n",
      "Epoch: 560, Loss: 12279.0654, Recall: 97.52%, Acc: 96.37% Test: 95.86%\n",
      "Epoch: 561, Loss: 12335.9316, Recall: 97.53%, Acc: 96.38% Test: 95.86%\n",
      "Epoch: 562, Loss: 12304.9658, Recall: 97.51%, Acc: 96.39% Test: 95.78%\n",
      "Epoch: 563, Loss: 12322.8652, Recall: 97.51%, Acc: 96.39% Test: 95.64%\n",
      "Epoch: 564, Loss: 12291.6055, Recall: 97.50%, Acc: 96.40% Test: 95.56%\n",
      "Epoch: 565, Loss: 12289.2676, Recall: 97.51%, Acc: 96.40% Test: 95.56%\n",
      "Epoch: 566, Loss: 12294.5527, Recall: 97.49%, Acc: 96.41% Test: 95.56%\n",
      "Epoch: 567, Loss: 12291.8838, Recall: 97.49%, Acc: 96.41% Test: 95.49%\n",
      "Epoch: 568, Loss: 12292.2402, Recall: 97.51%, Acc: 96.42% Test: 95.49%\n",
      "Epoch: 569, Loss: 12306.6660, Recall: 97.49%, Acc: 96.42% Test: 95.56%\n",
      "Epoch: 570, Loss: 12259.1094, Recall: 97.50%, Acc: 96.43% Test: 95.49%\n",
      "Epoch: 571, Loss: 12306.6758, Recall: 97.50%, Acc: 96.43% Test: 95.56%\n",
      "Epoch: 572, Loss: 12264.4551, Recall: 97.51%, Acc: 96.44% Test: 95.56%\n",
      "Epoch: 573, Loss: 12296.3779, Recall: 97.51%, Acc: 96.44% Test: 95.64%\n",
      "Epoch: 574, Loss: 12304.3516, Recall: 97.53%, Acc: 96.45% Test: 95.64%\n",
      "Epoch: 575, Loss: 12315.4336, Recall: 97.53%, Acc: 96.45% Test: 95.71%\n",
      "Epoch: 576, Loss: 12292.1045, Recall: 97.51%, Acc: 96.45% Test: 95.64%\n",
      "Epoch: 577, Loss: 12273.0010, Recall: 97.50%, Acc: 96.46% Test: 95.56%\n",
      "Epoch: 578, Loss: 12318.2510, Recall: 97.52%, Acc: 96.46% Test: 95.56%\n",
      "Epoch: 579, Loss: 12304.1748, Recall: 97.55%, Acc: 96.47% Test: 95.49%\n",
      "Epoch: 580, Loss: 12323.6465, Recall: 97.56%, Acc: 96.46% Test: 95.56%\n",
      "Epoch: 581, Loss: 12275.2461, Recall: 97.58%, Acc: 96.46% Test: 95.56%\n",
      "Epoch: 582, Loss: 12304.2715, Recall: 97.57%, Acc: 96.46% Test: 95.64%\n",
      "Epoch: 583, Loss: 12288.7021, Recall: 97.57%, Acc: 96.46% Test: 95.71%\n",
      "Epoch: 584, Loss: 12286.3447, Recall: 97.55%, Acc: 96.46% Test: 95.71%\n",
      "Epoch: 585, Loss: 12295.1113, Recall: 97.55%, Acc: 96.47% Test: 95.71%\n",
      "Epoch: 586, Loss: 12300.8564, Recall: 97.55%, Acc: 96.48% Test: 95.71%\n",
      "Epoch: 587, Loss: 12259.5410, Recall: 97.55%, Acc: 96.48% Test: 95.71%\n",
      "Epoch: 588, Loss: 12251.0576, Recall: 97.54%, Acc: 96.49% Test: 95.71%\n",
      "Epoch: 589, Loss: 12270.0898, Recall: 97.53%, Acc: 96.50% Test: 95.64%\n",
      "Epoch: 590, Loss: 12323.6113, Recall: 97.51%, Acc: 96.50% Test: 95.64%\n",
      "Epoch: 591, Loss: 12261.7188, Recall: 97.52%, Acc: 96.51% Test: 95.64%\n",
      "Epoch: 592, Loss: 12289.5762, Recall: 97.49%, Acc: 96.51% Test: 95.64%\n",
      "Epoch: 593, Loss: 12311.2773, Recall: 97.49%, Acc: 96.53% Test: 95.71%\n",
      "Epoch: 594, Loss: 12268.7627, Recall: 97.49%, Acc: 96.54% Test: 95.71%\n",
      "Epoch: 595, Loss: 12291.7363, Recall: 97.49%, Acc: 96.55% Test: 95.71%\n",
      "Epoch: 596, Loss: 12305.7021, Recall: 97.48%, Acc: 96.56% Test: 95.71%\n",
      "Epoch: 597, Loss: 12301.2871, Recall: 97.50%, Acc: 96.57% Test: 95.71%\n",
      "Epoch: 598, Loss: 12270.0879, Recall: 97.49%, Acc: 96.58% Test: 95.71%\n",
      "Epoch: 599, Loss: 12292.2266, Recall: 97.50%, Acc: 96.58% Test: 95.64%\n",
      "Epoch: 600, Loss: 12272.6875, Recall: 97.48%, Acc: 96.58% Test: 95.64%\n",
      "Epoch: 601, Loss: 12305.2021, Recall: 97.48%, Acc: 96.56% Test: 95.64%\n",
      "Epoch: 602, Loss: 12284.8525, Recall: 97.48%, Acc: 96.55% Test: 95.64%\n",
      "Epoch: 603, Loss: 12272.2480, Recall: 97.46%, Acc: 96.55% Test: 95.64%\n",
      "Epoch: 604, Loss: 12297.7734, Recall: 97.47%, Acc: 96.55% Test: 95.56%\n",
      "Epoch: 605, Loss: 12284.2471, Recall: 97.48%, Acc: 96.55% Test: 95.49%\n",
      "Epoch: 606, Loss: 12270.7090, Recall: 97.48%, Acc: 96.55% Test: 95.41%\n",
      "Epoch: 607, Loss: 12274.8711, Recall: 97.48%, Acc: 96.55% Test: 95.41%\n",
      "Epoch: 608, Loss: 12249.1719, Recall: 97.48%, Acc: 96.55% Test: 95.56%\n",
      "Epoch: 609, Loss: 12281.9111, Recall: 97.50%, Acc: 96.55% Test: 95.56%\n",
      "Epoch: 610, Loss: 12281.3438, Recall: 97.52%, Acc: 96.55% Test: 95.56%\n",
      "Epoch: 611, Loss: 12282.6250, Recall: 97.52%, Acc: 96.55% Test: 95.56%\n",
      "Epoch: 612, Loss: 12248.1816, Recall: 97.52%, Acc: 96.55% Test: 95.56%\n",
      "Epoch: 613, Loss: 12249.8477, Recall: 97.49%, Acc: 96.56% Test: 95.64%\n",
      "Epoch: 614, Loss: 12294.7734, Recall: 97.49%, Acc: 96.56% Test: 95.71%\n",
      "Epoch: 615, Loss: 12280.5684, Recall: 97.51%, Acc: 96.56% Test: 95.71%\n",
      "Epoch: 616, Loss: 12247.1924, Recall: 97.51%, Acc: 96.57% Test: 95.64%\n",
      "Epoch: 617, Loss: 12293.0879, Recall: 97.51%, Acc: 96.57% Test: 95.64%\n",
      "Epoch: 618, Loss: 12240.6494, Recall: 97.52%, Acc: 96.57% Test: 95.64%\n",
      "Epoch: 619, Loss: 12283.5225, Recall: 97.52%, Acc: 96.57% Test: 95.71%\n",
      "Epoch: 620, Loss: 12271.6455, Recall: 97.52%, Acc: 96.57% Test: 95.71%\n",
      "Epoch: 621, Loss: 12277.9414, Recall: 97.51%, Acc: 96.58% Test: 95.71%\n",
      "Epoch: 622, Loss: 12256.7480, Recall: 97.52%, Acc: 96.58% Test: 95.71%\n",
      "Epoch: 623, Loss: 12238.6777, Recall: 97.48%, Acc: 96.58% Test: 95.71%\n",
      "Epoch: 624, Loss: 12261.1191, Recall: 97.48%, Acc: 96.58% Test: 95.71%\n",
      "Epoch: 625, Loss: 12292.8379, Recall: 97.46%, Acc: 96.58% Test: 95.71%\n",
      "Epoch: 626, Loss: 12246.7666, Recall: 97.46%, Acc: 96.58% Test: 95.64%\n",
      "Epoch: 627, Loss: 12289.7363, Recall: 97.47%, Acc: 96.58% Test: 95.64%\n",
      "Epoch: 628, Loss: 12269.5488, Recall: 97.48%, Acc: 96.58% Test: 95.71%\n",
      "Epoch: 629, Loss: 12279.0342, Recall: 97.47%, Acc: 96.58% Test: 95.71%\n",
      "Epoch: 630, Loss: 12262.5996, Recall: 97.47%, Acc: 96.58% Test: 95.71%\n",
      "Epoch: 631, Loss: 12273.8027, Recall: 97.48%, Acc: 96.59% Test: 95.71%\n",
      "Epoch: 632, Loss: 12231.0020, Recall: 97.48%, Acc: 96.59% Test: 95.71%\n",
      "Epoch: 633, Loss: 12255.8838, Recall: 97.51%, Acc: 96.60% Test: 95.71%\n",
      "Epoch: 634, Loss: 12251.7617, Recall: 97.49%, Acc: 96.61% Test: 95.86%\n",
      "Epoch: 635, Loss: 12248.7969, Recall: 97.50%, Acc: 96.62% Test: 95.86%\n",
      "Epoch: 636, Loss: 12263.6777, Recall: 97.50%, Acc: 96.62% Test: 95.78%\n",
      "Epoch: 637, Loss: 12264.9268, Recall: 97.51%, Acc: 96.63% Test: 95.64%\n",
      "Epoch: 638, Loss: 12253.4023, Recall: 97.50%, Acc: 96.62% Test: 95.71%\n",
      "Epoch: 639, Loss: 12313.2803, Recall: 97.53%, Acc: 96.62% Test: 95.71%\n",
      "Epoch: 640, Loss: 12257.4121, Recall: 97.53%, Acc: 96.62% Test: 95.71%\n",
      "Epoch: 641, Loss: 12257.0410, Recall: 97.51%, Acc: 96.61% Test: 95.71%\n",
      "Epoch: 642, Loss: 12236.3477, Recall: 97.52%, Acc: 96.61% Test: 95.71%\n",
      "Epoch: 643, Loss: 12250.0371, Recall: 97.51%, Acc: 96.60% Test: 95.71%\n",
      "Epoch: 644, Loss: 12274.1338, Recall: 97.50%, Acc: 96.59% Test: 95.71%\n",
      "Epoch: 645, Loss: 12254.1875, Recall: 97.53%, Acc: 96.59% Test: 95.64%\n",
      "Epoch: 646, Loss: 12252.0439, Recall: 97.53%, Acc: 96.58% Test: 95.71%\n",
      "Epoch: 647, Loss: 12247.6152, Recall: 97.52%, Acc: 96.57% Test: 95.71%\n",
      "Epoch: 648, Loss: 12237.9658, Recall: 97.53%, Acc: 96.56% Test: 95.86%\n",
      "Epoch: 649, Loss: 12232.6250, Recall: 97.54%, Acc: 96.55% Test: 95.86%\n",
      "Epoch: 650, Loss: 12215.8086, Recall: 97.54%, Acc: 96.55% Test: 95.78%\n",
      "Epoch: 651, Loss: 12220.9893, Recall: 97.55%, Acc: 96.55% Test: 95.71%\n",
      "Epoch: 652, Loss: 12276.5020, Recall: 97.54%, Acc: 96.55% Test: 95.71%\n",
      "Epoch: 653, Loss: 12242.4492, Recall: 97.54%, Acc: 96.56% Test: 95.71%\n",
      "Epoch: 654, Loss: 12251.2109, Recall: 97.55%, Acc: 96.57% Test: 95.71%\n",
      "Epoch: 655, Loss: 12258.3887, Recall: 97.55%, Acc: 96.59% Test: 95.78%\n",
      "Epoch: 656, Loss: 12237.1211, Recall: 97.54%, Acc: 96.60% Test: 95.78%\n",
      "Epoch: 657, Loss: 12247.2959, Recall: 97.53%, Acc: 96.61% Test: 95.64%\n",
      "Epoch: 658, Loss: 12273.2275, Recall: 97.53%, Acc: 96.62% Test: 95.56%\n",
      "Epoch: 659, Loss: 12243.5342, Recall: 97.50%, Acc: 96.63% Test: 95.56%\n",
      "Epoch: 660, Loss: 12248.7031, Recall: 97.50%, Acc: 96.64% Test: 95.56%\n",
      "Epoch: 661, Loss: 12195.3965, Recall: 97.50%, Acc: 96.64% Test: 95.64%\n",
      "Epoch: 662, Loss: 12203.7461, Recall: 97.51%, Acc: 96.65% Test: 95.64%\n",
      "Epoch: 663, Loss: 12245.0273, Recall: 97.53%, Acc: 96.65% Test: 95.64%\n",
      "Epoch: 664, Loss: 12238.5352, Recall: 97.53%, Acc: 96.65% Test: 95.64%\n",
      "Epoch: 665, Loss: 12253.3867, Recall: 97.53%, Acc: 96.65% Test: 95.64%\n",
      "Epoch: 666, Loss: 12230.4082, Recall: 97.53%, Acc: 96.65% Test: 95.56%\n",
      "Epoch: 667, Loss: 12263.1367, Recall: 97.53%, Acc: 96.65% Test: 95.56%\n",
      "Epoch: 668, Loss: 12229.7441, Recall: 97.53%, Acc: 96.65% Test: 95.64%\n",
      "Epoch: 669, Loss: 12255.5635, Recall: 97.54%, Acc: 96.65% Test: 95.64%\n",
      "Epoch: 670, Loss: 12213.2900, Recall: 97.53%, Acc: 96.65% Test: 95.64%\n",
      "Epoch: 671, Loss: 12213.0117, Recall: 97.52%, Acc: 96.66% Test: 95.64%\n",
      "Epoch: 672, Loss: 12229.8506, Recall: 97.49%, Acc: 96.66% Test: 95.71%\n",
      "Epoch: 673, Loss: 12232.4180, Recall: 97.49%, Acc: 96.66% Test: 95.78%\n",
      "Epoch: 674, Loss: 12236.9453, Recall: 97.48%, Acc: 96.66% Test: 95.78%\n",
      "Epoch: 675, Loss: 12232.3223, Recall: 97.47%, Acc: 96.67% Test: 95.86%\n",
      "Epoch: 676, Loss: 12211.5020, Recall: 97.51%, Acc: 96.66% Test: 95.86%\n",
      "Epoch: 677, Loss: 12265.6758, Recall: 97.53%, Acc: 96.67% Test: 95.86%\n",
      "Epoch: 678, Loss: 12224.0469, Recall: 97.52%, Acc: 96.67% Test: 95.86%\n",
      "Epoch: 679, Loss: 12239.9209, Recall: 97.53%, Acc: 96.67% Test: 95.86%\n",
      "Epoch: 680, Loss: 12235.9834, Recall: 97.54%, Acc: 96.66% Test: 95.86%\n",
      "Epoch: 681, Loss: 12187.6992, Recall: 97.54%, Acc: 96.65% Test: 95.86%\n",
      "Epoch: 682, Loss: 12272.2324, Recall: 97.54%, Acc: 96.64% Test: 95.86%\n",
      "Epoch: 683, Loss: 12301.1348, Recall: 97.52%, Acc: 96.64% Test: 95.93%\n",
      "Epoch: 684, Loss: 12219.0400, Recall: 97.49%, Acc: 96.63% Test: 95.93%\n",
      "Epoch: 685, Loss: 12233.4365, Recall: 97.49%, Acc: 96.62% Test: 95.93%\n",
      "Epoch: 686, Loss: 12211.7500, Recall: 97.48%, Acc: 96.62% Test: 95.86%\n",
      "Epoch: 687, Loss: 12234.0176, Recall: 97.48%, Acc: 96.62% Test: 95.78%\n",
      "Epoch: 688, Loss: 12237.1406, Recall: 97.51%, Acc: 96.62% Test: 95.86%\n",
      "Epoch: 689, Loss: 12259.3916, Recall: 97.52%, Acc: 96.62% Test: 95.78%\n",
      "Epoch: 690, Loss: 12235.8184, Recall: 97.53%, Acc: 96.63% Test: 95.71%\n",
      "Epoch: 691, Loss: 12262.8613, Recall: 97.54%, Acc: 96.63% Test: 95.71%\n",
      "Epoch: 692, Loss: 12221.1699, Recall: 97.52%, Acc: 96.63% Test: 95.78%\n",
      "Epoch: 693, Loss: 12232.0879, Recall: 97.53%, Acc: 96.63% Test: 95.86%\n",
      "Epoch: 694, Loss: 12194.0039, Recall: 97.52%, Acc: 96.63% Test: 95.86%\n",
      "Epoch: 695, Loss: 12212.3320, Recall: 97.53%, Acc: 96.64% Test: 95.86%\n",
      "Epoch: 696, Loss: 12227.3496, Recall: 97.53%, Acc: 96.65% Test: 95.78%\n",
      "Epoch: 697, Loss: 12198.1992, Recall: 97.52%, Acc: 96.66% Test: 95.78%\n",
      "Epoch: 698, Loss: 12236.0059, Recall: 97.51%, Acc: 96.67% Test: 95.78%\n",
      "Epoch: 699, Loss: 12217.3301, Recall: 97.49%, Acc: 96.68% Test: 95.86%\n",
      "Epoch: 700, Loss: 12215.6582, Recall: 97.48%, Acc: 96.69% Test: 95.86%\n",
      "Epoch: 701, Loss: 12217.2598, Recall: 97.48%, Acc: 96.70% Test: 95.86%\n",
      "Epoch: 702, Loss: 12273.3701, Recall: 97.48%, Acc: 96.71% Test: 95.86%\n",
      "Epoch: 703, Loss: 12181.2676, Recall: 97.50%, Acc: 96.71% Test: 95.86%\n",
      "Epoch: 704, Loss: 12219.9570, Recall: 97.49%, Acc: 96.72% Test: 95.86%\n",
      "Epoch: 705, Loss: 12216.1348, Recall: 97.50%, Acc: 96.72% Test: 95.93%\n",
      "Epoch: 706, Loss: 12239.0977, Recall: 97.50%, Acc: 96.72% Test: 95.86%\n",
      "Epoch: 707, Loss: 12222.2617, Recall: 97.51%, Acc: 96.72% Test: 95.86%\n",
      "Epoch: 708, Loss: 12249.8008, Recall: 97.54%, Acc: 96.72% Test: 95.86%\n",
      "Epoch: 709, Loss: 12206.7070, Recall: 97.53%, Acc: 96.72% Test: 95.86%\n",
      "Epoch: 710, Loss: 12195.4316, Recall: 97.49%, Acc: 96.72% Test: 95.86%\n",
      "Epoch: 711, Loss: 12216.1279, Recall: 97.50%, Acc: 96.72% Test: 95.71%\n",
      "Epoch: 712, Loss: 12216.7598, Recall: 97.51%, Acc: 96.72% Test: 95.71%\n",
      "Epoch: 713, Loss: 12193.1523, Recall: 97.52%, Acc: 96.71% Test: 95.78%\n",
      "Epoch: 714, Loss: 12215.1641, Recall: 97.50%, Acc: 96.70% Test: 95.78%\n",
      "Epoch: 715, Loss: 12222.5166, Recall: 97.50%, Acc: 96.69% Test: 95.78%\n",
      "Epoch: 716, Loss: 12219.1494, Recall: 97.49%, Acc: 96.69% Test: 95.93%\n",
      "Epoch: 717, Loss: 12183.2891, Recall: 97.51%, Acc: 96.68% Test: 95.93%\n",
      "Epoch: 718, Loss: 12203.6377, Recall: 97.50%, Acc: 96.67% Test: 95.86%\n",
      "Epoch: 719, Loss: 12216.6143, Recall: 97.52%, Acc: 96.66% Test: 95.86%\n",
      "Epoch: 720, Loss: 12218.2930, Recall: 97.53%, Acc: 96.65% Test: 95.86%\n",
      "Epoch: 721, Loss: 12213.1475, Recall: 97.55%, Acc: 96.65% Test: 95.86%\n",
      "Epoch: 722, Loss: 12171.2598, Recall: 97.56%, Acc: 96.64% Test: 95.86%\n",
      "Epoch: 723, Loss: 12207.3438, Recall: 97.56%, Acc: 96.64% Test: 95.86%\n",
      "Epoch: 724, Loss: 12242.9746, Recall: 97.56%, Acc: 96.64% Test: 95.78%\n",
      "Epoch: 725, Loss: 12182.9316, Recall: 97.55%, Acc: 96.64% Test: 95.71%\n",
      "Epoch: 726, Loss: 12225.5234, Recall: 97.54%, Acc: 96.65% Test: 95.71%\n",
      "Epoch: 727, Loss: 12180.3818, Recall: 97.50%, Acc: 96.66% Test: 95.78%\n",
      "Epoch: 728, Loss: 12216.6211, Recall: 97.52%, Acc: 96.66% Test: 95.78%\n",
      "Epoch: 729, Loss: 12215.0078, Recall: 97.51%, Acc: 96.67% Test: 95.86%\n",
      "Epoch: 730, Loss: 12212.7578, Recall: 97.53%, Acc: 96.68% Test: 95.93%\n",
      "Epoch: 731, Loss: 12202.2793, Recall: 97.53%, Acc: 96.69% Test: 95.93%\n",
      "Epoch: 732, Loss: 12210.4727, Recall: 97.52%, Acc: 96.69% Test: 95.93%\n",
      "Epoch: 733, Loss: 12186.5039, Recall: 97.55%, Acc: 96.70% Test: 95.93%\n",
      "Epoch: 734, Loss: 12222.5176, Recall: 97.55%, Acc: 96.70% Test: 95.93%\n",
      "Epoch: 735, Loss: 12187.9014, Recall: 97.57%, Acc: 96.71% Test: 95.93%\n",
      "Epoch: 736, Loss: 12184.7490, Recall: 97.56%, Acc: 96.71% Test: 95.93%\n",
      "Epoch: 737, Loss: 12207.6934, Recall: 97.56%, Acc: 96.72% Test: 96.01%\n",
      "Epoch: 738, Loss: 12210.7812, Recall: 97.56%, Acc: 96.73% Test: 96.01%\n",
      "Epoch: 739, Loss: 12203.4648, Recall: 97.55%, Acc: 96.73% Test: 96.01%\n",
      "Epoch: 740, Loss: 12180.0039, Recall: 97.54%, Acc: 96.73% Test: 96.01%\n",
      "Epoch: 741, Loss: 12196.4004, Recall: 97.53%, Acc: 96.74% Test: 95.93%\n",
      "Epoch: 742, Loss: 12179.0273, Recall: 97.53%, Acc: 96.73% Test: 95.93%\n",
      "Epoch: 743, Loss: 12201.6191, Recall: 97.52%, Acc: 96.74% Test: 95.93%\n",
      "Epoch: 744, Loss: 12230.0898, Recall: 97.52%, Acc: 96.74% Test: 95.93%\n",
      "Epoch: 745, Loss: 12180.4932, Recall: 97.50%, Acc: 96.73% Test: 95.93%\n",
      "Epoch: 746, Loss: 12206.2383, Recall: 97.51%, Acc: 96.73% Test: 95.93%\n",
      "Epoch: 747, Loss: 12139.5371, Recall: 97.52%, Acc: 96.72% Test: 95.93%\n",
      "Epoch: 748, Loss: 12209.5674, Recall: 97.52%, Acc: 96.73% Test: 95.86%\n",
      "Epoch: 749, Loss: 12185.3828, Recall: 97.53%, Acc: 96.73% Test: 95.86%\n",
      "Epoch: 750, Loss: 12180.1201, Recall: 97.54%, Acc: 96.73% Test: 95.86%\n",
      "Epoch: 751, Loss: 12183.7090, Recall: 97.54%, Acc: 96.73% Test: 95.86%\n",
      "Epoch: 752, Loss: 12194.4971, Recall: 97.54%, Acc: 96.73% Test: 95.86%\n",
      "Epoch: 753, Loss: 12168.4854, Recall: 97.55%, Acc: 96.72% Test: 95.86%\n",
      "Epoch: 754, Loss: 12210.1406, Recall: 97.54%, Acc: 96.71% Test: 95.86%\n",
      "Epoch: 755, Loss: 12138.0605, Recall: 97.53%, Acc: 96.72% Test: 95.86%\n",
      "Epoch: 756, Loss: 12181.3984, Recall: 97.52%, Acc: 96.73% Test: 95.78%\n",
      "Epoch: 757, Loss: 12191.7461, Recall: 97.53%, Acc: 96.74% Test: 95.78%\n",
      "Epoch: 758, Loss: 12207.0850, Recall: 97.54%, Acc: 96.75% Test: 95.86%\n",
      "Epoch: 759, Loss: 12202.3770, Recall: 97.54%, Acc: 96.75% Test: 95.86%\n",
      "Epoch: 760, Loss: 12204.9805, Recall: 97.55%, Acc: 96.76% Test: 95.93%\n",
      "Epoch: 761, Loss: 12169.5625, Recall: 97.54%, Acc: 96.76% Test: 95.93%\n",
      "Epoch: 762, Loss: 12193.3496, Recall: 97.55%, Acc: 96.76% Test: 95.93%\n",
      "Epoch: 763, Loss: 12214.3008, Recall: 97.54%, Acc: 96.77% Test: 95.93%\n",
      "Epoch: 764, Loss: 12189.7773, Recall: 97.56%, Acc: 96.76% Test: 95.93%\n",
      "Epoch: 765, Loss: 12164.5273, Recall: 97.58%, Acc: 96.76% Test: 95.93%\n",
      "Epoch: 766, Loss: 12177.5371, Recall: 97.58%, Acc: 96.76% Test: 95.93%\n",
      "Epoch: 767, Loss: 12199.8691, Recall: 97.59%, Acc: 96.76% Test: 95.93%\n",
      "Epoch: 768, Loss: 12217.8516, Recall: 97.59%, Acc: 96.75% Test: 96.01%\n",
      "Epoch: 769, Loss: 12147.1318, Recall: 97.60%, Acc: 96.76% Test: 96.01%\n",
      "Epoch: 770, Loss: 12243.6816, Recall: 97.60%, Acc: 96.76% Test: 96.01%\n",
      "Epoch: 771, Loss: 12183.9238, Recall: 97.60%, Acc: 96.76% Test: 96.01%\n",
      "Epoch: 772, Loss: 12178.3906, Recall: 97.60%, Acc: 96.76% Test: 96.01%\n",
      "Epoch: 773, Loss: 12197.9570, Recall: 97.58%, Acc: 96.76% Test: 96.01%\n",
      "Epoch: 774, Loss: 12201.8564, Recall: 97.57%, Acc: 96.77% Test: 96.01%\n",
      "Epoch: 775, Loss: 12197.5088, Recall: 97.56%, Acc: 96.76% Test: 96.01%\n",
      "Epoch: 776, Loss: 12182.4092, Recall: 97.54%, Acc: 96.75% Test: 96.01%\n",
      "Epoch: 777, Loss: 12190.2656, Recall: 97.55%, Acc: 96.75% Test: 96.01%\n",
      "Epoch: 778, Loss: 12173.6455, Recall: 97.56%, Acc: 96.74% Test: 96.01%\n",
      "Epoch: 779, Loss: 12184.0898, Recall: 97.55%, Acc: 96.74% Test: 96.01%\n",
      "Epoch: 780, Loss: 12148.9375, Recall: 97.55%, Acc: 96.74% Test: 95.93%\n",
      "Epoch: 781, Loss: 12168.5635, Recall: 97.55%, Acc: 96.74% Test: 95.93%\n",
      "Epoch: 782, Loss: 12202.3545, Recall: 97.55%, Acc: 96.74% Test: 95.93%\n",
      "Epoch: 783, Loss: 12158.4980, Recall: 97.53%, Acc: 96.74% Test: 95.93%\n",
      "Epoch: 784, Loss: 12190.3105, Recall: 97.55%, Acc: 96.74% Test: 95.93%\n",
      "Epoch: 785, Loss: 12195.1465, Recall: 97.55%, Acc: 96.74% Test: 95.93%\n",
      "Epoch: 786, Loss: 12227.3652, Recall: 97.56%, Acc: 96.75% Test: 95.93%\n",
      "Epoch: 787, Loss: 12188.7783, Recall: 97.57%, Acc: 96.75% Test: 95.93%\n",
      "Epoch: 788, Loss: 12181.7129, Recall: 97.55%, Acc: 96.75% Test: 95.93%\n",
      "Epoch: 789, Loss: 12156.2119, Recall: 97.56%, Acc: 96.76% Test: 95.93%\n",
      "Epoch: 790, Loss: 12186.8418, Recall: 97.56%, Acc: 96.76% Test: 95.93%\n",
      "Epoch: 791, Loss: 12164.4805, Recall: 97.55%, Acc: 96.75% Test: 95.86%\n",
      "Epoch: 792, Loss: 12181.4512, Recall: 97.54%, Acc: 96.76% Test: 95.93%\n",
      "Epoch: 793, Loss: 12180.4072, Recall: 97.54%, Acc: 96.76% Test: 95.93%\n",
      "Epoch: 794, Loss: 12195.0215, Recall: 97.55%, Acc: 96.76% Test: 95.93%\n",
      "Epoch: 795, Loss: 12208.4980, Recall: 97.54%, Acc: 96.76% Test: 95.93%\n",
      "Epoch: 796, Loss: 12185.0020, Recall: 97.54%, Acc: 96.76% Test: 95.93%\n",
      "Epoch: 797, Loss: 12174.6562, Recall: 97.53%, Acc: 96.75% Test: 95.86%\n",
      "Epoch: 798, Loss: 12185.0781, Recall: 97.54%, Acc: 96.74% Test: 95.93%\n",
      "Epoch: 799, Loss: 12171.6055, Recall: 97.54%, Acc: 96.73% Test: 95.93%\n",
      "Epoch: 800, Loss: 12179.3828, Recall: 97.57%, Acc: 96.72% Test: 95.93%\n",
      "Epoch: 801, Loss: 12209.2578, Recall: 97.56%, Acc: 96.72% Test: 95.86%\n",
      "Epoch: 802, Loss: 12204.4004, Recall: 97.55%, Acc: 96.72% Test: 95.93%\n",
      "Epoch: 803, Loss: 12156.0684, Recall: 97.55%, Acc: 96.73% Test: 95.86%\n",
      "Epoch: 804, Loss: 12156.2754, Recall: 97.53%, Acc: 96.73% Test: 95.78%\n",
      "Epoch: 805, Loss: 12164.8486, Recall: 97.53%, Acc: 96.73% Test: 95.78%\n",
      "Epoch: 806, Loss: 12169.9297, Recall: 97.53%, Acc: 96.74% Test: 95.86%\n",
      "Epoch: 807, Loss: 12214.4121, Recall: 97.53%, Acc: 96.74% Test: 95.86%\n",
      "Epoch: 808, Loss: 12186.3770, Recall: 97.54%, Acc: 96.74% Test: 95.78%\n",
      "Epoch: 809, Loss: 12159.2354, Recall: 97.55%, Acc: 96.74% Test: 95.78%\n",
      "Epoch: 810, Loss: 12180.4043, Recall: 97.54%, Acc: 96.73% Test: 95.78%\n",
      "Epoch: 811, Loss: 12160.1934, Recall: 97.55%, Acc: 96.72% Test: 95.78%\n",
      "Epoch: 812, Loss: 12174.3516, Recall: 97.54%, Acc: 96.73% Test: 95.78%\n",
      "Epoch: 813, Loss: 12193.2422, Recall: 97.54%, Acc: 96.73% Test: 95.86%\n",
      "Epoch: 814, Loss: 12159.0967, Recall: 97.53%, Acc: 96.73% Test: 95.86%\n",
      "Epoch: 815, Loss: 12174.4141, Recall: 97.52%, Acc: 96.74% Test: 95.78%\n",
      "Epoch: 816, Loss: 12152.1875, Recall: 97.52%, Acc: 96.74% Test: 95.78%\n",
      "Epoch: 817, Loss: 12148.9951, Recall: 97.53%, Acc: 96.75% Test: 95.78%\n",
      "Epoch: 818, Loss: 12147.1299, Recall: 97.53%, Acc: 96.77% Test: 95.86%\n",
      "Epoch: 819, Loss: 12161.6680, Recall: 97.53%, Acc: 96.78% Test: 95.86%\n",
      "Epoch: 820, Loss: 12148.6396, Recall: 97.51%, Acc: 96.79% Test: 95.78%\n",
      "Epoch: 821, Loss: 12191.1768, Recall: 97.53%, Acc: 96.79% Test: 95.78%\n",
      "Epoch: 822, Loss: 12175.0215, Recall: 97.52%, Acc: 96.79% Test: 95.78%\n",
      "Epoch: 823, Loss: 12188.8926, Recall: 97.54%, Acc: 96.79% Test: 95.78%\n",
      "Epoch: 824, Loss: 12144.4551, Recall: 97.54%, Acc: 96.79% Test: 95.78%\n",
      "Epoch: 825, Loss: 12141.0566, Recall: 97.55%, Acc: 96.79% Test: 95.86%\n",
      "Epoch: 826, Loss: 12165.3105, Recall: 97.56%, Acc: 96.79% Test: 95.86%\n",
      "Epoch: 827, Loss: 12136.4707, Recall: 97.58%, Acc: 96.79% Test: 95.78%\n",
      "Epoch: 828, Loss: 12179.4355, Recall: 97.59%, Acc: 96.79% Test: 95.86%\n",
      "Epoch: 829, Loss: 12143.1572, Recall: 97.59%, Acc: 96.79% Test: 95.86%\n",
      "Epoch: 830, Loss: 12197.6660, Recall: 97.58%, Acc: 96.78% Test: 95.86%\n",
      "Epoch: 831, Loss: 12199.3750, Recall: 97.59%, Acc: 96.78% Test: 95.86%\n",
      "Epoch: 832, Loss: 12133.9414, Recall: 97.59%, Acc: 96.77% Test: 95.86%\n",
      "Epoch: 833, Loss: 12145.4521, Recall: 97.59%, Acc: 96.77% Test: 95.86%\n",
      "Epoch: 834, Loss: 12171.3535, Recall: 97.59%, Acc: 96.78% Test: 95.86%\n",
      "Epoch: 835, Loss: 12214.0430, Recall: 97.59%, Acc: 96.78% Test: 95.86%\n",
      "Epoch: 836, Loss: 12167.5928, Recall: 97.59%, Acc: 96.78% Test: 95.86%\n",
      "Epoch: 837, Loss: 12165.7842, Recall: 97.58%, Acc: 96.78% Test: 95.93%\n",
      "Epoch: 838, Loss: 12138.1426, Recall: 97.56%, Acc: 96.79% Test: 95.93%\n",
      "Epoch: 839, Loss: 12137.7471, Recall: 97.56%, Acc: 96.80% Test: 95.93%\n",
      "Epoch: 840, Loss: 12188.2100, Recall: 97.56%, Acc: 96.81% Test: 95.93%\n",
      "Epoch: 841, Loss: 12188.0547, Recall: 97.55%, Acc: 96.81% Test: 95.93%\n",
      "Epoch: 842, Loss: 12137.7715, Recall: 97.54%, Acc: 96.82% Test: 95.93%\n",
      "Epoch: 843, Loss: 12192.3467, Recall: 97.54%, Acc: 96.82% Test: 95.93%\n",
      "Epoch: 844, Loss: 12155.3398, Recall: 97.54%, Acc: 96.83% Test: 95.93%\n",
      "Epoch: 845, Loss: 12187.6641, Recall: 97.54%, Acc: 96.84% Test: 95.93%\n",
      "Epoch: 846, Loss: 12169.4463, Recall: 97.52%, Acc: 96.83% Test: 95.93%\n",
      "Epoch: 847, Loss: 12116.9824, Recall: 97.52%, Acc: 96.83% Test: 95.93%\n",
      "Epoch: 848, Loss: 12164.1455, Recall: 97.52%, Acc: 96.83% Test: 95.93%\n",
      "Epoch: 849, Loss: 12146.9238, Recall: 97.52%, Acc: 96.83% Test: 95.93%\n",
      "Epoch: 850, Loss: 12185.4746, Recall: 97.52%, Acc: 96.83% Test: 95.86%\n",
      "Epoch: 851, Loss: 12122.5645, Recall: 97.52%, Acc: 96.85% Test: 95.86%\n",
      "Epoch: 852, Loss: 12127.7852, Recall: 97.52%, Acc: 96.85% Test: 95.86%\n",
      "Epoch: 853, Loss: 12144.7090, Recall: 97.52%, Acc: 96.86% Test: 95.86%\n",
      "Epoch: 854, Loss: 12156.4121, Recall: 97.52%, Acc: 96.86% Test: 95.93%\n",
      "Epoch: 855, Loss: 12146.9453, Recall: 97.52%, Acc: 96.86% Test: 95.93%\n",
      "Epoch: 856, Loss: 12136.7529, Recall: 97.54%, Acc: 96.88% Test: 95.93%\n",
      "Epoch: 857, Loss: 12160.0879, Recall: 97.53%, Acc: 96.89% Test: 95.93%\n",
      "Epoch: 858, Loss: 12145.1270, Recall: 97.54%, Acc: 96.89% Test: 95.93%\n",
      "Epoch: 859, Loss: 12150.4951, Recall: 97.55%, Acc: 96.89% Test: 96.08%\n",
      "Epoch: 860, Loss: 12147.1621, Recall: 97.56%, Acc: 96.89% Test: 96.01%\n",
      "Epoch: 861, Loss: 12166.9043, Recall: 97.57%, Acc: 96.89% Test: 96.01%\n",
      "Epoch: 862, Loss: 12165.5303, Recall: 97.58%, Acc: 96.88% Test: 96.01%\n",
      "Epoch: 863, Loss: 12121.7793, Recall: 97.58%, Acc: 96.88% Test: 96.01%\n",
      "Epoch: 864, Loss: 12174.0938, Recall: 97.58%, Acc: 96.87% Test: 96.01%\n",
      "Epoch: 865, Loss: 12183.7568, Recall: 97.61%, Acc: 96.87% Test: 96.01%\n",
      "Epoch: 866, Loss: 12142.3418, Recall: 97.61%, Acc: 96.87% Test: 96.01%\n",
      "Epoch: 867, Loss: 12145.4707, Recall: 97.60%, Acc: 96.87% Test: 95.93%\n",
      "Epoch: 868, Loss: 12150.6299, Recall: 97.61%, Acc: 96.87% Test: 95.93%\n",
      "Epoch: 869, Loss: 12135.9092, Recall: 97.60%, Acc: 96.88% Test: 95.93%\n",
      "Epoch: 870, Loss: 12178.2119, Recall: 97.60%, Acc: 96.87% Test: 95.93%\n",
      "Epoch: 871, Loss: 12145.4941, Recall: 97.60%, Acc: 96.86% Test: 95.86%\n",
      "Epoch: 872, Loss: 12132.4414, Recall: 97.60%, Acc: 96.86% Test: 95.86%\n",
      "Epoch: 873, Loss: 12158.9717, Recall: 97.60%, Acc: 96.86% Test: 95.86%\n",
      "Epoch: 874, Loss: 12150.9590, Recall: 97.60%, Acc: 96.86% Test: 95.93%\n",
      "Epoch: 875, Loss: 12126.2109, Recall: 97.59%, Acc: 96.85% Test: 95.93%\n",
      "Epoch: 876, Loss: 12158.5742, Recall: 97.59%, Acc: 96.84% Test: 95.93%\n",
      "Epoch: 877, Loss: 12136.5576, Recall: 97.59%, Acc: 96.84% Test: 95.93%\n",
      "Epoch: 878, Loss: 12143.2207, Recall: 97.59%, Acc: 96.83% Test: 95.93%\n",
      "Epoch: 879, Loss: 12121.3330, Recall: 97.58%, Acc: 96.84% Test: 95.93%\n",
      "Epoch: 880, Loss: 12148.4531, Recall: 97.59%, Acc: 96.84% Test: 95.93%\n",
      "Epoch: 881, Loss: 12127.7754, Recall: 97.58%, Acc: 96.85% Test: 95.93%\n",
      "Epoch: 882, Loss: 12137.5420, Recall: 97.58%, Acc: 96.85% Test: 95.86%\n",
      "Epoch: 883, Loss: 12125.9287, Recall: 97.57%, Acc: 96.86% Test: 95.78%\n",
      "Epoch: 884, Loss: 12149.9004, Recall: 97.55%, Acc: 96.86% Test: 95.78%\n",
      "Epoch: 885, Loss: 12124.8984, Recall: 97.54%, Acc: 96.87% Test: 95.78%\n",
      "Epoch: 886, Loss: 12126.7305, Recall: 97.54%, Acc: 96.88% Test: 95.86%\n",
      "Epoch: 887, Loss: 12110.6211, Recall: 97.54%, Acc: 96.88% Test: 95.86%\n",
      "Epoch: 888, Loss: 12150.2305, Recall: 97.56%, Acc: 96.87% Test: 96.01%\n",
      "Epoch: 889, Loss: 12110.3496, Recall: 97.57%, Acc: 96.87% Test: 96.01%\n",
      "Epoch: 890, Loss: 12154.4902, Recall: 97.57%, Acc: 96.86% Test: 96.01%\n",
      "Epoch: 891, Loss: 12193.2930, Recall: 97.57%, Acc: 96.85% Test: 96.01%\n",
      "Epoch: 892, Loss: 12148.5215, Recall: 97.58%, Acc: 96.85% Test: 96.01%\n",
      "Epoch: 893, Loss: 12163.5332, Recall: 97.58%, Acc: 96.84% Test: 95.93%\n",
      "Epoch: 894, Loss: 12126.3174, Recall: 97.59%, Acc: 96.83% Test: 95.93%\n",
      "Epoch: 895, Loss: 12151.6973, Recall: 97.60%, Acc: 96.82% Test: 95.93%\n",
      "Epoch: 896, Loss: 12151.3379, Recall: 97.60%, Acc: 96.82% Test: 95.93%\n",
      "Epoch: 897, Loss: 12137.1973, Recall: 97.61%, Acc: 96.81% Test: 95.93%\n",
      "Epoch: 898, Loss: 12150.2910, Recall: 97.62%, Acc: 96.81% Test: 95.86%\n",
      "Epoch: 899, Loss: 12103.6074, Recall: 97.59%, Acc: 96.81% Test: 96.01%\n",
      "Epoch: 900, Loss: 12134.1289, Recall: 97.59%, Acc: 96.82% Test: 96.01%\n",
      "Epoch: 901, Loss: 12161.5352, Recall: 97.57%, Acc: 96.83% Test: 96.01%\n",
      "Epoch: 902, Loss: 12124.8496, Recall: 97.57%, Acc: 96.84% Test: 96.01%\n",
      "Epoch: 903, Loss: 12116.8184, Recall: 97.57%, Acc: 96.85% Test: 96.01%\n",
      "Epoch: 904, Loss: 12141.1895, Recall: 97.57%, Acc: 96.86% Test: 96.01%\n",
      "Epoch: 905, Loss: 12153.2090, Recall: 97.58%, Acc: 96.87% Test: 95.93%\n",
      "Epoch: 906, Loss: 12128.0527, Recall: 97.56%, Acc: 96.88% Test: 95.93%\n",
      "Epoch: 907, Loss: 12141.3525, Recall: 97.56%, Acc: 96.88% Test: 95.93%\n",
      "Epoch: 908, Loss: 12134.7305, Recall: 97.57%, Acc: 96.90% Test: 95.93%\n",
      "Epoch: 909, Loss: 12117.7754, Recall: 97.59%, Acc: 96.91% Test: 95.86%\n",
      "Epoch: 910, Loss: 12152.0166, Recall: 97.59%, Acc: 96.91% Test: 95.86%\n",
      "Epoch: 911, Loss: 12128.4219, Recall: 97.60%, Acc: 96.91% Test: 95.93%\n",
      "Epoch: 912, Loss: 12159.2637, Recall: 97.61%, Acc: 96.90% Test: 95.93%\n",
      "Epoch: 913, Loss: 12133.3730, Recall: 97.62%, Acc: 96.90% Test: 95.93%\n",
      "Epoch: 914, Loss: 12150.8945, Recall: 97.61%, Acc: 96.91% Test: 96.01%\n",
      "Epoch: 915, Loss: 12121.5996, Recall: 97.61%, Acc: 96.90% Test: 95.93%\n",
      "Epoch: 916, Loss: 12140.7588, Recall: 97.61%, Acc: 96.90% Test: 95.93%\n",
      "Epoch: 917, Loss: 12111.5225, Recall: 97.62%, Acc: 96.90% Test: 96.01%\n",
      "Epoch: 918, Loss: 12104.7773, Recall: 97.61%, Acc: 96.89% Test: 96.01%\n",
      "Epoch: 919, Loss: 12151.3887, Recall: 97.59%, Acc: 96.88% Test: 96.01%\n",
      "Epoch: 920, Loss: 12145.7588, Recall: 97.59%, Acc: 96.88% Test: 96.01%\n",
      "Epoch: 921, Loss: 12147.1357, Recall: 97.59%, Acc: 96.87% Test: 96.01%\n",
      "Epoch: 922, Loss: 12104.8164, Recall: 97.59%, Acc: 96.86% Test: 96.01%\n",
      "Epoch: 923, Loss: 12098.3789, Recall: 97.59%, Acc: 96.86% Test: 96.01%\n",
      "Epoch: 924, Loss: 12107.5039, Recall: 97.60%, Acc: 96.86% Test: 96.08%\n",
      "Epoch: 925, Loss: 12117.3164, Recall: 97.58%, Acc: 96.86% Test: 96.08%\n",
      "Epoch: 926, Loss: 12114.1621, Recall: 97.59%, Acc: 96.88% Test: 96.08%\n",
      "Epoch: 927, Loss: 12122.9824, Recall: 97.58%, Acc: 96.89% Test: 96.08%\n",
      "Epoch: 928, Loss: 12110.5859, Recall: 97.57%, Acc: 96.90% Test: 96.01%\n",
      "Epoch: 929, Loss: 12151.6016, Recall: 97.58%, Acc: 96.92% Test: 96.08%\n",
      "Epoch: 930, Loss: 12092.1426, Recall: 97.58%, Acc: 96.93% Test: 96.08%\n",
      "Epoch: 931, Loss: 12136.8301, Recall: 97.56%, Acc: 96.94% Test: 96.08%\n",
      "Epoch: 932, Loss: 12123.0059, Recall: 97.58%, Acc: 96.94% Test: 96.08%\n",
      "Epoch: 933, Loss: 12154.9277, Recall: 97.57%, Acc: 96.95% Test: 96.01%\n",
      "Epoch: 934, Loss: 12131.0176, Recall: 97.54%, Acc: 96.95% Test: 96.01%\n",
      "Epoch: 935, Loss: 12143.8203, Recall: 97.55%, Acc: 96.95% Test: 96.01%\n",
      "Epoch: 936, Loss: 12132.0166, Recall: 97.55%, Acc: 96.94% Test: 95.93%\n",
      "Epoch: 937, Loss: 12110.0723, Recall: 97.54%, Acc: 96.93% Test: 95.86%\n",
      "Epoch: 938, Loss: 12124.6240, Recall: 97.55%, Acc: 96.92% Test: 95.86%\n",
      "Epoch: 939, Loss: 12119.4375, Recall: 97.55%, Acc: 96.90% Test: 95.86%\n",
      "Epoch: 940, Loss: 12144.9277, Recall: 97.54%, Acc: 96.89% Test: 95.93%\n",
      "Epoch: 941, Loss: 12134.0859, Recall: 97.51%, Acc: 96.87% Test: 95.93%\n",
      "Epoch: 942, Loss: 12128.5938, Recall: 97.51%, Acc: 96.86% Test: 95.93%\n",
      "Epoch: 943, Loss: 12143.7930, Recall: 97.51%, Acc: 96.84% Test: 95.86%\n",
      "Epoch: 944, Loss: 12102.2500, Recall: 97.51%, Acc: 96.83% Test: 95.93%\n",
      "Epoch: 945, Loss: 12095.1504, Recall: 97.53%, Acc: 96.81% Test: 96.01%\n",
      "Epoch: 946, Loss: 12137.3086, Recall: 97.53%, Acc: 96.80% Test: 96.01%\n",
      "Epoch: 947, Loss: 12121.3184, Recall: 97.52%, Acc: 96.80% Test: 96.01%\n",
      "Epoch: 948, Loss: 12128.1045, Recall: 97.54%, Acc: 96.80% Test: 96.01%\n",
      "Epoch: 949, Loss: 12126.4893, Recall: 97.54%, Acc: 96.80% Test: 96.08%\n",
      "Epoch: 950, Loss: 12127.4658, Recall: 97.56%, Acc: 96.81% Test: 96.15%\n",
      "Epoch: 951, Loss: 12138.5234, Recall: 97.57%, Acc: 96.82% Test: 96.15%\n",
      "Epoch: 952, Loss: 12142.8076, Recall: 97.56%, Acc: 96.83% Test: 96.15%\n",
      "Epoch: 953, Loss: 12114.5361, Recall: 97.58%, Acc: 96.83% Test: 96.15%\n",
      "Epoch: 954, Loss: 12143.6152, Recall: 97.57%, Acc: 96.84% Test: 96.15%\n",
      "Epoch: 955, Loss: 12117.9521, Recall: 97.58%, Acc: 96.85% Test: 96.15%\n",
      "Epoch: 956, Loss: 12129.6309, Recall: 97.56%, Acc: 96.86% Test: 96.08%\n",
      "Epoch: 957, Loss: 12130.8652, Recall: 97.56%, Acc: 96.86% Test: 96.08%\n",
      "Epoch: 958, Loss: 12095.8965, Recall: 97.55%, Acc: 96.87% Test: 95.86%\n",
      "Epoch: 959, Loss: 12103.4062, Recall: 97.54%, Acc: 96.87% Test: 95.86%\n",
      "Epoch: 960, Loss: 12122.0889, Recall: 97.56%, Acc: 96.87% Test: 95.86%\n",
      "Epoch: 961, Loss: 12127.1758, Recall: 97.56%, Acc: 96.88% Test: 95.86%\n",
      "Epoch: 962, Loss: 12128.3799, Recall: 97.55%, Acc: 96.88% Test: 95.86%\n",
      "Epoch: 963, Loss: 12097.7812, Recall: 97.55%, Acc: 96.88% Test: 95.93%\n",
      "Epoch: 964, Loss: 12080.2676, Recall: 97.56%, Acc: 96.88% Test: 95.93%\n",
      "Epoch: 965, Loss: 12115.6719, Recall: 97.57%, Acc: 96.88% Test: 95.93%\n",
      "Epoch: 966, Loss: 12094.3633, Recall: 97.56%, Acc: 96.89% Test: 95.86%\n",
      "Epoch: 967, Loss: 12108.2314, Recall: 97.56%, Acc: 96.89% Test: 95.93%\n",
      "Epoch: 968, Loss: 12098.1533, Recall: 97.57%, Acc: 96.89% Test: 95.93%\n",
      "Epoch: 969, Loss: 12114.3750, Recall: 97.59%, Acc: 96.90% Test: 95.93%\n",
      "Epoch: 970, Loss: 12103.5967, Recall: 97.58%, Acc: 96.90% Test: 95.93%\n",
      "Epoch: 971, Loss: 12089.3008, Recall: 97.58%, Acc: 96.91% Test: 95.86%\n",
      "Epoch: 972, Loss: 12117.9375, Recall: 97.58%, Acc: 96.91% Test: 95.86%\n",
      "Epoch: 973, Loss: 12110.9824, Recall: 97.57%, Acc: 96.91% Test: 95.86%\n",
      "Epoch: 974, Loss: 12140.8232, Recall: 97.57%, Acc: 96.92% Test: 95.93%\n",
      "Epoch: 975, Loss: 12136.6045, Recall: 97.55%, Acc: 96.92% Test: 95.93%\n",
      "Epoch: 976, Loss: 12131.5352, Recall: 97.55%, Acc: 96.92% Test: 95.93%\n",
      "Epoch: 977, Loss: 12125.7988, Recall: 97.54%, Acc: 96.92% Test: 96.01%\n",
      "Epoch: 978, Loss: 12111.8174, Recall: 97.52%, Acc: 96.92% Test: 96.08%\n",
      "Epoch: 979, Loss: 12095.2559, Recall: 97.53%, Acc: 96.92% Test: 96.08%\n",
      "Epoch: 980, Loss: 12102.3789, Recall: 97.54%, Acc: 96.91% Test: 96.08%\n",
      "Epoch: 981, Loss: 12117.9980, Recall: 97.55%, Acc: 96.91% Test: 96.08%\n",
      "Epoch: 982, Loss: 12093.8105, Recall: 97.55%, Acc: 96.92% Test: 96.08%\n",
      "Epoch: 983, Loss: 12145.3594, Recall: 97.53%, Acc: 96.92% Test: 96.08%\n",
      "Epoch: 984, Loss: 12098.6816, Recall: 97.53%, Acc: 96.92% Test: 96.08%\n",
      "Epoch: 985, Loss: 12123.0713, Recall: 97.53%, Acc: 96.93% Test: 96.15%\n",
      "Epoch: 986, Loss: 12135.1260, Recall: 97.53%, Acc: 96.94% Test: 96.01%\n",
      "Epoch: 987, Loss: 12108.8623, Recall: 97.53%, Acc: 96.95% Test: 96.01%\n",
      "Epoch: 988, Loss: 12096.9043, Recall: 97.53%, Acc: 96.96% Test: 95.93%\n",
      "Epoch: 989, Loss: 12107.8818, Recall: 97.53%, Acc: 96.97% Test: 95.93%\n",
      "Epoch: 990, Loss: 12116.9893, Recall: 97.54%, Acc: 96.98% Test: 95.93%\n",
      "Epoch: 991, Loss: 12123.1191, Recall: 97.56%, Acc: 96.98% Test: 95.93%\n",
      "Epoch: 992, Loss: 12134.5020, Recall: 97.56%, Acc: 96.98% Test: 96.01%\n",
      "Epoch: 993, Loss: 12139.8633, Recall: 97.56%, Acc: 96.97% Test: 96.01%\n",
      "Epoch: 994, Loss: 12116.9219, Recall: 97.56%, Acc: 96.97% Test: 96.01%\n",
      "Epoch: 995, Loss: 12120.3789, Recall: 97.56%, Acc: 96.97% Test: 96.01%\n",
      "Epoch: 996, Loss: 12111.8975, Recall: 97.55%, Acc: 96.97% Test: 96.08%\n",
      "Epoch: 997, Loss: 12116.8086, Recall: 97.53%, Acc: 96.96% Test: 96.08%\n",
      "Epoch: 998, Loss: 12084.9609, Recall: 97.53%, Acc: 96.96% Test: 96.08%\n",
      "Epoch: 999, Loss: 12112.1758, Recall: 97.54%, Acc: 96.95% Test: 96.08%\n",
      "Epoch: 1000, Loss: 12107.3291, Recall: 97.53%, Acc: 96.95% Test: 96.08%\n"
     ]
    }
   ],
   "source": [
    "gcn_model.reset_parameters()\n",
    "\n",
    "optimizer = torch.optim.Adam(gcn_model.parameters(), lr=gcn_args['lr'])\n",
    "loss_fn = weighted_BCE(reduction=\"sum\" , true_weight=1.2 , false_weight=0.01)\n",
    "\n",
    "best_model = None\n",
    "best_valid_acc = 0\n",
    "\n",
    "for epoch in range(1, 1 + gcn_args[\"epochs\"]):\n",
    "  \n",
    "  loss = train_gcn(gcn_model , data , optimizer, loss_fn)\n",
    "  result = test_gcn(gcn_model, data)\n",
    "\n",
    "  c_train , c_val , c_test = result\n",
    "\n",
    "  if acc(c_val) > best_valid_acc:\n",
    "      best_valid_acc = acc(c_val)\n",
    "      best_model = copy.deepcopy(gcn_model)\n",
    "\n",
    "  gcn_logger.info(f'Epoch {epoch:02d} '\n",
    "        f'Loss {loss:.4f} '\n",
    "        f'Train {c_train[0][0]:02d} {c_train[0][1]:02d} {c_train[1][0]:02d} {c_train[1][1]:02d} '\n",
    "        f'Valid {c_val[0][0]:02d} {c_val[0][1]:02d} {c_val[1][0]:02d} {c_val[1][1]:02d} '\n",
    "        f'Test {c_val[0][0]:02d} {c_val[0][1]:02d} {c_val[1][0]:02d} {c_val[1][1]:02d} ')\n",
    "  \n",
    "  print((f'Epoch: {epoch:02d}, '\n",
    "        f'Loss: {loss:.4f}, '\n",
    "        f'Recall: {100 * recall(c_train):.2f}%, '\n",
    "        f'Acc: {100 * acc(c_train):.2f}% '\n",
    "        f'Test: {100 * recall(c_test):.2f}%'))\n",
    "  \n",
    "handlers = gcn_logger.handlers[:]\n",
    "for handler in handlers:\n",
    "    gcn_logger.removeHandler(handler)\n",
    "    handler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9702013677811551"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../models/gcn_1_200.pt\"\n",
    "torch.save(best_model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_dim': 16, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.01, 'epochs': 1000}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_args = {\n",
    "    \"hidden_dim\":16,\n",
    "    \"num_layers\":4,\n",
    "    \"dropout\":0.2,\n",
    "    \"lr\":0.01,\n",
    "    \"epochs\":1000\n",
    "}\n",
    "\n",
    "mlp_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP model number of parameters: 4296\n"
     ]
    }
   ],
   "source": [
    "mlp_model = MLP(input_dim = data.x.shape[1], hidden_dim = mlp_args[\"hidden_dim\"], output_dim = data.y.shape[1], num_layers = mlp_args[\"num_layers\"], dropout = mlp_args['dropout']).to(device)\n",
    "\n",
    "total_params_mlp = sum(\n",
    "\tparam.numel() for param in mlp_model.parameters()\n",
    ")\n",
    "print(\"MLP model number of parameters:\" , total_params_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 28084.5059, recall: 59.10%, acc: 55.96% Test: 55.96%\n",
      "Epoch: 02, Loss: 27716.3262, recall: 60.12%, acc: 59.29% Test: 59.30%\n",
      "Epoch: 03, Loss: 27367.2031, recall: 62.58%, acc: 62.76% Test: 62.75%\n",
      "Epoch: 04, Loss: 27000.5078, recall: 65.17%, acc: 67.28% Test: 67.25%\n",
      "Epoch: 05, Loss: 26548.0273, recall: 65.05%, acc: 73.49% Test: 73.52%\n",
      "Epoch: 06, Loss: 26000.3613, recall: 66.33%, acc: 78.37% Test: 78.39%\n",
      "Epoch: 07, Loss: 25324.9062, recall: 69.16%, acc: 81.08% Test: 81.10%\n",
      "Epoch: 08, Loss: 24525.8555, recall: 69.59%, acc: 82.93% Test: 82.95%\n",
      "Epoch: 09, Loss: 23589.8477, recall: 68.44%, acc: 85.22% Test: 85.22%\n",
      "Epoch: 10, Loss: 22503.8086, recall: 67.90%, acc: 86.48% Test: 86.49%\n",
      "Epoch: 11, Loss: 21661.3164, recall: 70.56%, acc: 86.70% Test: 86.72%\n",
      "Epoch: 12, Loss: 21291.8691, recall: 71.39%, acc: 86.67% Test: 86.67%\n",
      "Epoch: 13, Loss: 21328.4004, recall: 71.13%, acc: 86.71% Test: 86.70%\n",
      "Epoch: 14, Loss: 21062.5000, recall: 71.36%, acc: 86.66% Test: 86.66%\n",
      "Epoch: 15, Loss: 20862.9180, recall: 72.14%, acc: 86.45% Test: 86.45%\n",
      "Epoch: 16, Loss: 20275.1094, recall: 72.83%, acc: 86.03% Test: 86.04%\n",
      "Epoch: 17, Loss: 19868.4414, recall: 72.98%, acc: 85.71% Test: 85.71%\n",
      "Epoch: 18, Loss: 19578.1309, recall: 73.29%, acc: 85.46% Test: 85.48%\n",
      "Epoch: 19, Loss: 19445.0078, recall: 73.72%, acc: 85.29% Test: 85.33%\n",
      "Epoch: 20, Loss: 19395.8438, recall: 74.32%, acc: 85.24% Test: 85.27%\n",
      "Epoch: 21, Loss: 19337.0430, recall: 74.72%, acc: 85.29% Test: 85.33%\n",
      "Epoch: 22, Loss: 19212.7578, recall: 74.68%, acc: 85.46% Test: 85.50%\n",
      "Epoch: 23, Loss: 18980.1367, recall: 74.59%, acc: 85.69% Test: 85.71%\n",
      "Epoch: 24, Loss: 18898.3438, recall: 74.63%, acc: 85.93% Test: 85.97%\n",
      "Epoch: 25, Loss: 18714.9199, recall: 74.83%, acc: 86.16% Test: 86.22%\n",
      "Epoch: 26, Loss: 18562.2480, recall: 74.78%, acc: 86.35% Test: 86.42%\n",
      "Epoch: 27, Loss: 18404.4355, recall: 74.86%, acc: 86.46% Test: 86.52%\n",
      "Epoch: 28, Loss: 18279.6660, recall: 75.00%, acc: 86.50% Test: 86.54%\n",
      "Epoch: 29, Loss: 18079.3672, recall: 75.35%, acc: 86.49% Test: 86.53%\n",
      "Epoch: 30, Loss: 17892.5977, recall: 76.11%, acc: 86.44% Test: 86.48%\n",
      "Epoch: 31, Loss: 17689.4688, recall: 76.58%, acc: 86.42% Test: 86.47%\n",
      "Epoch: 32, Loss: 17552.3633, recall: 77.05%, acc: 86.42% Test: 86.47%\n",
      "Epoch: 33, Loss: 17332.2441, recall: 77.46%, acc: 86.45% Test: 86.50%\n",
      "Epoch: 34, Loss: 17223.7539, recall: 77.70%, acc: 86.51% Test: 86.56%\n",
      "Epoch: 35, Loss: 16946.7910, recall: 78.10%, acc: 86.57% Test: 86.63%\n",
      "Epoch: 36, Loss: 16840.1758, recall: 78.38%, acc: 86.62% Test: 86.67%\n",
      "Epoch: 37, Loss: 16706.4688, recall: 78.80%, acc: 86.64% Test: 86.70%\n",
      "Epoch: 38, Loss: 16553.3047, recall: 79.50%, acc: 86.60% Test: 86.68%\n",
      "Epoch: 39, Loss: 16288.1523, recall: 79.86%, acc: 86.58% Test: 86.66%\n",
      "Epoch: 40, Loss: 16152.8369, recall: 80.16%, acc: 86.57% Test: 86.64%\n",
      "Epoch: 41, Loss: 16048.0195, recall: 80.75%, acc: 86.57% Test: 86.63%\n",
      "Epoch: 42, Loss: 15784.8760, recall: 81.25%, acc: 86.66% Test: 86.71%\n",
      "Epoch: 43, Loss: 15689.9541, recall: 81.91%, acc: 86.77% Test: 86.85%\n",
      "Epoch: 44, Loss: 15519.5469, recall: 82.51%, acc: 86.91% Test: 87.00%\n",
      "Epoch: 45, Loss: 15345.1094, recall: 83.02%, acc: 87.05% Test: 87.14%\n",
      "Epoch: 46, Loss: 15209.9805, recall: 83.53%, acc: 87.15% Test: 87.26%\n",
      "Epoch: 47, Loss: 15004.1348, recall: 83.98%, acc: 87.26% Test: 87.33%\n",
      "Epoch: 48, Loss: 14936.4238, recall: 84.66%, acc: 87.32% Test: 87.37%\n",
      "Epoch: 49, Loss: 14880.0000, recall: 85.31%, acc: 87.35% Test: 87.41%\n",
      "Epoch: 50, Loss: 14708.2881, recall: 86.21%, acc: 87.38% Test: 87.44%\n",
      "Epoch: 51, Loss: 14552.1953, recall: 87.11%, acc: 87.41% Test: 87.49%\n",
      "Epoch: 52, Loss: 14434.4648, recall: 87.87%, acc: 87.46% Test: 87.53%\n",
      "Epoch: 53, Loss: 14393.8975, recall: 88.21%, acc: 87.50% Test: 87.55%\n",
      "Epoch: 54, Loss: 14288.6152, recall: 88.67%, acc: 87.49% Test: 87.55%\n",
      "Epoch: 55, Loss: 14099.9688, recall: 89.02%, acc: 87.47% Test: 87.53%\n",
      "Epoch: 56, Loss: 13960.8154, recall: 89.55%, acc: 87.46% Test: 87.50%\n",
      "Epoch: 57, Loss: 13848.3037, recall: 89.86%, acc: 87.46% Test: 87.51%\n",
      "Epoch: 58, Loss: 13791.1680, recall: 90.24%, acc: 87.47% Test: 87.51%\n",
      "Epoch: 59, Loss: 13663.9131, recall: 90.60%, acc: 87.50% Test: 87.56%\n",
      "Epoch: 60, Loss: 13496.8105, recall: 90.85%, acc: 87.62% Test: 87.70%\n",
      "Epoch: 61, Loss: 13537.6055, recall: 91.16%, acc: 87.76% Test: 87.84%\n",
      "Epoch: 62, Loss: 13324.4658, recall: 91.34%, acc: 87.89% Test: 87.98%\n",
      "Epoch: 63, Loss: 13309.4453, recall: 91.72%, acc: 87.97% Test: 88.06%\n",
      "Epoch: 64, Loss: 13170.3115, recall: 92.07%, acc: 87.99% Test: 88.09%\n",
      "Epoch: 65, Loss: 13043.6641, recall: 92.44%, acc: 88.00% Test: 88.10%\n",
      "Epoch: 66, Loss: 13029.8906, recall: 92.93%, acc: 87.99% Test: 88.08%\n",
      "Epoch: 67, Loss: 12804.9062, recall: 93.26%, acc: 88.02% Test: 88.09%\n",
      "Epoch: 68, Loss: 12763.5820, recall: 93.54%, acc: 88.08% Test: 88.15%\n",
      "Epoch: 69, Loss: 12800.8623, recall: 93.85%, acc: 88.15% Test: 88.22%\n",
      "Epoch: 70, Loss: 12686.4932, recall: 94.11%, acc: 88.17% Test: 88.24%\n",
      "Epoch: 71, Loss: 12601.9463, recall: 94.41%, acc: 88.16% Test: 88.25%\n",
      "Epoch: 72, Loss: 12483.3682, recall: 94.57%, acc: 88.22% Test: 88.29%\n",
      "Epoch: 73, Loss: 12523.0801, recall: 94.76%, acc: 88.29% Test: 88.35%\n",
      "Epoch: 74, Loss: 12493.9941, recall: 94.82%, acc: 88.35% Test: 88.40%\n",
      "Epoch: 75, Loss: 12297.9365, recall: 94.93%, acc: 88.42% Test: 88.48%\n",
      "Epoch: 76, Loss: 12170.2402, recall: 94.95%, acc: 88.50% Test: 88.55%\n",
      "Epoch: 77, Loss: 12250.6055, recall: 95.03%, acc: 88.58% Test: 88.61%\n",
      "Epoch: 78, Loss: 12148.8965, recall: 95.08%, acc: 88.65% Test: 88.68%\n",
      "Epoch: 79, Loss: 12149.9492, recall: 95.26%, acc: 88.72% Test: 88.78%\n",
      "Epoch: 80, Loss: 11905.1230, recall: 95.39%, acc: 88.81% Test: 88.87%\n",
      "Epoch: 81, Loss: 11891.1699, recall: 95.50%, acc: 88.88% Test: 88.93%\n",
      "Epoch: 82, Loss: 11806.7168, recall: 95.66%, acc: 88.93% Test: 88.97%\n",
      "Epoch: 83, Loss: 11694.0273, recall: 95.78%, acc: 88.97% Test: 89.01%\n",
      "Epoch: 84, Loss: 11803.0234, recall: 96.03%, acc: 89.00% Test: 89.03%\n",
      "Epoch: 85, Loss: 11683.1328, recall: 96.24%, acc: 89.06% Test: 89.07%\n",
      "Epoch: 86, Loss: 11737.1543, recall: 96.44%, acc: 89.09% Test: 89.09%\n",
      "Epoch: 87, Loss: 11613.1758, recall: 96.58%, acc: 89.12% Test: 89.12%\n",
      "Epoch: 88, Loss: 11526.8447, recall: 96.76%, acc: 89.16% Test: 89.17%\n",
      "Epoch: 89, Loss: inf, recall: 58.05%, acc: 76.34% Test: 76.28%\n",
      "Epoch: 90, Loss: nan, recall: 66.40%, acc: 70.17% Test: 70.16%\n",
      "Epoch: 91, Loss: nan, recall: 66.40%, acc: 70.17% Test: 70.16%\n",
      "Epoch: 92, Loss: nan, recall: 66.40%, acc: 70.17% Test: 70.16%\n",
      "Epoch: 93, Loss: nan, recall: 68.84%, acc: 70.19% Test: 70.18%\n",
      "Epoch: 94, Loss: nan, recall: 68.22%, acc: 71.69% Test: 71.68%\n",
      "Epoch: 95, Loss: nan, recall: 68.22%, acc: 71.69% Test: 71.68%\n",
      "Epoch: 96, Loss: nan, recall: 67.46%, acc: 73.18% Test: 73.17%\n",
      "Epoch: 97, Loss: nan, recall: 69.12%, acc: 73.20% Test: 73.19%\n",
      "Epoch: 98, Loss: nan, recall: 69.94%, acc: 74.70% Test: 74.70%\n",
      "Epoch: 99, Loss: nan, recall: 69.82%, acc: 75.20% Test: 75.20%\n",
      "Epoch: 100, Loss: nan, recall: 69.25%, acc: 76.70% Test: 76.69%\n",
      "Epoch: 101, Loss: nan, recall: 69.49%, acc: 77.20% Test: 77.20%\n",
      "Epoch: 102, Loss: nan, recall: 69.36%, acc: 77.70% Test: 77.70%\n",
      "Epoch: 103, Loss: nan, recall: 68.80%, acc: 78.69% Test: 78.69%\n",
      "Epoch: 104, Loss: nan, recall: 68.14%, acc: 80.19% Test: 80.18%\n",
      "Epoch: 105, Loss: nan, recall: 68.14%, acc: 80.19% Test: 80.18%\n",
      "Epoch: 106, Loss: nan, recall: 67.29%, acc: 81.68% Test: 81.67%\n",
      "Epoch: 107, Loss: nan, recall: 66.72%, acc: 83.17% Test: 83.16%\n",
      "Epoch: 108, Loss: nan, recall: 66.37%, acc: 84.17% Test: 84.16%\n",
      "Epoch: 109, Loss: nan, recall: 66.14%, acc: 84.67% Test: 84.66%\n",
      "Epoch: 110, Loss: nan, recall: 66.14%, acc: 84.67% Test: 84.66%\n",
      "Epoch: 111, Loss: nan, recall: 66.14%, acc: 84.67% Test: 84.66%\n",
      "Epoch: 112, Loss: nan, recall: 65.82%, acc: 85.16% Test: 85.16%\n",
      "Epoch: 113, Loss: nan, recall: 65.82%, acc: 85.16% Test: 85.16%\n",
      "Epoch: 114, Loss: nan, recall: 65.82%, acc: 85.16% Test: 85.16%\n",
      "Epoch: 115, Loss: nan, recall: 65.82%, acc: 85.16% Test: 85.16%\n",
      "Epoch: 116, Loss: nan, recall: 65.54%, acc: 85.66% Test: 85.66%\n",
      "Epoch: 117, Loss: nan, recall: 65.54%, acc: 85.66% Test: 85.66%\n",
      "Epoch: 118, Loss: nan, recall: 65.54%, acc: 85.66% Test: 85.66%\n",
      "Epoch: 119, Loss: nan, recall: 65.54%, acc: 85.66% Test: 85.66%\n",
      "Epoch: 120, Loss: nan, recall: 65.29%, acc: 86.16% Test: 86.15%\n",
      "Epoch: 121, Loss: nan, recall: 65.29%, acc: 86.16% Test: 86.15%\n",
      "Epoch: 122, Loss: nan, recall: 65.29%, acc: 86.16% Test: 86.15%\n",
      "Epoch: 123, Loss: nan, recall: 65.29%, acc: 86.16% Test: 86.15%\n",
      "Epoch: 124, Loss: nan, recall: 65.29%, acc: 86.16% Test: 86.15%\n",
      "Epoch: 125, Loss: nan, recall: 65.29%, acc: 86.16% Test: 86.15%\n",
      "Epoch: 126, Loss: nan, recall: 65.29%, acc: 86.16% Test: 86.15%\n",
      "Epoch: 127, Loss: nan, recall: 65.29%, acc: 86.16% Test: 86.15%\n",
      "Epoch: 128, Loss: nan, recall: 65.29%, acc: 86.16% Test: 86.15%\n",
      "Epoch: 129, Loss: nan, recall: 65.29%, acc: 86.16% Test: 86.15%\n",
      "Epoch: 130, Loss: nan, recall: 65.29%, acc: 86.16% Test: 86.15%\n",
      "Epoch: 131, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 132, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 133, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 134, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 135, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 136, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 137, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 138, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 139, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 140, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 141, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 142, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 143, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 144, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 145, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 146, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 147, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 148, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 149, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 150, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 151, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 152, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 153, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 154, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 155, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 156, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 157, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 158, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 159, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 160, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 161, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 162, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 163, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 164, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 165, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 166, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 167, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 168, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 169, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 170, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 171, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 172, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 173, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 174, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 175, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 176, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 177, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 178, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 179, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 180, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 181, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 182, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 183, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 184, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 185, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 186, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 187, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 188, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 189, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 190, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 191, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 192, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 193, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 194, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 195, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 196, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 197, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 198, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 199, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 200, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 201, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 202, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 203, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 204, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 205, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 206, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 207, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 208, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 209, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 210, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 211, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 212, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 213, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 214, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 215, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 216, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 217, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 218, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 219, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 220, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 221, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 222, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 223, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 224, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 225, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 226, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 227, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 228, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 229, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 230, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 231, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 232, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 233, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 234, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 235, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 236, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 237, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 238, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 239, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 240, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 241, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 242, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 243, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 244, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 245, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 246, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 247, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 248, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 249, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 250, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 251, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 252, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 253, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 254, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 255, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 256, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 257, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 258, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 259, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 260, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 261, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 262, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 263, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 264, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 265, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 266, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 267, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 268, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 269, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 270, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 271, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 272, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 273, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 274, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 275, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 276, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 277, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 278, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 279, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 280, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 281, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 282, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 283, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 284, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 285, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 286, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 287, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 288, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 289, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 290, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 291, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 292, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 293, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 294, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 295, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 296, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 297, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 298, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 299, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 300, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 301, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 302, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 303, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 304, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 305, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 306, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 307, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 308, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 309, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 310, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 311, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 312, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 313, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 314, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 315, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 316, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 317, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 318, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 319, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 320, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 321, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 322, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 323, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 324, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 325, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 326, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 327, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 328, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 329, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 330, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 331, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 332, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 333, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 334, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 335, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 336, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 337, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 338, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 339, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 340, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 341, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 342, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 343, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 344, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 345, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 346, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 347, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 348, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 349, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 350, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 351, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 352, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 353, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 354, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 355, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 356, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 357, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 358, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 359, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 360, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 361, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 362, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 363, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 364, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 365, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 366, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 367, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 368, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 369, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 370, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 371, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 372, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 373, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 374, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 375, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 376, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 377, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 378, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 379, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 380, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 381, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 382, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 383, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 384, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 385, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 386, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 387, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 388, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 389, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 390, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 391, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 392, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 393, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 394, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 395, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 396, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 397, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 398, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 399, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 400, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 401, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 402, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 403, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 404, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 405, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 406, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 407, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 408, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 409, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 410, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 411, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 412, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 413, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 414, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 415, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 416, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 417, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 418, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 419, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 420, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 421, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 422, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 423, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 424, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 425, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 426, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 427, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 428, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 429, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 430, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 431, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 432, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 433, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 434, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 435, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 436, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 437, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 438, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 439, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 440, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 441, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 442, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 443, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 444, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 445, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 446, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 447, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 448, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 449, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 450, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 451, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 452, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 453, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 454, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 455, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 456, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 457, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 458, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 459, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 460, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 461, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 462, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 463, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 464, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 465, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 466, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 467, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 468, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 469, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 470, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 471, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 472, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 473, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 474, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 475, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 476, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 477, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 478, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 479, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 480, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 481, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 482, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 483, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 484, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 485, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 486, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 487, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 488, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 489, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 490, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 491, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 492, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 493, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 494, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 495, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 496, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 497, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 498, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 499, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 500, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 501, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 502, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 503, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 504, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 505, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 506, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 507, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 508, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 509, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 510, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 511, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 512, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 513, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 514, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 515, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 516, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 517, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 518, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 519, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 520, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 521, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 522, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 523, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 524, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 525, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 526, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 527, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 528, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 529, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 530, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 531, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 532, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 533, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 534, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 535, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 536, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 537, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 538, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 539, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 540, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 541, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 542, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 543, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 544, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 545, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 546, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 547, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 548, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 549, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 550, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 551, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 552, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 553, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 554, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 555, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 556, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 557, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 558, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 559, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 560, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 561, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 562, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 563, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 564, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 565, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 566, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 567, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 568, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 569, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 570, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 571, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 572, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 573, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 574, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 575, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 576, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 577, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 578, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 579, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 580, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 581, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 582, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 583, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 584, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 585, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 586, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 587, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 588, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 589, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 590, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 591, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 592, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 593, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 594, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 595, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 596, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 597, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 598, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 599, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 600, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 601, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 602, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 603, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 604, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 605, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 606, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 607, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 608, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 609, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 610, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 611, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 612, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 613, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 614, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 615, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 616, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 617, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 618, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 619, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 620, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 621, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 622, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 623, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 624, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 625, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 626, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 627, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 628, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 629, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 630, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 631, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 632, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 633, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 634, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 635, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 636, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 637, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 638, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 639, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 640, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 641, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 642, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 643, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 644, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 645, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 646, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 647, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 648, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 649, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 650, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 651, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 652, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 653, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 654, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 655, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 656, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 657, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 658, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 659, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 660, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 661, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 662, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 663, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 664, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 665, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 666, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 667, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 668, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 669, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 670, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 671, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 672, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 673, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 674, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 675, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 676, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 677, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 678, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 679, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 680, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 681, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 682, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 683, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 684, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 685, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 686, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 687, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 688, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 689, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 690, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 691, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 692, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 693, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 694, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 695, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 696, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 697, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 698, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 699, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 700, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 701, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 702, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 703, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 704, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 705, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 706, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 707, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 708, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 709, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 710, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 711, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 712, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 713, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 714, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 715, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 716, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 717, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 718, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 719, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 720, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 721, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 722, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 723, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 724, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 725, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 726, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 727, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 728, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 729, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 730, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 731, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 732, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 733, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 734, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 735, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 736, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 737, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 738, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 739, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 740, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 741, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 742, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 743, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 744, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 745, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 746, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 747, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 748, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 749, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 750, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 751, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 752, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 753, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 754, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 755, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 756, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 757, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 758, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 759, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 760, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 761, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 762, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 763, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 764, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 765, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 766, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 767, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 768, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 769, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 770, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 771, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 772, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 773, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 774, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 775, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 776, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 777, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 778, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 779, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 780, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 781, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 782, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 783, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 784, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 785, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 786, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 787, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 788, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 789, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 790, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 791, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 792, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 793, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 794, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 795, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 796, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 797, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 798, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 799, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 800, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 801, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 802, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 803, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 804, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 805, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 806, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 807, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 808, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 809, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 810, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 811, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 812, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 813, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 814, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 815, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 816, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 817, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 818, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 819, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 820, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 821, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 822, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 823, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 824, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 825, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 826, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 827, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 828, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 829, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 830, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 831, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 832, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 833, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 834, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 835, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 836, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 837, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 838, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 839, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 840, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 841, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 842, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 843, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 844, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 845, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 846, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 847, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 848, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 849, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 850, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 851, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 852, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 853, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 854, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 855, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 856, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 857, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 858, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 859, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 860, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 861, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 862, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 863, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 864, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 865, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 866, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 867, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 868, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 869, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 870, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 871, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 872, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 873, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 874, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 875, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 876, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 877, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 878, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 879, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 880, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 881, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 882, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 883, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 884, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 885, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 886, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 887, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 888, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 889, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 890, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 891, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 892, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 893, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 894, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 895, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 896, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 897, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 898, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 899, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 900, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 901, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 902, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 903, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 904, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 905, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 906, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 907, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 908, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 909, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 910, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 911, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 912, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 913, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 914, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 915, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 916, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 917, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 918, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 919, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 920, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 921, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 922, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 923, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 924, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 925, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 926, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 927, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 928, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 929, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 930, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 931, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 932, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 933, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 934, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 935, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 936, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 937, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 938, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 939, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 940, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 941, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 942, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 943, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 944, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 945, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 946, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 947, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 948, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 949, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 950, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 951, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 952, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 953, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 954, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 955, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 956, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 957, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 958, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 959, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 960, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 961, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 962, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 963, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 964, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 965, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 966, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 967, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 968, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 969, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 970, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 971, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 972, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 973, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 974, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 975, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 976, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 977, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 978, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 979, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 980, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 981, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 982, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 983, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 984, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 985, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 986, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 987, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 988, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 989, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 990, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 991, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 992, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 993, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 994, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 995, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 996, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 997, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 998, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 999, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n",
      "Epoch: 1000, Loss: nan, recall: 64.79%, acc: 86.65% Test: 86.65%\n"
     ]
    }
   ],
   "source": [
    "mlp_model.reset_parameters()\n",
    "\n",
    "optimizer = torch.optim.Adam(mlp_model.parameters(), lr=mlp_args['lr'])\n",
    "loss_fn = weighted_BCE(reduction=\"sum\" , true_weight=1.8 , false_weight=0.01)\n",
    "\n",
    "best_model = None\n",
    "best_valid_acc = 0\n",
    "\n",
    "for epoch in range(1, 1 + mlp_args[\"epochs\"]):\n",
    "  \n",
    "  loss = train_mlp(mlp_model , data , optimizer, loss_fn)\n",
    "  result = test_mlp(mlp_model, data)\n",
    "\n",
    "  c_train , c_val , c_test = result\n",
    "\n",
    "  if acc(c_val) > best_valid_acc:\n",
    "      best_valid_acc = acc(c_val)\n",
    "      best_model = copy.deepcopy(mlp_model)\n",
    "        \n",
    "  mlp_logger.info(f'Epoch {epoch:02d} '\n",
    "      f'Loss {loss:.4f} '\n",
    "      f'Train {c_train[0][0]:02d} {c_train[0][1]:02d} {c_train[1][0]:02d} {c_train[1][1]:02d} '\n",
    "      f'Valid {c_val[0][0]:02d} {c_val[0][1]:02d} {c_val[1][0]:02d} {c_val[1][1]:02d} '\n",
    "      f'Test {c_val[0][0]:02d} {c_val[0][1]:02d} {c_val[1][0]:02d} {c_val[1][1]:02d} ')\n",
    "  \n",
    "  print((f'Epoch: {epoch:02d}, '\n",
    "        f'Loss: {loss:.4f}, '\n",
    "        f'recall: {100 * recall(c_train):.2f}%, '\n",
    "        f'acc: {100 * acc(c_train):.2f}% '\n",
    "        f'Test: {100 * acc(c_test):.2f}%'))\n",
    "  \n",
    "handlers = mlp_logger.handlers[:]\n",
    "for handler in handlers:\n",
    "    mlp_logger.removeHandler(handler)\n",
    "    handler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.3765197568389"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_valid_acc*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(best_model , \"../models/mlp_1_200.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN model with MLP layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_dim': 16,\n",
       " 'encoding_dim': 16,\n",
       " 'num_layers': 4,\n",
       " 'dropout': 0.2,\n",
       " 'lr': 0.005,\n",
       " 'epochs': 1000}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_gcn_args = {\n",
    "    \"hidden_dim\":16,\n",
    "    \"encoding_dim\":16,\n",
    "    \"num_layers\":4,\n",
    "    \"dropout\":0.2,\n",
    "    \"lr\":0.005,\n",
    "    \"epochs\":1000\n",
    "}\n",
    "\n",
    "mlp_gcn_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN model with MLP layers number of parameters: 5208\n"
     ]
    }
   ],
   "source": [
    "mlp_gcn_model = mlp_GCN(input_dim = data.x.shape[1], encoding_dim = mlp_gcn_args[\"encoding_dim\"] , hidden_dim = mlp_gcn_args[\"hidden_dim\"], output_dim = data.y.shape[1], num_layers = mlp_gcn_args[\"num_layers\"], dropout = mlp_gcn_args['dropout']).to(device)\n",
    "\n",
    "total_params_mlp_gcn = sum(\n",
    "\tparam.numel() for param in mlp_gcn_model.parameters()\n",
    ")\n",
    "print(\"GCN model with MLP layers number of parameters:\" , total_params_mlp_gcn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 23539.3711, Recall: 66.24%, Valid: 54.08% Test: 54.06%\n",
      "Epoch: 02, Loss: 23231.8770, Recall: 67.15%, Valid: 54.96% Test: 54.99%\n",
      "Epoch: 03, Loss: 22977.9414, Recall: 67.52%, Valid: 56.36% Test: 56.38%\n",
      "Epoch: 04, Loss: 22712.5957, Recall: 68.31%, Valid: 57.83% Test: 57.82%\n",
      "Epoch: 05, Loss: 22480.7344, Recall: 70.18%, Valid: 58.94% Test: 58.93%\n",
      "Epoch: 06, Loss: 22190.2754, Recall: 73.77%, Valid: 59.88% Test: 59.91%\n",
      "Epoch: 07, Loss: 21893.7715, Recall: 74.55%, Valid: 61.22% Test: 61.25%\n",
      "Epoch: 08, Loss: 21591.1289, Recall: 74.45%, Valid: 63.15% Test: 63.20%\n",
      "Epoch: 09, Loss: 21280.4922, Recall: 74.21%, Valid: 65.73% Test: 65.72%\n",
      "Epoch: 10, Loss: 20959.5156, Recall: 73.90%, Valid: 68.79% Test: 68.80%\n",
      "Epoch: 11, Loss: 20608.9453, Recall: 73.71%, Valid: 72.04% Test: 72.02%\n",
      "Epoch: 12, Loss: 20241.2852, Recall: 73.38%, Valid: 75.28% Test: 75.30%\n",
      "Epoch: 13, Loss: 19926.0254, Recall: 73.18%, Valid: 78.27% Test: 78.25%\n",
      "Epoch: 14, Loss: 19588.2910, Recall: 73.08%, Valid: 80.75% Test: 80.74%\n",
      "Epoch: 15, Loss: 19254.6641, Recall: 73.03%, Valid: 82.69% Test: 82.72%\n",
      "Epoch: 16, Loss: 18946.2031, Recall: 72.45%, Valid: 84.20% Test: 84.22%\n",
      "Epoch: 17, Loss: 18626.1465, Recall: 71.91%, Valid: 85.42% Test: 85.41%\n",
      "Epoch: 18, Loss: 18341.7051, Recall: 71.45%, Valid: 86.35% Test: 86.35%\n",
      "Epoch: 19, Loss: 18074.0234, Recall: 71.40%, Valid: 87.05% Test: 87.06%\n",
      "Epoch: 20, Loss: 17825.6777, Recall: 71.36%, Valid: 87.61% Test: 87.61%\n",
      "Epoch: 21, Loss: 17601.6680, Recall: 71.11%, Valid: 88.01% Test: 88.00%\n",
      "Epoch: 22, Loss: 17391.1328, Recall: 70.96%, Valid: 88.26% Test: 88.27%\n",
      "Epoch: 23, Loss: 17231.7207, Recall: 70.93%, Valid: 88.42% Test: 88.43%\n",
      "Epoch: 24, Loss: 17077.6016, Recall: 70.82%, Valid: 88.54% Test: 88.55%\n",
      "Epoch: 25, Loss: 16939.5312, Recall: 70.79%, Valid: 88.65% Test: 88.66%\n",
      "Epoch: 26, Loss: 16814.6055, Recall: 70.92%, Valid: 88.77% Test: 88.78%\n",
      "Epoch: 27, Loss: 16689.9844, Recall: 71.04%, Valid: 88.90% Test: 88.88%\n",
      "Epoch: 28, Loss: 16631.5859, Recall: 71.27%, Valid: 89.00% Test: 88.98%\n",
      "Epoch: 29, Loss: 16544.1426, Recall: 71.52%, Valid: 89.08% Test: 89.06%\n",
      "Epoch: 30, Loss: 16454.5723, Recall: 71.88%, Valid: 89.14% Test: 89.12%\n",
      "Epoch: 31, Loss: 16401.4062, Recall: 72.44%, Valid: 89.19% Test: 89.18%\n",
      "Epoch: 32, Loss: 16351.4033, Recall: 72.91%, Valid: 89.23% Test: 89.23%\n",
      "Epoch: 33, Loss: 16277.7568, Recall: 73.22%, Valid: 89.29% Test: 89.28%\n",
      "Epoch: 34, Loss: 16237.1816, Recall: 73.54%, Valid: 89.35% Test: 89.36%\n",
      "Epoch: 35, Loss: 16175.9639, Recall: 73.79%, Valid: 89.42% Test: 89.44%\n",
      "Epoch: 36, Loss: 16138.3721, Recall: 74.36%, Valid: 89.50% Test: 89.52%\n",
      "Epoch: 37, Loss: 16087.8027, Recall: 74.64%, Valid: 89.58% Test: 89.59%\n",
      "Epoch: 38, Loss: 16026.5547, Recall: 74.73%, Valid: 89.65% Test: 89.66%\n",
      "Epoch: 39, Loss: 15977.8057, Recall: 75.06%, Valid: 89.75% Test: 89.75%\n",
      "Epoch: 40, Loss: 15955.3086, Recall: 75.32%, Valid: 89.83% Test: 89.84%\n",
      "Epoch: 41, Loss: 15895.8311, Recall: 75.64%, Valid: 89.92% Test: 89.93%\n",
      "Epoch: 42, Loss: 15876.0537, Recall: 76.25%, Valid: 90.00% Test: 90.00%\n",
      "Epoch: 43, Loss: 15821.3496, Recall: 76.89%, Valid: 90.06% Test: 90.08%\n",
      "Epoch: 44, Loss: 15763.5400, Recall: 77.38%, Valid: 90.11% Test: 90.13%\n",
      "Epoch: 45, Loss: 15710.0244, Recall: 77.70%, Valid: 90.15% Test: 90.17%\n",
      "Epoch: 46, Loss: 15670.6885, Recall: 78.12%, Valid: 90.18% Test: 90.19%\n",
      "Epoch: 47, Loss: 15629.7686, Recall: 78.23%, Valid: 90.20% Test: 90.20%\n",
      "Epoch: 48, Loss: 15594.8086, Recall: 78.55%, Valid: 90.25% Test: 90.24%\n",
      "Epoch: 49, Loss: 15568.8105, Recall: 79.16%, Valid: 90.29% Test: 90.28%\n",
      "Epoch: 50, Loss: 15514.4746, Recall: 79.43%, Valid: 90.39% Test: 90.37%\n",
      "Epoch: 51, Loss: 15487.0254, Recall: 79.58%, Valid: 90.51% Test: 90.49%\n",
      "Epoch: 52, Loss: 15437.7812, Recall: 79.67%, Valid: 90.65% Test: 90.63%\n",
      "Epoch: 53, Loss: 15425.4268, Recall: 79.73%, Valid: 90.80% Test: 90.77%\n",
      "Epoch: 54, Loss: 15349.4854, Recall: 79.68%, Valid: 90.94% Test: 90.88%\n",
      "Epoch: 55, Loss: 15321.3594, Recall: 79.69%, Valid: 91.04% Test: 90.99%\n",
      "Epoch: 56, Loss: 15285.1836, Recall: 79.79%, Valid: 91.12% Test: 91.09%\n",
      "Epoch: 57, Loss: 15251.4092, Recall: 79.81%, Valid: 91.18% Test: 91.16%\n",
      "Epoch: 58, Loss: 15182.9551, Recall: 79.92%, Valid: 91.26% Test: 91.23%\n",
      "Epoch: 59, Loss: 15148.1465, Recall: 79.86%, Valid: 91.33% Test: 91.32%\n",
      "Epoch: 60, Loss: 15126.4316, Recall: 79.94%, Valid: 91.38% Test: 91.37%\n",
      "Epoch: 61, Loss: 15045.2500, Recall: 80.19%, Valid: 91.41% Test: 91.41%\n",
      "Epoch: 62, Loss: 15045.8467, Recall: 80.58%, Valid: 91.43% Test: 91.42%\n",
      "Epoch: 63, Loss: 14996.9434, Recall: 81.23%, Valid: 91.42% Test: 91.41%\n",
      "Epoch: 64, Loss: 14981.8262, Recall: 82.47%, Valid: 91.36% Test: 91.36%\n",
      "Epoch: 65, Loss: 14931.1250, Recall: 83.26%, Valid: 91.30% Test: 91.30%\n",
      "Epoch: 66, Loss: 14913.5469, Recall: 83.47%, Valid: 91.30% Test: 91.31%\n",
      "Epoch: 67, Loss: 14862.8203, Recall: 83.66%, Valid: 91.34% Test: 91.32%\n",
      "Epoch: 68, Loss: 14857.1973, Recall: 83.58%, Valid: 91.40% Test: 91.38%\n",
      "Epoch: 69, Loss: 14822.6426, Recall: 83.50%, Valid: 91.45% Test: 91.42%\n",
      "Epoch: 70, Loss: 14779.3760, Recall: 83.58%, Valid: 91.47% Test: 91.43%\n",
      "Epoch: 71, Loss: 14746.9414, Recall: 83.62%, Valid: 91.45% Test: 91.41%\n",
      "Epoch: 72, Loss: 14723.6514, Recall: 83.97%, Valid: 91.44% Test: 91.39%\n",
      "Epoch: 73, Loss: 14672.7285, Recall: 84.08%, Valid: 91.47% Test: 91.42%\n",
      "Epoch: 74, Loss: 14671.2207, Recall: 84.09%, Valid: 91.49% Test: 91.47%\n",
      "Epoch: 75, Loss: 14629.9844, Recall: 84.01%, Valid: 91.53% Test: 91.49%\n",
      "Epoch: 76, Loss: 14625.9766, Recall: 84.37%, Valid: 91.54% Test: 91.51%\n",
      "Epoch: 77, Loss: 14598.8398, Recall: 84.83%, Valid: 91.56% Test: 91.51%\n",
      "Epoch: 78, Loss: 14552.2754, Recall: 85.35%, Valid: 91.61% Test: 91.56%\n",
      "Epoch: 79, Loss: 14563.1562, Recall: 85.69%, Valid: 91.68% Test: 91.62%\n",
      "Epoch: 80, Loss: 14509.7334, Recall: 85.96%, Valid: 91.72% Test: 91.67%\n",
      "Epoch: 81, Loss: 14511.8418, Recall: 86.15%, Valid: 91.79% Test: 91.74%\n",
      "Epoch: 82, Loss: 14480.5742, Recall: 86.48%, Valid: 91.81% Test: 91.76%\n",
      "Epoch: 83, Loss: 14468.6260, Recall: 86.65%, Valid: 91.88% Test: 91.81%\n",
      "Epoch: 84, Loss: 14437.6562, Recall: 86.75%, Valid: 91.94% Test: 91.89%\n",
      "Epoch: 85, Loss: 14412.2773, Recall: 86.87%, Valid: 92.00% Test: 91.95%\n",
      "Epoch: 86, Loss: 14385.1533, Recall: 87.02%, Valid: 92.08% Test: 92.02%\n",
      "Epoch: 87, Loss: 14386.0352, Recall: 87.03%, Valid: 92.13% Test: 92.08%\n",
      "Epoch: 88, Loss: 14361.2422, Recall: 87.06%, Valid: 92.14% Test: 92.10%\n",
      "Epoch: 89, Loss: 14331.0957, Recall: 87.20%, Valid: 92.17% Test: 92.10%\n",
      "Epoch: 90, Loss: 14295.5938, Recall: 87.27%, Valid: 92.18% Test: 92.14%\n",
      "Epoch: 91, Loss: 14309.0498, Recall: 87.34%, Valid: 92.22% Test: 92.20%\n",
      "Epoch: 92, Loss: 14291.3242, Recall: 87.35%, Valid: 92.28% Test: 92.24%\n",
      "Epoch: 93, Loss: 14226.9668, Recall: 87.43%, Valid: 92.30% Test: 92.24%\n",
      "Epoch: 94, Loss: 14257.5400, Recall: 87.40%, Valid: 92.33% Test: 92.27%\n",
      "Epoch: 95, Loss: 14217.2773, Recall: 87.41%, Valid: 92.35% Test: 92.28%\n",
      "Epoch: 96, Loss: 14231.4053, Recall: 87.41%, Valid: 92.41% Test: 92.33%\n",
      "Epoch: 97, Loss: 14204.6826, Recall: 87.49%, Valid: 92.44% Test: 92.36%\n",
      "Epoch: 98, Loss: 14170.0762, Recall: 87.55%, Valid: 92.47% Test: 92.40%\n",
      "Epoch: 99, Loss: 14167.9053, Recall: 87.68%, Valid: 92.48% Test: 92.42%\n",
      "Epoch: 100, Loss: 14155.6279, Recall: 87.80%, Valid: 92.53% Test: 92.47%\n",
      "Epoch: 101, Loss: 14117.4688, Recall: 87.86%, Valid: 92.60% Test: 92.53%\n",
      "Epoch: 102, Loss: 14128.1465, Recall: 87.85%, Valid: 92.66% Test: 92.59%\n",
      "Epoch: 103, Loss: 14121.8975, Recall: 87.78%, Valid: 92.73% Test: 92.65%\n",
      "Epoch: 104, Loss: 14100.0039, Recall: 87.86%, Valid: 92.77% Test: 92.68%\n",
      "Epoch: 105, Loss: 14069.6289, Recall: 88.03%, Valid: 92.77% Test: 92.69%\n",
      "Epoch: 106, Loss: 14081.8125, Recall: 88.05%, Valid: 92.74% Test: 92.68%\n",
      "Epoch: 107, Loss: 14027.5879, Recall: 88.04%, Valid: 92.81% Test: 92.73%\n",
      "Epoch: 108, Loss: 14070.6016, Recall: 88.12%, Valid: 92.89% Test: 92.80%\n",
      "Epoch: 109, Loss: 14063.2852, Recall: 88.15%, Valid: 92.92% Test: 92.84%\n",
      "Epoch: 110, Loss: 13992.9453, Recall: 88.31%, Valid: 92.94% Test: 92.87%\n",
      "Epoch: 111, Loss: 14023.0918, Recall: 88.39%, Valid: 92.96% Test: 92.90%\n",
      "Epoch: 112, Loss: 14004.3906, Recall: 88.51%, Valid: 92.98% Test: 92.93%\n",
      "Epoch: 113, Loss: 13961.8711, Recall: 88.44%, Valid: 93.04% Test: 92.98%\n",
      "Epoch: 114, Loss: 13985.7520, Recall: 88.40%, Valid: 93.07% Test: 93.00%\n",
      "Epoch: 115, Loss: 13978.5107, Recall: 88.54%, Valid: 93.06% Test: 92.98%\n",
      "Epoch: 116, Loss: 13972.7559, Recall: 88.48%, Valid: 93.09% Test: 93.03%\n",
      "Epoch: 117, Loss: 13966.5039, Recall: 88.57%, Valid: 93.15% Test: 93.08%\n",
      "Epoch: 118, Loss: 13960.8301, Recall: 88.50%, Valid: 93.20% Test: 93.14%\n",
      "Epoch: 119, Loss: 13923.1084, Recall: 88.44%, Valid: 93.23% Test: 93.16%\n",
      "Epoch: 120, Loss: 13900.3340, Recall: 88.38%, Valid: 93.27% Test: 93.19%\n",
      "Epoch: 121, Loss: 13902.2051, Recall: 88.37%, Valid: 93.29% Test: 93.20%\n",
      "Epoch: 122, Loss: 13881.7051, Recall: 88.47%, Valid: 93.33% Test: 93.23%\n",
      "Epoch: 123, Loss: 13877.7969, Recall: 88.39%, Valid: 93.36% Test: 93.26%\n",
      "Epoch: 124, Loss: 13841.7383, Recall: 88.48%, Valid: 93.35% Test: 93.25%\n",
      "Epoch: 125, Loss: 13868.0840, Recall: 88.69%, Valid: 93.32% Test: 93.23%\n",
      "Epoch: 126, Loss: 13864.9043, Recall: 88.73%, Valid: 93.30% Test: 93.20%\n",
      "Epoch: 127, Loss: 13833.3867, Recall: 88.88%, Valid: 93.29% Test: 93.20%\n",
      "Epoch: 128, Loss: 13833.9473, Recall: 88.87%, Valid: 93.30% Test: 93.21%\n",
      "Epoch: 129, Loss: 13820.0508, Recall: 88.82%, Valid: 93.32% Test: 93.22%\n",
      "Epoch: 130, Loss: 13831.2441, Recall: 88.84%, Valid: 93.36% Test: 93.27%\n",
      "Epoch: 131, Loss: 13834.4521, Recall: 88.83%, Valid: 93.36% Test: 93.27%\n",
      "Epoch: 132, Loss: 13813.4150, Recall: 88.90%, Valid: 93.34% Test: 93.25%\n",
      "Epoch: 133, Loss: 13789.2383, Recall: 89.02%, Valid: 93.35% Test: 93.26%\n",
      "Epoch: 134, Loss: 13779.5742, Recall: 89.10%, Valid: 93.36% Test: 93.26%\n",
      "Epoch: 135, Loss: 13791.1982, Recall: 89.06%, Valid: 93.37% Test: 93.27%\n",
      "Epoch: 136, Loss: 13775.1094, Recall: 89.07%, Valid: 93.38% Test: 93.28%\n",
      "Epoch: 137, Loss: 13766.3945, Recall: 89.12%, Valid: 93.41% Test: 93.29%\n",
      "Epoch: 138, Loss: 13777.7246, Recall: 89.10%, Valid: 93.42% Test: 93.31%\n",
      "Epoch: 139, Loss: 13754.9590, Recall: 89.08%, Valid: 93.46% Test: 93.36%\n",
      "Epoch: 140, Loss: 13763.9512, Recall: 89.08%, Valid: 93.49% Test: 93.39%\n",
      "Epoch: 141, Loss: 13738.6758, Recall: 89.14%, Valid: 93.51% Test: 93.42%\n",
      "Epoch: 142, Loss: 13695.8604, Recall: 89.16%, Valid: 93.54% Test: 93.44%\n",
      "Epoch: 143, Loss: 13709.1729, Recall: 89.32%, Valid: 93.58% Test: 93.46%\n",
      "Epoch: 144, Loss: 13714.8359, Recall: 89.39%, Valid: 93.55% Test: 93.44%\n",
      "Epoch: 145, Loss: 13723.2822, Recall: 89.40%, Valid: 93.53% Test: 93.42%\n",
      "Epoch: 146, Loss: 13663.9600, Recall: 89.53%, Valid: 93.54% Test: 93.44%\n",
      "Epoch: 147, Loss: 13707.5020, Recall: 89.67%, Valid: 93.55% Test: 93.46%\n",
      "Epoch: 148, Loss: 13675.1670, Recall: 89.62%, Valid: 93.58% Test: 93.49%\n",
      "Epoch: 149, Loss: 13675.1729, Recall: 89.62%, Valid: 93.62% Test: 93.52%\n",
      "Epoch: 150, Loss: 13690.4863, Recall: 89.65%, Valid: 93.64% Test: 93.54%\n",
      "Epoch: 151, Loss: 13666.0420, Recall: 89.63%, Valid: 93.65% Test: 93.54%\n",
      "Epoch: 152, Loss: 13664.9922, Recall: 89.58%, Valid: 93.60% Test: 93.49%\n",
      "Epoch: 153, Loss: 13657.3467, Recall: 89.59%, Valid: 93.62% Test: 93.51%\n",
      "Epoch: 154, Loss: 13649.7852, Recall: 89.54%, Valid: 93.68% Test: 93.56%\n",
      "Epoch: 155, Loss: 13648.3320, Recall: 89.53%, Valid: 93.71% Test: 93.61%\n",
      "Epoch: 156, Loss: 13676.9785, Recall: 89.57%, Valid: 93.75% Test: 93.65%\n",
      "Epoch: 157, Loss: 13627.8564, Recall: 89.58%, Valid: 93.76% Test: 93.65%\n",
      "Epoch: 158, Loss: 13626.9863, Recall: 89.62%, Valid: 93.77% Test: 93.65%\n",
      "Epoch: 159, Loss: 13624.1348, Recall: 89.62%, Valid: 93.79% Test: 93.66%\n",
      "Epoch: 160, Loss: 13615.5020, Recall: 89.51%, Valid: 93.80% Test: 93.68%\n",
      "Epoch: 161, Loss: 13607.4561, Recall: 89.57%, Valid: 93.81% Test: 93.68%\n",
      "Epoch: 162, Loss: 13603.8838, Recall: 89.73%, Valid: 93.79% Test: 93.65%\n",
      "Epoch: 163, Loss: 13613.0146, Recall: 89.67%, Valid: 93.77% Test: 93.63%\n",
      "Epoch: 164, Loss: 13611.3262, Recall: 89.62%, Valid: 93.73% Test: 93.60%\n",
      "Epoch: 165, Loss: 13621.8848, Recall: 89.69%, Valid: 93.73% Test: 93.63%\n",
      "Epoch: 166, Loss: 13586.1924, Recall: 89.72%, Valid: 93.76% Test: 93.66%\n",
      "Epoch: 167, Loss: 13593.6367, Recall: 89.76%, Valid: 93.80% Test: 93.68%\n",
      "Epoch: 168, Loss: 13571.1719, Recall: 89.78%, Valid: 93.82% Test: 93.70%\n",
      "Epoch: 169, Loss: 13583.5645, Recall: 89.85%, Valid: 93.82% Test: 93.69%\n",
      "Epoch: 170, Loss: 13552.4746, Recall: 89.87%, Valid: 93.84% Test: 93.70%\n",
      "Epoch: 171, Loss: 13616.2744, Recall: 89.94%, Valid: 93.86% Test: 93.70%\n",
      "Epoch: 172, Loss: 13526.9219, Recall: 89.95%, Valid: 93.89% Test: 93.74%\n",
      "Epoch: 173, Loss: 13522.9150, Recall: 89.97%, Valid: 93.92% Test: 93.77%\n",
      "Epoch: 174, Loss: 13508.2402, Recall: 89.98%, Valid: 93.98% Test: 93.84%\n",
      "Epoch: 175, Loss: 13551.6650, Recall: 89.96%, Valid: 94.02% Test: 93.88%\n",
      "Epoch: 176, Loss: 13538.7646, Recall: 89.97%, Valid: 94.05% Test: 93.93%\n",
      "Epoch: 177, Loss: 13521.4873, Recall: 90.07%, Valid: 94.06% Test: 93.95%\n",
      "Epoch: 178, Loss: 13513.9844, Recall: 90.03%, Valid: 94.09% Test: 94.00%\n",
      "Epoch: 179, Loss: 13502.7559, Recall: 89.96%, Valid: 94.08% Test: 93.98%\n",
      "Epoch: 180, Loss: 13497.5059, Recall: 89.99%, Valid: 94.08% Test: 93.97%\n",
      "Epoch: 181, Loss: 13509.6133, Recall: 90.01%, Valid: 94.09% Test: 93.97%\n",
      "Epoch: 182, Loss: 13506.0996, Recall: 89.98%, Valid: 94.11% Test: 93.98%\n",
      "Epoch: 183, Loss: 13484.4541, Recall: 90.05%, Valid: 94.12% Test: 94.00%\n",
      "Epoch: 184, Loss: 13487.0156, Recall: 90.11%, Valid: 94.12% Test: 94.00%\n",
      "Epoch: 185, Loss: 13469.1406, Recall: 90.10%, Valid: 94.12% Test: 94.01%\n",
      "Epoch: 186, Loss: 13463.5391, Recall: 90.03%, Valid: 94.12% Test: 94.00%\n",
      "Epoch: 187, Loss: 13480.6768, Recall: 89.93%, Valid: 94.13% Test: 94.00%\n",
      "Epoch: 188, Loss: 13465.2842, Recall: 90.06%, Valid: 94.15% Test: 94.01%\n",
      "Epoch: 189, Loss: 13471.4355, Recall: 90.14%, Valid: 94.17% Test: 94.05%\n",
      "Epoch: 190, Loss: 13482.5781, Recall: 90.12%, Valid: 94.18% Test: 94.05%\n",
      "Epoch: 191, Loss: 13489.1016, Recall: 90.15%, Valid: 94.19% Test: 94.06%\n",
      "Epoch: 192, Loss: 13475.2930, Recall: 90.18%, Valid: 94.21% Test: 94.05%\n",
      "Epoch: 193, Loss: 13439.0020, Recall: 90.01%, Valid: 94.22% Test: 94.09%\n",
      "Epoch: 194, Loss: 13458.6074, Recall: 89.98%, Valid: 94.25% Test: 94.12%\n",
      "Epoch: 195, Loss: 13431.7334, Recall: 89.99%, Valid: 94.29% Test: 94.15%\n",
      "Epoch: 196, Loss: 13434.3281, Recall: 90.11%, Valid: 94.31% Test: 94.17%\n",
      "Epoch: 197, Loss: 13476.4004, Recall: 90.18%, Valid: 94.33% Test: 94.17%\n",
      "Epoch: 198, Loss: 13430.4590, Recall: 90.20%, Valid: 94.33% Test: 94.18%\n",
      "Epoch: 199, Loss: 13495.5859, Recall: 90.24%, Valid: 94.33% Test: 94.18%\n",
      "Epoch: 200, Loss: 13447.1855, Recall: 90.17%, Valid: 94.33% Test: 94.20%\n",
      "Epoch: 201, Loss: 13425.5156, Recall: 90.12%, Valid: 94.35% Test: 94.21%\n",
      "Epoch: 202, Loss: 13440.8701, Recall: 90.02%, Valid: 94.39% Test: 94.26%\n",
      "Epoch: 203, Loss: 13425.0498, Recall: 89.99%, Valid: 94.43% Test: 94.28%\n",
      "Epoch: 204, Loss: 13425.4434, Recall: 90.16%, Valid: 94.45% Test: 94.30%\n",
      "Epoch: 205, Loss: 13440.0176, Recall: 90.23%, Valid: 94.42% Test: 94.29%\n",
      "Epoch: 206, Loss: 13428.5801, Recall: 90.27%, Valid: 94.38% Test: 94.26%\n",
      "Epoch: 207, Loss: 13386.0195, Recall: 90.30%, Valid: 94.39% Test: 94.26%\n",
      "Epoch: 208, Loss: 13430.8770, Recall: 90.34%, Valid: 94.39% Test: 94.26%\n",
      "Epoch: 209, Loss: 13401.8848, Recall: 90.33%, Valid: 94.41% Test: 94.28%\n",
      "Epoch: 210, Loss: 13402.6777, Recall: 90.34%, Valid: 94.41% Test: 94.28%\n",
      "Epoch: 211, Loss: 13398.4639, Recall: 90.28%, Valid: 94.42% Test: 94.29%\n",
      "Epoch: 212, Loss: 13422.6055, Recall: 90.26%, Valid: 94.42% Test: 94.30%\n",
      "Epoch: 213, Loss: 13413.6445, Recall: 90.23%, Valid: 94.39% Test: 94.27%\n",
      "Epoch: 214, Loss: 13409.2607, Recall: 90.23%, Valid: 94.39% Test: 94.28%\n",
      "Epoch: 215, Loss: 13397.2930, Recall: 90.22%, Valid: 94.40% Test: 94.29%\n",
      "Epoch: 216, Loss: 13390.8828, Recall: 90.19%, Valid: 94.41% Test: 94.28%\n",
      "Epoch: 217, Loss: 13373.0488, Recall: 90.30%, Valid: 94.41% Test: 94.30%\n",
      "Epoch: 218, Loss: 13376.4785, Recall: 90.48%, Valid: 94.39% Test: 94.29%\n",
      "Epoch: 219, Loss: 13377.1895, Recall: 90.46%, Valid: 94.37% Test: 94.26%\n",
      "Epoch: 220, Loss: 13376.3291, Recall: 90.50%, Valid: 94.36% Test: 94.27%\n",
      "Epoch: 221, Loss: 13377.6953, Recall: 90.52%, Valid: 94.36% Test: 94.26%\n",
      "Epoch: 222, Loss: 13377.5518, Recall: 90.53%, Valid: 94.39% Test: 94.28%\n",
      "Epoch: 223, Loss: 13384.1621, Recall: 90.49%, Valid: 94.43% Test: 94.32%\n",
      "Epoch: 224, Loss: 13371.5059, Recall: 90.47%, Valid: 94.44% Test: 94.34%\n",
      "Epoch: 225, Loss: 13377.3652, Recall: 90.48%, Valid: 94.45% Test: 94.34%\n",
      "Epoch: 226, Loss: 13352.0137, Recall: 90.48%, Valid: 94.47% Test: 94.38%\n",
      "Epoch: 227, Loss: 13372.6963, Recall: 90.45%, Valid: 94.49% Test: 94.39%\n",
      "Epoch: 228, Loss: 13357.6562, Recall: 90.37%, Valid: 94.53% Test: 94.44%\n",
      "Epoch: 229, Loss: 13357.5918, Recall: 90.49%, Valid: 94.56% Test: 94.45%\n",
      "Epoch: 230, Loss: 13340.3848, Recall: 90.51%, Valid: 94.60% Test: 94.48%\n",
      "Epoch: 231, Loss: 13363.7598, Recall: 90.51%, Valid: 94.62% Test: 94.50%\n",
      "Epoch: 232, Loss: 13361.0186, Recall: 90.52%, Valid: 94.61% Test: 94.50%\n",
      "Epoch: 233, Loss: 13330.2500, Recall: 90.55%, Valid: 94.60% Test: 94.51%\n",
      "Epoch: 234, Loss: 13295.8545, Recall: 90.55%, Valid: 94.58% Test: 94.47%\n",
      "Epoch: 235, Loss: 13348.1738, Recall: 90.52%, Valid: 94.56% Test: 94.45%\n",
      "Epoch: 236, Loss: 13304.6211, Recall: 90.46%, Valid: 94.57% Test: 94.46%\n",
      "Epoch: 237, Loss: 13323.2402, Recall: 90.41%, Valid: 94.60% Test: 94.50%\n",
      "Epoch: 238, Loss: 13313.1582, Recall: 90.59%, Valid: 94.63% Test: 94.50%\n",
      "Epoch: 239, Loss: 13316.4473, Recall: 90.70%, Valid: 94.63% Test: 94.49%\n",
      "Epoch: 240, Loss: 13306.6758, Recall: 90.74%, Valid: 94.60% Test: 94.46%\n",
      "Epoch: 241, Loss: 13311.7090, Recall: 90.82%, Valid: 94.54% Test: 94.41%\n",
      "Epoch: 242, Loss: 13272.1211, Recall: 90.76%, Valid: 94.50% Test: 94.37%\n",
      "Epoch: 243, Loss: 13302.7725, Recall: 90.79%, Valid: 94.50% Test: 94.38%\n",
      "Epoch: 244, Loss: 13287.6953, Recall: 90.83%, Valid: 94.51% Test: 94.40%\n",
      "Epoch: 245, Loss: 13303.7949, Recall: 90.86%, Valid: 94.53% Test: 94.40%\n",
      "Epoch: 246, Loss: 13239.9160, Recall: 90.88%, Valid: 94.55% Test: 94.42%\n",
      "Epoch: 247, Loss: 13297.8359, Recall: 90.82%, Valid: 94.58% Test: 94.46%\n",
      "Epoch: 248, Loss: 13302.0234, Recall: 90.81%, Valid: 94.57% Test: 94.46%\n",
      "Epoch: 249, Loss: 13276.3027, Recall: 90.83%, Valid: 94.57% Test: 94.47%\n",
      "Epoch: 250, Loss: 13276.8105, Recall: 90.81%, Valid: 94.59% Test: 94.49%\n",
      "Epoch: 251, Loss: 13273.5215, Recall: 90.85%, Valid: 94.62% Test: 94.52%\n",
      "Epoch: 252, Loss: 13272.2227, Recall: 90.80%, Valid: 94.67% Test: 94.53%\n",
      "Epoch: 253, Loss: 13246.9258, Recall: 90.75%, Valid: 94.70% Test: 94.59%\n",
      "Epoch: 254, Loss: 13261.6543, Recall: 90.80%, Valid: 94.71% Test: 94.60%\n",
      "Epoch: 255, Loss: 13261.9199, Recall: 90.84%, Valid: 94.68% Test: 94.58%\n",
      "Epoch: 256, Loss: 13254.9277, Recall: 90.66%, Valid: 94.68% Test: 94.60%\n",
      "Epoch: 257, Loss: 13241.9023, Recall: 90.65%, Valid: 94.70% Test: 94.61%\n",
      "Epoch: 258, Loss: 13278.2383, Recall: 90.76%, Valid: 94.72% Test: 94.63%\n",
      "Epoch: 259, Loss: 13268.9531, Recall: 90.75%, Valid: 94.76% Test: 94.65%\n",
      "Epoch: 260, Loss: 13248.8379, Recall: 90.77%, Valid: 94.76% Test: 94.64%\n",
      "Epoch: 261, Loss: 13210.0986, Recall: 90.83%, Valid: 94.73% Test: 94.62%\n",
      "Epoch: 262, Loss: 13263.0215, Recall: 90.78%, Valid: 94.71% Test: 94.60%\n",
      "Epoch: 263, Loss: 13252.1758, Recall: 90.77%, Valid: 94.68% Test: 94.58%\n",
      "Epoch: 264, Loss: 13254.4414, Recall: 90.82%, Valid: 94.69% Test: 94.59%\n",
      "Epoch: 265, Loss: 13231.7422, Recall: 90.87%, Valid: 94.73% Test: 94.61%\n",
      "Epoch: 266, Loss: 13253.2188, Recall: 90.93%, Valid: 94.76% Test: 94.63%\n",
      "Epoch: 267, Loss: 13251.7119, Recall: 90.91%, Valid: 94.77% Test: 94.66%\n",
      "Epoch: 268, Loss: 13207.3516, Recall: 90.85%, Valid: 94.75% Test: 94.65%\n",
      "Epoch: 269, Loss: 13221.7832, Recall: 90.74%, Valid: 94.73% Test: 94.62%\n",
      "Epoch: 270, Loss: 13231.8389, Recall: 90.74%, Valid: 94.73% Test: 94.62%\n",
      "Epoch: 271, Loss: 13223.0176, Recall: 90.89%, Valid: 94.80% Test: 94.68%\n",
      "Epoch: 272, Loss: 13205.7471, Recall: 90.85%, Valid: 94.85% Test: 94.73%\n",
      "Epoch: 273, Loss: 13244.2842, Recall: 90.83%, Valid: 94.88% Test: 94.76%\n",
      "Epoch: 274, Loss: 13229.0576, Recall: 90.74%, Valid: 94.84% Test: 94.73%\n",
      "Epoch: 275, Loss: 13256.5547, Recall: 90.60%, Valid: 94.79% Test: 94.68%\n",
      "Epoch: 276, Loss: 13245.4326, Recall: 90.66%, Valid: 94.76% Test: 94.65%\n",
      "Epoch: 277, Loss: 13231.2930, Recall: 90.83%, Valid: 94.76% Test: 94.65%\n",
      "Epoch: 278, Loss: 13218.7070, Recall: 90.89%, Valid: 94.79% Test: 94.69%\n",
      "Epoch: 279, Loss: 13236.3848, Recall: 90.94%, Valid: 94.81% Test: 94.70%\n",
      "Epoch: 280, Loss: 13227.4902, Recall: 90.96%, Valid: 94.81% Test: 94.70%\n",
      "Epoch: 281, Loss: 13187.6230, Recall: 90.91%, Valid: 94.82% Test: 94.70%\n",
      "Epoch: 282, Loss: 13236.2363, Recall: 90.87%, Valid: 94.83% Test: 94.71%\n",
      "Epoch: 283, Loss: 13186.8457, Recall: 90.97%, Valid: 94.87% Test: 94.76%\n",
      "Epoch: 284, Loss: 13220.4590, Recall: 90.92%, Valid: 94.90% Test: 94.79%\n",
      "Epoch: 285, Loss: 13210.2881, Recall: 90.92%, Valid: 94.89% Test: 94.80%\n",
      "Epoch: 286, Loss: 13208.0117, Recall: 90.93%, Valid: 94.88% Test: 94.81%\n",
      "Epoch: 287, Loss: 13220.3506, Recall: 90.96%, Valid: 94.87% Test: 94.78%\n",
      "Epoch: 288, Loss: 13199.1641, Recall: 90.88%, Valid: 94.89% Test: 94.78%\n",
      "Epoch: 289, Loss: 13180.2832, Recall: 90.88%, Valid: 94.92% Test: 94.79%\n",
      "Epoch: 290, Loss: 13209.4932, Recall: 90.97%, Valid: 94.94% Test: 94.82%\n",
      "Epoch: 291, Loss: 13186.2764, Recall: 90.93%, Valid: 94.92% Test: 94.82%\n",
      "Epoch: 292, Loss: 13201.4473, Recall: 90.93%, Valid: 94.93% Test: 94.85%\n",
      "Epoch: 293, Loss: 13201.0625, Recall: 90.91%, Valid: 94.95% Test: 94.87%\n",
      "Epoch: 294, Loss: 13196.9746, Recall: 90.93%, Valid: 95.00% Test: 94.92%\n",
      "Epoch: 295, Loss: 13183.4453, Recall: 90.87%, Valid: 95.04% Test: 94.94%\n",
      "Epoch: 296, Loss: 13184.1094, Recall: 90.86%, Valid: 95.04% Test: 94.94%\n",
      "Epoch: 297, Loss: 13191.3604, Recall: 90.86%, Valid: 95.01% Test: 94.91%\n",
      "Epoch: 298, Loss: 13172.4199, Recall: 90.93%, Valid: 94.99% Test: 94.88%\n",
      "Epoch: 299, Loss: 13187.2969, Recall: 90.91%, Valid: 94.99% Test: 94.88%\n",
      "Epoch: 300, Loss: 13176.6230, Recall: 90.91%, Valid: 95.00% Test: 94.89%\n",
      "Epoch: 301, Loss: 13194.3164, Recall: 90.90%, Valid: 94.99% Test: 94.88%\n",
      "Epoch: 302, Loss: 13163.1973, Recall: 90.91%, Valid: 95.00% Test: 94.90%\n",
      "Epoch: 303, Loss: 13167.4473, Recall: 90.98%, Valid: 95.00% Test: 94.90%\n",
      "Epoch: 304, Loss: 13126.4102, Recall: 91.01%, Valid: 95.00% Test: 94.90%\n",
      "Epoch: 305, Loss: 13160.5049, Recall: 90.98%, Valid: 94.98% Test: 94.89%\n",
      "Epoch: 306, Loss: 13172.7441, Recall: 91.02%, Valid: 94.98% Test: 94.89%\n",
      "Epoch: 307, Loss: 13156.9766, Recall: 91.02%, Valid: 94.98% Test: 94.89%\n",
      "Epoch: 308, Loss: 13182.0449, Recall: 91.06%, Valid: 94.96% Test: 94.88%\n",
      "Epoch: 309, Loss: 13145.1719, Recall: 91.06%, Valid: 94.97% Test: 94.90%\n",
      "Epoch: 310, Loss: 13167.2822, Recall: 91.11%, Valid: 95.01% Test: 94.91%\n",
      "Epoch: 311, Loss: 13164.0840, Recall: 91.11%, Valid: 95.04% Test: 94.94%\n",
      "Epoch: 312, Loss: 13154.3174, Recall: 91.11%, Valid: 95.06% Test: 94.96%\n",
      "Epoch: 313, Loss: 13162.9199, Recall: 91.05%, Valid: 95.07% Test: 94.95%\n",
      "Epoch: 314, Loss: 13141.3193, Recall: 91.09%, Valid: 95.04% Test: 94.93%\n",
      "Epoch: 315, Loss: 13159.8809, Recall: 91.10%, Valid: 95.00% Test: 94.89%\n",
      "Epoch: 316, Loss: 13139.7852, Recall: 91.08%, Valid: 94.96% Test: 94.84%\n",
      "Epoch: 317, Loss: 13146.1719, Recall: 91.09%, Valid: 94.94% Test: 94.81%\n",
      "Epoch: 318, Loss: 13141.2471, Recall: 91.13%, Valid: 94.95% Test: 94.82%\n",
      "Epoch: 319, Loss: 13151.5967, Recall: 91.10%, Valid: 94.96% Test: 94.83%\n",
      "Epoch: 320, Loss: 13167.1973, Recall: 91.09%, Valid: 94.98% Test: 94.87%\n",
      "Epoch: 321, Loss: 13175.6963, Recall: 91.11%, Valid: 94.99% Test: 94.87%\n",
      "Epoch: 322, Loss: 13130.7852, Recall: 90.97%, Valid: 94.96% Test: 94.84%\n",
      "Epoch: 323, Loss: 13177.5059, Recall: 90.87%, Valid: 94.96% Test: 94.85%\n",
      "Epoch: 324, Loss: 13148.3926, Recall: 91.00%, Valid: 95.00% Test: 94.89%\n",
      "Epoch: 325, Loss: 13157.2021, Recall: 91.07%, Valid: 95.03% Test: 94.93%\n",
      "Epoch: 326, Loss: 13136.0391, Recall: 91.03%, Valid: 95.03% Test: 94.94%\n",
      "Epoch: 327, Loss: 13173.6074, Recall: 91.03%, Valid: 95.01% Test: 94.90%\n",
      "Epoch: 328, Loss: 13173.3984, Recall: 91.07%, Valid: 94.99% Test: 94.89%\n",
      "Epoch: 329, Loss: 13120.9941, Recall: 91.14%, Valid: 95.00% Test: 94.91%\n",
      "Epoch: 330, Loss: 13159.6016, Recall: 91.20%, Valid: 95.00% Test: 94.92%\n",
      "Epoch: 331, Loss: 13107.0020, Recall: 91.17%, Valid: 95.04% Test: 94.96%\n",
      "Epoch: 332, Loss: 13127.2715, Recall: 91.15%, Valid: 95.09% Test: 95.02%\n",
      "Epoch: 333, Loss: 13131.4160, Recall: 91.15%, Valid: 95.11% Test: 95.04%\n",
      "Epoch: 334, Loss: 13126.5039, Recall: 91.07%, Valid: 95.12% Test: 95.04%\n",
      "Epoch: 335, Loss: 13116.0068, Recall: 90.96%, Valid: 95.11% Test: 95.01%\n",
      "Epoch: 336, Loss: 13147.8320, Recall: 91.08%, Valid: 95.12% Test: 95.01%\n",
      "Epoch: 337, Loss: 13139.3340, Recall: 91.14%, Valid: 95.14% Test: 95.05%\n",
      "Epoch: 338, Loss: 13116.0254, Recall: 91.13%, Valid: 95.15% Test: 95.07%\n",
      "Epoch: 339, Loss: 13140.6895, Recall: 91.11%, Valid: 95.14% Test: 95.06%\n",
      "Epoch: 340, Loss: 13106.5947, Recall: 91.12%, Valid: 95.14% Test: 95.06%\n",
      "Epoch: 341, Loss: 13102.1016, Recall: 91.17%, Valid: 95.14% Test: 95.07%\n",
      "Epoch: 342, Loss: 13149.1465, Recall: 91.20%, Valid: 95.12% Test: 95.06%\n",
      "Epoch: 343, Loss: 13128.9531, Recall: 91.15%, Valid: 95.12% Test: 95.03%\n",
      "Epoch: 344, Loss: 13097.8125, Recall: 91.07%, Valid: 95.13% Test: 95.04%\n",
      "Epoch: 345, Loss: 13108.1094, Recall: 91.07%, Valid: 95.16% Test: 95.08%\n",
      "Epoch: 346, Loss: 13110.8604, Recall: 91.11%, Valid: 95.18% Test: 95.12%\n",
      "Epoch: 347, Loss: 13124.3809, Recall: 91.20%, Valid: 95.18% Test: 95.10%\n",
      "Epoch: 348, Loss: 13102.7227, Recall: 91.26%, Valid: 95.16% Test: 95.09%\n",
      "Epoch: 349, Loss: 13118.3096, Recall: 91.21%, Valid: 95.14% Test: 95.07%\n",
      "Epoch: 350, Loss: 13083.0557, Recall: 91.20%, Valid: 95.12% Test: 95.05%\n",
      "Epoch: 351, Loss: 13105.0459, Recall: 91.23%, Valid: 95.12% Test: 95.05%\n",
      "Epoch: 352, Loss: 13096.8789, Recall: 91.12%, Valid: 95.12% Test: 95.04%\n",
      "Epoch: 353, Loss: 13107.7344, Recall: 91.11%, Valid: 95.14% Test: 95.06%\n",
      "Epoch: 354, Loss: 13105.1094, Recall: 91.16%, Valid: 95.17% Test: 95.07%\n",
      "Epoch: 355, Loss: 13080.0596, Recall: 91.11%, Valid: 95.19% Test: 95.11%\n",
      "Epoch: 356, Loss: 13071.4082, Recall: 91.12%, Valid: 95.20% Test: 95.11%\n",
      "Epoch: 357, Loss: 13070.2900, Recall: 91.09%, Valid: 95.21% Test: 95.11%\n",
      "Epoch: 358, Loss: 13086.7305, Recall: 91.05%, Valid: 95.20% Test: 95.09%\n",
      "Epoch: 359, Loss: 13086.0586, Recall: 91.16%, Valid: 95.20% Test: 95.11%\n",
      "Epoch: 360, Loss: 13073.6133, Recall: 91.21%, Valid: 95.21% Test: 95.11%\n",
      "Epoch: 361, Loss: 13072.4570, Recall: 91.21%, Valid: 95.22% Test: 95.12%\n",
      "Epoch: 362, Loss: 13085.8027, Recall: 91.17%, Valid: 95.22% Test: 95.13%\n",
      "Epoch: 363, Loss: 13062.2617, Recall: 91.11%, Valid: 95.22% Test: 95.12%\n",
      "Epoch: 364, Loss: 13063.3867, Recall: 91.14%, Valid: 95.22% Test: 95.13%\n",
      "Epoch: 365, Loss: 13128.7832, Recall: 91.22%, Valid: 95.20% Test: 95.13%\n",
      "Epoch: 366, Loss: 13092.5996, Recall: 91.28%, Valid: 95.19% Test: 95.10%\n",
      "Epoch: 367, Loss: 13104.0508, Recall: 91.29%, Valid: 95.18% Test: 95.09%\n",
      "Epoch: 368, Loss: 13119.8271, Recall: 91.26%, Valid: 95.15% Test: 95.05%\n",
      "Epoch: 369, Loss: 13089.4844, Recall: 91.21%, Valid: 95.13% Test: 95.04%\n",
      "Epoch: 370, Loss: 13055.9268, Recall: 91.14%, Valid: 95.12% Test: 95.03%\n",
      "Epoch: 371, Loss: 13067.7393, Recall: 91.09%, Valid: 95.11% Test: 95.04%\n",
      "Epoch: 372, Loss: 13106.8809, Recall: 91.18%, Valid: 95.14% Test: 95.07%\n",
      "Epoch: 373, Loss: 13068.9590, Recall: 91.22%, Valid: 95.17% Test: 95.11%\n",
      "Epoch: 374, Loss: 13086.7422, Recall: 91.24%, Valid: 95.19% Test: 95.12%\n",
      "Epoch: 375, Loss: 13085.9492, Recall: 91.22%, Valid: 95.20% Test: 95.13%\n",
      "Epoch: 376, Loss: 13089.0156, Recall: 91.23%, Valid: 95.20% Test: 95.12%\n",
      "Epoch: 377, Loss: 13100.7441, Recall: 91.22%, Valid: 95.18% Test: 95.10%\n",
      "Epoch: 378, Loss: 13078.6611, Recall: 91.16%, Valid: 95.18% Test: 95.09%\n",
      "Epoch: 379, Loss: 13077.8281, Recall: 91.22%, Valid: 95.21% Test: 95.13%\n",
      "Epoch: 380, Loss: 13033.3926, Recall: 91.23%, Valid: 95.28% Test: 95.19%\n",
      "Epoch: 381, Loss: 13078.5068, Recall: 91.15%, Valid: 95.32% Test: 95.25%\n",
      "Epoch: 382, Loss: 13075.2305, Recall: 91.16%, Valid: 95.34% Test: 95.27%\n",
      "Epoch: 383, Loss: 13071.0088, Recall: 91.21%, Valid: 95.34% Test: 95.25%\n",
      "Epoch: 384, Loss: 13041.3750, Recall: 91.18%, Valid: 95.33% Test: 95.26%\n",
      "Epoch: 385, Loss: 13069.4834, Recall: 91.22%, Valid: 95.34% Test: 95.25%\n",
      "Epoch: 386, Loss: 13074.1104, Recall: 91.16%, Valid: 95.34% Test: 95.26%\n",
      "Epoch: 387, Loss: 13056.4482, Recall: 91.18%, Valid: 95.35% Test: 95.26%\n",
      "Epoch: 388, Loss: 13070.4668, Recall: 90.98%, Valid: 95.34% Test: 95.25%\n",
      "Epoch: 389, Loss: 13052.9375, Recall: 91.12%, Valid: 95.35% Test: 95.26%\n",
      "Epoch: 390, Loss: 13042.0059, Recall: 91.22%, Valid: 95.34% Test: 95.25%\n",
      "Epoch: 391, Loss: 13066.4727, Recall: 91.27%, Valid: 95.33% Test: 95.25%\n",
      "Epoch: 392, Loss: 13056.7422, Recall: 91.24%, Valid: 95.33% Test: 95.24%\n",
      "Epoch: 393, Loss: 13053.5527, Recall: 91.27%, Valid: 95.32% Test: 95.24%\n",
      "Epoch: 394, Loss: 13041.6680, Recall: 91.34%, Valid: 95.34% Test: 95.24%\n",
      "Epoch: 395, Loss: 13076.1992, Recall: 91.07%, Valid: 95.34% Test: 95.26%\n",
      "Epoch: 396, Loss: 13076.1992, Recall: 91.34%, Valid: 95.33% Test: 95.24%\n",
      "Epoch: 397, Loss: 13032.5723, Recall: 91.31%, Valid: 95.33% Test: 95.23%\n",
      "Epoch: 398, Loss: 13028.1660, Recall: 91.29%, Valid: 95.31% Test: 95.22%\n",
      "Epoch: 399, Loss: 13096.0234, Recall: 91.34%, Valid: 95.31% Test: 95.21%\n",
      "Epoch: 400, Loss: 13066.9902, Recall: 91.34%, Valid: 95.31% Test: 95.21%\n",
      "Epoch: 401, Loss: 13031.6396, Recall: 91.23%, Valid: 95.32% Test: 95.21%\n",
      "Epoch: 402, Loss: 13033.1436, Recall: 91.22%, Valid: 95.32% Test: 95.23%\n",
      "Epoch: 403, Loss: 13064.7305, Recall: 91.21%, Valid: 95.34% Test: 95.23%\n",
      "Epoch: 404, Loss: 13043.3359, Recall: 91.13%, Valid: 95.34% Test: 95.24%\n",
      "Epoch: 405, Loss: 13050.5508, Recall: 91.29%, Valid: 95.36% Test: 95.25%\n",
      "Epoch: 406, Loss: 13042.9150, Recall: 91.22%, Valid: 95.38% Test: 95.28%\n",
      "Epoch: 407, Loss: 13041.3613, Recall: 91.22%, Valid: 95.42% Test: 95.33%\n",
      "Epoch: 408, Loss: 13046.0713, Recall: 91.22%, Valid: 95.43% Test: 95.32%\n",
      "Epoch: 409, Loss: 13038.2373, Recall: 91.18%, Valid: 95.39% Test: 95.28%\n",
      "Epoch: 410, Loss: 13039.4600, Recall: 91.49%, Valid: 95.36% Test: 95.26%\n",
      "Epoch: 411, Loss: 13029.6885, Recall: 91.45%, Valid: 95.32% Test: 95.19%\n",
      "Epoch: 412, Loss: 13022.8486, Recall: 91.41%, Valid: 95.29% Test: 95.17%\n",
      "Epoch: 413, Loss: 13032.6982, Recall: 91.46%, Valid: 95.30% Test: 95.17%\n",
      "Epoch: 414, Loss: 13042.2988, Recall: 91.47%, Valid: 95.32% Test: 95.20%\n",
      "Epoch: 415, Loss: 13002.1152, Recall: 91.46%, Valid: 95.33% Test: 95.21%\n",
      "Epoch: 416, Loss: 13022.0273, Recall: 91.40%, Valid: 95.33% Test: 95.21%\n",
      "Epoch: 417, Loss: 13032.7559, Recall: 91.40%, Valid: 95.33% Test: 95.22%\n",
      "Epoch: 418, Loss: 13037.1035, Recall: 91.40%, Valid: 95.32% Test: 95.19%\n",
      "Epoch: 419, Loss: 13060.4941, Recall: 91.41%, Valid: 95.34% Test: 95.18%\n",
      "Epoch: 420, Loss: 13036.5596, Recall: 91.38%, Valid: 95.36% Test: 95.22%\n",
      "Epoch: 421, Loss: 13031.1465, Recall: 91.39%, Valid: 95.39% Test: 95.23%\n",
      "Epoch: 422, Loss: 13009.2090, Recall: 91.47%, Valid: 95.41% Test: 95.26%\n",
      "Epoch: 423, Loss: 13006.0645, Recall: 91.49%, Valid: 95.42% Test: 95.29%\n",
      "Epoch: 424, Loss: 12997.2129, Recall: 91.48%, Valid: 95.42% Test: 95.30%\n",
      "Epoch: 425, Loss: 13051.2852, Recall: 91.50%, Valid: 95.42% Test: 95.30%\n",
      "Epoch: 426, Loss: 13010.1582, Recall: 91.53%, Valid: 95.44% Test: 95.33%\n",
      "Epoch: 427, Loss: 13008.9375, Recall: 91.46%, Valid: 95.44% Test: 95.35%\n",
      "Epoch: 428, Loss: 13007.7412, Recall: 91.44%, Valid: 95.44% Test: 95.34%\n",
      "Epoch: 429, Loss: 13002.7236, Recall: 91.40%, Valid: 95.45% Test: 95.34%\n",
      "Epoch: 430, Loss: 12989.4873, Recall: 91.30%, Valid: 95.45% Test: 95.34%\n",
      "Epoch: 431, Loss: 13013.8057, Recall: 91.35%, Valid: 95.46% Test: 95.34%\n",
      "Epoch: 432, Loss: 13038.6035, Recall: 91.38%, Valid: 95.46% Test: 95.34%\n",
      "Epoch: 433, Loss: 13011.9902, Recall: 91.40%, Valid: 95.45% Test: 95.33%\n",
      "Epoch: 434, Loss: 13014.0605, Recall: 91.32%, Valid: 95.46% Test: 95.36%\n",
      "Epoch: 435, Loss: 13002.2227, Recall: 91.18%, Valid: 95.46% Test: 95.35%\n",
      "Epoch: 436, Loss: 13015.2637, Recall: 91.20%, Valid: 95.47% Test: 95.39%\n",
      "Epoch: 437, Loss: 12996.2178, Recall: 91.10%, Valid: 95.50% Test: 95.40%\n",
      "Epoch: 438, Loss: 13016.2412, Recall: 91.04%, Valid: 95.52% Test: 95.41%\n",
      "Epoch: 439, Loss: 13002.9814, Recall: 91.43%, Valid: 95.52% Test: 95.41%\n",
      "Epoch: 440, Loss: 12994.7910, Recall: 91.38%, Valid: 95.51% Test: 95.39%\n",
      "Epoch: 441, Loss: 12992.7578, Recall: 91.35%, Valid: 95.51% Test: 95.39%\n",
      "Epoch: 442, Loss: 12996.4863, Recall: 91.38%, Valid: 95.52% Test: 95.40%\n",
      "Epoch: 443, Loss: 13000.3594, Recall: 91.34%, Valid: 95.51% Test: 95.40%\n",
      "Epoch: 444, Loss: 12991.6689, Recall: 91.23%, Valid: 95.50% Test: 95.39%\n",
      "Epoch: 445, Loss: 12986.1191, Recall: 91.09%, Valid: 95.49% Test: 95.41%\n",
      "Epoch: 446, Loss: 13010.7461, Recall: 91.25%, Valid: 95.49% Test: 95.39%\n",
      "Epoch: 447, Loss: 13022.8457, Recall: 91.38%, Valid: 95.46% Test: 95.36%\n",
      "Epoch: 448, Loss: 12997.6348, Recall: 91.42%, Valid: 95.43% Test: 95.34%\n",
      "Epoch: 449, Loss: 13037.2852, Recall: 91.41%, Valid: 95.42% Test: 95.31%\n",
      "Epoch: 450, Loss: 13016.7559, Recall: 91.42%, Valid: 95.42% Test: 95.30%\n",
      "Epoch: 451, Loss: 13000.2119, Recall: 91.46%, Valid: 95.44% Test: 95.31%\n",
      "Epoch: 452, Loss: 13022.6738, Recall: 91.35%, Valid: 95.42% Test: 95.31%\n",
      "Epoch: 453, Loss: 13024.0195, Recall: 91.31%, Valid: 95.42% Test: 95.29%\n",
      "Epoch: 454, Loss: 13007.7793, Recall: 91.34%, Valid: 95.42% Test: 95.27%\n",
      "Epoch: 455, Loss: 12997.1191, Recall: 91.46%, Valid: 95.41% Test: 95.26%\n",
      "Epoch: 456, Loss: 13001.6504, Recall: 91.44%, Valid: 95.42% Test: 95.30%\n",
      "Epoch: 457, Loss: 13000.7891, Recall: 91.28%, Valid: 95.42% Test: 95.32%\n",
      "Epoch: 458, Loss: 13014.6719, Recall: 91.43%, Valid: 95.43% Test: 95.32%\n",
      "Epoch: 459, Loss: 13001.6504, Recall: 91.43%, Valid: 95.44% Test: 95.33%\n",
      "Epoch: 460, Loss: 12997.5215, Recall: 91.46%, Valid: 95.45% Test: 95.33%\n",
      "Epoch: 461, Loss: 13020.1426, Recall: 91.22%, Valid: 95.44% Test: 95.34%\n",
      "Epoch: 462, Loss: 13020.4805, Recall: 91.15%, Valid: 95.42% Test: 95.34%\n",
      "Epoch: 463, Loss: 12985.7227, Recall: 91.37%, Valid: 95.42% Test: 95.34%\n",
      "Epoch: 464, Loss: 13043.6680, Recall: 91.44%, Valid: 95.41% Test: 95.34%\n",
      "Epoch: 465, Loss: 13010.4844, Recall: 91.47%, Valid: 95.42% Test: 95.35%\n",
      "Epoch: 466, Loss: 13004.5459, Recall: 91.48%, Valid: 95.45% Test: 95.37%\n",
      "Epoch: 467, Loss: 12971.0039, Recall: 91.50%, Valid: 95.49% Test: 95.40%\n",
      "Epoch: 468, Loss: 12958.7314, Recall: 91.39%, Valid: 95.51% Test: 95.43%\n",
      "Epoch: 469, Loss: 12984.8643, Recall: 91.53%, Valid: 95.52% Test: 95.43%\n",
      "Epoch: 470, Loss: 12978.0371, Recall: 91.57%, Valid: 95.52% Test: 95.43%\n",
      "Epoch: 471, Loss: 13000.8232, Recall: 91.58%, Valid: 95.51% Test: 95.43%\n",
      "Epoch: 472, Loss: 12949.3008, Recall: 91.58%, Valid: 95.53% Test: 95.44%\n",
      "Epoch: 473, Loss: 12988.8135, Recall: 91.59%, Valid: 95.55% Test: 95.46%\n",
      "Epoch: 474, Loss: 12985.0684, Recall: 91.47%, Valid: 95.55% Test: 95.47%\n",
      "Epoch: 475, Loss: 12955.7207, Recall: 91.49%, Valid: 95.57% Test: 95.49%\n",
      "Epoch: 476, Loss: 12988.8262, Recall: 91.54%, Valid: 95.57% Test: 95.48%\n",
      "Epoch: 477, Loss: 12952.3594, Recall: 91.54%, Valid: 95.55% Test: 95.47%\n",
      "Epoch: 478, Loss: 12962.3164, Recall: 91.50%, Valid: 95.53% Test: 95.45%\n",
      "Epoch: 479, Loss: 12995.3340, Recall: 91.53%, Valid: 95.52% Test: 95.43%\n",
      "Epoch: 480, Loss: 12981.7012, Recall: 91.56%, Valid: 95.51% Test: 95.42%\n",
      "Epoch: 481, Loss: 12968.4316, Recall: 91.50%, Valid: 95.51% Test: 95.42%\n",
      "Epoch: 482, Loss: 12967.9922, Recall: 91.49%, Valid: 95.51% Test: 95.44%\n",
      "Epoch: 483, Loss: 12966.8242, Recall: 91.47%, Valid: 95.51% Test: 95.44%\n",
      "Epoch: 484, Loss: 12960.4902, Recall: 91.54%, Valid: 95.51% Test: 95.42%\n",
      "Epoch: 485, Loss: 12958.2402, Recall: 91.51%, Valid: 95.50% Test: 95.41%\n",
      "Epoch: 486, Loss: 12962.6729, Recall: 91.55%, Valid: 95.50% Test: 95.42%\n",
      "Epoch: 487, Loss: 12946.8203, Recall: 91.52%, Valid: 95.51% Test: 95.43%\n",
      "Epoch: 488, Loss: 12951.0684, Recall: 91.50%, Valid: 95.51% Test: 95.44%\n",
      "Epoch: 489, Loss: 12978.4609, Recall: 91.55%, Valid: 95.51% Test: 95.43%\n",
      "Epoch: 490, Loss: 12937.3643, Recall: 91.58%, Valid: 95.51% Test: 95.43%\n",
      "Epoch: 491, Loss: 12954.9258, Recall: 91.59%, Valid: 95.52% Test: 95.42%\n",
      "Epoch: 492, Loss: 12957.2900, Recall: 91.64%, Valid: 95.51% Test: 95.44%\n",
      "Epoch: 493, Loss: 12963.6406, Recall: 91.67%, Valid: 95.51% Test: 95.44%\n",
      "Epoch: 494, Loss: 12974.1572, Recall: 91.77%, Valid: 95.54% Test: 95.46%\n",
      "Epoch: 495, Loss: 12956.7227, Recall: 91.73%, Valid: 95.55% Test: 95.47%\n",
      "Epoch: 496, Loss: 12957.6914, Recall: 91.61%, Valid: 95.53% Test: 95.47%\n",
      "Epoch: 497, Loss: 12939.0381, Recall: 91.60%, Valid: 95.53% Test: 95.48%\n",
      "Epoch: 498, Loss: 12930.6250, Recall: 91.59%, Valid: 95.55% Test: 95.50%\n",
      "Epoch: 499, Loss: 12955.7148, Recall: 91.56%, Valid: 95.55% Test: 95.48%\n",
      "Epoch: 500, Loss: 12945.7676, Recall: 91.64%, Valid: 95.55% Test: 95.48%\n",
      "Epoch: 501, Loss: 12965.1250, Recall: 91.63%, Valid: 95.56% Test: 95.50%\n",
      "Epoch: 502, Loss: 12943.5879, Recall: 91.70%, Valid: 95.57% Test: 95.51%\n",
      "Epoch: 503, Loss: 12950.9727, Recall: 91.70%, Valid: 95.58% Test: 95.52%\n",
      "Epoch: 504, Loss: 12952.0898, Recall: 91.64%, Valid: 95.58% Test: 95.51%\n",
      "Epoch: 505, Loss: 12966.5312, Recall: 91.71%, Valid: 95.58% Test: 95.50%\n",
      "Epoch: 506, Loss: 12936.1875, Recall: 91.68%, Valid: 95.56% Test: 95.49%\n",
      "Epoch: 507, Loss: 12925.2754, Recall: 91.75%, Valid: 95.53% Test: 95.47%\n",
      "Epoch: 508, Loss: 12944.5977, Recall: 91.76%, Valid: 95.52% Test: 95.42%\n",
      "Epoch: 509, Loss: 12935.6484, Recall: 91.76%, Valid: 95.51% Test: 95.41%\n",
      "Epoch: 510, Loss: 12924.7285, Recall: 91.70%, Valid: 95.51% Test: 95.41%\n",
      "Epoch: 511, Loss: 12964.1172, Recall: 91.66%, Valid: 95.52% Test: 95.42%\n",
      "Epoch: 512, Loss: 12943.1836, Recall: 91.64%, Valid: 95.54% Test: 95.46%\n",
      "Epoch: 513, Loss: 12931.2080, Recall: 91.71%, Valid: 95.56% Test: 95.47%\n",
      "Epoch: 514, Loss: 12943.3652, Recall: 91.66%, Valid: 95.59% Test: 95.50%\n",
      "Epoch: 515, Loss: 12976.5596, Recall: 91.64%, Valid: 95.59% Test: 95.51%\n",
      "Epoch: 516, Loss: 12979.2373, Recall: 91.60%, Valid: 95.59% Test: 95.50%\n",
      "Epoch: 517, Loss: 12946.2607, Recall: 91.68%, Valid: 95.58% Test: 95.51%\n",
      "Epoch: 518, Loss: 12932.4541, Recall: 91.74%, Valid: 95.56% Test: 95.47%\n",
      "Epoch: 519, Loss: 12938.8438, Recall: 91.78%, Valid: 95.53% Test: 95.45%\n",
      "Epoch: 520, Loss: 12929.3975, Recall: 91.71%, Valid: 95.49% Test: 95.41%\n",
      "Epoch: 521, Loss: 12919.7402, Recall: 91.75%, Valid: 95.48% Test: 95.41%\n",
      "Epoch: 522, Loss: 12956.9434, Recall: 91.76%, Valid: 95.52% Test: 95.43%\n",
      "Epoch: 523, Loss: 12943.5693, Recall: 91.73%, Valid: 95.55% Test: 95.47%\n",
      "Epoch: 524, Loss: 12964.1523, Recall: 91.62%, Valid: 95.59% Test: 95.50%\n",
      "Epoch: 525, Loss: 12960.8037, Recall: 91.58%, Valid: 95.61% Test: 95.53%\n",
      "Epoch: 526, Loss: 12949.1836, Recall: 91.72%, Valid: 95.61% Test: 95.53%\n",
      "Epoch: 527, Loss: 12939.5713, Recall: 91.74%, Valid: 95.61% Test: 95.53%\n",
      "Epoch: 528, Loss: 12950.7100, Recall: 91.67%, Valid: 95.60% Test: 95.50%\n",
      "Epoch: 529, Loss: 12942.2773, Recall: 91.71%, Valid: 95.61% Test: 95.52%\n",
      "Epoch: 530, Loss: 12929.6230, Recall: 91.62%, Valid: 95.62% Test: 95.53%\n",
      "Epoch: 531, Loss: 12944.1309, Recall: 91.61%, Valid: 95.63% Test: 95.55%\n",
      "Epoch: 532, Loss: 12902.3594, Recall: 91.67%, Valid: 95.62% Test: 95.55%\n",
      "Epoch: 533, Loss: 12919.0801, Recall: 91.68%, Valid: 95.60% Test: 95.53%\n",
      "Epoch: 534, Loss: 12941.2812, Recall: 91.71%, Valid: 95.58% Test: 95.51%\n",
      "Epoch: 535, Loss: 12916.5332, Recall: 91.67%, Valid: 95.57% Test: 95.49%\n",
      "Epoch: 536, Loss: 12964.4297, Recall: 91.69%, Valid: 95.58% Test: 95.50%\n",
      "Epoch: 537, Loss: 12920.6738, Recall: 91.69%, Valid: 95.59% Test: 95.52%\n",
      "Epoch: 538, Loss: 12911.9277, Recall: 91.71%, Valid: 95.62% Test: 95.54%\n",
      "Epoch: 539, Loss: 12924.4414, Recall: 91.71%, Valid: 95.64% Test: 95.57%\n",
      "Epoch: 540, Loss: 12908.7451, Recall: 91.65%, Valid: 95.66% Test: 95.58%\n",
      "Epoch: 541, Loss: 12917.8281, Recall: 91.71%, Valid: 95.67% Test: 95.61%\n",
      "Epoch: 542, Loss: 12949.2031, Recall: 91.71%, Valid: 95.66% Test: 95.59%\n",
      "Epoch: 543, Loss: 12922.7598, Recall: 91.69%, Valid: 95.67% Test: 95.61%\n",
      "Epoch: 544, Loss: 12938.9258, Recall: 91.63%, Valid: 95.67% Test: 95.60%\n",
      "Epoch: 545, Loss: 12925.3496, Recall: 91.61%, Valid: 95.67% Test: 95.61%\n",
      "Epoch: 546, Loss: 12935.9648, Recall: 91.71%, Valid: 95.66% Test: 95.60%\n",
      "Epoch: 547, Loss: 12916.0527, Recall: 91.81%, Valid: 95.64% Test: 95.55%\n",
      "Epoch: 548, Loss: 12891.8789, Recall: 91.69%, Valid: 95.60% Test: 95.48%\n",
      "Epoch: 549, Loss: 12906.7549, Recall: 91.58%, Valid: 95.58% Test: 95.45%\n",
      "Epoch: 550, Loss: 12921.7686, Recall: 91.65%, Valid: 95.59% Test: 95.47%\n",
      "Epoch: 551, Loss: 12912.4297, Recall: 91.58%, Valid: 95.62% Test: 95.50%\n",
      "Epoch: 552, Loss: 12914.9355, Recall: 91.87%, Valid: 95.65% Test: 95.55%\n",
      "Epoch: 553, Loss: 12920.7432, Recall: 91.87%, Valid: 95.68% Test: 95.61%\n",
      "Epoch: 554, Loss: 12885.9844, Recall: 91.83%, Valid: 95.71% Test: 95.65%\n",
      "Epoch: 555, Loss: 12911.5703, Recall: 91.78%, Valid: 95.71% Test: 95.65%\n",
      "Epoch: 556, Loss: 12921.4717, Recall: 91.77%, Valid: 95.70% Test: 95.63%\n",
      "Epoch: 557, Loss: 12907.5840, Recall: 91.78%, Valid: 95.67% Test: 95.61%\n",
      "Epoch: 558, Loss: 12948.1328, Recall: 91.81%, Valid: 95.63% Test: 95.58%\n",
      "Epoch: 559, Loss: 12906.3535, Recall: 91.82%, Valid: 95.60% Test: 95.54%\n",
      "Epoch: 560, Loss: 12882.8828, Recall: 91.91%, Valid: 95.59% Test: 95.53%\n",
      "Epoch: 561, Loss: 12873.6270, Recall: 91.92%, Valid: 95.58% Test: 95.52%\n",
      "Epoch: 562, Loss: 12906.7012, Recall: 91.92%, Valid: 95.59% Test: 95.53%\n",
      "Epoch: 563, Loss: 12903.7422, Recall: 91.89%, Valid: 95.60% Test: 95.55%\n",
      "Epoch: 564, Loss: 12895.9443, Recall: 91.88%, Valid: 95.62% Test: 95.56%\n",
      "Epoch: 565, Loss: 12897.1826, Recall: 91.85%, Valid: 95.64% Test: 95.58%\n",
      "Epoch: 566, Loss: 12898.3145, Recall: 91.80%, Valid: 95.66% Test: 95.60%\n",
      "Epoch: 567, Loss: 12918.6777, Recall: 91.80%, Valid: 95.67% Test: 95.60%\n",
      "Epoch: 568, Loss: 12891.9727, Recall: 91.84%, Valid: 95.68% Test: 95.61%\n",
      "Epoch: 569, Loss: 12886.1602, Recall: 91.84%, Valid: 95.68% Test: 95.60%\n",
      "Epoch: 570, Loss: 12884.6484, Recall: 91.88%, Valid: 95.69% Test: 95.61%\n",
      "Epoch: 571, Loss: 12897.0898, Recall: 91.90%, Valid: 95.70% Test: 95.63%\n",
      "Epoch: 572, Loss: 12903.3262, Recall: 91.91%, Valid: 95.71% Test: 95.64%\n",
      "Epoch: 573, Loss: 12856.7158, Recall: 91.86%, Valid: 95.71% Test: 95.64%\n",
      "Epoch: 574, Loss: 12933.0469, Recall: 91.86%, Valid: 95.69% Test: 95.62%\n",
      "Epoch: 575, Loss: 12901.9795, Recall: 91.89%, Valid: 95.68% Test: 95.60%\n",
      "Epoch: 576, Loss: 12871.5732, Recall: 91.86%, Valid: 95.65% Test: 95.55%\n",
      "Epoch: 577, Loss: 12901.6328, Recall: 91.73%, Valid: 95.63% Test: 95.55%\n",
      "Epoch: 578, Loss: 12884.4727, Recall: 91.76%, Valid: 95.63% Test: 95.54%\n",
      "Epoch: 579, Loss: 12914.6973, Recall: 91.94%, Valid: 95.64% Test: 95.53%\n",
      "Epoch: 580, Loss: 12898.2559, Recall: 91.96%, Valid: 95.64% Test: 95.55%\n",
      "Epoch: 581, Loss: 12892.7852, Recall: 91.89%, Valid: 95.65% Test: 95.55%\n",
      "Epoch: 582, Loss: 12894.7910, Recall: 91.91%, Valid: 95.66% Test: 95.57%\n",
      "Epoch: 583, Loss: 12899.7178, Recall: 91.87%, Valid: 95.66% Test: 95.58%\n",
      "Epoch: 584, Loss: 12894.7725, Recall: 91.89%, Valid: 95.68% Test: 95.60%\n",
      "Epoch: 585, Loss: 12869.9824, Recall: 91.85%, Valid: 95.70% Test: 95.61%\n",
      "Epoch: 586, Loss: 12887.6816, Recall: 91.78%, Valid: 95.73% Test: 95.64%\n",
      "Epoch: 587, Loss: 12865.7344, Recall: 91.77%, Valid: 95.74% Test: 95.64%\n",
      "Epoch: 588, Loss: 12889.7441, Recall: 91.84%, Valid: 95.73% Test: 95.65%\n",
      "Epoch: 589, Loss: 12909.8271, Recall: 91.89%, Valid: 95.74% Test: 95.66%\n",
      "Epoch: 590, Loss: 12896.0166, Recall: 91.88%, Valid: 95.73% Test: 95.66%\n",
      "Epoch: 591, Loss: 12885.5771, Recall: 91.92%, Valid: 95.71% Test: 95.62%\n",
      "Epoch: 592, Loss: 12896.1270, Recall: 91.81%, Valid: 95.69% Test: 95.60%\n",
      "Epoch: 593, Loss: 12867.0986, Recall: 91.81%, Valid: 95.66% Test: 95.59%\n",
      "Epoch: 594, Loss: 12904.7100, Recall: 91.83%, Valid: 95.65% Test: 95.57%\n",
      "Epoch: 595, Loss: 12882.6328, Recall: 91.83%, Valid: 95.63% Test: 95.56%\n",
      "Epoch: 596, Loss: 12868.7246, Recall: 91.78%, Valid: 95.64% Test: 95.57%\n",
      "Epoch: 597, Loss: 12902.1836, Recall: 91.95%, Valid: 95.66% Test: 95.60%\n",
      "Epoch: 598, Loss: 12894.8184, Recall: 91.95%, Valid: 95.67% Test: 95.60%\n",
      "Epoch: 599, Loss: 12886.2891, Recall: 91.89%, Valid: 95.67% Test: 95.61%\n",
      "Epoch: 600, Loss: 12903.8975, Recall: 91.88%, Valid: 95.65% Test: 95.59%\n",
      "Epoch: 601, Loss: 12899.4199, Recall: 91.99%, Valid: 95.64% Test: 95.57%\n",
      "Epoch: 602, Loss: 12847.2891, Recall: 91.99%, Valid: 95.65% Test: 95.57%\n",
      "Epoch: 603, Loss: 12888.5664, Recall: 92.02%, Valid: 95.65% Test: 95.58%\n",
      "Epoch: 604, Loss: 12869.9219, Recall: 91.98%, Valid: 95.68% Test: 95.62%\n",
      "Epoch: 605, Loss: 12890.3555, Recall: 91.94%, Valid: 95.71% Test: 95.67%\n",
      "Epoch: 606, Loss: 12874.0527, Recall: 91.88%, Valid: 95.74% Test: 95.69%\n",
      "Epoch: 607, Loss: 12854.2900, Recall: 91.88%, Valid: 95.76% Test: 95.72%\n",
      "Epoch: 608, Loss: 12921.4570, Recall: 91.84%, Valid: 95.75% Test: 95.72%\n",
      "Epoch: 609, Loss: 12900.2734, Recall: 91.35%, Valid: 95.75% Test: 95.71%\n",
      "Epoch: 610, Loss: 12848.2188, Recall: 91.41%, Valid: 95.72% Test: 95.67%\n",
      "Epoch: 611, Loss: 12869.0068, Recall: 91.68%, Valid: 95.70% Test: 95.65%\n",
      "Epoch: 612, Loss: 12849.6777, Recall: 91.83%, Valid: 95.70% Test: 95.62%\n",
      "Epoch: 613, Loss: 12873.2305, Recall: 91.95%, Valid: 95.71% Test: 95.62%\n",
      "Epoch: 614, Loss: 12889.7432, Recall: 91.97%, Valid: 95.71% Test: 95.64%\n",
      "Epoch: 615, Loss: 12907.0547, Recall: 92.01%, Valid: 95.71% Test: 95.65%\n",
      "Epoch: 616, Loss: 12879.2412, Recall: 92.02%, Valid: 95.70% Test: 95.65%\n",
      "Epoch: 617, Loss: 12868.9492, Recall: 92.02%, Valid: 95.71% Test: 95.64%\n",
      "Epoch: 618, Loss: 12869.9229, Recall: 92.00%, Valid: 95.73% Test: 95.64%\n",
      "Epoch: 619, Loss: 12875.4922, Recall: 92.05%, Valid: 95.75% Test: 95.66%\n",
      "Epoch: 620, Loss: 12851.1523, Recall: 92.02%, Valid: 95.77% Test: 95.67%\n",
      "Epoch: 621, Loss: 12899.4463, Recall: 91.98%, Valid: 95.78% Test: 95.70%\n",
      "Epoch: 622, Loss: 12857.9248, Recall: 92.03%, Valid: 95.77% Test: 95.69%\n",
      "Epoch: 623, Loss: 12879.4707, Recall: 92.01%, Valid: 95.76% Test: 95.69%\n",
      "Epoch: 624, Loss: 12832.9805, Recall: 91.93%, Valid: 95.75% Test: 95.68%\n",
      "Epoch: 625, Loss: 12837.9521, Recall: 91.93%, Valid: 95.74% Test: 95.66%\n",
      "Epoch: 626, Loss: 12860.8027, Recall: 91.96%, Valid: 95.74% Test: 95.66%\n",
      "Epoch: 627, Loss: 12861.0020, Recall: 92.00%, Valid: 95.75% Test: 95.67%\n",
      "Epoch: 628, Loss: 12892.5986, Recall: 91.96%, Valid: 95.75% Test: 95.65%\n",
      "Epoch: 629, Loss: 12856.0391, Recall: 91.88%, Valid: 95.75% Test: 95.64%\n",
      "Epoch: 630, Loss: 12890.0508, Recall: 91.87%, Valid: 95.75% Test: 95.64%\n",
      "Epoch: 631, Loss: 12872.1387, Recall: 91.83%, Valid: 95.74% Test: 95.63%\n",
      "Epoch: 632, Loss: 12867.4863, Recall: 91.91%, Valid: 95.72% Test: 95.63%\n",
      "Epoch: 633, Loss: 12869.8164, Recall: 91.96%, Valid: 95.71% Test: 95.63%\n",
      "Epoch: 634, Loss: 12854.6777, Recall: 91.96%, Valid: 95.73% Test: 95.63%\n",
      "Epoch: 635, Loss: 12865.1348, Recall: 91.98%, Valid: 95.74% Test: 95.64%\n",
      "Epoch: 636, Loss: 12854.8438, Recall: 91.95%, Valid: 95.75% Test: 95.65%\n",
      "Epoch: 637, Loss: 12865.3008, Recall: 91.94%, Valid: 95.75% Test: 95.65%\n",
      "Epoch: 638, Loss: 12845.0703, Recall: 91.97%, Valid: 95.75% Test: 95.65%\n",
      "Epoch: 639, Loss: 12847.9941, Recall: 91.95%, Valid: 95.76% Test: 95.67%\n",
      "Epoch: 640, Loss: 12838.8359, Recall: 91.93%, Valid: 95.78% Test: 95.70%\n",
      "Epoch: 641, Loss: 12842.8613, Recall: 91.90%, Valid: 95.81% Test: 95.73%\n",
      "Epoch: 642, Loss: 12866.3340, Recall: 91.94%, Valid: 95.83% Test: 95.75%\n",
      "Epoch: 643, Loss: 12848.0059, Recall: 91.94%, Valid: 95.83% Test: 95.75%\n",
      "Epoch: 644, Loss: 12814.2520, Recall: 91.97%, Valid: 95.84% Test: 95.76%\n",
      "Epoch: 645, Loss: 12871.8916, Recall: 91.98%, Valid: 95.85% Test: 95.77%\n",
      "Epoch: 646, Loss: 12838.8311, Recall: 91.98%, Valid: 95.86% Test: 95.78%\n",
      "Epoch: 647, Loss: 12860.4873, Recall: 92.02%, Valid: 95.85% Test: 95.79%\n",
      "Epoch: 648, Loss: 12844.5459, Recall: 92.01%, Valid: 95.83% Test: 95.76%\n",
      "Epoch: 649, Loss: 12842.9141, Recall: 92.01%, Valid: 95.82% Test: 95.75%\n",
      "Epoch: 650, Loss: 12854.5000, Recall: 92.03%, Valid: 95.80% Test: 95.73%\n",
      "Epoch: 651, Loss: 12838.2617, Recall: 92.02%, Valid: 95.77% Test: 95.71%\n",
      "Epoch: 652, Loss: 12864.8691, Recall: 92.01%, Valid: 95.76% Test: 95.69%\n",
      "Epoch: 653, Loss: 12823.1533, Recall: 91.99%, Valid: 95.77% Test: 95.69%\n",
      "Epoch: 654, Loss: 12858.2861, Recall: 92.00%, Valid: 95.77% Test: 95.69%\n",
      "Epoch: 655, Loss: 12839.8018, Recall: 91.94%, Valid: 95.77% Test: 95.69%\n",
      "Epoch: 656, Loss: 12860.9180, Recall: 91.90%, Valid: 95.77% Test: 95.69%\n",
      "Epoch: 657, Loss: 12843.3965, Recall: 91.66%, Valid: 95.77% Test: 95.67%\n",
      "Epoch: 658, Loss: 12860.8916, Recall: 91.62%, Valid: 95.76% Test: 95.66%\n",
      "Epoch: 659, Loss: 12845.5039, Recall: 91.88%, Valid: 95.77% Test: 95.68%\n",
      "Epoch: 660, Loss: 12839.3223, Recall: 91.96%, Valid: 95.78% Test: 95.70%\n",
      "Epoch: 661, Loss: 12836.9229, Recall: 91.90%, Valid: 95.80% Test: 95.72%\n",
      "Epoch: 662, Loss: 12872.2930, Recall: 91.99%, Valid: 95.80% Test: 95.74%\n",
      "Epoch: 663, Loss: 12864.3613, Recall: 91.96%, Valid: 95.80% Test: 95.73%\n",
      "Epoch: 664, Loss: 12847.3525, Recall: 91.95%, Valid: 95.79% Test: 95.72%\n",
      "Epoch: 665, Loss: 12875.0488, Recall: 91.95%, Valid: 95.80% Test: 95.73%\n",
      "Epoch: 666, Loss: 12816.7500, Recall: 91.93%, Valid: 95.81% Test: 95.75%\n",
      "Epoch: 667, Loss: 12817.7861, Recall: 91.83%, Valid: 95.82% Test: 95.76%\n",
      "Epoch: 668, Loss: 12840.0254, Recall: 91.77%, Valid: 95.82% Test: 95.77%\n",
      "Epoch: 669, Loss: 12853.0557, Recall: 91.62%, Valid: 95.83% Test: 95.77%\n",
      "Epoch: 670, Loss: 12838.6309, Recall: 91.75%, Valid: 95.83% Test: 95.78%\n",
      "Epoch: 671, Loss: 12863.0215, Recall: 91.99%, Valid: 95.82% Test: 95.77%\n",
      "Epoch: 672, Loss: 12848.6973, Recall: 92.02%, Valid: 95.80% Test: 95.74%\n",
      "Epoch: 673, Loss: 12858.8623, Recall: 92.05%, Valid: 95.79% Test: 95.73%\n",
      "Epoch: 674, Loss: 12841.0039, Recall: 92.07%, Valid: 95.79% Test: 95.74%\n",
      "Epoch: 675, Loss: 12828.0557, Recall: 92.03%, Valid: 95.81% Test: 95.74%\n",
      "Epoch: 676, Loss: 12852.1816, Recall: 91.98%, Valid: 95.81% Test: 95.74%\n",
      "Epoch: 677, Loss: 12823.9033, Recall: 91.97%, Valid: 95.82% Test: 95.75%\n",
      "Epoch: 678, Loss: 12848.9805, Recall: 91.95%, Valid: 95.84% Test: 95.74%\n",
      "Epoch: 679, Loss: 12854.7969, Recall: 91.93%, Valid: 95.84% Test: 95.75%\n",
      "Epoch: 680, Loss: 12854.2129, Recall: 91.94%, Valid: 95.85% Test: 95.75%\n",
      "Epoch: 681, Loss: 12851.1016, Recall: 91.95%, Valid: 95.85% Test: 95.75%\n",
      "Epoch: 682, Loss: 12846.6777, Recall: 91.99%, Valid: 95.85% Test: 95.75%\n",
      "Epoch: 683, Loss: 12811.3418, Recall: 91.98%, Valid: 95.85% Test: 95.76%\n",
      "Epoch: 684, Loss: 12797.7012, Recall: 92.03%, Valid: 95.85% Test: 95.76%\n",
      "Epoch: 685, Loss: 12834.4297, Recall: 92.00%, Valid: 95.85% Test: 95.77%\n",
      "Epoch: 686, Loss: 12859.8594, Recall: 92.02%, Valid: 95.88% Test: 95.79%\n",
      "Epoch: 687, Loss: 12824.0332, Recall: 92.02%, Valid: 95.90% Test: 95.82%\n",
      "Epoch: 688, Loss: 12806.0156, Recall: 92.00%, Valid: 95.91% Test: 95.83%\n",
      "Epoch: 689, Loss: 12842.6016, Recall: 91.97%, Valid: 95.89% Test: 95.82%\n",
      "Epoch: 690, Loss: 12845.9668, Recall: 91.95%, Valid: 95.88% Test: 95.81%\n",
      "Epoch: 691, Loss: 12831.3477, Recall: 91.92%, Valid: 95.86% Test: 95.78%\n",
      "Epoch: 692, Loss: 12835.2695, Recall: 91.91%, Valid: 95.83% Test: 95.75%\n",
      "Epoch: 693, Loss: 12836.6426, Recall: 91.92%, Valid: 95.80% Test: 95.72%\n",
      "Epoch: 694, Loss: 12836.9551, Recall: 91.93%, Valid: 95.78% Test: 95.67%\n",
      "Epoch: 695, Loss: 12845.6025, Recall: 91.95%, Valid: 95.76% Test: 95.66%\n",
      "Epoch: 696, Loss: 12839.0918, Recall: 91.86%, Valid: 95.74% Test: 95.65%\n",
      "Epoch: 697, Loss: 12838.2812, Recall: 91.88%, Valid: 95.73% Test: 95.66%\n",
      "Epoch: 698, Loss: 12836.9854, Recall: 91.95%, Valid: 95.73% Test: 95.68%\n",
      "Epoch: 699, Loss: 12842.1357, Recall: 92.02%, Valid: 95.74% Test: 95.69%\n",
      "Epoch: 700, Loss: 12856.6289, Recall: 92.03%, Valid: 95.76% Test: 95.69%\n",
      "Epoch: 701, Loss: 12807.7422, Recall: 92.03%, Valid: 95.78% Test: 95.72%\n",
      "Epoch: 702, Loss: 12822.7324, Recall: 92.02%, Valid: 95.82% Test: 95.73%\n",
      "Epoch: 703, Loss: 12810.0400, Recall: 91.95%, Valid: 95.84% Test: 95.75%\n",
      "Epoch: 704, Loss: 12849.0918, Recall: 91.98%, Valid: 95.87% Test: 95.77%\n",
      "Epoch: 705, Loss: 12820.5967, Recall: 91.99%, Valid: 95.89% Test: 95.79%\n",
      "Epoch: 706, Loss: 12828.5586, Recall: 92.02%, Valid: 95.91% Test: 95.82%\n",
      "Epoch: 707, Loss: 12833.3887, Recall: 92.06%, Valid: 95.91% Test: 95.83%\n",
      "Epoch: 708, Loss: 12826.6855, Recall: 92.05%, Valid: 95.92% Test: 95.84%\n",
      "Epoch: 709, Loss: 12826.2881, Recall: 92.05%, Valid: 95.92% Test: 95.85%\n",
      "Epoch: 710, Loss: 12834.8105, Recall: 92.06%, Valid: 95.92% Test: 95.86%\n",
      "Epoch: 711, Loss: 12819.5059, Recall: 92.06%, Valid: 95.92% Test: 95.84%\n",
      "Epoch: 712, Loss: 12796.4727, Recall: 92.06%, Valid: 95.91% Test: 95.84%\n",
      "Epoch: 713, Loss: 12828.2354, Recall: 92.00%, Valid: 95.90% Test: 95.81%\n",
      "Epoch: 714, Loss: 12805.0762, Recall: 91.86%, Valid: 95.90% Test: 95.81%\n",
      "Epoch: 715, Loss: 12830.0801, Recall: 91.90%, Valid: 95.91% Test: 95.83%\n",
      "Epoch: 716, Loss: 12830.9902, Recall: 91.91%, Valid: 95.92% Test: 95.83%\n",
      "Epoch: 717, Loss: 12805.4424, Recall: 91.93%, Valid: 95.92% Test: 95.84%\n",
      "Epoch: 718, Loss: 12823.6035, Recall: 91.94%, Valid: 95.94% Test: 95.85%\n",
      "Epoch: 719, Loss: 12839.9082, Recall: 92.01%, Valid: 95.95% Test: 95.87%\n",
      "Epoch: 720, Loss: 12812.6396, Recall: 91.95%, Valid: 95.96% Test: 95.88%\n",
      "Epoch: 721, Loss: 12835.4990, Recall: 91.89%, Valid: 95.95% Test: 95.86%\n",
      "Epoch: 722, Loss: 12841.0986, Recall: 91.95%, Valid: 95.92% Test: 95.81%\n",
      "Epoch: 723, Loss: 12826.8418, Recall: 91.95%, Valid: 95.88% Test: 95.76%\n",
      "Epoch: 724, Loss: 12799.6836, Recall: 91.86%, Valid: 95.84% Test: 95.73%\n",
      "Epoch: 725, Loss: 12850.0098, Recall: 91.79%, Valid: 95.81% Test: 95.71%\n",
      "Epoch: 726, Loss: 12831.5820, Recall: 91.92%, Valid: 95.84% Test: 95.73%\n",
      "Epoch: 727, Loss: 12824.4121, Recall: 91.97%, Valid: 95.87% Test: 95.77%\n",
      "Epoch: 728, Loss: 12821.6816, Recall: 92.01%, Valid: 95.90% Test: 95.81%\n",
      "Epoch: 729, Loss: 12826.3652, Recall: 91.96%, Valid: 95.91% Test: 95.84%\n",
      "Epoch: 730, Loss: 12834.1943, Recall: 91.95%, Valid: 95.93% Test: 95.85%\n",
      "Epoch: 731, Loss: 12798.7051, Recall: 91.95%, Valid: 95.95% Test: 95.88%\n",
      "Epoch: 732, Loss: 12788.6826, Recall: 91.97%, Valid: 95.95% Test: 95.88%\n",
      "Epoch: 733, Loss: 12830.9658, Recall: 91.88%, Valid: 95.95% Test: 95.88%\n",
      "Epoch: 734, Loss: 12834.7754, Recall: 91.89%, Valid: 95.95% Test: 95.88%\n",
      "Epoch: 735, Loss: 12812.0996, Recall: 92.04%, Valid: 95.96% Test: 95.88%\n",
      "Epoch: 736, Loss: 12827.4609, Recall: 92.07%, Valid: 95.96% Test: 95.89%\n",
      "Epoch: 737, Loss: 12816.6240, Recall: 92.03%, Valid: 95.94% Test: 95.88%\n",
      "Epoch: 738, Loss: 12805.2148, Recall: 91.99%, Valid: 95.93% Test: 95.87%\n",
      "Epoch: 739, Loss: 12832.8281, Recall: 91.98%, Valid: 95.92% Test: 95.86%\n",
      "Epoch: 740, Loss: 12826.1738, Recall: 91.95%, Valid: 95.90% Test: 95.83%\n",
      "Epoch: 741, Loss: 12829.0010, Recall: 91.95%, Valid: 95.88% Test: 95.82%\n",
      "Epoch: 742, Loss: 12816.0352, Recall: 91.97%, Valid: 95.87% Test: 95.80%\n",
      "Epoch: 743, Loss: 12811.6035, Recall: 92.01%, Valid: 95.86% Test: 95.78%\n",
      "Epoch: 744, Loss: 12833.9658, Recall: 91.97%, Valid: 95.84% Test: 95.76%\n",
      "Epoch: 745, Loss: 12842.4434, Recall: 91.96%, Valid: 95.84% Test: 95.76%\n",
      "Epoch: 746, Loss: 12822.6982, Recall: 91.95%, Valid: 95.84% Test: 95.75%\n",
      "Epoch: 747, Loss: 12801.1631, Recall: 91.97%, Valid: 95.85% Test: 95.77%\n",
      "Epoch: 748, Loss: 12833.3555, Recall: 91.99%, Valid: 95.86% Test: 95.78%\n",
      "Epoch: 749, Loss: 12804.0391, Recall: 92.04%, Valid: 95.89% Test: 95.79%\n",
      "Epoch: 750, Loss: 12818.1914, Recall: 92.04%, Valid: 95.94% Test: 95.84%\n",
      "Epoch: 751, Loss: 12795.5762, Recall: 92.03%, Valid: 95.97% Test: 95.89%\n",
      "Epoch: 752, Loss: 12812.5361, Recall: 92.01%, Valid: 96.00% Test: 95.93%\n",
      "Epoch: 753, Loss: 12838.6973, Recall: 92.03%, Valid: 96.02% Test: 95.94%\n",
      "Epoch: 754, Loss: 12811.7109, Recall: 92.04%, Valid: 96.01% Test: 95.93%\n",
      "Epoch: 755, Loss: 12816.1465, Recall: 92.01%, Valid: 96.00% Test: 95.92%\n",
      "Epoch: 756, Loss: 12800.2373, Recall: 91.99%, Valid: 95.99% Test: 95.92%\n",
      "Epoch: 757, Loss: 12843.1582, Recall: 92.00%, Valid: 95.98% Test: 95.91%\n",
      "Epoch: 758, Loss: 12804.2441, Recall: 92.02%, Valid: 95.99% Test: 95.91%\n",
      "Epoch: 759, Loss: 12800.4551, Recall: 91.99%, Valid: 95.98% Test: 95.91%\n",
      "Epoch: 760, Loss: 12807.2080, Recall: 91.98%, Valid: 95.97% Test: 95.90%\n",
      "Epoch: 761, Loss: 12779.7734, Recall: 91.99%, Valid: 95.95% Test: 95.87%\n",
      "Epoch: 762, Loss: 12814.9658, Recall: 92.01%, Valid: 95.93% Test: 95.85%\n",
      "Epoch: 763, Loss: 12800.6221, Recall: 92.00%, Valid: 95.90% Test: 95.81%\n",
      "Epoch: 764, Loss: 12825.5439, Recall: 91.98%, Valid: 95.88% Test: 95.81%\n",
      "Epoch: 765, Loss: 12821.0576, Recall: 91.87%, Valid: 95.87% Test: 95.80%\n",
      "Epoch: 766, Loss: 12818.7480, Recall: 91.92%, Valid: 95.89% Test: 95.83%\n",
      "Epoch: 767, Loss: 12790.4844, Recall: 91.94%, Valid: 95.92% Test: 95.84%\n",
      "Epoch: 768, Loss: 12825.5703, Recall: 91.95%, Valid: 95.93% Test: 95.84%\n",
      "Epoch: 769, Loss: 12803.1875, Recall: 91.95%, Valid: 95.92% Test: 95.83%\n",
      "Epoch: 770, Loss: 12788.0566, Recall: 91.95%, Valid: 95.93% Test: 95.85%\n",
      "Epoch: 771, Loss: 12799.0508, Recall: 91.94%, Valid: 95.94% Test: 95.86%\n",
      "Epoch: 772, Loss: 12810.0908, Recall: 91.89%, Valid: 95.95% Test: 95.87%\n",
      "Epoch: 773, Loss: 12827.9521, Recall: 91.97%, Valid: 95.97% Test: 95.89%\n",
      "Epoch: 774, Loss: 12809.1309, Recall: 92.00%, Valid: 95.99% Test: 95.88%\n",
      "Epoch: 775, Loss: 12812.1670, Recall: 91.88%, Valid: 95.96% Test: 95.87%\n",
      "Epoch: 776, Loss: 12815.2129, Recall: 91.93%, Valid: 95.95% Test: 95.88%\n",
      "Epoch: 777, Loss: 12804.5098, Recall: 91.88%, Valid: 95.95% Test: 95.89%\n",
      "Epoch: 778, Loss: 12786.4824, Recall: 91.93%, Valid: 95.98% Test: 95.89%\n",
      "Epoch: 779, Loss: 12800.3457, Recall: 91.83%, Valid: 95.99% Test: 95.91%\n",
      "Epoch: 780, Loss: 12812.1113, Recall: 91.85%, Valid: 95.98% Test: 95.91%\n",
      "Epoch: 781, Loss: 12815.3789, Recall: 91.98%, Valid: 95.99% Test: 95.92%\n",
      "Epoch: 782, Loss: 12788.2148, Recall: 91.97%, Valid: 95.99% Test: 95.93%\n",
      "Epoch: 783, Loss: 12806.6104, Recall: 91.91%, Valid: 95.98% Test: 95.93%\n",
      "Epoch: 784, Loss: 12816.7588, Recall: 91.91%, Valid: 95.98% Test: 95.93%\n",
      "Epoch: 785, Loss: 12788.7822, Recall: 91.85%, Valid: 95.98% Test: 95.93%\n",
      "Epoch: 786, Loss: 12783.8857, Recall: 91.94%, Valid: 95.99% Test: 95.93%\n",
      "Epoch: 787, Loss: 12797.2920, Recall: 92.00%, Valid: 96.01% Test: 95.94%\n",
      "Epoch: 788, Loss: 12808.4863, Recall: 92.02%, Valid: 96.02% Test: 95.94%\n",
      "Epoch: 789, Loss: 12782.9199, Recall: 92.04%, Valid: 96.03% Test: 95.95%\n",
      "Epoch: 790, Loss: 12793.4990, Recall: 92.06%, Valid: 96.03% Test: 95.94%\n",
      "Epoch: 791, Loss: 12800.3945, Recall: 92.03%, Valid: 96.03% Test: 95.94%\n",
      "Epoch: 792, Loss: 12807.5869, Recall: 91.98%, Valid: 96.05% Test: 95.96%\n",
      "Epoch: 793, Loss: 12822.6611, Recall: 91.94%, Valid: 96.05% Test: 95.96%\n",
      "Epoch: 794, Loss: 12776.3467, Recall: 91.89%, Valid: 96.05% Test: 95.97%\n",
      "Epoch: 795, Loss: 12802.2188, Recall: 91.87%, Valid: 96.03% Test: 95.96%\n",
      "Epoch: 796, Loss: 12806.4893, Recall: 91.84%, Valid: 96.02% Test: 95.93%\n",
      "Epoch: 797, Loss: 12788.0762, Recall: 91.94%, Valid: 96.00% Test: 95.90%\n",
      "Epoch: 798, Loss: 12819.1855, Recall: 91.93%, Valid: 96.00% Test: 95.90%\n",
      "Epoch: 799, Loss: 12797.4893, Recall: 91.94%, Valid: 96.00% Test: 95.91%\n",
      "Epoch: 800, Loss: 12800.2432, Recall: 91.95%, Valid: 96.00% Test: 95.92%\n",
      "Epoch: 801, Loss: 12799.6289, Recall: 91.98%, Valid: 96.01% Test: 95.92%\n",
      "Epoch: 802, Loss: 12789.7686, Recall: 91.96%, Valid: 96.03% Test: 95.93%\n",
      "Epoch: 803, Loss: 12805.0107, Recall: 91.97%, Valid: 96.05% Test: 95.94%\n",
      "Epoch: 804, Loss: 12803.0215, Recall: 91.94%, Valid: 96.07% Test: 95.97%\n",
      "Epoch: 805, Loss: 12799.1328, Recall: 92.00%, Valid: 96.08% Test: 96.00%\n",
      "Epoch: 806, Loss: 12789.9629, Recall: 92.01%, Valid: 96.10% Test: 96.02%\n",
      "Epoch: 807, Loss: 12793.5918, Recall: 91.98%, Valid: 96.11% Test: 96.03%\n",
      "Epoch: 808, Loss: 12785.5615, Recall: 92.01%, Valid: 96.12% Test: 96.04%\n",
      "Epoch: 809, Loss: 12807.0508, Recall: 91.99%, Valid: 96.12% Test: 96.04%\n",
      "Epoch: 810, Loss: 12812.1689, Recall: 92.02%, Valid: 96.11% Test: 96.03%\n",
      "Epoch: 811, Loss: 12786.2617, Recall: 92.04%, Valid: 96.09% Test: 96.02%\n",
      "Epoch: 812, Loss: 12752.2783, Recall: 92.03%, Valid: 96.08% Test: 96.01%\n",
      "Epoch: 813, Loss: 12801.1787, Recall: 91.96%, Valid: 96.06% Test: 95.98%\n",
      "Epoch: 814, Loss: 12769.1670, Recall: 91.85%, Valid: 96.03% Test: 95.95%\n",
      "Epoch: 815, Loss: 12812.0566, Recall: 91.81%, Valid: 96.02% Test: 95.94%\n",
      "Epoch: 816, Loss: 12802.4375, Recall: 91.77%, Valid: 96.01% Test: 95.92%\n",
      "Epoch: 817, Loss: 12786.9756, Recall: 91.76%, Valid: 96.01% Test: 95.92%\n",
      "Epoch: 818, Loss: 12784.1504, Recall: 91.87%, Valid: 96.01% Test: 95.94%\n",
      "Epoch: 819, Loss: 12780.5840, Recall: 91.85%, Valid: 96.01% Test: 95.93%\n",
      "Epoch: 820, Loss: 12772.6504, Recall: 91.89%, Valid: 96.00% Test: 95.90%\n",
      "Epoch: 821, Loss: 12790.7656, Recall: 91.87%, Valid: 96.01% Test: 95.92%\n",
      "Epoch: 822, Loss: 12790.8086, Recall: 91.97%, Valid: 96.00% Test: 95.92%\n",
      "Epoch: 823, Loss: 12804.1836, Recall: 92.00%, Valid: 96.02% Test: 95.92%\n",
      "Epoch: 824, Loss: 12804.0117, Recall: 92.02%, Valid: 96.04% Test: 95.94%\n",
      "Epoch: 825, Loss: 12813.8486, Recall: 92.01%, Valid: 96.05% Test: 95.97%\n",
      "Epoch: 826, Loss: 12784.5508, Recall: 91.99%, Valid: 96.06% Test: 95.97%\n",
      "Epoch: 827, Loss: 12787.7285, Recall: 91.96%, Valid: 96.07% Test: 95.98%\n",
      "Epoch: 828, Loss: 12807.1201, Recall: 91.98%, Valid: 96.07% Test: 95.99%\n",
      "Epoch: 829, Loss: 12780.7842, Recall: 91.94%, Valid: 96.07% Test: 95.99%\n",
      "Epoch: 830, Loss: 12806.9844, Recall: 91.97%, Valid: 96.08% Test: 95.99%\n",
      "Epoch: 831, Loss: 12797.2236, Recall: 92.05%, Valid: 96.09% Test: 96.00%\n",
      "Epoch: 832, Loss: 12772.1426, Recall: 92.02%, Valid: 96.10% Test: 96.01%\n",
      "Epoch: 833, Loss: 12768.7793, Recall: 91.99%, Valid: 96.11% Test: 96.02%\n",
      "Epoch: 834, Loss: 12770.5566, Recall: 92.01%, Valid: 96.11% Test: 96.03%\n",
      "Epoch: 835, Loss: 12809.5215, Recall: 91.87%, Valid: 96.10% Test: 96.03%\n",
      "Epoch: 836, Loss: 12767.3047, Recall: 91.86%, Valid: 96.10% Test: 96.03%\n",
      "Epoch: 837, Loss: 12798.8145, Recall: 92.02%, Valid: 96.07% Test: 96.00%\n",
      "Epoch: 838, Loss: 12794.1621, Recall: 92.07%, Valid: 96.03% Test: 95.96%\n",
      "Epoch: 839, Loss: 12791.2002, Recall: 92.10%, Valid: 95.98% Test: 95.91%\n",
      "Epoch: 840, Loss: 12830.3076, Recall: 92.07%, Valid: 95.94% Test: 95.88%\n",
      "Epoch: 841, Loss: 12790.9736, Recall: 92.04%, Valid: 95.93% Test: 95.86%\n",
      "Epoch: 842, Loss: 12769.6035, Recall: 92.05%, Valid: 95.93% Test: 95.87%\n",
      "Epoch: 843, Loss: 12790.0859, Recall: 92.04%, Valid: 95.94% Test: 95.89%\n",
      "Epoch: 844, Loss: 12784.7969, Recall: 92.02%, Valid: 95.97% Test: 95.92%\n",
      "Epoch: 845, Loss: 12822.7783, Recall: 91.98%, Valid: 95.99% Test: 95.94%\n",
      "Epoch: 846, Loss: 12789.7227, Recall: 91.79%, Valid: 96.01% Test: 95.95%\n",
      "Epoch: 847, Loss: 12781.3926, Recall: 91.65%, Valid: 96.03% Test: 95.98%\n",
      "Epoch: 848, Loss: 12788.2412, Recall: 91.95%, Valid: 96.04% Test: 95.99%\n",
      "Epoch: 849, Loss: 12780.8096, Recall: 92.02%, Valid: 96.07% Test: 96.00%\n",
      "Epoch: 850, Loss: 12792.7891, Recall: 92.04%, Valid: 96.09% Test: 96.02%\n",
      "Epoch: 851, Loss: 12785.3203, Recall: 92.05%, Valid: 96.09% Test: 96.02%\n",
      "Epoch: 852, Loss: 12789.8438, Recall: 92.06%, Valid: 96.07% Test: 96.01%\n",
      "Epoch: 853, Loss: 12759.4141, Recall: 92.03%, Valid: 96.06% Test: 95.99%\n",
      "Epoch: 854, Loss: 12793.2568, Recall: 92.08%, Valid: 96.06% Test: 95.99%\n",
      "Epoch: 855, Loss: 12787.4189, Recall: 92.06%, Valid: 96.06% Test: 95.99%\n",
      "Epoch: 856, Loss: 12785.6758, Recall: 92.05%, Valid: 96.07% Test: 96.00%\n",
      "Epoch: 857, Loss: 12805.5488, Recall: 92.04%, Valid: 96.09% Test: 95.99%\n",
      "Epoch: 858, Loss: 12786.7441, Recall: 92.03%, Valid: 96.09% Test: 95.99%\n",
      "Epoch: 859, Loss: 12790.4238, Recall: 92.01%, Valid: 96.09% Test: 95.99%\n",
      "Epoch: 860, Loss: 12792.1055, Recall: 92.02%, Valid: 96.09% Test: 95.99%\n",
      "Epoch: 861, Loss: 12765.6523, Recall: 92.04%, Valid: 96.09% Test: 95.99%\n",
      "Epoch: 862, Loss: 12772.6758, Recall: 92.04%, Valid: 96.09% Test: 95.98%\n",
      "Epoch: 863, Loss: 12765.4570, Recall: 92.06%, Valid: 96.09% Test: 96.00%\n",
      "Epoch: 864, Loss: 12779.2812, Recall: 92.04%, Valid: 96.09% Test: 96.01%\n",
      "Epoch: 865, Loss: 12743.4980, Recall: 91.97%, Valid: 96.10% Test: 96.01%\n",
      "Epoch: 866, Loss: 12781.0322, Recall: 91.99%, Valid: 96.11% Test: 96.01%\n",
      "Epoch: 867, Loss: 12779.2422, Recall: 92.00%, Valid: 96.10% Test: 96.02%\n",
      "Epoch: 868, Loss: 12780.0469, Recall: 91.97%, Valid: 96.10% Test: 96.02%\n",
      "Epoch: 869, Loss: 12754.0527, Recall: 92.01%, Valid: 96.10% Test: 96.02%\n",
      "Epoch: 870, Loss: 12768.5195, Recall: 92.06%, Valid: 96.11% Test: 96.02%\n",
      "Epoch: 871, Loss: 12769.5645, Recall: 92.07%, Valid: 96.10% Test: 96.02%\n",
      "Epoch: 872, Loss: 12769.3848, Recall: 92.04%, Valid: 96.09% Test: 96.00%\n",
      "Epoch: 873, Loss: 12792.0410, Recall: 92.05%, Valid: 96.08% Test: 95.98%\n",
      "Epoch: 874, Loss: 12764.2676, Recall: 92.08%, Valid: 96.06% Test: 95.96%\n",
      "Epoch: 875, Loss: 12781.6484, Recall: 92.06%, Valid: 96.06% Test: 95.96%\n",
      "Epoch: 876, Loss: 12766.5078, Recall: 92.08%, Valid: 96.05% Test: 95.95%\n",
      "Epoch: 877, Loss: 12772.5820, Recall: 92.06%, Valid: 96.04% Test: 95.95%\n",
      "Epoch: 878, Loss: 12796.3213, Recall: 92.00%, Valid: 96.02% Test: 95.96%\n",
      "Epoch: 879, Loss: 12748.8809, Recall: 92.03%, Valid: 96.02% Test: 95.97%\n",
      "Epoch: 880, Loss: 12797.3027, Recall: 91.99%, Valid: 96.04% Test: 95.96%\n",
      "Epoch: 881, Loss: 12787.7812, Recall: 92.03%, Valid: 96.05% Test: 95.97%\n",
      "Epoch: 882, Loss: 12764.7324, Recall: 92.03%, Valid: 96.05% Test: 95.96%\n",
      "Epoch: 883, Loss: 12779.1992, Recall: 92.04%, Valid: 96.04% Test: 95.96%\n",
      "Epoch: 884, Loss: 12760.3594, Recall: 92.04%, Valid: 96.05% Test: 95.96%\n",
      "Epoch: 885, Loss: 12785.3311, Recall: 91.91%, Valid: 96.04% Test: 95.95%\n",
      "Epoch: 886, Loss: 12768.6191, Recall: 92.01%, Valid: 96.04% Test: 95.94%\n",
      "Epoch: 887, Loss: 12789.1094, Recall: 91.95%, Valid: 96.02% Test: 95.93%\n",
      "Epoch: 888, Loss: 12766.7002, Recall: 91.97%, Valid: 96.00% Test: 95.93%\n",
      "Epoch: 889, Loss: 12802.1641, Recall: 91.89%, Valid: 95.98% Test: 95.90%\n",
      "Epoch: 890, Loss: 12769.6973, Recall: 91.74%, Valid: 95.97% Test: 95.88%\n",
      "Epoch: 891, Loss: 12786.2832, Recall: 91.85%, Valid: 96.00% Test: 95.90%\n",
      "Epoch: 892, Loss: 12787.2988, Recall: 91.96%, Valid: 96.02% Test: 95.93%\n",
      "Epoch: 893, Loss: 12795.3916, Recall: 92.04%, Valid: 96.01% Test: 95.93%\n",
      "Epoch: 894, Loss: 12766.0625, Recall: 92.06%, Valid: 96.00% Test: 95.93%\n",
      "Epoch: 895, Loss: 12753.0664, Recall: 92.04%, Valid: 96.01% Test: 95.94%\n",
      "Epoch: 896, Loss: 12787.3750, Recall: 92.05%, Valid: 96.02% Test: 95.94%\n",
      "Epoch: 897, Loss: 12775.8359, Recall: 92.03%, Valid: 96.04% Test: 95.95%\n",
      "Epoch: 898, Loss: 12761.5732, Recall: 92.01%, Valid: 96.06% Test: 95.98%\n",
      "Epoch: 899, Loss: 12773.2881, Recall: 92.02%, Valid: 96.09% Test: 96.01%\n",
      "Epoch: 900, Loss: 12774.0117, Recall: 91.96%, Valid: 96.10% Test: 96.02%\n",
      "Epoch: 901, Loss: 12766.3926, Recall: 91.98%, Valid: 96.11% Test: 96.03%\n",
      "Epoch: 902, Loss: 12782.7041, Recall: 92.03%, Valid: 96.11% Test: 96.03%\n",
      "Epoch: 903, Loss: 12787.9033, Recall: 92.02%, Valid: 96.10% Test: 96.03%\n",
      "Epoch: 904, Loss: 12780.8818, Recall: 91.96%, Valid: 96.09% Test: 96.01%\n",
      "Epoch: 905, Loss: 12755.4199, Recall: 91.95%, Valid: 96.07% Test: 95.99%\n",
      "Epoch: 906, Loss: 12747.8730, Recall: 91.98%, Valid: 96.06% Test: 95.98%\n",
      "Epoch: 907, Loss: 12767.0820, Recall: 91.95%, Valid: 96.05% Test: 95.96%\n",
      "Epoch: 908, Loss: 12774.4043, Recall: 92.00%, Valid: 96.05% Test: 95.95%\n",
      "Epoch: 909, Loss: 12745.3350, Recall: 92.03%, Valid: 96.04% Test: 95.95%\n",
      "Epoch: 910, Loss: 12766.6572, Recall: 92.08%, Valid: 96.04% Test: 95.94%\n",
      "Epoch: 911, Loss: 12755.7871, Recall: 92.08%, Valid: 96.05% Test: 95.95%\n",
      "Epoch: 912, Loss: 12783.2803, Recall: 92.10%, Valid: 96.05% Test: 95.94%\n",
      "Epoch: 913, Loss: 12765.2754, Recall: 92.09%, Valid: 96.06% Test: 95.96%\n",
      "Epoch: 914, Loss: 12761.7451, Recall: 92.07%, Valid: 96.06% Test: 95.96%\n",
      "Epoch: 915, Loss: 12743.8584, Recall: 92.06%, Valid: 96.09% Test: 95.99%\n",
      "Epoch: 916, Loss: 12764.4365, Recall: 92.05%, Valid: 96.11% Test: 96.01%\n",
      "Epoch: 917, Loss: 12751.6143, Recall: 92.08%, Valid: 96.12% Test: 96.03%\n",
      "Epoch: 918, Loss: 12772.3301, Recall: 92.09%, Valid: 96.11% Test: 96.03%\n",
      "Epoch: 919, Loss: 12784.9678, Recall: 92.05%, Valid: 96.11% Test: 96.04%\n",
      "Epoch: 920, Loss: 12740.9902, Recall: 92.02%, Valid: 96.11% Test: 96.04%\n",
      "Epoch: 921, Loss: 12757.6475, Recall: 92.00%, Valid: 96.09% Test: 96.03%\n",
      "Epoch: 922, Loss: 12745.7598, Recall: 92.05%, Valid: 96.09% Test: 96.02%\n",
      "Epoch: 923, Loss: 12768.4316, Recall: 92.03%, Valid: 96.09% Test: 96.02%\n",
      "Epoch: 924, Loss: 12733.6230, Recall: 92.03%, Valid: 96.11% Test: 96.03%\n",
      "Epoch: 925, Loss: 12761.1104, Recall: 92.04%, Valid: 96.12% Test: 96.05%\n",
      "Epoch: 926, Loss: 12759.0029, Recall: 92.05%, Valid: 96.13% Test: 96.07%\n",
      "Epoch: 927, Loss: 12777.5273, Recall: 92.10%, Valid: 96.16% Test: 96.08%\n",
      "Epoch: 928, Loss: 12751.6973, Recall: 92.05%, Valid: 96.16% Test: 96.09%\n",
      "Epoch: 929, Loss: 12759.9150, Recall: 92.06%, Valid: 96.17% Test: 96.09%\n",
      "Epoch: 930, Loss: 12764.0938, Recall: 92.02%, Valid: 96.17% Test: 96.09%\n",
      "Epoch: 931, Loss: 12757.7988, Recall: 91.92%, Valid: 96.15% Test: 96.07%\n",
      "Epoch: 932, Loss: 12757.8164, Recall: 91.92%, Valid: 96.13% Test: 96.05%\n",
      "Epoch: 933, Loss: 12781.2773, Recall: 92.06%, Valid: 96.12% Test: 96.04%\n",
      "Epoch: 934, Loss: 12792.8691, Recall: 92.09%, Valid: 96.09% Test: 96.01%\n",
      "Epoch: 935, Loss: 12806.2754, Recall: 92.09%, Valid: 96.04% Test: 95.99%\n",
      "Epoch: 936, Loss: 12756.8223, Recall: 92.03%, Valid: 96.01% Test: 95.96%\n",
      "Epoch: 937, Loss: 12752.7910, Recall: 91.94%, Valid: 95.99% Test: 95.93%\n",
      "Epoch: 938, Loss: 12744.2578, Recall: 91.93%, Valid: 95.99% Test: 95.92%\n",
      "Epoch: 939, Loss: 12741.4346, Recall: 92.05%, Valid: 96.01% Test: 95.93%\n",
      "Epoch: 940, Loss: 12761.7822, Recall: 92.05%, Valid: 96.04% Test: 95.96%\n",
      "Epoch: 941, Loss: 12765.9697, Recall: 92.06%, Valid: 96.07% Test: 95.99%\n",
      "Epoch: 942, Loss: 12755.3848, Recall: 92.05%, Valid: 96.11% Test: 96.02%\n",
      "Epoch: 943, Loss: 12778.2451, Recall: 92.05%, Valid: 96.13% Test: 96.05%\n",
      "Epoch: 944, Loss: 12744.8037, Recall: 92.02%, Valid: 96.14% Test: 96.06%\n",
      "Epoch: 945, Loss: 12772.9785, Recall: 92.02%, Valid: 96.14% Test: 96.08%\n",
      "Epoch: 946, Loss: 12793.8496, Recall: 92.03%, Valid: 96.15% Test: 96.08%\n",
      "Epoch: 947, Loss: 12750.7061, Recall: 91.96%, Valid: 96.15% Test: 96.10%\n",
      "Epoch: 948, Loss: 12772.6807, Recall: 92.01%, Valid: 96.17% Test: 96.11%\n",
      "Epoch: 949, Loss: 12757.0703, Recall: 91.99%, Valid: 96.18% Test: 96.11%\n",
      "Epoch: 950, Loss: 12757.3555, Recall: 92.11%, Valid: 96.19% Test: 96.11%\n",
      "Epoch: 951, Loss: 12743.9561, Recall: 92.08%, Valid: 96.19% Test: 96.11%\n",
      "Epoch: 952, Loss: 12762.1553, Recall: 92.06%, Valid: 96.17% Test: 96.10%\n",
      "Epoch: 953, Loss: 12756.6660, Recall: 91.97%, Valid: 96.15% Test: 96.08%\n",
      "Epoch: 954, Loss: 12746.2012, Recall: 91.94%, Valid: 96.12% Test: 96.05%\n",
      "Epoch: 955, Loss: 12740.4863, Recall: 91.92%, Valid: 96.10% Test: 96.03%\n",
      "Epoch: 956, Loss: 12742.8633, Recall: 91.94%, Valid: 96.09% Test: 96.02%\n",
      "Epoch: 957, Loss: 12761.3398, Recall: 91.92%, Valid: 96.07% Test: 96.01%\n",
      "Epoch: 958, Loss: 12797.7549, Recall: 91.90%, Valid: 96.03% Test: 95.97%\n",
      "Epoch: 959, Loss: 12786.4971, Recall: 91.93%, Valid: 96.01% Test: 95.95%\n",
      "Epoch: 960, Loss: 12764.8125, Recall: 91.92%, Valid: 96.00% Test: 95.93%\n",
      "Epoch: 961, Loss: 12745.4326, Recall: 91.91%, Valid: 95.99% Test: 95.91%\n",
      "Epoch: 962, Loss: 12740.4609, Recall: 91.96%, Valid: 96.01% Test: 95.93%\n",
      "Epoch: 963, Loss: 12745.5371, Recall: 92.05%, Valid: 96.05% Test: 95.96%\n",
      "Epoch: 964, Loss: 12783.3477, Recall: 92.04%, Valid: 96.08% Test: 95.99%\n",
      "Epoch: 965, Loss: 12758.2705, Recall: 92.05%, Valid: 96.11% Test: 96.04%\n",
      "Epoch: 966, Loss: 12754.8564, Recall: 92.05%, Valid: 96.13% Test: 96.05%\n",
      "Epoch: 967, Loss: 12755.1221, Recall: 92.07%, Valid: 96.15% Test: 96.07%\n",
      "Epoch: 968, Loss: 12760.3447, Recall: 92.01%, Valid: 96.15% Test: 96.07%\n",
      "Epoch: 969, Loss: 12765.0391, Recall: 92.04%, Valid: 96.15% Test: 96.06%\n",
      "Epoch: 970, Loss: 12740.4707, Recall: 92.02%, Valid: 96.13% Test: 96.06%\n",
      "Epoch: 971, Loss: 12756.8164, Recall: 92.01%, Valid: 96.12% Test: 96.05%\n",
      "Epoch: 972, Loss: 12752.8721, Recall: 92.03%, Valid: 96.11% Test: 96.05%\n",
      "Epoch: 973, Loss: 12753.3242, Recall: 92.05%, Valid: 96.11% Test: 96.04%\n",
      "Epoch: 974, Loss: 12762.8320, Recall: 91.94%, Valid: 96.10% Test: 96.03%\n",
      "Epoch: 975, Loss: 12724.7998, Recall: 91.84%, Valid: 96.10% Test: 96.02%\n",
      "Epoch: 976, Loss: 12759.4102, Recall: 91.94%, Valid: 96.12% Test: 96.04%\n",
      "Epoch: 977, Loss: 12783.1514, Recall: 92.11%, Valid: 96.14% Test: 96.06%\n",
      "Epoch: 978, Loss: 12772.5146, Recall: 92.13%, Valid: 96.15% Test: 96.06%\n",
      "Epoch: 979, Loss: 12726.1279, Recall: 92.13%, Valid: 96.15% Test: 96.06%\n",
      "Epoch: 980, Loss: 12769.9902, Recall: 92.14%, Valid: 96.15% Test: 96.06%\n",
      "Epoch: 981, Loss: 12746.7500, Recall: 92.14%, Valid: 96.15% Test: 96.07%\n",
      "Epoch: 982, Loss: 12740.8877, Recall: 92.12%, Valid: 96.16% Test: 96.09%\n",
      "Epoch: 983, Loss: 12753.6836, Recall: 92.08%, Valid: 96.17% Test: 96.10%\n",
      "Epoch: 984, Loss: 12759.9824, Recall: 91.95%, Valid: 96.16% Test: 96.10%\n",
      "Epoch: 985, Loss: 12749.4805, Recall: 91.91%, Valid: 96.17% Test: 96.11%\n",
      "Epoch: 986, Loss: 12755.3594, Recall: 91.94%, Valid: 96.18% Test: 96.11%\n",
      "Epoch: 987, Loss: 12751.7930, Recall: 92.04%, Valid: 96.19% Test: 96.11%\n",
      "Epoch: 988, Loss: 12756.8691, Recall: 92.13%, Valid: 96.19% Test: 96.13%\n",
      "Epoch: 989, Loss: 12727.1758, Recall: 92.12%, Valid: 96.19% Test: 96.13%\n",
      "Epoch: 990, Loss: 12734.5254, Recall: 92.08%, Valid: 96.19% Test: 96.13%\n",
      "Epoch: 991, Loss: 12753.2549, Recall: 92.04%, Valid: 96.18% Test: 96.11%\n",
      "Epoch: 992, Loss: 12748.8730, Recall: 91.96%, Valid: 96.15% Test: 96.08%\n",
      "Epoch: 993, Loss: 12753.5078, Recall: 91.98%, Valid: 96.15% Test: 96.08%\n",
      "Epoch: 994, Loss: 12751.3301, Recall: 91.99%, Valid: 96.16% Test: 96.08%\n",
      "Epoch: 995, Loss: 12760.5850, Recall: 92.09%, Valid: 96.15% Test: 96.07%\n",
      "Epoch: 996, Loss: 12755.4590, Recall: 92.10%, Valid: 96.15% Test: 96.06%\n",
      "Epoch: 997, Loss: 12730.0137, Recall: 92.13%, Valid: 96.15% Test: 96.06%\n",
      "Epoch: 998, Loss: 12760.6641, Recall: 92.08%, Valid: 96.14% Test: 96.06%\n",
      "Epoch: 999, Loss: 12744.6426, Recall: 92.08%, Valid: 96.14% Test: 96.06%\n",
      "Epoch: 1000, Loss: 12725.7744, Recall: 92.09%, Valid: 96.14% Test: 96.06%\n"
     ]
    }
   ],
   "source": [
    "mlp_gcn_model.reset_parameters()\n",
    "\n",
    "optimizer = torch.optim.Adam(mlp_gcn_model.parameters(), lr=mlp_gcn_args['lr'])\n",
    "# loss_fn = torch.nn.CrossEntropyLoss(weight=None , reduction=\"sum\")\n",
    "loss_fn = weighted_BCE(reduction=\"sum\" , true_weight=1.2 , false_weight=0.01)\n",
    "\n",
    "\n",
    "best_model = None\n",
    "best_valid_acc = 0\n",
    "\n",
    "for epoch in range(1, 1 + mlp_gcn_args[\"epochs\"]):\n",
    "  \n",
    "  loss = train_gcn(mlp_gcn_model , data , optimizer, loss_fn)\n",
    "  result = test_gcn(mlp_gcn_model, data)\n",
    "\n",
    "  c_train , c_val , c_test = result\n",
    "\n",
    "  if acc(c_val) > best_valid_acc:\n",
    "      best_valid_acc = acc(c_val)\n",
    "      best_model = copy.deepcopy(mlp_gcn_model)\n",
    "        \n",
    "  mlp_gcn_logger.info(f'Epoch {epoch:02d} '\n",
    "      f'Loss {loss:.4f} '\n",
    "      f'Train {c_train[0][0]:02d} {c_train[0][1]:02d} {c_train[1][0]:02d} {c_train[1][1]:02d} '\n",
    "      f'Valid {c_val[0][0]:02d} {c_val[0][1]:02d} {c_val[1][0]:02d} {c_val[1][1]:02d} '\n",
    "      f'Test {c_val[0][0]:02d} {c_val[0][1]:02d} {c_val[1][0]:02d} {c_val[1][1]:02d} ')\n",
    "  \n",
    "  print((f'Epoch: {epoch:02d}, '\n",
    "        f'Loss: {loss:.4f}, '\n",
    "        f'Recall: {100 * recall(c_train):.2f}%, '\n",
    "        f'Valid: {100 * acc(c_train):.2f}% '\n",
    "        f'Test: {100 * acc(c_test):.2f}%'))\n",
    "  \n",
    "handlers = mlp_gcn_logger.handlers[:]\n",
    "for handler in handlers:\n",
    "    mlp_gcn_logger.removeHandler(handler)\n",
    "    handler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9616983282674773"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(best_model , \"../models/mlp_gcn_1_200.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## node2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding_dim': 16,\n",
       " 'walk_length': 10,\n",
       " 'num_walks': 100,\n",
       " 'min_count': 1,\n",
       " 'batch_words': 4,\n",
       " 'window': 5,\n",
       " 'hidden_dim': 16,\n",
       " 'num_layers': 3,\n",
       " 'dropout': 0.2,\n",
       " 'lr': 0.01,\n",
       " 'epochs': 1000}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n2vnet_args = {\n",
    "    \"embedding_dim\":16,\n",
    "    \"walk_length\":10,\n",
    "    \"num_walks\":100,\n",
    "    \"min_count\":1,\n",
    "    \"batch_words\":4,\n",
    "    \"window\":5,\n",
    "\n",
    "    \"hidden_dim\":16,\n",
    "    \"num_layers\":3,\n",
    "    \"dropout\":0.2,\n",
    "\n",
    "    \"lr\":0.01,\n",
    "    \"epochs\":1000\n",
    "}\n",
    "\n",
    "n2vnet_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ef07dd60da484a819eb5993300a139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/33244 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 100/100 [00:48<00:00,  2.05it/s]\n"
     ]
    }
   ],
   "source": [
    "sorted_node_list = (list(data.g.nodes))\n",
    "sorted_node_list.sort()\n",
    "sorted_node_list = [str(node) for node in sorted_node_list]\n",
    "\n",
    "n2v = node2vec.Node2Vec(data.g , dimensions=n2vnet_args[\"embedding_dim\"] , walk_length=n2vnet_args[\"walk_length\"] , num_walks=n2vnet_args[\"num_walks\"]) \n",
    "embeddings = torch.tensor((n2v.fit(window=n2vnet_args[\"window\"] , min_count=n2vnet_args[\"min_count\"] , batch_words=n2vnet_args[\"batch_words\"]).wv)[sorted_node_list] , dtype=torch.float32 , device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n2vnet number of parameters: 3944\n"
     ]
    }
   ],
   "source": [
    "n2vnet_model = n2vnet(data.g , input_dim = n2vnet_args[\"embedding_dim\"], hidden_dim = n2vnet_args[\"hidden_dim\"], output_dim = data.y.shape[1], num_layers = n2vnet_args[\"num_layers\"], dropout = n2vnet_args['dropout']).to(device)\n",
    "\n",
    "total_params_n2vnet = sum(\n",
    "\tparam.numel() for param in n2vnet_model.parameters()\n",
    ")\n",
    "print(\"n2vnet number of parameters:\" , total_params_n2vnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 74703.9375, Acc: 50.39%, Recall: 60.64% Test: 50.34%\n",
      "Epoch: 02, Loss: 73192.5703, Acc: 54.09%, Recall: 67.77% Test: 54.05%\n",
      "Epoch: 03, Loss: 71767.7578, Acc: 57.70%, Recall: 71.21% Test: 57.67%\n",
      "Epoch: 04, Loss: 70159.2266, Acc: 61.36%, Recall: 74.14% Test: 61.36%\n",
      "Epoch: 05, Loss: 68305.1250, Acc: 65.15%, Recall: 76.89% Test: 65.10%\n",
      "Epoch: 06, Loss: 66139.2891, Acc: 68.82%, Recall: 79.29% Test: 68.77%\n",
      "Epoch: 07, Loss: 63626.0781, Acc: 71.86%, Recall: 83.43% Test: 71.83%\n",
      "Epoch: 08, Loss: 60853.7148, Acc: 75.01%, Recall: 85.86% Test: 74.99%\n",
      "Epoch: 09, Loss: 57962.2656, Acc: 77.55%, Recall: 86.91% Test: 77.56%\n",
      "Epoch: 10, Loss: 55235.4102, Acc: 79.18%, Recall: 86.94% Test: 79.18%\n",
      "Epoch: 11, Loss: 53103.7812, Acc: 80.25%, Recall: 86.88% Test: 80.26%\n",
      "Epoch: 12, Loss: 51777.7773, Acc: 80.85%, Recall: 86.79% Test: 80.87%\n",
      "Epoch: 13, Loss: 51223.4844, Acc: 81.40%, Recall: 86.73% Test: 81.43%\n",
      "Epoch: 14, Loss: 51124.3516, Acc: 81.91%, Recall: 86.62% Test: 81.92%\n",
      "Epoch: 15, Loss: 50944.6719, Acc: 82.18%, Recall: 86.24% Test: 82.17%\n",
      "Epoch: 16, Loss: 50538.8125, Acc: 82.26%, Recall: 86.10% Test: 82.26%\n",
      "Epoch: 17, Loss: 49717.9297, Acc: 82.33%, Recall: 86.06% Test: 82.34%\n",
      "Epoch: 18, Loss: 48630.5391, Acc: 82.30%, Recall: 86.11% Test: 82.30%\n",
      "Epoch: 19, Loss: 47604.6797, Acc: 82.39%, Recall: 86.05% Test: 82.41%\n",
      "Epoch: 20, Loss: 46905.2188, Acc: 82.32%, Recall: 86.15% Test: 82.35%\n",
      "Epoch: 21, Loss: 46407.8945, Acc: 82.21%, Recall: 86.23% Test: 82.23%\n",
      "Epoch: 22, Loss: 45920.1484, Acc: 81.99%, Recall: 86.58% Test: 82.00%\n",
      "Epoch: 23, Loss: 45720.9258, Acc: 81.80%, Recall: 86.87% Test: 81.81%\n",
      "Epoch: 24, Loss: 45474.8555, Acc: 81.65%, Recall: 87.10% Test: 81.66%\n",
      "Epoch: 25, Loss: 45312.5625, Acc: 81.48%, Recall: 87.28% Test: 81.48%\n",
      "Epoch: 26, Loss: 45009.3984, Acc: 81.41%, Recall: 87.32% Test: 81.42%\n",
      "Epoch: 27, Loss: 44696.3750, Acc: 81.40%, Recall: 87.37% Test: 81.41%\n",
      "Epoch: 28, Loss: 44312.0547, Acc: 81.40%, Recall: 87.40% Test: 81.42%\n",
      "Epoch: 29, Loss: 43878.0625, Acc: 81.44%, Recall: 87.41% Test: 81.45%\n",
      "Epoch: 30, Loss: 43508.4688, Acc: 81.59%, Recall: 87.29% Test: 81.60%\n",
      "Epoch: 31, Loss: 43224.4453, Acc: 81.68%, Recall: 87.24% Test: 81.70%\n",
      "Epoch: 32, Loss: 42936.0273, Acc: 81.80%, Recall: 87.22% Test: 81.82%\n",
      "Epoch: 33, Loss: 42827.0352, Acc: 82.01%, Recall: 87.10% Test: 82.04%\n",
      "Epoch: 34, Loss: 42629.3789, Acc: 82.28%, Recall: 86.90% Test: 82.31%\n",
      "Epoch: 35, Loss: 42588.4961, Acc: 82.43%, Recall: 86.91% Test: 82.45%\n",
      "Epoch: 36, Loss: 42366.8281, Acc: 82.62%, Recall: 86.69% Test: 82.64%\n",
      "Epoch: 37, Loss: 42205.0078, Acc: 82.72%, Recall: 86.63% Test: 82.75%\n",
      "Epoch: 38, Loss: 42008.8828, Acc: 82.82%, Recall: 86.54% Test: 82.85%\n",
      "Epoch: 39, Loss: 41801.3438, Acc: 82.88%, Recall: 86.52% Test: 82.90%\n",
      "Epoch: 40, Loss: 41667.3477, Acc: 82.88%, Recall: 86.55% Test: 82.90%\n",
      "Epoch: 41, Loss: 41534.0664, Acc: 82.84%, Recall: 86.66% Test: 82.86%\n",
      "Epoch: 42, Loss: 41453.4922, Acc: 82.74%, Recall: 86.88% Test: 82.75%\n",
      "Epoch: 43, Loss: 41331.4570, Acc: 82.66%, Recall: 86.99% Test: 82.67%\n",
      "Epoch: 44, Loss: 41139.9844, Acc: 82.62%, Recall: 87.06% Test: 82.63%\n",
      "Epoch: 45, Loss: 41055.7344, Acc: 82.58%, Recall: 87.13% Test: 82.60%\n",
      "Epoch: 46, Loss: 40933.1875, Acc: 82.55%, Recall: 87.14% Test: 82.57%\n",
      "Epoch: 47, Loss: 40774.3359, Acc: 82.53%, Recall: 87.21% Test: 82.54%\n",
      "Epoch: 48, Loss: 40579.2578, Acc: 82.52%, Recall: 87.23% Test: 82.52%\n",
      "Epoch: 49, Loss: 40496.0078, Acc: 82.54%, Recall: 87.23% Test: 82.54%\n",
      "Epoch: 50, Loss: 40392.5859, Acc: 82.60%, Recall: 87.25% Test: 82.60%\n",
      "Epoch: 51, Loss: 40272.8711, Acc: 82.67%, Recall: 87.23% Test: 82.67%\n",
      "Epoch: 52, Loss: 40228.6328, Acc: 82.72%, Recall: 87.27% Test: 82.72%\n",
      "Epoch: 53, Loss: 40093.9102, Acc: 82.79%, Recall: 87.31% Test: 82.79%\n",
      "Epoch: 54, Loss: 39905.4062, Acc: 82.87%, Recall: 87.30% Test: 82.87%\n",
      "Epoch: 55, Loss: 39895.8906, Acc: 82.96%, Recall: 87.30% Test: 82.95%\n",
      "Epoch: 56, Loss: 39756.8203, Acc: 83.04%, Recall: 87.31% Test: 83.02%\n",
      "Epoch: 57, Loss: 39621.1914, Acc: 83.10%, Recall: 87.32% Test: 83.09%\n",
      "Epoch: 58, Loss: 39624.6328, Acc: 83.14%, Recall: 87.38% Test: 83.13%\n",
      "Epoch: 59, Loss: 39574.9531, Acc: 83.16%, Recall: 87.44% Test: 83.15%\n",
      "Epoch: 60, Loss: 39464.9531, Acc: 83.17%, Recall: 87.53% Test: 83.16%\n",
      "Epoch: 61, Loss: 39375.9844, Acc: 83.19%, Recall: 87.60% Test: 83.19%\n",
      "Epoch: 62, Loss: 39260.5742, Acc: 83.18%, Recall: 87.69% Test: 83.18%\n",
      "Epoch: 63, Loss: 39182.4609, Acc: 83.13%, Recall: 87.79% Test: 83.13%\n",
      "Epoch: 64, Loss: 39133.2969, Acc: 83.10%, Recall: 87.90% Test: 83.11%\n",
      "Epoch: 65, Loss: 38966.3438, Acc: 83.10%, Recall: 87.96% Test: 83.11%\n",
      "Epoch: 66, Loss: 38904.3359, Acc: 83.11%, Recall: 88.01% Test: 83.12%\n",
      "Epoch: 67, Loss: 38885.4258, Acc: 83.13%, Recall: 88.06% Test: 83.13%\n",
      "Epoch: 68, Loss: 38828.6211, Acc: 83.14%, Recall: 88.16% Test: 83.14%\n",
      "Epoch: 69, Loss: 38635.0469, Acc: 83.16%, Recall: 88.22% Test: 83.17%\n",
      "Epoch: 70, Loss: 38708.0234, Acc: 83.20%, Recall: 88.25% Test: 83.21%\n",
      "Epoch: 71, Loss: 38505.4453, Acc: 83.24%, Recall: 88.29% Test: 83.24%\n",
      "Epoch: 72, Loss: 38515.0117, Acc: 83.29%, Recall: 88.30% Test: 83.30%\n",
      "Epoch: 73, Loss: 38385.3906, Acc: 83.34%, Recall: 88.31% Test: 83.35%\n",
      "Epoch: 74, Loss: 38258.6680, Acc: 83.39%, Recall: 88.30% Test: 83.40%\n",
      "Epoch: 75, Loss: 38237.6875, Acc: 83.44%, Recall: 88.35% Test: 83.44%\n",
      "Epoch: 76, Loss: 38214.8633, Acc: 83.48%, Recall: 88.42% Test: 83.48%\n",
      "Epoch: 77, Loss: 38109.5234, Acc: 83.50%, Recall: 88.46% Test: 83.51%\n",
      "Epoch: 78, Loss: 37998.9297, Acc: 83.51%, Recall: 88.57% Test: 83.52%\n",
      "Epoch: 79, Loss: 38005.2031, Acc: 83.50%, Recall: 88.66% Test: 83.50%\n",
      "Epoch: 80, Loss: 37840.4336, Acc: 83.50%, Recall: 88.74% Test: 83.50%\n",
      "Epoch: 81, Loss: 37808.1484, Acc: 83.51%, Recall: 88.84% Test: 83.51%\n",
      "Epoch: 82, Loss: 37748.8359, Acc: 83.51%, Recall: 88.90% Test: 83.51%\n",
      "Epoch: 83, Loss: 37696.2383, Acc: 83.52%, Recall: 88.99% Test: 83.52%\n",
      "Epoch: 84, Loss: 37599.3203, Acc: 83.54%, Recall: 89.03% Test: 83.54%\n",
      "Epoch: 85, Loss: 37485.1250, Acc: 83.55%, Recall: 89.07% Test: 83.55%\n",
      "Epoch: 86, Loss: 37483.5391, Acc: 83.58%, Recall: 89.12% Test: 83.57%\n",
      "Epoch: 87, Loss: 37405.8906, Acc: 83.60%, Recall: 89.15% Test: 83.60%\n",
      "Epoch: 88, Loss: 37376.5039, Acc: 83.61%, Recall: 89.15% Test: 83.60%\n",
      "Epoch: 89, Loss: 37312.7500, Acc: 83.60%, Recall: 89.18% Test: 83.59%\n",
      "Epoch: 90, Loss: 37300.3555, Acc: 83.57%, Recall: 89.26% Test: 83.56%\n",
      "Epoch: 91, Loss: 37215.9375, Acc: 83.54%, Recall: 89.30% Test: 83.54%\n",
      "Epoch: 92, Loss: 37095.6406, Acc: 83.54%, Recall: 89.35% Test: 83.53%\n",
      "Epoch: 93, Loss: 37071.5547, Acc: 83.56%, Recall: 89.35% Test: 83.55%\n",
      "Epoch: 94, Loss: 36937.7656, Acc: 83.60%, Recall: 89.35% Test: 83.59%\n",
      "Epoch: 95, Loss: 37006.4609, Acc: 83.66%, Recall: 89.33% Test: 83.65%\n",
      "Epoch: 96, Loss: 36910.6602, Acc: 83.68%, Recall: 89.38% Test: 83.67%\n",
      "Epoch: 97, Loss: 36935.9805, Acc: 83.67%, Recall: 89.43% Test: 83.66%\n",
      "Epoch: 98, Loss: 36781.9609, Acc: 83.64%, Recall: 89.50% Test: 83.63%\n",
      "Epoch: 99, Loss: 36807.8438, Acc: 83.64%, Recall: 89.59% Test: 83.63%\n",
      "Epoch: 100, Loss: 36751.7148, Acc: 83.64%, Recall: 89.64% Test: 83.63%\n",
      "Epoch: 101, Loss: 36677.3984, Acc: 83.65%, Recall: 89.70% Test: 83.65%\n",
      "Epoch: 102, Loss: 36584.5156, Acc: 83.68%, Recall: 89.72% Test: 83.67%\n",
      "Epoch: 103, Loss: 36547.0078, Acc: 83.70%, Recall: 89.76% Test: 83.70%\n",
      "Epoch: 104, Loss: 36462.1367, Acc: 83.71%, Recall: 89.81% Test: 83.71%\n",
      "Epoch: 105, Loss: 36450.5078, Acc: 83.71%, Recall: 89.83% Test: 83.71%\n",
      "Epoch: 106, Loss: 36502.9766, Acc: 83.70%, Recall: 89.86% Test: 83.70%\n",
      "Epoch: 107, Loss: 36443.5195, Acc: 83.69%, Recall: 89.90% Test: 83.69%\n",
      "Epoch: 108, Loss: 36256.3945, Acc: 83.70%, Recall: 89.92% Test: 83.71%\n",
      "Epoch: 109, Loss: 36323.7031, Acc: 83.70%, Recall: 89.93% Test: 83.71%\n",
      "Epoch: 110, Loss: 36352.5234, Acc: 83.68%, Recall: 90.00% Test: 83.68%\n",
      "Epoch: 111, Loss: 36361.0156, Acc: 83.64%, Recall: 90.12% Test: 83.65%\n",
      "Epoch: 112, Loss: 36176.0391, Acc: 83.63%, Recall: 90.20% Test: 83.63%\n",
      "Epoch: 113, Loss: 36163.1250, Acc: 83.63%, Recall: 90.23% Test: 83.63%\n",
      "Epoch: 114, Loss: 36049.3984, Acc: 83.66%, Recall: 90.25% Test: 83.66%\n",
      "Epoch: 115, Loss: 36110.2891, Acc: 83.68%, Recall: 90.27% Test: 83.69%\n",
      "Epoch: 116, Loss: 36082.6367, Acc: 83.69%, Recall: 90.32% Test: 83.69%\n",
      "Epoch: 117, Loss: 35960.7656, Acc: 83.65%, Recall: 90.36% Test: 83.66%\n",
      "Epoch: 118, Loss: 35972.8203, Acc: 83.64%, Recall: 90.42% Test: 83.64%\n",
      "Epoch: 119, Loss: 36082.0352, Acc: 83.63%, Recall: 90.47% Test: 83.62%\n",
      "Epoch: 120, Loss: 35866.6836, Acc: 83.66%, Recall: 90.45% Test: 83.66%\n",
      "Epoch: 121, Loss: 36002.3789, Acc: 83.71%, Recall: 90.44% Test: 83.71%\n",
      "Epoch: 122, Loss: 35842.8203, Acc: 83.78%, Recall: 90.45% Test: 83.78%\n",
      "Epoch: 123, Loss: 35886.7969, Acc: 83.80%, Recall: 90.47% Test: 83.80%\n",
      "Epoch: 124, Loss: 35857.5078, Acc: 83.77%, Recall: 90.50% Test: 83.77%\n",
      "Epoch: 125, Loss: 35750.8750, Acc: 83.77%, Recall: 90.53% Test: 83.77%\n",
      "Epoch: 126, Loss: 35717.9766, Acc: 83.74%, Recall: 90.61% Test: 83.74%\n",
      "Epoch: 127, Loss: 35769.0078, Acc: 83.72%, Recall: 90.69% Test: 83.72%\n",
      "Epoch: 128, Loss: 35751.0000, Acc: 83.72%, Recall: 90.72% Test: 83.72%\n",
      "Epoch: 129, Loss: 35590.6797, Acc: 83.76%, Recall: 90.72% Test: 83.76%\n",
      "Epoch: 130, Loss: 35596.3125, Acc: 83.80%, Recall: 90.73% Test: 83.79%\n",
      "Epoch: 131, Loss: 35638.2344, Acc: 83.82%, Recall: 90.77% Test: 83.81%\n",
      "Epoch: 132, Loss: 35541.2969, Acc: 83.82%, Recall: 90.80% Test: 83.82%\n",
      "Epoch: 133, Loss: 35492.8086, Acc: 83.85%, Recall: 90.84% Test: 83.84%\n",
      "Epoch: 134, Loss: 35457.3828, Acc: 83.88%, Recall: 90.82% Test: 83.88%\n",
      "Epoch: 135, Loss: 35365.1914, Acc: 83.91%, Recall: 90.80% Test: 83.91%\n",
      "Epoch: 136, Loss: 35512.4688, Acc: 83.95%, Recall: 90.80% Test: 83.94%\n",
      "Epoch: 137, Loss: 35391.4766, Acc: 83.95%, Recall: 90.86% Test: 83.94%\n",
      "Epoch: 138, Loss: 35410.1680, Acc: 83.93%, Recall: 90.94% Test: 83.93%\n",
      "Epoch: 139, Loss: 35326.7188, Acc: 83.86%, Recall: 91.05% Test: 83.86%\n",
      "Epoch: 140, Loss: 35371.4180, Acc: 83.81%, Recall: 91.15% Test: 83.81%\n",
      "Epoch: 141, Loss: 35342.3906, Acc: 83.78%, Recall: 91.20% Test: 83.78%\n",
      "Epoch: 142, Loss: 35240.5977, Acc: 83.82%, Recall: 91.24% Test: 83.82%\n",
      "Epoch: 143, Loss: 35317.0234, Acc: 83.87%, Recall: 91.23% Test: 83.88%\n",
      "Epoch: 144, Loss: 35385.6016, Acc: 83.90%, Recall: 91.22% Test: 83.90%\n",
      "Epoch: 145, Loss: 35148.9062, Acc: 83.92%, Recall: 91.19% Test: 83.93%\n",
      "Epoch: 146, Loss: 35157.7812, Acc: 83.92%, Recall: 91.21% Test: 83.93%\n",
      "Epoch: 147, Loss: 35217.4727, Acc: 83.89%, Recall: 91.23% Test: 83.90%\n",
      "Epoch: 148, Loss: 35153.7930, Acc: 83.87%, Recall: 91.27% Test: 83.87%\n",
      "Epoch: 149, Loss: 35115.7891, Acc: 83.84%, Recall: 91.36% Test: 83.83%\n",
      "Epoch: 150, Loss: 35136.6328, Acc: 83.83%, Recall: 91.40% Test: 83.83%\n",
      "Epoch: 151, Loss: 35209.8008, Acc: 83.85%, Recall: 91.41% Test: 83.84%\n",
      "Epoch: 152, Loss: 35128.9766, Acc: 83.90%, Recall: 91.40% Test: 83.90%\n",
      "Epoch: 153, Loss: 35067.6367, Acc: 83.94%, Recall: 91.39% Test: 83.94%\n",
      "Epoch: 154, Loss: 35156.2422, Acc: 83.96%, Recall: 91.39% Test: 83.96%\n",
      "Epoch: 155, Loss: 34884.6133, Acc: 83.95%, Recall: 91.41% Test: 83.96%\n",
      "Epoch: 156, Loss: 35051.6680, Acc: 83.93%, Recall: 91.41% Test: 83.93%\n",
      "Epoch: 157, Loss: 34942.4766, Acc: 83.90%, Recall: 91.45% Test: 83.90%\n",
      "Epoch: 158, Loss: 34934.5586, Acc: 83.88%, Recall: 91.50% Test: 83.88%\n",
      "Epoch: 159, Loss: 34862.0703, Acc: 83.89%, Recall: 91.49% Test: 83.88%\n",
      "Epoch: 160, Loss: 34809.9609, Acc: 83.92%, Recall: 91.48% Test: 83.91%\n",
      "Epoch: 161, Loss: 34828.4766, Acc: 83.96%, Recall: 91.48% Test: 83.95%\n",
      "Epoch: 162, Loss: 34914.2109, Acc: 83.99%, Recall: 91.45% Test: 83.99%\n",
      "Epoch: 163, Loss: 34881.2305, Acc: 83.99%, Recall: 91.46% Test: 83.99%\n",
      "Epoch: 164, Loss: 34802.1094, Acc: 83.97%, Recall: 91.49% Test: 83.97%\n",
      "Epoch: 165, Loss: 34730.0820, Acc: 83.96%, Recall: 91.57% Test: 83.95%\n",
      "Epoch: 166, Loss: 34847.2422, Acc: 83.94%, Recall: 91.63% Test: 83.93%\n",
      "Epoch: 167, Loss: 34772.8281, Acc: 83.96%, Recall: 91.66% Test: 83.95%\n",
      "Epoch: 168, Loss: 34810.5938, Acc: 83.98%, Recall: 91.66% Test: 83.97%\n",
      "Epoch: 169, Loss: 34827.1562, Acc: 84.00%, Recall: 91.66% Test: 83.99%\n",
      "Epoch: 170, Loss: 34835.5195, Acc: 83.99%, Recall: 91.70% Test: 83.99%\n",
      "Epoch: 171, Loss: 34671.7344, Acc: 83.96%, Recall: 91.76% Test: 83.96%\n",
      "Epoch: 172, Loss: 34671.4844, Acc: 83.92%, Recall: 91.81% Test: 83.91%\n",
      "Epoch: 173, Loss: 34684.0234, Acc: 83.90%, Recall: 91.87% Test: 83.88%\n",
      "Epoch: 174, Loss: 34695.3125, Acc: 83.91%, Recall: 91.86% Test: 83.90%\n",
      "Epoch: 175, Loss: 34756.5234, Acc: 83.94%, Recall: 91.85% Test: 83.93%\n",
      "Epoch: 176, Loss: 34712.0547, Acc: 83.98%, Recall: 91.83% Test: 83.97%\n",
      "Epoch: 177, Loss: 34632.2695, Acc: 84.04%, Recall: 91.81% Test: 84.03%\n",
      "Epoch: 178, Loss: 34762.2305, Acc: 84.07%, Recall: 91.81% Test: 84.06%\n",
      "Epoch: 179, Loss: 34671.6172, Acc: 84.08%, Recall: 91.84% Test: 84.06%\n",
      "Epoch: 180, Loss: 34573.7500, Acc: 84.07%, Recall: 91.86% Test: 84.05%\n",
      "Epoch: 181, Loss: 34603.0391, Acc: 84.06%, Recall: 91.86% Test: 84.04%\n",
      "Epoch: 182, Loss: 34541.8750, Acc: 84.06%, Recall: 91.89% Test: 84.04%\n",
      "Epoch: 183, Loss: 34567.4766, Acc: 84.05%, Recall: 91.86% Test: 84.04%\n",
      "Epoch: 184, Loss: 34471.4219, Acc: 84.06%, Recall: 91.85% Test: 84.05%\n",
      "Epoch: 185, Loss: 34635.8164, Acc: 84.05%, Recall: 91.89% Test: 84.04%\n",
      "Epoch: 186, Loss: 34502.1211, Acc: 84.03%, Recall: 91.96% Test: 84.02%\n",
      "Epoch: 187, Loss: 34446.3711, Acc: 84.03%, Recall: 91.98% Test: 84.02%\n",
      "Epoch: 188, Loss: 34574.1758, Acc: 84.02%, Recall: 92.01% Test: 84.01%\n",
      "Epoch: 189, Loss: 34496.8516, Acc: 84.01%, Recall: 92.02% Test: 84.00%\n",
      "Epoch: 190, Loss: 34386.9648, Acc: 84.02%, Recall: 92.03% Test: 84.01%\n",
      "Epoch: 191, Loss: 34384.0078, Acc: 84.03%, Recall: 92.03% Test: 84.03%\n",
      "Epoch: 192, Loss: 34363.5234, Acc: 84.05%, Recall: 92.03% Test: 84.04%\n",
      "Epoch: 193, Loss: 34326.3359, Acc: 84.06%, Recall: 92.01% Test: 84.06%\n",
      "Epoch: 194, Loss: 34395.2148, Acc: 84.06%, Recall: 92.05% Test: 84.06%\n",
      "Epoch: 195, Loss: 34419.2344, Acc: 84.08%, Recall: 92.08% Test: 84.08%\n",
      "Epoch: 196, Loss: 34355.3516, Acc: 84.12%, Recall: 92.05% Test: 84.11%\n",
      "Epoch: 197, Loss: 34454.6602, Acc: 84.13%, Recall: 92.05% Test: 84.13%\n",
      "Epoch: 198, Loss: 34504.6523, Acc: 84.14%, Recall: 92.08% Test: 84.13%\n",
      "Epoch: 199, Loss: 34332.9922, Acc: 84.14%, Recall: 92.07% Test: 84.13%\n",
      "Epoch: 200, Loss: 34340.3594, Acc: 84.14%, Recall: 92.10% Test: 84.14%\n",
      "Epoch: 201, Loss: 34323.6602, Acc: 84.14%, Recall: 92.13% Test: 84.13%\n",
      "Epoch: 202, Loss: 34358.4297, Acc: 84.12%, Recall: 92.17% Test: 84.12%\n",
      "Epoch: 203, Loss: 34213.4688, Acc: 84.12%, Recall: 92.19% Test: 84.11%\n",
      "Epoch: 204, Loss: 34279.8203, Acc: 84.12%, Recall: 92.21% Test: 84.12%\n",
      "Epoch: 205, Loss: 34366.0742, Acc: 84.12%, Recall: 92.20% Test: 84.11%\n",
      "Epoch: 206, Loss: 34308.6953, Acc: 84.13%, Recall: 92.21% Test: 84.12%\n",
      "Epoch: 207, Loss: 34362.5312, Acc: 84.12%, Recall: 92.20% Test: 84.12%\n",
      "Epoch: 208, Loss: 34209.9531, Acc: 84.12%, Recall: 92.19% Test: 84.10%\n",
      "Epoch: 209, Loss: 34198.6484, Acc: 84.11%, Recall: 92.20% Test: 84.09%\n",
      "Epoch: 210, Loss: 34216.7500, Acc: 84.11%, Recall: 92.19% Test: 84.09%\n",
      "Epoch: 211, Loss: 34056.7266, Acc: 84.11%, Recall: 92.22% Test: 84.10%\n",
      "Epoch: 212, Loss: 34149.6562, Acc: 84.13%, Recall: 92.21% Test: 84.12%\n",
      "Epoch: 213, Loss: 34109.6055, Acc: 84.16%, Recall: 92.20% Test: 84.16%\n",
      "Epoch: 214, Loss: 34175.9766, Acc: 84.18%, Recall: 92.23% Test: 84.18%\n",
      "Epoch: 215, Loss: 34273.9805, Acc: 84.18%, Recall: 92.25% Test: 84.18%\n",
      "Epoch: 216, Loss: 34114.6016, Acc: 84.16%, Recall: 92.29% Test: 84.16%\n",
      "Epoch: 217, Loss: 34023.8711, Acc: 84.17%, Recall: 92.30% Test: 84.16%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m n2vnet_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m     11\u001b[0m   loss \u001b[38;5;241m=\u001b[39m train_n2v(n2vnet_model , embeddings , data , optimizer, loss_fn)\n\u001b[0;32m---> 12\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mtest_n2v\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn2vnet_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m   c_train , c_val , c_test \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m     16\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m acc(c_val) \u001b[38;5;241m>\u001b[39m best_valid_acc:\n",
      "File \u001b[0;32m~/Documents/GraphNodeClassification/p2_env/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GraphNodeClassification/src/models/training.py:111\u001b[0m, in \u001b[0;36mtest_n2v\u001b[0;34m(model, embeddings, data)\u001b[0m\n\u001b[1;32m    108\u001b[0m out \u001b[38;5;241m=\u001b[39m model(embeddings)\n\u001b[1;32m    110\u001b[0m c_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(multilabel_confusion_matrix((data\u001b[38;5;241m.\u001b[39my[data\u001b[38;5;241m.\u001b[39mtrain_mask]\u001b[38;5;241m.\u001b[39mint())\u001b[38;5;241m.\u001b[39mcpu() , ((out\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0.5\u001b[39m)[data\u001b[38;5;241m.\u001b[39mtrain_mask]\u001b[38;5;241m.\u001b[39mint())\u001b[38;5;241m.\u001b[39mcpu()) , axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 111\u001b[0m c_val \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[43mmultilabel_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_mask\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_mask\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m , axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)    \n\u001b[1;32m    112\u001b[0m c_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(multilabel_confusion_matrix((data\u001b[38;5;241m.\u001b[39my[data\u001b[38;5;241m.\u001b[39mtest_mask]\u001b[38;5;241m.\u001b[39mint())\u001b[38;5;241m.\u001b[39mcpu() , ((out\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0.5\u001b[39m)[data\u001b[38;5;241m.\u001b[39mtest_mask]\u001b[38;5;241m.\u001b[39mint())\u001b[38;5;241m.\u001b[39mcpu()) , axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c_train , c_val , c_test\n",
      "File \u001b[0;32m~/Documents/GraphNodeClassification/p2_env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/GraphNodeClassification/p2_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:508\u001b[0m, in \u001b[0;36mmultilabel_confusion_matrix\u001b[0;34m(y_true, y_pred, sample_weight, labels, samplewise)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    399\u001b[0m     {\n\u001b[1;32m    400\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    409\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, samplewise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    410\u001b[0m ):\n\u001b[1;32m    411\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute a confusion matrix for each class or sample.\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \n\u001b[1;32m    413\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 0.21\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;124;03m            [1, 2]]])\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 508\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m         sample_weight \u001b[38;5;241m=\u001b[39m column_or_1d(sample_weight)\n",
      "File \u001b[0;32m~/Documents/GraphNodeClassification/p2_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:86\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     85\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m---> 86\u001b[0m type_true \u001b[38;5;241m=\u001b[39m \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_true\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     89\u001b[0m y_type \u001b[38;5;241m=\u001b[39m {type_true, type_pred}\n",
      "File \u001b[0;32m~/Documents/GraphNodeClassification/p2_env/lib/python3.10/site-packages/sklearn/utils/multiclass.py:316\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse_pandas:\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseSeries\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseArray\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_multilabel\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;66;03m# DeprecationWarning will be replaced by ValueError, see NEP 34\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;66;03m# https://numpy.org/neps/nep-0034-infer-dtype-is-object.html\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# We therefore catch both deprecation (NumPy < 1.24) warning and\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;66;03m# value error (NumPy >= 1.24).\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GraphNodeClassification/p2_env/lib/python3.10/site-packages/sklearn/utils/multiclass.py:193\u001b[0m, in \u001b[0;36mis_multilabel\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28mlen\u001b[39m(y\u001b[38;5;241m.\u001b[39mdata) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (labels\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (labels\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01min\u001b[39;00m labels))\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m (y\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbiu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m _is_integral_float(labels))  \u001b[38;5;66;03m# bool, int, uint\u001b[39;00m\n\u001b[1;32m    191\u001b[0m     )\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 193\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m labels\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    196\u001b[0m         xp\u001b[38;5;241m.\u001b[39misdtype(y\u001b[38;5;241m.\u001b[39mdtype, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigned integer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsigned integer\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _is_integral_float(labels)\n\u001b[1;32m    198\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/GraphNodeClassification/p2_env/lib/python3.10/site-packages/sklearn/utils/_array_api.py:307\u001b[0m, in \u001b[0;36m_NumPyAPIWrapper.unique_values\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GraphNodeClassification/p2_env/lib/python3.10/site-packages/numpy/lib/arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GraphNodeClassification/p2_env/lib/python3.10/site-packages/numpy/lib/arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    334\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 336\u001b[0m     \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n\u001b[1;32m    338\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n2vnet_model.reset_parameters()\n",
    "\n",
    "optimizer = torch.optim.Adam(n2vnet_model.parameters(), lr=n2vnet_args['lr'])\n",
    "loss_fn = weighted_BCE(reduction=\"sum\" , true_weight=1.8 , false_weight=0.01)\n",
    "\n",
    "best_model = None\n",
    "best_valid_acc = 0\n",
    "\n",
    "for epoch in range(1, 1 + n2vnet_args[\"epochs\"]):\n",
    "  \n",
    "  loss = train_n2v(n2vnet_model , embeddings , data , optimizer, loss_fn)\n",
    "  result = test_n2v(n2vnet_model, embeddings , data)\n",
    "\n",
    "  c_train , c_val , c_test = result\n",
    "\n",
    "  if acc(c_val) > best_valid_acc:\n",
    "      best_valid_acc = acc(c_val)\n",
    "      best_model = copy.deepcopy(n2vnet_model)\n",
    "        \n",
    "#   n2vnet_logger.info(f'Epoch {epoch:02d} '\n",
    "#       f'Loss {loss:.4f} '\n",
    "#       f'Train {c_train[0][0]:02d} {c_train[0][1]:02d} {c_train[1][0]:02d} {c_train[1][1]:02d} '\n",
    "#       f'Valid {c_val[0][0]:02d} {c_val[0][1]:02d} {c_val[1][0]:02d} {c_val[1][1]:02d} '\n",
    "#       f'Test {c_val[0][0]:02d} {c_val[0][1]:02d} {c_val[1][0]:02d} {c_val[1][1]:02d} ')\n",
    "  \n",
    "  print((f'Epoch: {epoch:02d}, '\n",
    "        f'Loss: {loss:.4f}, '\n",
    "        f'Acc: {100 * acc(c_train):.2f}%, '\n",
    "        f'Recall: {100 * recall(c_train):.2f}% '\n",
    "        f'Test: {100 * acc(c_test):.2f}%'))\n",
    "  \n",
    "# handlers = n2vnet_logger.handlers[:]\n",
    "# for handler in handlers:\n",
    "#     n2vnet_logger.removeHandler(handler)\n",
    "#     handler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8516746554823248"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_valid_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of communities experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_logger = logging.getLogger('gcn')\n",
    "mlp_logger = logging.getLogger('mlp')\n",
    "mlp_gcn_logger = logging.getLogger('mlp_gcn')\n",
    "n2vnet_logger = logging.getLogger(\"n2vnet\")\n",
    "\n",
    "gcn_logger.setLevel(logging.INFO)\n",
    "mlp_logger.setLevel(logging.INFO)\n",
    "mlp_gcn_logger.setLevel(logging.INFO)\n",
    "n2vnet_logger.setLevel(logging.INFO)\n",
    "\n",
    "file_handler_gcn = logging.FileHandler(f'../src/logs/nc_expt/gcn_{run}.log' , mode=\"w\")\n",
    "file_handler_mlp = logging.FileHandler(f'../src/logs/nc_expt/mlp_{run}.log' , mode=\"w\")\n",
    "file_handler_mlp_gcn = logging.FileHandler(f\"../src/logs/nc_expt/mlp_gcn_{run}.log\" , mode=\"w\")\n",
    "file_handler_n2vnet = logging.FileHandler(f\"../src/logs/nc_expt/n2vnet_{run}.log\" , mode=\"w\")\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "file_handler_gcn.setFormatter(formatter)\n",
    "file_handler_mlp.setFormatter(formatter)\n",
    "file_handler_mlp_gcn.setFormatter(formatter)\n",
    "file_handler_n2vnet.setFormatter(formatter)\n",
    "\n",
    "gcn_logger.addHandler(file_handler_gcn)\n",
    "mlp_logger.addHandler(file_handler_mlp)\n",
    "mlp_gcn_logger.addHandler(file_handler_mlp_gcn)\n",
    "n2vnet_logger.addHandler(file_handler_n2vnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root': '/Users/sbhardwaj/Documents/project_2/data',\n",
       " 'raw_filenames': ['graph_edges.txt', '5000_communities.txt'],\n",
       " 'expt': 'n_communities',\n",
       " 'processed_filenames': ['data_nc_0.pt',\n",
       "  'data_nc_1.pt',\n",
       "  'data_nc_2.pt',\n",
       "  'data_nc_3.pt']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader_args = {\n",
    "    \"root\":os.path.abspath(\"..\")+\"/data\",\n",
    "    \"raw_filenames\":[\"graph_edges.txt\" , \"5000_communities.txt\"],\n",
    "    \"expt\":\"n_communities\",\n",
    "    \"processed_filenames\":[\"data_nc_0.pt\" , \"data_nc_1.pt\" , \"data_nc_2.pt\" , \"data_nc_3.pt\" ]\n",
    "}\n",
    "\n",
    "dataloader_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_cn = DBLP_dataset(root = dataloader_args[\"root\"] , raw_filenames = dataloader_args[\"raw_filenames\"] ,\n",
    "                    expt = dataloader_args[\"expt\"], processed_filenames = dataloader_args[\"processed_filenames\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[14050, 5], edge_index=[2, 85388], y=[14050, 200], dtype=torch.float32, g=Graph with 14050 nodes and 35669 edges, train_mask=[14050], val_mask=[14050], test_mask=[14050])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = d_cn[run].to(device)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'device': device(type='mps'),\n",
       " 'num_layers': 4,\n",
       " 'hidden_dim': 16,\n",
       " 'dropout': 0.4,\n",
       " 'lr': 0.01,\n",
       " 'epochs': 1000}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcn_args = {\n",
    "    'device': device,\n",
    "    'num_layers': 4,\n",
    "    'hidden_dim': 16,\n",
    "    'dropout': 0.4,\n",
    "    'lr': 0.01,\n",
    "    'epochs': 1000,\n",
    "}\n",
    "\n",
    "gcn_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN model number of parameters: 2436\n"
     ]
    }
   ],
   "source": [
    "gcn_model = GCN(data.x.shape[1] , gcn_args['hidden_dim'] , data.y.shape[1] , gcn_args['num_layers'] , gcn_args['dropout']).to(device)\n",
    "\n",
    "total_params_GCN = sum(\n",
    "\tparam.numel() for param in gcn_model.parameters()\n",
    ")\n",
    "print(\"GCN model number of parameters:\" , total_params_GCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loc(\"mps_not_equal\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/4e1473ee-9f66-11ee-8daf-cedaeb4cabe2/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":253:0)): error: 'anec.not_equal_zero' op Invalid configuration for the following reasons: Tensor dimensions N1D1C1H1W33561 are not within supported range, N[1-65536]D[1-16384]C[1-65536]H[1-16384]W[1-16384].\n",
      "loc(\"mps_select\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/4e1473ee-9f66-11ee-8daf-cedaeb4cabe2/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":294:0)): error: 'anec.not_equal_zero' op Invalid configuration for the following reasons: Tensor dimensions N1D1C1H1W33561 are not within supported range, N[1-65536]D[1-16384]C[1-65536]H[1-16384]W[1-16384].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 21855.3652, Train: 65.80%, Valid: 62.88% Test: 66.22%\n",
      "Epoch: 02, Loss: 21800.3984, Train: 63.99%, Valid: 61.02% Test: 63.85%\n",
      "Epoch: 03, Loss: 21755.1992, Train: 65.46%, Valid: 62.71% Test: 64.36%\n",
      "Epoch: 04, Loss: 21695.5957, Train: 65.38%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 05, Loss: 21637.1309, Train: 65.36%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 06, Loss: 21594.3398, Train: 65.29%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 07, Loss: 21542.4199, Train: 65.27%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 08, Loss: 21485.6699, Train: 65.27%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 09, Loss: 21399.9492, Train: 65.27%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 10, Loss: 21327.3555, Train: 65.27%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 11, Loss: 21260.0859, Train: 65.27%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 12, Loss: 21190.1484, Train: 65.29%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 13, Loss: 21084.5469, Train: 65.36%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 14, Loss: 21024.2617, Train: 65.40%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 15, Loss: 20951.3555, Train: 65.38%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 16, Loss: 20914.3574, Train: 65.32%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 17, Loss: 20782.3574, Train: 65.29%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 18, Loss: 20755.1094, Train: 65.27%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 19, Loss: 20706.2188, Train: 65.27%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 20, Loss: 20610.1133, Train: 65.27%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 21, Loss: 20549.6289, Train: 65.27%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 22, Loss: 20473.9648, Train: 65.27%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 23, Loss: 20398.2598, Train: 65.27%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 24, Loss: 20369.1973, Train: 65.17%, Valid: 62.37% Test: 64.86%\n",
      "Epoch: 25, Loss: 20309.9180, Train: 65.19%, Valid: 62.37% Test: 64.86%\n",
      "Epoch: 26, Loss: 20265.1133, Train: 65.23%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 27, Loss: 20231.7148, Train: 65.21%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 28, Loss: 20191.1973, Train: 65.29%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 29, Loss: 20135.3945, Train: 65.40%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 30, Loss: 20110.5781, Train: 65.67%, Valid: 63.39% Test: 65.54%\n",
      "Epoch: 31, Loss: 20069.1875, Train: 65.97%, Valid: 63.90% Test: 65.71%\n",
      "Epoch: 32, Loss: 20048.4492, Train: 65.99%, Valid: 64.07% Test: 65.71%\n",
      "Epoch: 33, Loss: 20019.0566, Train: 66.05%, Valid: 64.07% Test: 66.22%\n",
      "Epoch: 34, Loss: 20018.3418, Train: 66.14%, Valid: 64.07% Test: 66.22%\n",
      "Epoch: 35, Loss: 19977.5703, Train: 66.71%, Valid: 64.41% Test: 66.55%\n",
      "Epoch: 36, Loss: 19966.2891, Train: 66.75%, Valid: 63.90% Test: 66.55%\n",
      "Epoch: 37, Loss: 19918.1250, Train: 66.69%, Valid: 63.90% Test: 66.22%\n",
      "Epoch: 38, Loss: 19911.3887, Train: 66.01%, Valid: 62.54% Test: 65.71%\n",
      "Epoch: 39, Loss: 19883.7383, Train: 65.29%, Valid: 62.54% Test: 65.37%\n",
      "Epoch: 40, Loss: 19873.9258, Train: 65.53%, Valid: 63.22% Test: 65.37%\n",
      "Epoch: 41, Loss: 19881.3281, Train: 65.63%, Valid: 63.39% Test: 65.54%\n",
      "Epoch: 42, Loss: 19844.7617, Train: 65.80%, Valid: 63.39% Test: 65.20%\n",
      "Epoch: 43, Loss: 19843.1328, Train: 64.83%, Valid: 62.54% Test: 64.19%\n",
      "Epoch: 44, Loss: 19815.7148, Train: 64.62%, Valid: 62.20% Test: 64.19%\n",
      "Epoch: 45, Loss: 19798.2969, Train: 64.62%, Valid: 62.37% Test: 64.19%\n",
      "Epoch: 46, Loss: 19811.8691, Train: 64.56%, Valid: 62.03% Test: 64.19%\n",
      "Epoch: 47, Loss: 19784.5781, Train: 64.70%, Valid: 62.20% Test: 63.85%\n",
      "Epoch: 48, Loss: 19770.5840, Train: 64.83%, Valid: 61.86% Test: 64.02%\n",
      "Epoch: 49, Loss: 19775.3125, Train: 65.42%, Valid: 62.20% Test: 64.70%\n",
      "Epoch: 50, Loss: 19745.8867, Train: 65.53%, Valid: 62.20% Test: 64.86%\n",
      "Epoch: 51, Loss: 19739.3398, Train: 65.61%, Valid: 62.20% Test: 64.86%\n",
      "Epoch: 52, Loss: 19760.0645, Train: 65.65%, Valid: 62.03% Test: 65.03%\n",
      "Epoch: 53, Loss: 19737.6680, Train: 65.86%, Valid: 62.54% Test: 65.37%\n",
      "Epoch: 54, Loss: 19721.9473, Train: 65.86%, Valid: 62.54% Test: 65.37%\n",
      "Epoch: 55, Loss: 19719.8477, Train: 65.97%, Valid: 62.88% Test: 65.54%\n",
      "Epoch: 56, Loss: 19728.7578, Train: 66.20%, Valid: 63.05% Test: 66.22%\n",
      "Epoch: 57, Loss: 19709.6387, Train: 66.18%, Valid: 62.71% Test: 65.71%\n",
      "Epoch: 58, Loss: 19700.0039, Train: 66.39%, Valid: 62.20% Test: 66.39%\n",
      "Epoch: 59, Loss: 19689.1602, Train: 66.56%, Valid: 62.20% Test: 66.05%\n",
      "Epoch: 60, Loss: 19688.0938, Train: 66.37%, Valid: 61.86% Test: 65.71%\n",
      "Epoch: 61, Loss: 19669.5469, Train: 66.37%, Valid: 61.69% Test: 65.54%\n",
      "Epoch: 62, Loss: 19662.2773, Train: 66.39%, Valid: 61.69% Test: 65.37%\n",
      "Epoch: 63, Loss: 19687.0977, Train: 66.39%, Valid: 61.69% Test: 65.37%\n",
      "Epoch: 64, Loss: 19658.5605, Train: 66.81%, Valid: 61.69% Test: 66.22%\n",
      "Epoch: 65, Loss: 19664.3496, Train: 67.36%, Valid: 62.03% Test: 66.89%\n",
      "Epoch: 66, Loss: 19638.7461, Train: 67.72%, Valid: 62.71% Test: 67.57%\n",
      "Epoch: 67, Loss: 19622.3711, Train: 67.76%, Valid: 62.88% Test: 67.74%\n",
      "Epoch: 68, Loss: 19638.0703, Train: 67.89%, Valid: 62.88% Test: 67.74%\n",
      "Epoch: 69, Loss: 19663.5332, Train: 67.70%, Valid: 62.88% Test: 67.57%\n",
      "Epoch: 70, Loss: 19647.5703, Train: 67.36%, Valid: 62.03% Test: 66.89%\n",
      "Epoch: 71, Loss: 19625.9727, Train: 67.49%, Valid: 62.54% Test: 67.06%\n",
      "Epoch: 72, Loss: 19615.4258, Train: 66.46%, Valid: 61.69% Test: 65.54%\n",
      "Epoch: 73, Loss: 19617.9805, Train: 67.19%, Valid: 62.37% Test: 66.05%\n",
      "Epoch: 74, Loss: 19622.5684, Train: 65.42%, Valid: 62.03% Test: 64.86%\n",
      "Epoch: 75, Loss: 19645.2695, Train: 65.46%, Valid: 62.03% Test: 65.20%\n",
      "Epoch: 76, Loss: 19593.9102, Train: 66.86%, Valid: 62.20% Test: 66.39%\n",
      "Epoch: 77, Loss: 19587.9512, Train: 67.26%, Valid: 62.37% Test: 66.55%\n",
      "Epoch: 78, Loss: 19608.9102, Train: 67.11%, Valid: 62.37% Test: 66.55%\n",
      "Epoch: 79, Loss: 19605.9961, Train: 67.05%, Valid: 62.20% Test: 66.39%\n",
      "Epoch: 80, Loss: 19613.3730, Train: 67.03%, Valid: 62.20% Test: 66.39%\n",
      "Epoch: 81, Loss: 19560.8320, Train: 67.24%, Valid: 62.37% Test: 66.39%\n",
      "Epoch: 82, Loss: 19591.0234, Train: 67.24%, Valid: 62.37% Test: 66.39%\n",
      "Epoch: 83, Loss: 19578.5000, Train: 67.07%, Valid: 62.37% Test: 66.22%\n",
      "Epoch: 84, Loss: 19591.6875, Train: 66.88%, Valid: 61.86% Test: 66.22%\n",
      "Epoch: 85, Loss: 19561.5879, Train: 66.88%, Valid: 61.86% Test: 66.05%\n",
      "Epoch: 86, Loss: 19562.6641, Train: 66.88%, Valid: 61.86% Test: 66.05%\n",
      "Epoch: 87, Loss: 19575.7656, Train: 66.75%, Valid: 61.69% Test: 66.22%\n",
      "Epoch: 88, Loss: 19544.2695, Train: 66.75%, Valid: 62.20% Test: 66.05%\n",
      "Epoch: 89, Loss: 19544.5801, Train: 67.87%, Valid: 63.22% Test: 67.40%\n",
      "Epoch: 90, Loss: 19531.8438, Train: 66.81%, Valid: 63.05% Test: 66.05%\n",
      "Epoch: 91, Loss: 19556.6094, Train: 66.24%, Valid: 62.03% Test: 65.88%\n",
      "Epoch: 92, Loss: 19545.0742, Train: 65.80%, Valid: 61.86% Test: 65.71%\n",
      "Epoch: 93, Loss: 19514.6445, Train: 65.57%, Valid: 61.19% Test: 65.54%\n",
      "Epoch: 94, Loss: 19558.9805, Train: 65.93%, Valid: 62.37% Test: 66.05%\n",
      "Epoch: 95, Loss: 19518.7227, Train: 66.50%, Valid: 63.56% Test: 66.55%\n",
      "Epoch: 96, Loss: 19535.6855, Train: 67.60%, Valid: 65.08% Test: 68.58%\n",
      "Epoch: 97, Loss: 19540.0273, Train: 68.17%, Valid: 65.42% Test: 69.43%\n",
      "Epoch: 98, Loss: 19553.2480, Train: 67.28%, Valid: 64.58% Test: 68.24%\n",
      "Epoch: 99, Loss: 19533.3672, Train: 66.96%, Valid: 63.90% Test: 67.57%\n",
      "Epoch: 100, Loss: 19531.7500, Train: 65.61%, Valid: 61.36% Test: 65.37%\n",
      "Epoch: 101, Loss: 19520.2988, Train: 65.95%, Valid: 60.85% Test: 65.71%\n",
      "Epoch: 102, Loss: 19531.5039, Train: 65.95%, Valid: 60.85% Test: 65.71%\n",
      "Epoch: 103, Loss: 19535.7031, Train: 65.97%, Valid: 60.85% Test: 65.88%\n",
      "Epoch: 104, Loss: 19518.1797, Train: 66.22%, Valid: 62.03% Test: 67.06%\n",
      "Epoch: 105, Loss: 19525.3750, Train: 66.84%, Valid: 63.90% Test: 68.07%\n",
      "Epoch: 106, Loss: 19500.0195, Train: 67.57%, Valid: 64.92% Test: 68.58%\n",
      "Epoch: 107, Loss: 19502.4023, Train: 67.68%, Valid: 64.92% Test: 68.58%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m gcn_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m     11\u001b[0m   loss \u001b[38;5;241m=\u001b[39m train_gcn(gcn_model , data , optimizer, loss_fn)\n\u001b[0;32m---> 12\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mtest_gcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgcn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m   train_acc , val_acc , test_acc \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m     16\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m val_acc \u001b[38;5;241m>\u001b[39m best_valid_acc:\n",
      "File \u001b[0;32m~/Documents/project_2/p2_env/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/project_2/src/models/model_train.py:28\u001b[0m, in \u001b[0;36mtest_gcn\u001b[0;34m(model, data)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_gcn\u001b[39m(model, data):\n\u001b[1;32m     26\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 28\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     c_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(multilabel_confusion_matrix((data\u001b[38;5;241m.\u001b[39my[data\u001b[38;5;241m.\u001b[39mtrain_mask]\u001b[38;5;241m.\u001b[39mint())\u001b[38;5;241m.\u001b[39mcpu() , ((out\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0.5\u001b[39m)[data\u001b[38;5;241m.\u001b[39mtrain_mask]\u001b[38;5;241m.\u001b[39mint())\u001b[38;5;241m.\u001b[39mcpu()) , axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     31\u001b[0m     train_acc \u001b[38;5;241m=\u001b[39m (c_train[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m/\u001b[39m(c_train[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m c_train[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/project_2/p2_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/project_2/src/models/model_architecture.py:79\u001b[0m, in \u001b[0;36mGCN.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     75\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conv, batch_norm \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbns):\n\u001b[0;32m---> 79\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     x \u001b[38;5;241m=\u001b[39m batch_norm(x)\n\u001b[1;32m     81\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/Documents/project_2/p2_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/project_2/p2_env/lib/python3.10/site-packages/torch_geometric/nn/conv/gcn_conv.py:241\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    239\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 241\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached:\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index \u001b[38;5;241m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[0;32m~/Documents/project_2/p2_env/lib/python3.10/site-packages/torch_geometric/nn/conv/gcn_conv.py:99\u001b[0m, in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m num_nodes \u001b[38;5;241m=\u001b[39m maybe_num_nodes(edge_index, num_nodes)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_self_loops:\n\u001b[0;32m---> 99\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43madd_remaining_self_loops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edge_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     edge_weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((edge_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), ), dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    104\u001b[0m                              device\u001b[38;5;241m=\u001b[39medge_index\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/Documents/project_2/p2_env/lib/python3.10/site-packages/torch_geometric/utils/loop.py:654\u001b[0m, in \u001b[0;36madd_remaining_self_loops\u001b[0;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, EdgeIndex):\n\u001b[1;32m    652\u001b[0m     edge_index\u001b[38;5;241m.\u001b[39m_is_undirected \u001b[38;5;241m=\u001b[39m is_undirected\n\u001b[0;32m--> 654\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m edge_index, edge_attr\n",
      "File \u001b[0;32m~/Documents/project_2/p2_env/lib/python3.10/site-packages/torch_geometric/edge_index.py:1057\u001b[0m, in \u001b[0;36mEdgeIndex.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__torch_function__\u001b[39m(\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28mcls\u001b[39m: Type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1054\u001b[0m     \u001b[38;5;66;03m# To account for this, we hold a number of `HANDLED_FUNCTIONS` that\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;66;03m# implement specific functions for valid `EdgeIndex` routines.\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m HANDLED_FUNCTIONS:\n\u001b[0;32m-> 1057\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHANDLED_FUNCTIONS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1059\u001b[0m     \u001b[38;5;66;03m# For all other PyTorch functions, we return a vanilla PyTorch tensor.\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m     _types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(Tensor \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(t, \u001b[38;5;28mcls\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m types)\n",
      "File \u001b[0;32m~/Documents/project_2/p2_env/lib/python3.10/site-packages/torch_geometric/edge_index.py:1204\u001b[0m, in \u001b[0;36mcat\u001b[0;34m(tensors, dim, out)\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tensors) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensors[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1204\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# No valid `EdgeIndex` anymore.\u001b[39;00m\n\u001b[1;32m   1208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/Documents/project_2/p2_env/lib/python3.10/site-packages/torch/_tensor.py:1295\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m-> 1295\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1297\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gcn_model.reset_parameters()\n",
    "\n",
    "optimizer = torch.optim.Adam(gcn_model.parameters(), lr=gcn_args['lr'])\n",
    "loss_fn = weighted_BCE(weight=None , reduction=\"sum\")\n",
    "\n",
    "best_model = None\n",
    "best_valid_acc = 0\n",
    "\n",
    "for epoch in range(1, 1 + gcn_args[\"epochs\"]):\n",
    "  \n",
    "  loss = train_gcn(gcn_model , data , optimizer, loss_fn)\n",
    "  result = test_gcn(gcn_model, data)\n",
    "\n",
    "  c_train , c_val , c_test = result\n",
    "\n",
    "  if acc(c_val) > best_valid_acc:\n",
    "      best_valid_acc = acc(c_val)\n",
    "      best_model = copy.deepcopy(gcn_model)\n",
    "\n",
    "  gcn_logger.info(f'Epoch {epoch:02d} '\n",
    "      f'Loss {loss:.4f} '\n",
    "      f'Train {c_train[0][0]:02d} {c_train[0][1]:02d} {c_train[1][0]:02d} {c_train[1][1]:02d} '\n",
    "      f'Valid {c_val[0][0]:02d} {c_val[0][1]:02d} {c_val[1][0]:02d} {c_val[1][1]:02d} '\n",
    "      f'Test {c_val[0][0]:02d} {c_val[0][1]:02d} {c_val[1][0]:02d} {c_val[1][1]:02d} ')\n",
    "  \n",
    "  print((f'Epoch: {epoch:02d}, '\n",
    "        f'Loss: {loss:.4f}, '\n",
    "        f'Train: {100 * acc(c_train):.2f}%, '\n",
    "        f'Valid: {100 * acc(c_val):.2f}% '\n",
    "        f'Test: {100 * acc(c_test):.2f}%'))\n",
    "  \n",
    "handlers = gcn_logger.handlers[:]\n",
    "for handler in handlers:\n",
    "    gcn_logger.removeHandler(handler)\n",
    "    handler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9205389179755672"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_dim': 16, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.01, 'epochs': 200}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_args = {\n",
    "    \"hidden_dim\":16,\n",
    "    \"num_layers\":4,\n",
    "    \"dropout\":0.2,\n",
    "    \"lr\":0.01,\n",
    "    \"epochs\":200\n",
    "}\n",
    "\n",
    "mlp_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP model number of parameters: 2340\n"
     ]
    }
   ],
   "source": [
    "mlp_model = MLP(input_dim = data.x.shape[1], hidden_dim = mlp_args[\"hidden_dim\"], output_dim = data.y.shape[1], num_layers = mlp_args[\"num_layers\"], dropout = mlp_args['dropout']).to(device)\n",
    "\n",
    "total_params_mlp = sum(\n",
    "\tparam.numel() for param in mlp_model.parameters()\n",
    ")\n",
    "print(\"MLP model number of parameters:\" , total_params_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 21797.4688, Train: 59.47%, Valid: 58.14% Test: 60.47%\n",
      "Epoch: 02, Loss: 21769.3242, Train: 57.88%, Valid: 57.46% Test: 59.80%\n",
      "Epoch: 03, Loss: 21734.1836, Train: 55.75%, Valid: 55.42% Test: 57.26%\n",
      "Epoch: 04, Loss: 21694.2051, Train: 61.52%, Valid: 62.54% Test: 61.82%\n",
      "Epoch: 05, Loss: 21647.6953, Train: 67.70%, Valid: 66.95% Test: 67.74%\n",
      "Epoch: 06, Loss: 21591.1562, Train: 64.62%, Valid: 63.22% Test: 65.20%\n",
      "Epoch: 07, Loss: 21523.9414, Train: 66.73%, Valid: 65.25% Test: 66.72%\n",
      "Epoch: 08, Loss: 21448.9297, Train: 65.76%, Valid: 63.05% Test: 65.37%\n",
      "Epoch: 09, Loss: 21361.0430, Train: 65.76%, Valid: 63.05% Test: 65.37%\n",
      "Epoch: 10, Loss: 21255.2266, Train: 65.27%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 11, Loss: 21143.1562, Train: 65.27%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 12, Loss: 21018.9102, Train: 65.27%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 13, Loss: 20893.0820, Train: 65.27%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 14, Loss: 20748.2930, Train: 65.27%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 15, Loss: 20593.5625, Train: 65.27%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 16, Loss: 20462.7617, Train: 65.27%, Valid: 62.54% Test: 65.03%\n",
      "Epoch: 17, Loss: 20325.5781, Train: 64.18%, Valid: 61.19% Test: 64.36%\n",
      "Epoch: 18, Loss: 20222.6309, Train: 64.18%, Valid: 61.19% Test: 64.36%\n",
      "Epoch: 19, Loss: 20119.8848, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 20, Loss: 20052.2246, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 21, Loss: 19998.8516, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 22, Loss: 19964.1973, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 23, Loss: 19940.2578, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 24, Loss: 19928.2363, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 25, Loss: 19918.6055, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 26, Loss: 19909.9453, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 27, Loss: 19905.2695, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 28, Loss: 19908.2051, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 29, Loss: 19906.0547, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 30, Loss: 19903.0137, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 31, Loss: 19904.7949, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 32, Loss: 19902.9395, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 33, Loss: 19902.5820, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 34, Loss: 19904.7773, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 35, Loss: 19903.7324, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 36, Loss: 19901.6875, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 37, Loss: 19898.3027, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 38, Loss: 19899.1035, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 39, Loss: 19904.2031, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 40, Loss: 19898.8105, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 41, Loss: 19900.7480, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 42, Loss: 19898.5332, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 43, Loss: 19900.6035, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 44, Loss: 19902.0625, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 45, Loss: 19903.0938, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 46, Loss: 19902.8652, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 47, Loss: 19902.7969, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 48, Loss: 19897.0586, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 49, Loss: 19903.1348, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 50, Loss: 19901.5508, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 51, Loss: 19900.9922, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 52, Loss: 19903.0508, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 53, Loss: 19902.8340, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 54, Loss: 19900.8320, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 55, Loss: 19902.7109, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 56, Loss: 19901.8906, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 57, Loss: 19899.7109, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 58, Loss: 19895.7891, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 59, Loss: 19898.5898, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 60, Loss: 19899.5000, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 61, Loss: 19900.4570, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 62, Loss: 19899.9805, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 63, Loss: 19895.9023, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 64, Loss: 19905.1523, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 65, Loss: 19898.5137, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 66, Loss: 19901.2695, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 67, Loss: 19903.0547, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 68, Loss: 19898.6836, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 69, Loss: 19899.0703, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 70, Loss: 19899.1152, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 71, Loss: 19903.4023, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 72, Loss: 19899.8691, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 73, Loss: 19894.5391, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 74, Loss: 19899.8652, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 75, Loss: 19899.7051, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 76, Loss: 19900.5137, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 77, Loss: 19898.6953, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 78, Loss: 19897.8438, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 79, Loss: 19900.1133, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 80, Loss: 19901.5723, Train: 63.04%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 81, Loss: 19897.8750, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 82, Loss: 19896.0508, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 83, Loss: 19901.3125, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 84, Loss: 19901.4082, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 85, Loss: 19894.3633, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 86, Loss: 19898.8594, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 87, Loss: 19899.8008, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 88, Loss: 19904.3125, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 89, Loss: 19898.9570, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 90, Loss: 19900.6680, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 91, Loss: 19900.1602, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 92, Loss: 19898.7461, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 93, Loss: 19900.0781, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 94, Loss: 19895.4297, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 95, Loss: 19901.2930, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 96, Loss: 19898.9219, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 97, Loss: 19896.9766, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 98, Loss: 19897.2031, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 99, Loss: 19898.3789, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 100, Loss: 19898.0215, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 101, Loss: 19898.2617, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 102, Loss: 19902.2383, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 103, Loss: 19900.5449, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 104, Loss: 19898.7266, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 105, Loss: 19898.8945, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 106, Loss: 19897.7227, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 107, Loss: 19900.5586, Train: 63.04%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 108, Loss: 19899.4297, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 109, Loss: 19896.6172, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 110, Loss: 19899.9707, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 111, Loss: 19898.7969, Train: 63.04%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 112, Loss: 19898.7148, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 113, Loss: 19898.6602, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 114, Loss: 19895.8750, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 115, Loss: 19894.4727, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 116, Loss: 19899.7324, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 117, Loss: 19900.4141, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 118, Loss: 19896.8672, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 119, Loss: 19895.9785, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 120, Loss: 19899.5703, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 121, Loss: 19895.2539, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 122, Loss: 19900.6016, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 123, Loss: 19899.1016, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 124, Loss: 19898.4609, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 125, Loss: 19896.7461, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 126, Loss: 19894.9492, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 127, Loss: 19898.0977, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 128, Loss: 19899.1367, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 129, Loss: 19898.5156, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 130, Loss: 19897.0508, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 131, Loss: 19898.7656, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 132, Loss: 19897.6562, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 133, Loss: 19899.9102, Train: 63.04%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 134, Loss: 19896.3535, Train: 63.04%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 135, Loss: 19896.1914, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 136, Loss: 19898.3633, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 137, Loss: 19896.7812, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 138, Loss: 19897.8457, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 139, Loss: 19896.4746, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 140, Loss: 19897.4824, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 141, Loss: 19894.6094, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 142, Loss: 19897.6289, Train: 63.04%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 143, Loss: 19896.4219, Train: 62.97%, Valid: 59.66% Test: 61.99%\n",
      "Epoch: 144, Loss: 19899.6465, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 145, Loss: 19896.5020, Train: 63.01%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 146, Loss: 19897.8359, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 147, Loss: 19900.4316, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 148, Loss: 19895.7207, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 149, Loss: 19899.5547, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 150, Loss: 19896.7227, Train: 63.04%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 151, Loss: 19895.0898, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 152, Loss: 19896.9141, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 153, Loss: 19896.2266, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 154, Loss: 19896.2598, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 155, Loss: 19898.1914, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 156, Loss: 19898.8789, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 157, Loss: 19896.0117, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 158, Loss: 19898.6211, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 159, Loss: 19895.3906, Train: 62.19%, Valid: 58.81% Test: 60.98%\n",
      "Epoch: 160, Loss: 19896.2402, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 161, Loss: 19899.0059, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 162, Loss: 19899.2520, Train: 63.04%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 163, Loss: 19898.6348, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 164, Loss: 19897.4883, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 165, Loss: 19899.3535, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 166, Loss: 19898.0410, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 167, Loss: 19899.4980, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 168, Loss: 19897.7383, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 169, Loss: 19897.0488, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 170, Loss: 19896.4805, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 171, Loss: 19897.1504, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 172, Loss: 19898.9102, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 173, Loss: 19897.7227, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 174, Loss: 19896.7695, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 175, Loss: 19898.1719, Train: 63.04%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 176, Loss: 19898.6777, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 177, Loss: 19896.0078, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 178, Loss: 19899.5469, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 179, Loss: 19897.4863, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 180, Loss: 19899.4395, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 181, Loss: 19898.0078, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 182, Loss: 19896.3066, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 183, Loss: 19900.4805, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 184, Loss: 19898.2656, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 185, Loss: 19898.1094, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 186, Loss: 19898.5820, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 187, Loss: 19898.1172, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 188, Loss: 19896.7500, Train: 63.06%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 189, Loss: 19896.8926, Train: 63.04%, Valid: 59.83% Test: 62.16%\n",
      "Epoch: 190, Loss: 19896.6406, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 191, Loss: 19896.0957, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 192, Loss: 19898.5625, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 193, Loss: 19897.9434, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 194, Loss: 19897.5625, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 195, Loss: 19897.1367, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 196, Loss: 19894.7012, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 197, Loss: 19897.0859, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 198, Loss: 19897.3633, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 199, Loss: 19899.8691, Train: 61.77%, Valid: 58.81% Test: 59.97%\n",
      "Epoch: 200, Loss: 19898.6211, Train: 61.77%, Valid: 58.81% Test: 59.97%\n"
     ]
    }
   ],
   "source": [
    "mlp_model.reset_parameters()\n",
    "\n",
    "optimizer = torch.optim.Adam(mlp_model.parameters(), lr=mlp_args['lr'])\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=None , reduction=\"sum\")\n",
    "\n",
    "best_model = None\n",
    "best_valid_acc = 0\n",
    "\n",
    "for epoch in range(1, 1 + mlp_args[\"epochs\"]):\n",
    "  \n",
    "  loss = train_mlp(mlp_model , data , optimizer, loss_fn)\n",
    "  result = test_mlp(mlp_model, data)\n",
    "\n",
    "  c_train , c_val , c_test = result\n",
    "\n",
    "  if acc(c_val) > best_valid_acc:\n",
    "      best_valid_acc = acc(c_val)\n",
    "      best_model = copy.deepcopy(mlp_model)\n",
    "        \n",
    "  mlp_logger.info(f'Epoch {epoch:02d} '\n",
    "      f'Loss {loss:.4f} '\n",
    "      f'Train {c_train[0][0]:02d} {c_train[0][1]:02d} {c_train[1][0]:02d} {c_train[1][1]:02d} '\n",
    "      f'Valid {c_val[0][0]:02d} {c_val[0][1]:02d} {c_val[1][0]:02d} {c_val[1][1]:02d} '\n",
    "      f'Test {c_val[0][0]:02d} {c_val[0][1]:02d} {c_val[1][0]:02d} {c_val[1][1]:02d} ')\n",
    "  \n",
    "  print((f'Epoch: {epoch:02d}, '\n",
    "        f'Loss: {loss:.4f}, '\n",
    "        f'Train: {100 * acc(c_train):.2f}%, '\n",
    "        f'Valid: {100 * acc(c_val):.2f}% '\n",
    "        f'Test: {100 * acc(c_test):.2f}%'))\n",
    "  \n",
    "handlers = mlp_logger.handlers[:]\n",
    "for handler in handlers:\n",
    "    mlp_logger.removeHandler(handler)\n",
    "    handler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.90038394415357"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_valid_acc*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_dim': 16,\n",
       " 'encoding_dim': 16,\n",
       " 'num_layers': 3,\n",
       " 'dropout': 0.2,\n",
       " 'lr': 0.01,\n",
       " 'epochs': 200}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_gcn_args = {\n",
    "    \"hidden_dim\":16,\n",
    "    \"encoding_dim\":16,\n",
    "    \"num_layers\":3,\n",
    "    \"dropout\":0.2,\n",
    "    \"lr\":0.01,\n",
    "    \"epochs\":200\n",
    "}\n",
    "\n",
    "mlp_gcn_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN model with MLP layers number of parameters: 9476\n"
     ]
    }
   ],
   "source": [
    "mlp_gcn_model = mlp_GCN(input_dim = data.x.shape[1], encoding_dim = mlp_gcn_args[\"encoding_dim\"] , hidden_dim = mlp_gcn_args[\"hidden_dim\"], output_dim = data.y.shape[1], num_layers = mlp_gcn_args[\"num_layers\"], dropout = mlp_gcn_args['dropout']).to(device)\n",
    "\n",
    "total_params_mlp_gcn = sum(\n",
    "\tparam.numel() for param in mlp_gcn_model.parameters()\n",
    ")\n",
    "print(\"GCN model with MLP layers number of parameters:\" , total_params_mlp_gcn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 155684.2344, Train: 52.03%, Valid: 52.03% Test: 52.04%\n",
      "Epoch: 02, Loss: 155064.6719, Train: 54.03%, Valid: 54.02% Test: 54.04%\n",
      "Epoch: 03, Loss: 154387.7188, Train: 57.56%, Valid: 57.55% Test: 57.56%\n",
      "Epoch: 04, Loss: 153664.0156, Train: 62.91%, Valid: 62.91% Test: 62.91%\n",
      "Epoch: 05, Loss: 152829.0000, Train: 68.60%, Valid: 68.59% Test: 68.60%\n",
      "Epoch: 06, Loss: 151871.5781, Train: 77.01%, Valid: 77.01% Test: 77.00%\n",
      "Epoch: 07, Loss: 150776.1562, Train: 82.04%, Valid: 82.04% Test: 82.03%\n",
      "Epoch: 08, Loss: 149709.9531, Train: 86.30%, Valid: 86.28% Test: 86.29%\n",
      "Epoch: 09, Loss: 148523.2500, Train: 88.38%, Valid: 88.38% Test: 88.38%\n",
      "Epoch: 10, Loss: 147324.6562, Train: 89.90%, Valid: 89.91% Test: 89.90%\n",
      "Epoch: 11, Loss: 146213.3438, Train: 90.26%, Valid: 90.26% Test: 90.26%\n",
      "Epoch: 12, Loss: 145205.7812, Train: 90.78%, Valid: 90.78% Test: 90.78%\n",
      "Epoch: 13, Loss: 144247.4375, Train: 91.31%, Valid: 91.31% Test: 91.31%\n",
      "Epoch: 14, Loss: 143440.2969, Train: 91.41%, Valid: 91.41% Test: 91.41%\n",
      "Epoch: 15, Loss: 142765.4531, Train: 91.69%, Valid: 91.69% Test: 91.69%\n",
      "Epoch: 16, Loss: 142258.9219, Train: 91.70%, Valid: 91.70% Test: 91.70%\n",
      "Epoch: 17, Loss: 141817.6250, Train: 91.70%, Valid: 91.70% Test: 91.70%\n",
      "Epoch: 18, Loss: 141529.9844, Train: 91.70%, Valid: 91.70% Test: 91.70%\n",
      "Epoch: 19, Loss: 141316.5312, Train: 91.70%, Valid: 91.70% Test: 91.70%\n",
      "Epoch: 20, Loss: 141162.5312, Train: 91.70%, Valid: 91.70% Test: 91.70%\n",
      "Epoch: 21, Loss: 141037.8281, Train: 91.51%, Valid: 91.51% Test: 91.51%\n",
      "Epoch: 22, Loss: 140953.0156, Train: 91.50%, Valid: 91.50% Test: 91.50%\n",
      "Epoch: 23, Loss: 140899.6562, Train: 91.50%, Valid: 91.50% Test: 91.50%\n",
      "Epoch: 24, Loss: 140858.5312, Train: 91.50%, Valid: 91.50% Test: 91.50%\n",
      "Epoch: 25, Loss: 140829.4219, Train: 91.50%, Valid: 91.50% Test: 91.50%\n",
      "Epoch: 26, Loss: 140807.9062, Train: 91.50%, Valid: 91.50% Test: 91.50%\n",
      "Epoch: 27, Loss: 140790.1562, Train: 91.70%, Valid: 91.70% Test: 91.70%\n",
      "Epoch: 28, Loss: 140780.6875, Train: 91.70%, Valid: 91.70% Test: 91.70%\n",
      "Epoch: 29, Loss: 140774.5000, Train: 91.60%, Valid: 91.61% Test: 91.60%\n",
      "Epoch: 30, Loss: 140763.4844, Train: 91.52%, Valid: 91.52% Test: 91.52%\n",
      "Epoch: 31, Loss: 140766.2031, Train: 91.52%, Valid: 91.53% Test: 91.52%\n",
      "Epoch: 32, Loss: 140757.9688, Train: 91.53%, Valid: 91.53% Test: 91.52%\n",
      "Epoch: 33, Loss: 140755.3750, Train: 91.45%, Valid: 91.45% Test: 91.45%\n",
      "Epoch: 34, Loss: 140749.3438, Train: 91.32%, Valid: 91.32% Test: 91.32%\n",
      "Epoch: 35, Loss: 140743.9688, Train: 91.32%, Valid: 91.32% Test: 91.32%\n",
      "Epoch: 36, Loss: 140744.5781, Train: 91.30%, Valid: 91.30% Test: 91.30%\n",
      "Epoch: 37, Loss: 140741.4375, Train: 91.27%, Valid: 91.27% Test: 91.27%\n",
      "Epoch: 38, Loss: 140738.4375, Train: 91.29%, Valid: 91.29% Test: 91.29%\n",
      "Epoch: 39, Loss: 140739.9844, Train: 91.36%, Valid: 91.37% Test: 91.37%\n",
      "Epoch: 40, Loss: 140739.0312, Train: 91.54%, Valid: 91.55% Test: 91.54%\n",
      "Epoch: 41, Loss: 140730.3125, Train: 91.62%, Valid: 91.62% Test: 91.62%\n",
      "Epoch: 42, Loss: 140728.6562, Train: 91.61%, Valid: 91.61% Test: 91.60%\n",
      "Epoch: 43, Loss: 140730.6250, Train: 91.59%, Valid: 91.60% Test: 91.59%\n",
      "Epoch: 44, Loss: 140737.3594, Train: 91.55%, Valid: 91.55% Test: 91.54%\n",
      "Epoch: 45, Loss: 140721.1562, Train: 91.53%, Valid: 91.54% Test: 91.53%\n",
      "Epoch: 46, Loss: 140737.9688, Train: 91.54%, Valid: 91.54% Test: 91.54%\n",
      "Epoch: 47, Loss: 140725.9844, Train: 91.54%, Valid: 91.55% Test: 91.54%\n",
      "Epoch: 48, Loss: 140729.5625, Train: 91.53%, Valid: 91.53% Test: 91.53%\n",
      "Epoch: 49, Loss: 140730.2656, Train: 91.49%, Valid: 91.49% Test: 91.48%\n",
      "Epoch: 50, Loss: 140721.2656, Train: 91.43%, Valid: 91.44% Test: 91.43%\n",
      "Epoch: 51, Loss: 140725.0625, Train: 91.39%, Valid: 91.39% Test: 91.39%\n",
      "Epoch: 52, Loss: 140726.5000, Train: 91.34%, Valid: 91.34% Test: 91.34%\n",
      "Epoch: 53, Loss: 140725.7812, Train: 91.31%, Valid: 91.31% Test: 91.31%\n",
      "Epoch: 54, Loss: 140721.7812, Train: 91.30%, Valid: 91.30% Test: 91.30%\n",
      "Epoch: 55, Loss: 140722.3750, Train: 91.31%, Valid: 91.31% Test: 91.30%\n",
      "Epoch: 56, Loss: 140716.3438, Train: 91.32%, Valid: 91.33% Test: 91.32%\n",
      "Epoch: 57, Loss: 140717.7344, Train: 91.35%, Valid: 91.35% Test: 91.34%\n",
      "Epoch: 58, Loss: 140718.4688, Train: 91.37%, Valid: 91.37% Test: 91.36%\n",
      "Epoch: 59, Loss: 140723.2656, Train: 91.39%, Valid: 91.39% Test: 91.39%\n",
      "Epoch: 60, Loss: 140717.5625, Train: 91.41%, Valid: 91.41% Test: 91.41%\n",
      "Epoch: 61, Loss: 140714.6406, Train: 91.42%, Valid: 91.42% Test: 91.42%\n",
      "Epoch: 62, Loss: 140710.2031, Train: 91.42%, Valid: 91.42% Test: 91.42%\n",
      "Epoch: 63, Loss: 140723.5625, Train: 91.42%, Valid: 91.42% Test: 91.42%\n",
      "Epoch: 64, Loss: 140717.6562, Train: 91.42%, Valid: 91.42% Test: 91.42%\n",
      "Epoch: 65, Loss: 140712.2500, Train: 91.42%, Valid: 91.41% Test: 91.42%\n",
      "Epoch: 66, Loss: 140718.1562, Train: 91.42%, Valid: 91.41% Test: 91.42%\n",
      "Epoch: 67, Loss: 140712.0156, Train: 91.42%, Valid: 91.42% Test: 91.42%\n",
      "Epoch: 68, Loss: 140715.2188, Train: 91.42%, Valid: 91.42% Test: 91.42%\n",
      "Epoch: 69, Loss: 140715.4062, Train: 91.43%, Valid: 91.43% Test: 91.43%\n",
      "Epoch: 70, Loss: 140713.7188, Train: 91.44%, Valid: 91.44% Test: 91.45%\n",
      "Epoch: 71, Loss: 140712.1094, Train: 91.46%, Valid: 91.46% Test: 91.46%\n",
      "Epoch: 72, Loss: 140708.2812, Train: 91.47%, Valid: 91.47% Test: 91.47%\n",
      "Epoch: 73, Loss: 140701.0781, Train: 91.48%, Valid: 91.49% Test: 91.48%\n",
      "Epoch: 74, Loss: 140711.7031, Train: 91.50%, Valid: 91.50% Test: 91.50%\n",
      "Epoch: 75, Loss: 140709.0000, Train: 91.52%, Valid: 91.53% Test: 91.52%\n",
      "Epoch: 76, Loss: 140701.2656, Train: 91.54%, Valid: 91.55% Test: 91.55%\n",
      "Epoch: 77, Loss: 140709.5781, Train: 91.56%, Valid: 91.57% Test: 91.57%\n",
      "Epoch: 78, Loss: 140700.6094, Train: 91.59%, Valid: 91.59% Test: 91.59%\n",
      "Epoch: 79, Loss: 140706.7031, Train: 91.62%, Valid: 91.62% Test: 91.62%\n",
      "Epoch: 80, Loss: 140704.1719, Train: 91.64%, Valid: 91.65% Test: 91.65%\n",
      "Epoch: 81, Loss: 140693.6406, Train: 91.67%, Valid: 91.68% Test: 91.68%\n",
      "Epoch: 82, Loss: 140694.5781, Train: 91.72%, Valid: 91.72% Test: 91.72%\n",
      "Epoch: 83, Loss: 140703.5000, Train: 91.76%, Valid: 91.76% Test: 91.77%\n",
      "Epoch: 84, Loss: 140700.7344, Train: 91.78%, Valid: 91.78% Test: 91.78%\n",
      "Epoch: 85, Loss: 140706.5938, Train: 91.78%, Valid: 91.78% Test: 91.78%\n",
      "Epoch: 86, Loss: 140699.3750, Train: 91.78%, Valid: 91.78% Test: 91.78%\n",
      "Epoch: 87, Loss: 140710.0625, Train: 91.79%, Valid: 91.79% Test: 91.79%\n",
      "Epoch: 88, Loss: 140701.2812, Train: 91.78%, Valid: 91.78% Test: 91.78%\n",
      "Epoch: 89, Loss: 140690.3125, Train: 91.78%, Valid: 91.78% Test: 91.78%\n",
      "Epoch: 90, Loss: 140694.3906, Train: 91.77%, Valid: 91.77% Test: 91.77%\n",
      "Epoch: 91, Loss: 140699.9688, Train: 91.77%, Valid: 91.77% Test: 91.77%\n",
      "Epoch: 92, Loss: 140693.6094, Train: 91.76%, Valid: 91.76% Test: 91.76%\n",
      "Epoch: 93, Loss: 140697.9531, Train: 91.75%, Valid: 91.75% Test: 91.75%\n",
      "Epoch: 94, Loss: 140690.8125, Train: 91.73%, Valid: 91.73% Test: 91.73%\n",
      "Epoch: 95, Loss: 140697.7031, Train: 91.75%, Valid: 91.75% Test: 91.75%\n",
      "Epoch: 96, Loss: 140678.1875, Train: 91.77%, Valid: 91.77% Test: 91.77%\n",
      "Epoch: 97, Loss: 140689.0625, Train: 91.79%, Valid: 91.79% Test: 91.79%\n",
      "Epoch: 98, Loss: 140687.9688, Train: 91.81%, Valid: 91.80% Test: 91.81%\n",
      "Epoch: 99, Loss: 140694.9375, Train: 91.66%, Valid: 91.66% Test: 91.67%\n",
      "Epoch: 100, Loss: 140690.5312, Train: 91.68%, Valid: 91.68% Test: 91.68%\n",
      "Epoch: 101, Loss: 140685.0625, Train: 91.69%, Valid: 91.69% Test: 91.69%\n",
      "Epoch: 102, Loss: 140684.7969, Train: 91.70%, Valid: 91.70% Test: 91.70%\n",
      "Epoch: 103, Loss: 140691.1719, Train: 91.70%, Valid: 91.70% Test: 91.70%\n",
      "Epoch: 104, Loss: 140691.5000, Train: 91.72%, Valid: 91.72% Test: 91.72%\n",
      "Epoch: 105, Loss: 140689.4062, Train: 91.76%, Valid: 91.76% Test: 91.76%\n",
      "Epoch: 106, Loss: 140692.0312, Train: 91.79%, Valid: 91.79% Test: 91.79%\n",
      "Epoch: 107, Loss: 140687.2188, Train: 91.79%, Valid: 91.79% Test: 91.79%\n",
      "Epoch: 108, Loss: 140686.0938, Train: 91.77%, Valid: 91.78% Test: 91.77%\n",
      "Epoch: 109, Loss: 140678.4062, Train: 91.77%, Valid: 91.77% Test: 91.77%\n",
      "Epoch: 110, Loss: 140680.5625, Train: 91.78%, Valid: 91.78% Test: 91.78%\n",
      "Epoch: 111, Loss: 140689.0781, Train: 91.81%, Valid: 91.81% Test: 91.81%\n",
      "Epoch: 112, Loss: 140675.2344, Train: 91.81%, Valid: 91.81% Test: 91.81%\n",
      "Epoch: 113, Loss: 140678.8906, Train: 91.79%, Valid: 91.79% Test: 91.78%\n",
      "Epoch: 114, Loss: 140677.7500, Train: 91.75%, Valid: 91.76% Test: 91.75%\n",
      "Epoch: 115, Loss: 140690.6562, Train: 91.73%, Valid: 91.73% Test: 91.73%\n",
      "Epoch: 116, Loss: 140678.2812, Train: 91.73%, Valid: 91.73% Test: 91.73%\n",
      "Epoch: 117, Loss: 140671.7812, Train: 91.73%, Valid: 91.74% Test: 91.73%\n",
      "Epoch: 118, Loss: 140679.3906, Train: 91.70%, Valid: 91.70% Test: 91.69%\n",
      "Epoch: 119, Loss: 140673.7812, Train: 91.63%, Valid: 91.63% Test: 91.62%\n",
      "Epoch: 120, Loss: 140677.3750, Train: 91.58%, Valid: 91.59% Test: 91.58%\n",
      "Epoch: 121, Loss: 140667.6406, Train: 91.55%, Valid: 91.56% Test: 91.55%\n",
      "Epoch: 122, Loss: 140662.9219, Train: 91.54%, Valid: 91.54% Test: 91.54%\n",
      "Epoch: 123, Loss: 140671.0938, Train: 91.52%, Valid: 91.53% Test: 91.52%\n",
      "Epoch: 124, Loss: 140678.9219, Train: 91.52%, Valid: 91.53% Test: 91.52%\n",
      "Epoch: 125, Loss: 140667.4375, Train: 91.54%, Valid: 91.55% Test: 91.54%\n",
      "Epoch: 126, Loss: 140678.4375, Train: 91.55%, Valid: 91.56% Test: 91.55%\n",
      "Epoch: 127, Loss: 140683.5000, Train: 91.56%, Valid: 91.57% Test: 91.56%\n",
      "Epoch: 128, Loss: 140669.5312, Train: 91.61%, Valid: 91.61% Test: 91.61%\n",
      "Epoch: 129, Loss: 140661.5000, Train: 91.69%, Valid: 91.69% Test: 91.69%\n",
      "Epoch: 130, Loss: 140674.9688, Train: 91.81%, Valid: 91.81% Test: 91.81%\n",
      "Epoch: 131, Loss: 140664.5312, Train: 91.83%, Valid: 91.83% Test: 91.83%\n",
      "Epoch: 132, Loss: 140661.7500, Train: 91.84%, Valid: 91.84% Test: 91.84%\n",
      "Epoch: 133, Loss: 140665.9062, Train: 91.82%, Valid: 91.82% Test: 91.81%\n",
      "Epoch: 134, Loss: 140670.6094, Train: 91.77%, Valid: 91.77% Test: 91.77%\n",
      "Epoch: 135, Loss: 140662.8906, Train: 91.74%, Valid: 91.75% Test: 91.74%\n",
      "Epoch: 136, Loss: 140671.3750, Train: 91.77%, Valid: 91.77% Test: 91.77%\n",
      "Epoch: 137, Loss: 140669.3125, Train: 91.71%, Valid: 91.72% Test: 91.71%\n",
      "Epoch: 138, Loss: 140675.5000, Train: 91.72%, Valid: 91.72% Test: 91.72%\n",
      "Epoch: 139, Loss: 140671.6719, Train: 91.73%, Valid: 91.73% Test: 91.72%\n",
      "Epoch: 140, Loss: 140660.4062, Train: 91.75%, Valid: 91.75% Test: 91.75%\n",
      "Epoch: 141, Loss: 140662.6250, Train: 91.64%, Valid: 91.64% Test: 91.64%\n",
      "Epoch: 142, Loss: 140657.2500, Train: 91.76%, Valid: 91.76% Test: 91.75%\n",
      "Epoch: 143, Loss: 140655.7188, Train: 91.71%, Valid: 91.71% Test: 91.71%\n",
      "Epoch: 144, Loss: 140671.4062, Train: 91.72%, Valid: 91.72% Test: 91.72%\n",
      "Epoch: 145, Loss: 140657.0938, Train: 91.52%, Valid: 91.53% Test: 91.52%\n",
      "Epoch: 146, Loss: 140655.2969, Train: 91.73%, Valid: 91.73% Test: 91.72%\n",
      "Epoch: 147, Loss: 140654.2812, Train: 91.74%, Valid: 91.74% Test: 91.74%\n",
      "Epoch: 148, Loss: 140652.7812, Train: 91.66%, Valid: 91.66% Test: 91.66%\n",
      "Epoch: 149, Loss: 140668.3438, Train: 91.54%, Valid: 91.54% Test: 91.54%\n",
      "Epoch: 150, Loss: 140654.4219, Train: 91.49%, Valid: 91.49% Test: 91.49%\n",
      "Epoch: 151, Loss: 140660.3906, Train: 91.72%, Valid: 91.72% Test: 91.71%\n",
      "Epoch: 152, Loss: 140656.4062, Train: 91.66%, Valid: 91.66% Test: 91.65%\n",
      "Epoch: 153, Loss: 140643.0781, Train: 91.66%, Valid: 91.67% Test: 91.67%\n",
      "Epoch: 154, Loss: 140653.5625, Train: 91.43%, Valid: 91.43% Test: 91.44%\n",
      "Epoch: 155, Loss: 140645.0312, Train: 91.46%, Valid: 91.46% Test: 91.46%\n",
      "Epoch: 156, Loss: 140650.0625, Train: 91.57%, Valid: 91.57% Test: 91.57%\n",
      "Epoch: 157, Loss: 140652.5938, Train: 91.51%, Valid: 91.50% Test: 91.50%\n",
      "Epoch: 158, Loss: 140646.7812, Train: 91.54%, Valid: 91.53% Test: 91.53%\n",
      "Epoch: 159, Loss: 140650.0781, Train: 91.55%, Valid: 91.55% Test: 91.54%\n",
      "Epoch: 160, Loss: 140645.0938, Train: 91.64%, Valid: 91.64% Test: 91.63%\n",
      "Epoch: 161, Loss: 140640.3125, Train: 91.55%, Valid: 91.55% Test: 91.54%\n",
      "Epoch: 162, Loss: 140643.0625, Train: 91.56%, Valid: 91.56% Test: 91.56%\n",
      "Epoch: 163, Loss: 140650.6875, Train: 91.49%, Valid: 91.49% Test: 91.49%\n",
      "Epoch: 164, Loss: 140633.5781, Train: 91.44%, Valid: 91.44% Test: 91.43%\n",
      "Epoch: 165, Loss: 140645.3438, Train: 91.40%, Valid: 91.41% Test: 91.40%\n",
      "Epoch: 166, Loss: 140627.5781, Train: 91.61%, Valid: 91.62% Test: 91.61%\n",
      "Epoch: 167, Loss: 140629.8750, Train: 91.67%, Valid: 91.67% Test: 91.67%\n",
      "Epoch: 168, Loss: 140622.5469, Train: 91.46%, Valid: 91.46% Test: 91.46%\n",
      "Epoch: 169, Loss: 140659.2500, Train: 91.53%, Valid: 91.53% Test: 91.53%\n",
      "Epoch: 170, Loss: 140641.1875, Train: 91.58%, Valid: 91.58% Test: 91.58%\n",
      "Epoch: 171, Loss: 140621.4688, Train: 91.59%, Valid: 91.59% Test: 91.59%\n",
      "Epoch: 172, Loss: 140636.1562, Train: 91.60%, Valid: 91.60% Test: 91.59%\n",
      "Epoch: 173, Loss: 140620.9062, Train: 91.58%, Valid: 91.58% Test: 91.58%\n",
      "Epoch: 174, Loss: 140623.3438, Train: 91.57%, Valid: 91.57% Test: 91.57%\n",
      "Epoch: 175, Loss: 140610.7344, Train: 91.57%, Valid: 91.57% Test: 91.57%\n",
      "Epoch: 176, Loss: 140631.2969, Train: 91.57%, Valid: 91.57% Test: 91.57%\n",
      "Epoch: 177, Loss: 140627.2812, Train: 91.56%, Valid: 91.56% Test: 91.56%\n",
      "Epoch: 178, Loss: 140618.0000, Train: 91.55%, Valid: 91.56% Test: 91.55%\n",
      "Epoch: 179, Loss: 140616.4375, Train: 91.53%, Valid: 91.53% Test: 91.53%\n",
      "Epoch: 180, Loss: 140624.2344, Train: 91.50%, Valid: 91.50% Test: 91.50%\n",
      "Epoch: 181, Loss: 140633.2500, Train: 91.48%, Valid: 91.49% Test: 91.49%\n",
      "Epoch: 182, Loss: 140615.1875, Train: 91.47%, Valid: 91.47% Test: 91.47%\n",
      "Epoch: 183, Loss: 140626.2656, Train: 91.45%, Valid: 91.46% Test: 91.45%\n",
      "Epoch: 184, Loss: 140605.2500, Train: 91.60%, Valid: 91.60% Test: 91.59%\n",
      "Epoch: 185, Loss: 140614.9219, Train: 91.89%, Valid: 91.90% Test: 91.89%\n",
      "Epoch: 186, Loss: 140625.7031, Train: 91.88%, Valid: 91.89% Test: 91.88%\n",
      "Epoch: 187, Loss: 140617.6094, Train: 91.78%, Valid: 91.78% Test: 91.78%\n",
      "Epoch: 188, Loss: 140618.1875, Train: 91.90%, Valid: 91.90% Test: 91.90%\n",
      "Epoch: 189, Loss: 140606.7188, Train: 91.98%, Valid: 91.98% Test: 91.98%\n",
      "Epoch: 190, Loss: 140621.4844, Train: 91.91%, Valid: 91.91% Test: 91.91%\n",
      "Epoch: 191, Loss: 140620.4688, Train: 91.75%, Valid: 91.75% Test: 91.75%\n",
      "Epoch: 192, Loss: 140601.3750, Train: 91.63%, Valid: 91.63% Test: 91.63%\n",
      "Epoch: 193, Loss: 140622.0625, Train: 91.77%, Valid: 91.77% Test: 91.77%\n",
      "Epoch: 194, Loss: 140604.7969, Train: 91.75%, Valid: 91.76% Test: 91.76%\n",
      "Epoch: 195, Loss: 140614.8438, Train: 91.77%, Valid: 91.77% Test: 91.77%\n",
      "Epoch: 196, Loss: 140612.5781, Train: 91.67%, Valid: 91.67% Test: 91.67%\n",
      "Epoch: 197, Loss: 140593.5469, Train: 91.28%, Valid: 91.29% Test: 91.29%\n",
      "Epoch: 198, Loss: 140610.4062, Train: 91.47%, Valid: 91.48% Test: 91.47%\n",
      "Epoch: 199, Loss: 140593.2500, Train: 91.96%, Valid: 91.96% Test: 91.96%\n",
      "Epoch: 200, Loss: 140598.6875, Train: 92.12%, Valid: 92.12% Test: 92.12%\n"
     ]
    }
   ],
   "source": [
    "mlp_gcn_model.reset_parameters()\n",
    "\n",
    "optimizer = torch.optim.Adam(mlp_gcn_model.parameters(), lr=mlp_gcn_args['lr'])\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=None , reduction=\"sum\")\n",
    "\n",
    "best_model = None\n",
    "best_valid_acc = 0\n",
    "\n",
    "for epoch in range(1, 1 + mlp_gcn_args[\"epochs\"]):\n",
    "  \n",
    "  loss = train_gcn(mlp_gcn_model , data , optimizer, loss_fn)\n",
    "  result = test_gcn(mlp_gcn_model, data)\n",
    "\n",
    "  c_train , c_val , c_test = result\n",
    "\n",
    "  if acc(c_val) > best_valid_acc:\n",
    "      best_valid_acc = acc(c_val)\n",
    "      best_model = copy.deepcopy(mlp_gcn_model)\n",
    "        \n",
    "  mlp_gcn_logger.info(f'Epoch {epoch:02d} '\n",
    "      f'Loss {loss:.4f} '\n",
    "      f'Train {c_train[0][0]:02d} {c_train[0][1]:02d} {c_train[1][0]:02d} {c_train[1][1]:02d} '\n",
    "      f'Valid {c_val[0][0]:02d} {c_val[0][1]:02d} {c_val[1][0]:02d} {c_val[1][1]:02d} '\n",
    "      f'Test {c_val[0][0]:02d} {c_val[0][1]:02d} {c_val[1][0]:02d} {c_val[1][1]:02d} ')\n",
    "  \n",
    "  print((f'Epoch: {epoch:02d}, '\n",
    "        f'Loss: {loss:.4f}, '\n",
    "        f'Train: {100 * acc(c_train):.2f}%, '\n",
    "        f'Valid: {100 * acc(c_val):.2f}% '\n",
    "        f'Test: {100 * acc(c_test):.2f}%'))\n",
    "  \n",
    "handlers = mlp_gcn_logger.handlers[:]\n",
    "for handler in handlers:\n",
    "    mlp_gcn_logger.removeHandler(handler)\n",
    "    handler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9212132635253054"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding_dim': 16,\n",
       " 'walk_length': 10,\n",
       " 'num_walks': 100,\n",
       " 'min_count': 1,\n",
       " 'batch_words': 5,\n",
       " 'window': 10,\n",
       " 'hidden_dim': 16,\n",
       " 'num_layers': 4,\n",
       " 'dropout': 0.2,\n",
       " 'lr': 0.01,\n",
       " 'epochs': 2000}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n2vnet_args = {\n",
    "    \"embedding_dim\":16,\n",
    "    \"walk_length\":10,\n",
    "    \"num_walks\":100,\n",
    "    \"min_count\":1,\n",
    "    \"batch_words\":5,\n",
    "    \"window\":10,\n",
    "\n",
    "    \"hidden_dim\":16,\n",
    "    \"num_layers\":4,\n",
    "    \"dropout\":0.2,\n",
    "\n",
    "    \"lr\":0.01,\n",
    "    \"epochs\":2000\n",
    "}\n",
    "\n",
    "n2vnet_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84661e0b773a401d88e151d9434ac078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/14050 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 100/100 [00:27<00:00,  3.64it/s]\n"
     ]
    }
   ],
   "source": [
    "sorted_node_list = (list(data.g.nodes))\n",
    "sorted_node_list.sort()\n",
    "sorted_node_list = [str(node) for node in sorted_node_list]\n",
    "\n",
    "n2v = node2vec.Node2Vec(data.g , dimensions=n2vnet_args[\"embedding_dim\"] , walk_length=n2vnet_args[\"walk_length\"] , num_walks=n2vnet_args[\"num_walks\"]) \n",
    "embeddings = torch.tensor((n2v.fit(window=n2vnet_args[\"window\"] , min_count=n2vnet_args[\"min_count\"] , batch_words=n2vnet_args[\"batch_words\"]).wv)[sorted_node_list] , dtype=torch.float32 , device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n2vnet number of parameters: 4216\n"
     ]
    }
   ],
   "source": [
    "n2vnet_model = n2vnet(data.g , input_dim = n2vnet_args[\"embedding_dim\"], hidden_dim = n2vnet_args[\"hidden_dim\"], output_dim = data.y.shape[1], num_layers = n2vnet_args[\"num_layers\"], dropout = n2vnet_args['dropout']).to(device)\n",
    "\n",
    "total_params_n2vnet = sum(\n",
    "\tparam.numel() for param in n2vnet_model.parameters()\n",
    ")\n",
    "print(\"n2vnet number of parameters:\" , total_params_n2vnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 61421.4961, Train: 55.05%, Valid: 56.79% Test: 55.92%\n",
      "Epoch: 02, Loss: 61289.3047, Train: 61.48%, Valid: 63.64% Test: 63.36%\n",
      "Epoch: 03, Loss: 61142.0234, Train: 64.89%, Valid: 67.11% Test: 66.60%\n",
      "Epoch: 04, Loss: 60940.1562, Train: 64.93%, Valid: 67.11% Test: 66.87%\n",
      "Epoch: 05, Loss: 60660.4023, Train: 67.93%, Valid: 69.60% Test: 68.94%\n",
      "Epoch: 06, Loss: 60282.9414, Train: 72.89%, Valid: 74.24% Test: 73.55%\n",
      "Epoch: 07, Loss: 59792.6523, Train: 74.36%, Valid: 76.32% Test: 74.52%\n",
      "Epoch: 08, Loss: 59206.0078, Train: 73.87%, Valid: 76.04% Test: 73.76%\n",
      "Epoch: 09, Loss: 58531.7969, Train: 73.33%, Valid: 75.55% Test: 73.00%\n",
      "Epoch: 10, Loss: 57820.0898, Train: 73.52%, Valid: 76.52% Test: 73.69%\n",
      "Epoch: 11, Loss: 57156.1289, Train: 73.43%, Valid: 76.66% Test: 73.76%\n",
      "Epoch: 12, Loss: 56580.4453, Train: 72.70%, Valid: 76.18% Test: 73.07%\n",
      "Epoch: 13, Loss: 56157.2812, Train: 73.25%, Valid: 76.52% Test: 73.35%\n",
      "Epoch: 14, Loss: 55872.3516, Train: 72.97%, Valid: 76.25% Test: 73.00%\n",
      "Epoch: 15, Loss: 55697.0352, Train: 72.97%, Valid: 76.25% Test: 73.00%\n",
      "Epoch: 16, Loss: 55611.7383, Train: 72.97%, Valid: 76.25% Test: 73.00%\n",
      "Epoch: 17, Loss: 55557.2734, Train: 72.97%, Valid: 76.25% Test: 73.00%\n",
      "Epoch: 18, Loss: 55538.7461, Train: 72.97%, Valid: 76.25% Test: 73.00%\n",
      "Epoch: 19, Loss: 55515.3203, Train: 72.97%, Valid: 76.25% Test: 73.00%\n",
      "Epoch: 20, Loss: 55516.1836, Train: 72.14%, Valid: 75.62% Test: 72.18%\n",
      "Epoch: 21, Loss: 55505.9922, Train: 71.63%, Valid: 75.42% Test: 71.90%\n",
      "Epoch: 22, Loss: 55511.4336, Train: 71.57%, Valid: 75.42% Test: 71.83%\n",
      "Epoch: 23, Loss: 55511.8594, Train: 71.57%, Valid: 75.42% Test: 71.83%\n",
      "Epoch: 24, Loss: 55505.1953, Train: 71.59%, Valid: 75.42% Test: 71.83%\n",
      "Epoch: 25, Loss: 55511.3281, Train: 72.02%, Valid: 75.42% Test: 72.31%\n",
      "Epoch: 26, Loss: 55519.1406, Train: 71.62%, Valid: 75.14% Test: 71.83%\n",
      "Epoch: 27, Loss: 55507.6562, Train: 71.62%, Valid: 75.14% Test: 71.83%\n",
      "Epoch: 28, Loss: 55515.5430, Train: 72.32%, Valid: 75.90% Test: 72.66%\n",
      "Epoch: 29, Loss: 55513.0938, Train: 72.32%, Valid: 75.90% Test: 72.66%\n",
      "Epoch: 30, Loss: 55514.8203, Train: 72.32%, Valid: 75.90% Test: 72.66%\n",
      "Epoch: 31, Loss: 55507.5312, Train: 72.32%, Valid: 75.90% Test: 72.66%\n",
      "Epoch: 32, Loss: 55493.8906, Train: 72.36%, Valid: 75.90% Test: 72.73%\n",
      "Epoch: 33, Loss: 55500.9609, Train: 72.36%, Valid: 75.90% Test: 72.73%\n",
      "Epoch: 34, Loss: 55505.3438, Train: 72.36%, Valid: 75.90% Test: 72.73%\n",
      "Epoch: 35, Loss: 55497.2734, Train: 72.36%, Valid: 75.90% Test: 72.73%\n",
      "Epoch: 36, Loss: 55505.7969, Train: 72.36%, Valid: 75.90% Test: 72.73%\n",
      "Epoch: 37, Loss: 55507.4102, Train: 72.36%, Valid: 75.90% Test: 72.73%\n",
      "Epoch: 38, Loss: 55511.4688, Train: 72.36%, Valid: 75.90% Test: 72.73%\n",
      "Epoch: 39, Loss: 55496.4922, Train: 72.36%, Valid: 75.90% Test: 72.73%\n",
      "Epoch: 40, Loss: 55497.4766, Train: 72.35%, Valid: 75.90% Test: 72.73%\n",
      "Epoch: 41, Loss: 55509.3359, Train: 72.32%, Valid: 75.90% Test: 72.66%\n",
      "Epoch: 42, Loss: 55500.1797, Train: 72.32%, Valid: 75.90% Test: 72.66%\n",
      "Epoch: 43, Loss: 55511.0547, Train: 72.17%, Valid: 75.62% Test: 72.25%\n",
      "Epoch: 44, Loss: 55511.9141, Train: 71.73%, Valid: 75.21% Test: 71.83%\n",
      "Epoch: 45, Loss: 55508.2344, Train: 72.32%, Valid: 75.76% Test: 72.66%\n",
      "Epoch: 46, Loss: 55507.8906, Train: 72.32%, Valid: 75.90% Test: 72.66%\n",
      "Epoch: 47, Loss: 55506.0430, Train: 72.32%, Valid: 75.90% Test: 72.66%\n",
      "Epoch: 48, Loss: 55502.2344, Train: 72.32%, Valid: 75.90% Test: 72.66%\n",
      "Epoch: 49, Loss: 55498.9688, Train: 72.32%, Valid: 75.90% Test: 72.66%\n",
      "Epoch: 50, Loss: 55501.7109, Train: 72.32%, Valid: 75.90% Test: 72.66%\n",
      "Epoch: 51, Loss: 55508.2109, Train: 72.35%, Valid: 75.90% Test: 72.73%\n",
      "Epoch: 52, Loss: 55504.7305, Train: 72.36%, Valid: 75.90% Test: 72.73%\n",
      "Epoch: 53, Loss: 55509.5625, Train: 72.36%, Valid: 75.90% Test: 72.73%\n",
      "Epoch: 54, Loss: 55493.9258, Train: 72.36%, Valid: 75.90% Test: 72.73%\n",
      "Epoch: 55, Loss: 55505.5000, Train: 72.36%, Valid: 75.90% Test: 72.73%\n",
      "Epoch: 56, Loss: 55509.5547, Train: 72.36%, Valid: 75.90% Test: 72.73%\n",
      "Epoch: 57, Loss: 55505.3438, Train: 72.36%, Valid: 75.90% Test: 72.73%\n",
      "Epoch: 58, Loss: 55507.6016, Train: 72.36%, Valid: 75.90% Test: 72.73%\n",
      "Epoch: 59, Loss: 55504.7969, Train: 72.36%, Valid: 75.90% Test: 72.73%\n",
      "Epoch: 60, Loss: 55508.6953, Train: 72.36%, Valid: 75.90% Test: 72.73%\n",
      "Epoch: 61, Loss: 55509.1797, Train: 72.75%, Valid: 76.04% Test: 72.87%\n",
      "Epoch: 62, Loss: 55499.6641, Train: 72.71%, Valid: 76.04% Test: 72.87%\n",
      "Epoch: 63, Loss: 55497.6094, Train: 72.36%, Valid: 75.90% Test: 72.73%\n",
      "Epoch: 64, Loss: 55505.5078, Train: 72.36%, Valid: 75.90% Test: 72.73%\n",
      "Epoch: 65, Loss: 55505.7227, Train: 72.36%, Valid: 75.90% Test: 72.73%\n",
      "Epoch: 66, Loss: 55504.2109, Train: 72.45%, Valid: 75.90% Test: 72.73%\n",
      "Epoch: 67, Loss: 55497.8828, Train: 72.60%, Valid: 75.90% Test: 72.73%\n",
      "Epoch: 68, Loss: 55501.4844, Train: 72.56%, Valid: 75.90% Test: 72.73%\n",
      "Epoch: 69, Loss: 55499.9844, Train: 72.76%, Valid: 76.04% Test: 72.87%\n",
      "Epoch: 70, Loss: 55496.7109, Train: 72.96%, Valid: 76.25% Test: 73.00%\n",
      "Epoch: 71, Loss: 55500.5273, Train: 72.96%, Valid: 76.25% Test: 73.00%\n",
      "Epoch: 72, Loss: 55491.2656, Train: 72.96%, Valid: 76.25% Test: 73.00%\n",
      "Epoch: 73, Loss: 55498.8945, Train: 72.96%, Valid: 76.25% Test: 73.00%\n",
      "Epoch: 74, Loss: 55488.3672, Train: 72.96%, Valid: 76.25% Test: 73.00%\n",
      "Epoch: 75, Loss: 55491.1797, Train: 72.96%, Valid: 76.25% Test: 73.00%\n",
      "Epoch: 76, Loss: 55486.3125, Train: 72.96%, Valid: 76.25% Test: 73.00%\n",
      "Epoch: 77, Loss: 55486.9922, Train: 72.93%, Valid: 76.25% Test: 72.93%\n",
      "Epoch: 78, Loss: 55483.8828, Train: 72.85%, Valid: 76.04% Test: 72.93%\n",
      "Epoch: 79, Loss: 55484.8281, Train: 72.79%, Valid: 76.04% Test: 72.87%\n",
      "Epoch: 80, Loss: 55474.3828, Train: 72.77%, Valid: 75.97% Test: 72.87%\n",
      "Epoch: 81, Loss: 55480.6328, Train: 72.78%, Valid: 76.04% Test: 72.87%\n",
      "Epoch: 82, Loss: 55480.3438, Train: 72.93%, Valid: 76.25% Test: 72.93%\n",
      "Epoch: 83, Loss: 55472.4297, Train: 72.95%, Valid: 76.25% Test: 73.00%\n",
      "Epoch: 84, Loss: 55473.4727, Train: 72.95%, Valid: 76.25% Test: 73.00%\n",
      "Epoch: 85, Loss: 55473.9102, Train: 72.92%, Valid: 76.18% Test: 73.00%\n",
      "Epoch: 86, Loss: 55462.7188, Train: 72.87%, Valid: 76.11% Test: 72.87%\n",
      "Epoch: 87, Loss: 55461.3750, Train: 72.85%, Valid: 76.11% Test: 72.87%\n",
      "Epoch: 88, Loss: 55453.7500, Train: 72.86%, Valid: 76.11% Test: 72.87%\n",
      "Epoch: 89, Loss: 55441.2383, Train: 72.86%, Valid: 76.11% Test: 72.87%\n",
      "Epoch: 90, Loss: 55450.2656, Train: 72.87%, Valid: 76.11% Test: 72.87%\n",
      "Epoch: 91, Loss: 55438.6016, Train: 72.90%, Valid: 76.18% Test: 72.93%\n",
      "Epoch: 92, Loss: 55452.5703, Train: 72.90%, Valid: 76.18% Test: 72.93%\n",
      "Epoch: 93, Loss: 55440.9961, Train: 72.90%, Valid: 76.18% Test: 73.00%\n",
      "Epoch: 94, Loss: 55445.6914, Train: 72.90%, Valid: 76.18% Test: 73.00%\n",
      "Epoch: 95, Loss: 55442.7500, Train: 72.92%, Valid: 76.18% Test: 73.00%\n",
      "Epoch: 96, Loss: 55431.2539, Train: 72.92%, Valid: 76.18% Test: 73.00%\n",
      "Epoch: 97, Loss: 55426.8164, Train: 72.91%, Valid: 76.18% Test: 73.00%\n",
      "Epoch: 98, Loss: 55426.6133, Train: 72.88%, Valid: 76.11% Test: 72.87%\n",
      "Epoch: 99, Loss: 55430.7031, Train: 72.88%, Valid: 76.11% Test: 72.87%\n",
      "Epoch: 100, Loss: 55420.5820, Train: 72.88%, Valid: 76.11% Test: 72.87%\n",
      "Epoch: 101, Loss: 55427.6953, Train: 72.88%, Valid: 76.11% Test: 72.87%\n",
      "Epoch: 102, Loss: 55420.5000, Train: 72.86%, Valid: 76.11% Test: 72.87%\n",
      "Epoch: 103, Loss: 55409.9102, Train: 72.85%, Valid: 76.11% Test: 72.87%\n",
      "Epoch: 104, Loss: 55415.6328, Train: 72.85%, Valid: 76.11% Test: 72.87%\n",
      "Epoch: 105, Loss: 55415.2500, Train: 72.86%, Valid: 76.11% Test: 72.87%\n",
      "Epoch: 106, Loss: 55419.7617, Train: 72.86%, Valid: 76.11% Test: 72.87%\n",
      "Epoch: 107, Loss: 55410.0859, Train: 72.86%, Valid: 76.11% Test: 72.87%\n",
      "Epoch: 108, Loss: 55406.7930, Train: 72.87%, Valid: 76.11% Test: 72.87%\n",
      "Epoch: 109, Loss: 55411.3828, Train: 72.87%, Valid: 76.11% Test: 72.87%\n",
      "Epoch: 110, Loss: 55409.6953, Train: 72.87%, Valid: 76.11% Test: 72.87%\n",
      "Epoch: 111, Loss: 55408.1367, Train: 72.87%, Valid: 76.11% Test: 72.87%\n",
      "Epoch: 112, Loss: 55404.1875, Train: 72.87%, Valid: 76.11% Test: 72.87%\n",
      "Epoch: 113, Loss: 55406.3906, Train: 72.87%, Valid: 76.11% Test: 72.87%\n",
      "Epoch: 114, Loss: 55404.3594, Train: 72.86%, Valid: 76.11% Test: 72.87%\n",
      "Epoch: 115, Loss: 55400.2344, Train: 72.86%, Valid: 76.11% Test: 72.87%\n",
      "Epoch: 116, Loss: 55405.8477, Train: 72.85%, Valid: 76.11% Test: 72.87%\n",
      "Epoch: 117, Loss: 55396.2500, Train: 72.87%, Valid: 76.11% Test: 72.87%\n",
      "Epoch: 118, Loss: 55391.2422, Train: 73.11%, Valid: 76.32% Test: 73.35%\n",
      "Epoch: 119, Loss: 55384.9375, Train: 73.31%, Valid: 76.59% Test: 73.48%\n",
      "Epoch: 120, Loss: 55387.3828, Train: 73.28%, Valid: 76.59% Test: 73.48%\n",
      "Epoch: 121, Loss: 55379.0898, Train: 73.24%, Valid: 76.52% Test: 73.42%\n",
      "Epoch: 122, Loss: 55380.2539, Train: 73.21%, Valid: 76.45% Test: 73.35%\n",
      "Epoch: 123, Loss: 55371.8945, Train: 73.20%, Valid: 76.45% Test: 73.35%\n",
      "Epoch: 124, Loss: 55377.9922, Train: 73.32%, Valid: 76.45% Test: 73.35%\n",
      "Epoch: 125, Loss: 55366.1016, Train: 73.35%, Valid: 76.59% Test: 73.48%\n",
      "Epoch: 126, Loss: 55371.5391, Train: 73.37%, Valid: 76.66% Test: 73.48%\n",
      "Epoch: 127, Loss: 55355.7656, Train: 73.40%, Valid: 76.73% Test: 73.55%\n",
      "Epoch: 128, Loss: 55360.0898, Train: 73.44%, Valid: 76.73% Test: 73.55%\n",
      "Epoch: 129, Loss: 55360.2344, Train: 73.44%, Valid: 76.66% Test: 73.48%\n",
      "Epoch: 130, Loss: 55356.7422, Train: 73.52%, Valid: 76.87% Test: 73.48%\n",
      "Epoch: 131, Loss: 55352.3789, Train: 73.59%, Valid: 76.73% Test: 73.55%\n",
      "Epoch: 132, Loss: 55348.7070, Train: 73.66%, Valid: 76.80% Test: 73.55%\n",
      "Epoch: 133, Loss: 55353.5703, Train: 73.67%, Valid: 76.87% Test: 73.69%\n",
      "Epoch: 134, Loss: 55346.5859, Train: 73.65%, Valid: 76.87% Test: 73.62%\n",
      "Epoch: 135, Loss: 55349.3281, Train: 73.64%, Valid: 76.87% Test: 73.55%\n",
      "Epoch: 136, Loss: 55332.5547, Train: 73.62%, Valid: 76.94% Test: 73.55%\n",
      "Epoch: 137, Loss: 55337.0156, Train: 73.61%, Valid: 76.87% Test: 73.55%\n",
      "Epoch: 138, Loss: 55338.0703, Train: 73.64%, Valid: 76.87% Test: 73.55%\n",
      "Epoch: 139, Loss: 55335.5977, Train: 73.62%, Valid: 76.80% Test: 73.55%\n",
      "Epoch: 140, Loss: 55332.9219, Train: 73.62%, Valid: 76.80% Test: 73.55%\n",
      "Epoch: 141, Loss: 55322.0508, Train: 73.59%, Valid: 76.80% Test: 73.55%\n",
      "Epoch: 142, Loss: 55327.6250, Train: 73.59%, Valid: 76.80% Test: 73.55%\n",
      "Epoch: 143, Loss: 55329.7578, Train: 73.60%, Valid: 76.80% Test: 73.55%\n",
      "Epoch: 144, Loss: 55327.5039, Train: 73.61%, Valid: 76.80% Test: 73.55%\n",
      "Epoch: 145, Loss: 55326.8438, Train: 73.62%, Valid: 76.80% Test: 73.62%\n",
      "Epoch: 146, Loss: 55327.0664, Train: 73.63%, Valid: 76.80% Test: 73.69%\n",
      "Epoch: 147, Loss: 55321.7617, Train: 73.63%, Valid: 76.80% Test: 73.69%\n",
      "Epoch: 148, Loss: 55320.7773, Train: 73.63%, Valid: 76.80% Test: 73.69%\n",
      "Epoch: 149, Loss: 55321.5859, Train: 73.63%, Valid: 76.80% Test: 73.69%\n",
      "Epoch: 150, Loss: 55322.1953, Train: 73.63%, Valid: 76.80% Test: 73.69%\n",
      "Epoch: 151, Loss: 55311.2500, Train: 73.63%, Valid: 76.80% Test: 73.69%\n",
      "Epoch: 152, Loss: 55321.1289, Train: 73.63%, Valid: 76.80% Test: 73.69%\n",
      "Epoch: 153, Loss: 55321.2852, Train: 73.63%, Valid: 76.87% Test: 73.69%\n",
      "Epoch: 154, Loss: 55317.8242, Train: 73.63%, Valid: 76.87% Test: 73.69%\n",
      "Epoch: 155, Loss: 55314.9062, Train: 73.62%, Valid: 76.87% Test: 73.76%\n",
      "Epoch: 156, Loss: 55311.0898, Train: 73.61%, Valid: 76.87% Test: 73.76%\n",
      "Epoch: 157, Loss: 55310.2656, Train: 73.59%, Valid: 76.87% Test: 73.76%\n",
      "Epoch: 158, Loss: 55315.1836, Train: 73.58%, Valid: 76.87% Test: 73.76%\n",
      "Epoch: 159, Loss: 55309.0312, Train: 73.59%, Valid: 76.87% Test: 73.76%\n",
      "Epoch: 160, Loss: 55310.3789, Train: 73.63%, Valid: 76.87% Test: 73.69%\n",
      "Epoch: 161, Loss: 55307.8828, Train: 73.64%, Valid: 76.87% Test: 73.69%\n",
      "Epoch: 162, Loss: 55307.7422, Train: 73.65%, Valid: 76.80% Test: 73.76%\n",
      "Epoch: 163, Loss: 55304.9688, Train: 73.65%, Valid: 76.73% Test: 73.76%\n",
      "Epoch: 164, Loss: 55302.7500, Train: 73.65%, Valid: 76.73% Test: 73.76%\n",
      "Epoch: 165, Loss: 55304.0234, Train: 73.65%, Valid: 76.80% Test: 73.76%\n",
      "Epoch: 166, Loss: 55304.7695, Train: 73.65%, Valid: 76.80% Test: 73.76%\n",
      "Epoch: 167, Loss: 55306.4648, Train: 73.65%, Valid: 76.80% Test: 73.76%\n",
      "Epoch: 168, Loss: 55297.6562, Train: 73.65%, Valid: 76.73% Test: 73.76%\n",
      "Epoch: 169, Loss: 55300.3125, Train: 73.65%, Valid: 76.73% Test: 73.76%\n",
      "Epoch: 170, Loss: 55301.0977, Train: 73.67%, Valid: 76.73% Test: 73.76%\n",
      "Epoch: 171, Loss: 55293.3984, Train: 73.64%, Valid: 76.73% Test: 73.76%\n",
      "Epoch: 172, Loss: 55302.7188, Train: 73.64%, Valid: 76.73% Test: 73.76%\n",
      "Epoch: 173, Loss: 55297.2109, Train: 73.64%, Valid: 76.73% Test: 73.76%\n",
      "Epoch: 174, Loss: 55297.4336, Train: 73.64%, Valid: 76.73% Test: 73.76%\n",
      "Epoch: 175, Loss: 55303.3750, Train: 73.64%, Valid: 76.73% Test: 73.76%\n",
      "Epoch: 176, Loss: 55293.2109, Train: 73.65%, Valid: 76.73% Test: 73.76%\n",
      "Epoch: 177, Loss: 55290.3203, Train: 73.65%, Valid: 76.73% Test: 73.76%\n",
      "Epoch: 178, Loss: 55299.9688, Train: 73.65%, Valid: 76.80% Test: 73.76%\n",
      "Epoch: 179, Loss: 55302.7539, Train: 73.62%, Valid: 76.80% Test: 73.76%\n",
      "Epoch: 180, Loss: 55296.4883, Train: 73.62%, Valid: 76.87% Test: 73.76%\n",
      "Epoch: 181, Loss: 55297.6641, Train: 73.61%, Valid: 76.87% Test: 73.76%\n",
      "Epoch: 182, Loss: 55295.9883, Train: 73.67%, Valid: 76.94% Test: 73.83%\n",
      "Epoch: 183, Loss: 55300.5469, Train: 73.78%, Valid: 77.01% Test: 73.97%\n",
      "Epoch: 184, Loss: 55283.2891, Train: 73.64%, Valid: 76.87% Test: 73.76%\n",
      "Epoch: 185, Loss: 55287.8359, Train: 73.62%, Valid: 76.87% Test: 73.76%\n",
      "Epoch: 186, Loss: 55279.7227, Train: 73.62%, Valid: 76.87% Test: 73.83%\n",
      "Epoch: 187, Loss: 55284.6172, Train: 73.59%, Valid: 76.66% Test: 73.76%\n",
      "Epoch: 188, Loss: 55286.7812, Train: 73.58%, Valid: 76.66% Test: 73.76%\n",
      "Epoch: 189, Loss: 55278.3750, Train: 73.60%, Valid: 76.59% Test: 73.76%\n",
      "Epoch: 190, Loss: 55274.9297, Train: 73.76%, Valid: 76.73% Test: 73.97%\n",
      "Epoch: 191, Loss: 55278.4609, Train: 73.75%, Valid: 76.73% Test: 73.83%\n",
      "Epoch: 192, Loss: 55268.9375, Train: 73.59%, Valid: 76.52% Test: 73.55%\n",
      "Epoch: 193, Loss: 55265.3281, Train: 73.57%, Valid: 76.52% Test: 73.55%\n",
      "Epoch: 194, Loss: 55268.9375, Train: 73.57%, Valid: 76.52% Test: 73.55%\n",
      "Epoch: 195, Loss: 55266.8203, Train: 73.63%, Valid: 76.52% Test: 73.62%\n",
      "Epoch: 196, Loss: 55263.3203, Train: 73.57%, Valid: 76.52% Test: 73.55%\n",
      "Epoch: 197, Loss: 55261.0273, Train: 73.54%, Valid: 76.52% Test: 73.55%\n",
      "Epoch: 198, Loss: 55254.0312, Train: 73.53%, Valid: 76.45% Test: 73.55%\n",
      "Epoch: 199, Loss: 55252.3281, Train: 73.62%, Valid: 76.59% Test: 73.69%\n",
      "Epoch: 200, Loss: 55250.2422, Train: 73.76%, Valid: 76.66% Test: 73.76%\n",
      "Epoch: 201, Loss: 55251.1406, Train: 73.77%, Valid: 76.59% Test: 73.76%\n",
      "Epoch: 202, Loss: 55250.6523, Train: 73.79%, Valid: 76.59% Test: 73.76%\n",
      "Epoch: 203, Loss: 55247.9609, Train: 73.79%, Valid: 76.59% Test: 73.69%\n",
      "Epoch: 204, Loss: 55239.7734, Train: 73.78%, Valid: 76.52% Test: 73.62%\n",
      "Epoch: 205, Loss: 55244.4141, Train: 73.77%, Valid: 76.52% Test: 73.62%\n",
      "Epoch: 206, Loss: 55231.0156, Train: 73.75%, Valid: 76.52% Test: 73.62%\n",
      "Epoch: 207, Loss: 55235.6328, Train: 73.71%, Valid: 76.45% Test: 73.55%\n",
      "Epoch: 208, Loss: 55238.4141, Train: 73.68%, Valid: 76.45% Test: 73.55%\n",
      "Epoch: 209, Loss: 55220.0703, Train: 73.70%, Valid: 76.45% Test: 73.55%\n",
      "Epoch: 210, Loss: 55221.9219, Train: 73.70%, Valid: 76.45% Test: 73.48%\n",
      "Epoch: 211, Loss: 55212.9766, Train: 73.75%, Valid: 76.52% Test: 73.62%\n",
      "Epoch: 212, Loss: 55212.9609, Train: 73.80%, Valid: 76.52% Test: 73.69%\n",
      "Epoch: 213, Loss: 55218.0117, Train: 73.82%, Valid: 76.45% Test: 73.69%\n",
      "Epoch: 214, Loss: 55205.3672, Train: 73.82%, Valid: 76.45% Test: 73.69%\n",
      "Epoch: 215, Loss: 55198.0078, Train: 73.82%, Valid: 76.52% Test: 73.69%\n",
      "Epoch: 216, Loss: 55201.0469, Train: 73.82%, Valid: 76.59% Test: 73.69%\n",
      "Epoch: 217, Loss: 55203.8242, Train: 73.80%, Valid: 76.59% Test: 73.69%\n",
      "Epoch: 218, Loss: 55188.2969, Train: 73.73%, Valid: 76.59% Test: 73.69%\n",
      "Epoch: 219, Loss: 55198.7656, Train: 73.76%, Valid: 76.59% Test: 73.69%\n",
      "Epoch: 220, Loss: 55191.9062, Train: 73.78%, Valid: 76.59% Test: 73.69%\n",
      "Epoch: 221, Loss: 55180.0820, Train: 73.77%, Valid: 76.59% Test: 73.62%\n",
      "Epoch: 222, Loss: 55194.6797, Train: 73.76%, Valid: 76.59% Test: 73.69%\n",
      "Epoch: 223, Loss: 55180.9570, Train: 73.76%, Valid: 76.59% Test: 73.69%\n",
      "Epoch: 224, Loss: 55181.0938, Train: 73.77%, Valid: 76.59% Test: 73.69%\n",
      "Epoch: 225, Loss: 55168.4219, Train: 73.77%, Valid: 76.59% Test: 73.69%\n",
      "Epoch: 226, Loss: 55167.0664, Train: 73.77%, Valid: 76.59% Test: 73.69%\n",
      "Epoch: 227, Loss: 55180.1289, Train: 73.77%, Valid: 76.59% Test: 73.69%\n",
      "Epoch: 228, Loss: 55179.5898, Train: 73.77%, Valid: 76.59% Test: 73.69%\n",
      "Epoch: 229, Loss: 55179.5469, Train: 73.77%, Valid: 76.59% Test: 73.69%\n",
      "Epoch: 230, Loss: 55161.3594, Train: 73.78%, Valid: 76.59% Test: 73.69%\n",
      "Epoch: 231, Loss: 55164.1250, Train: 73.80%, Valid: 76.59% Test: 73.69%\n",
      "Epoch: 232, Loss: 55165.0234, Train: 73.93%, Valid: 76.73% Test: 73.83%\n",
      "Epoch: 233, Loss: 55160.6758, Train: 73.97%, Valid: 76.66% Test: 73.90%\n",
      "Epoch: 234, Loss: 55173.1875, Train: 73.97%, Valid: 76.66% Test: 73.90%\n",
      "Epoch: 235, Loss: 55153.4453, Train: 73.96%, Valid: 76.66% Test: 73.90%\n",
      "Epoch: 236, Loss: 55159.1055, Train: 73.95%, Valid: 76.66% Test: 73.90%\n",
      "Epoch: 237, Loss: 55152.9688, Train: 73.93%, Valid: 76.59% Test: 73.90%\n",
      "Epoch: 238, Loss: 55162.9766, Train: 73.92%, Valid: 76.45% Test: 73.90%\n",
      "Epoch: 239, Loss: 55150.5703, Train: 73.92%, Valid: 76.45% Test: 73.90%\n",
      "Epoch: 240, Loss: 55139.2422, Train: 73.87%, Valid: 76.45% Test: 73.76%\n",
      "Epoch: 241, Loss: 55138.3711, Train: 73.87%, Valid: 76.45% Test: 73.69%\n",
      "Epoch: 242, Loss: 55137.5078, Train: 73.84%, Valid: 76.45% Test: 73.62%\n",
      "Epoch: 243, Loss: 55143.4688, Train: 73.83%, Valid: 76.45% Test: 73.48%\n",
      "Epoch: 244, Loss: 55135.8281, Train: 73.76%, Valid: 76.32% Test: 73.48%\n",
      "Epoch: 245, Loss: 55138.2461, Train: 73.65%, Valid: 76.18% Test: 73.48%\n",
      "Epoch: 246, Loss: 55127.2227, Train: 73.64%, Valid: 76.11% Test: 73.21%\n",
      "Epoch: 247, Loss: 55132.3984, Train: 73.72%, Valid: 76.25% Test: 73.48%\n",
      "Epoch: 248, Loss: 55139.9766, Train: 73.86%, Valid: 76.45% Test: 73.55%\n",
      "Epoch: 249, Loss: 55120.4453, Train: 73.90%, Valid: 76.45% Test: 73.69%\n",
      "Epoch: 250, Loss: 55121.2422, Train: 73.96%, Valid: 76.52% Test: 73.76%\n",
      "Epoch: 251, Loss: 55110.9922, Train: 73.96%, Valid: 76.52% Test: 73.76%\n",
      "Epoch: 252, Loss: 55120.1055, Train: 73.92%, Valid: 76.39% Test: 73.83%\n",
      "Epoch: 253, Loss: 55118.3203, Train: 73.92%, Valid: 76.39% Test: 73.76%\n",
      "Epoch: 254, Loss: 55114.7773, Train: 73.90%, Valid: 76.45% Test: 73.76%\n",
      "Epoch: 255, Loss: 55107.3594, Train: 73.90%, Valid: 76.45% Test: 73.76%\n",
      "Epoch: 256, Loss: 55113.1094, Train: 73.90%, Valid: 76.45% Test: 73.76%\n",
      "Epoch: 257, Loss: 55113.7578, Train: 73.90%, Valid: 76.45% Test: 73.76%\n",
      "Epoch: 258, Loss: 55109.6016, Train: 73.90%, Valid: 76.45% Test: 73.76%\n",
      "Epoch: 259, Loss: 55098.8516, Train: 73.90%, Valid: 76.45% Test: 73.76%\n",
      "Epoch: 260, Loss: 55105.8867, Train: 73.90%, Valid: 76.45% Test: 73.76%\n",
      "Epoch: 261, Loss: 55099.1875, Train: 73.92%, Valid: 76.45% Test: 73.76%\n",
      "Epoch: 262, Loss: 55077.1250, Train: 73.90%, Valid: 76.52% Test: 73.83%\n",
      "Epoch: 263, Loss: 55078.7812, Train: 74.04%, Valid: 76.73% Test: 73.97%\n",
      "Epoch: 264, Loss: 55076.1016, Train: 74.10%, Valid: 76.73% Test: 74.04%\n",
      "Epoch: 265, Loss: 55069.4766, Train: 74.21%, Valid: 76.80% Test: 74.17%\n",
      "Epoch: 266, Loss: 55065.9766, Train: 74.28%, Valid: 76.94% Test: 74.38%\n",
      "Epoch: 267, Loss: 55060.2617, Train: 74.33%, Valid: 77.01% Test: 74.52%\n",
      "Epoch: 268, Loss: 55053.9688, Train: 74.33%, Valid: 77.01% Test: 74.52%\n",
      "Epoch: 269, Loss: 55050.2656, Train: 74.34%, Valid: 77.01% Test: 74.52%\n",
      "Epoch: 270, Loss: 55058.7578, Train: 74.34%, Valid: 76.94% Test: 74.52%\n",
      "Epoch: 271, Loss: 55060.8984, Train: 74.33%, Valid: 76.94% Test: 74.52%\n",
      "Epoch: 272, Loss: 55049.5859, Train: 74.28%, Valid: 76.87% Test: 74.45%\n",
      "Epoch: 273, Loss: 55024.6445, Train: 74.28%, Valid: 76.87% Test: 74.45%\n",
      "Epoch: 274, Loss: 55023.2812, Train: 74.28%, Valid: 76.87% Test: 74.45%\n",
      "Epoch: 275, Loss: 55025.4141, Train: 74.29%, Valid: 76.87% Test: 74.45%\n",
      "Epoch: 276, Loss: 55026.7812, Train: 74.28%, Valid: 76.87% Test: 74.45%\n",
      "Epoch: 277, Loss: 55038.3672, Train: 74.30%, Valid: 76.94% Test: 74.45%\n",
      "Epoch: 278, Loss: 55018.1523, Train: 74.43%, Valid: 77.08% Test: 74.52%\n",
      "Epoch: 279, Loss: 55004.7812, Train: 74.49%, Valid: 77.15% Test: 74.66%\n",
      "Epoch: 280, Loss: 55002.9844, Train: 74.56%, Valid: 77.15% Test: 74.72%\n",
      "Epoch: 281, Loss: 54993.3438, Train: 74.59%, Valid: 77.22% Test: 74.72%\n",
      "Epoch: 282, Loss: 54978.8516, Train: 74.66%, Valid: 77.22% Test: 74.79%\n",
      "Epoch: 283, Loss: 54960.2227, Train: 74.65%, Valid: 77.22% Test: 74.59%\n",
      "Epoch: 284, Loss: 54971.0234, Train: 74.62%, Valid: 77.08% Test: 74.52%\n",
      "Epoch: 285, Loss: 54964.0859, Train: 74.58%, Valid: 76.80% Test: 74.52%\n",
      "Epoch: 286, Loss: 54962.2656, Train: 74.59%, Valid: 76.80% Test: 74.59%\n",
      "Epoch: 287, Loss: 54950.0586, Train: 74.63%, Valid: 76.94% Test: 74.52%\n",
      "Epoch: 288, Loss: 54978.4062, Train: 74.65%, Valid: 77.01% Test: 74.52%\n",
      "Epoch: 289, Loss: 54962.4414, Train: 74.72%, Valid: 77.01% Test: 74.52%\n",
      "Epoch: 290, Loss: 54941.7344, Train: 74.73%, Valid: 77.01% Test: 74.52%\n",
      "Epoch: 291, Loss: 54937.6641, Train: 74.75%, Valid: 77.15% Test: 74.52%\n",
      "Epoch: 292, Loss: 54932.9453, Train: 74.79%, Valid: 77.22% Test: 74.52%\n",
      "Epoch: 293, Loss: 54921.1484, Train: 74.79%, Valid: 77.22% Test: 74.52%\n",
      "Epoch: 294, Loss: 54918.8750, Train: 74.71%, Valid: 77.29% Test: 74.52%\n",
      "Epoch: 295, Loss: 54927.6875, Train: 74.70%, Valid: 77.22% Test: 74.66%\n",
      "Epoch: 296, Loss: 54910.7031, Train: 74.64%, Valid: 77.22% Test: 74.66%\n",
      "Epoch: 297, Loss: 54917.1016, Train: 74.63%, Valid: 77.22% Test: 74.59%\n",
      "Epoch: 298, Loss: 54906.2734, Train: 74.60%, Valid: 77.15% Test: 74.66%\n",
      "Epoch: 299, Loss: 54912.8477, Train: 74.65%, Valid: 77.22% Test: 74.66%\n",
      "Epoch: 300, Loss: 54903.9297, Train: 74.65%, Valid: 77.22% Test: 74.66%\n",
      "Epoch: 301, Loss: 54900.7930, Train: 74.65%, Valid: 77.29% Test: 74.66%\n",
      "Epoch: 302, Loss: 54903.7500, Train: 74.70%, Valid: 77.22% Test: 74.66%\n",
      "Epoch: 303, Loss: 54890.1797, Train: 74.68%, Valid: 77.22% Test: 74.66%\n",
      "Epoch: 304, Loss: 54878.6797, Train: 74.69%, Valid: 77.22% Test: 74.59%\n",
      "Epoch: 305, Loss: 54887.4844, Train: 74.75%, Valid: 77.15% Test: 74.59%\n",
      "Epoch: 306, Loss: 54879.5508, Train: 74.76%, Valid: 77.15% Test: 74.59%\n",
      "Epoch: 307, Loss: 54884.8359, Train: 74.78%, Valid: 77.15% Test: 74.59%\n",
      "Epoch: 308, Loss: 54857.0078, Train: 74.79%, Valid: 77.29% Test: 74.59%\n",
      "Epoch: 309, Loss: 54865.8828, Train: 74.78%, Valid: 77.35% Test: 74.59%\n",
      "Epoch: 310, Loss: 54871.9180, Train: 74.78%, Valid: 77.35% Test: 74.59%\n",
      "Epoch: 311, Loss: 54832.8203, Train: 74.82%, Valid: 77.35% Test: 74.59%\n",
      "Epoch: 312, Loss: 54857.7344, Train: 74.82%, Valid: 77.29% Test: 74.52%\n",
      "Epoch: 313, Loss: 54853.7227, Train: 74.82%, Valid: 77.35% Test: 74.52%\n",
      "Epoch: 314, Loss: 54850.6406, Train: 74.79%, Valid: 77.35% Test: 74.52%\n",
      "Epoch: 315, Loss: 54847.7383, Train: 74.82%, Valid: 77.49% Test: 74.52%\n",
      "Epoch: 316, Loss: 54836.1250, Train: 74.92%, Valid: 77.49% Test: 74.66%\n",
      "Epoch: 317, Loss: 54845.8750, Train: 74.92%, Valid: 77.49% Test: 74.66%\n",
      "Epoch: 318, Loss: 54843.7422, Train: 74.84%, Valid: 77.42% Test: 74.59%\n",
      "Epoch: 319, Loss: 54839.4180, Train: 74.86%, Valid: 77.49% Test: 74.66%\n",
      "Epoch: 320, Loss: 54824.1406, Train: 74.88%, Valid: 77.49% Test: 74.66%\n",
      "Epoch: 321, Loss: 54829.8438, Train: 74.90%, Valid: 77.49% Test: 74.66%\n",
      "Epoch: 322, Loss: 54826.6562, Train: 74.93%, Valid: 77.49% Test: 74.66%\n",
      "Epoch: 323, Loss: 54825.1445, Train: 74.94%, Valid: 77.49% Test: 74.86%\n",
      "Epoch: 324, Loss: 54820.9297, Train: 74.93%, Valid: 77.49% Test: 74.86%\n",
      "Epoch: 325, Loss: 54821.2383, Train: 74.90%, Valid: 77.49% Test: 74.79%\n",
      "Epoch: 326, Loss: 54814.1562, Train: 74.90%, Valid: 77.49% Test: 74.86%\n",
      "Epoch: 327, Loss: 54796.1680, Train: 74.89%, Valid: 77.35% Test: 74.79%\n",
      "Epoch: 328, Loss: 54807.6055, Train: 74.97%, Valid: 77.29% Test: 74.86%\n",
      "Epoch: 329, Loss: 54812.5547, Train: 74.98%, Valid: 77.29% Test: 74.79%\n",
      "Epoch: 330, Loss: 54794.7969, Train: 75.01%, Valid: 77.35% Test: 74.79%\n",
      "Epoch: 331, Loss: 54783.7109, Train: 75.05%, Valid: 77.42% Test: 74.93%\n",
      "Epoch: 332, Loss: 54787.0391, Train: 75.08%, Valid: 77.42% Test: 75.00%\n",
      "Epoch: 333, Loss: 54791.6406, Train: 75.09%, Valid: 77.56% Test: 75.00%\n",
      "Epoch: 334, Loss: 54773.3203, Train: 75.08%, Valid: 77.56% Test: 74.86%\n",
      "Epoch: 335, Loss: 54783.0039, Train: 75.04%, Valid: 77.56% Test: 74.86%\n",
      "Epoch: 336, Loss: 54787.0898, Train: 75.09%, Valid: 77.56% Test: 74.93%\n",
      "Epoch: 337, Loss: 54773.6484, Train: 75.09%, Valid: 77.56% Test: 75.00%\n",
      "Epoch: 338, Loss: 54762.5625, Train: 75.14%, Valid: 77.56% Test: 75.00%\n",
      "Epoch: 339, Loss: 54758.5703, Train: 75.15%, Valid: 77.63% Test: 74.93%\n",
      "Epoch: 340, Loss: 54769.6016, Train: 75.16%, Valid: 77.63% Test: 74.93%\n",
      "Epoch: 341, Loss: 54754.2930, Train: 75.22%, Valid: 77.63% Test: 75.00%\n",
      "Epoch: 342, Loss: 54759.6250, Train: 75.25%, Valid: 77.56% Test: 75.00%\n",
      "Epoch: 343, Loss: 54755.9961, Train: 75.25%, Valid: 77.56% Test: 75.07%\n",
      "Epoch: 344, Loss: 54753.3594, Train: 75.24%, Valid: 77.56% Test: 75.07%\n",
      "Epoch: 345, Loss: 54769.1406, Train: 75.25%, Valid: 77.56% Test: 75.21%\n",
      "Epoch: 346, Loss: 54745.1758, Train: 75.27%, Valid: 77.56% Test: 75.21%\n",
      "Epoch: 347, Loss: 54734.9805, Train: 75.27%, Valid: 77.56% Test: 75.21%\n",
      "Epoch: 348, Loss: 54734.6094, Train: 75.27%, Valid: 77.56% Test: 75.14%\n",
      "Epoch: 349, Loss: 54737.6641, Train: 75.28%, Valid: 77.63% Test: 75.14%\n",
      "Epoch: 350, Loss: 54725.5664, Train: 75.27%, Valid: 77.56% Test: 75.14%\n",
      "Epoch: 351, Loss: 54737.9609, Train: 75.26%, Valid: 77.56% Test: 75.21%\n",
      "Epoch: 352, Loss: 54726.4453, Train: 75.28%, Valid: 77.49% Test: 75.21%\n",
      "Epoch: 353, Loss: 54723.9648, Train: 75.30%, Valid: 77.56% Test: 75.21%\n",
      "Epoch: 354, Loss: 54721.3242, Train: 75.38%, Valid: 77.70% Test: 75.28%\n",
      "Epoch: 355, Loss: 54719.1680, Train: 75.51%, Valid: 77.84% Test: 75.55%\n",
      "Epoch: 356, Loss: 54702.1562, Train: 75.52%, Valid: 77.84% Test: 75.34%\n",
      "Epoch: 357, Loss: 54706.4219, Train: 75.41%, Valid: 77.70% Test: 75.14%\n",
      "Epoch: 358, Loss: 54717.6289, Train: 75.34%, Valid: 77.70% Test: 75.14%\n",
      "Epoch: 359, Loss: 54717.4414, Train: 75.36%, Valid: 77.70% Test: 74.93%\n",
      "Epoch: 360, Loss: 54721.5156, Train: 75.41%, Valid: 77.77% Test: 75.14%\n",
      "Epoch: 361, Loss: 54702.0781, Train: 75.51%, Valid: 77.84% Test: 75.28%\n",
      "Epoch: 362, Loss: 54691.4297, Train: 75.59%, Valid: 78.05% Test: 75.41%\n",
      "Epoch: 363, Loss: 54690.0078, Train: 75.64%, Valid: 78.05% Test: 75.41%\n",
      "Epoch: 364, Loss: 54681.5547, Train: 75.66%, Valid: 78.05% Test: 75.41%\n",
      "Epoch: 365, Loss: 54690.2656, Train: 75.89%, Valid: 78.25% Test: 75.69%\n",
      "Epoch: 366, Loss: 54700.6094, Train: 75.98%, Valid: 78.53% Test: 75.69%\n",
      "Epoch: 367, Loss: 54701.7031, Train: 75.98%, Valid: 78.53% Test: 75.69%\n",
      "Epoch: 368, Loss: 54670.2695, Train: 75.96%, Valid: 78.53% Test: 75.69%\n",
      "Epoch: 369, Loss: 54672.5391, Train: 75.96%, Valid: 78.53% Test: 75.76%\n",
      "Epoch: 370, Loss: 54662.3008, Train: 75.97%, Valid: 78.39% Test: 75.76%\n",
      "Epoch: 371, Loss: 54663.1953, Train: 75.95%, Valid: 78.39% Test: 75.69%\n",
      "Epoch: 372, Loss: 54671.4531, Train: 75.97%, Valid: 78.39% Test: 75.76%\n",
      "Epoch: 373, Loss: 54666.1523, Train: 75.95%, Valid: 78.39% Test: 75.83%\n",
      "Epoch: 374, Loss: 54658.9141, Train: 75.93%, Valid: 78.39% Test: 75.96%\n",
      "Epoch: 375, Loss: 54660.5156, Train: 75.97%, Valid: 78.32% Test: 76.03%\n",
      "Epoch: 376, Loss: 54647.9922, Train: 76.04%, Valid: 78.32% Test: 76.03%\n",
      "Epoch: 377, Loss: 54647.8281, Train: 76.04%, Valid: 78.32% Test: 75.96%\n",
      "Epoch: 378, Loss: 54643.8672, Train: 76.11%, Valid: 78.32% Test: 76.03%\n",
      "Epoch: 379, Loss: 54637.8438, Train: 76.17%, Valid: 78.46% Test: 76.03%\n",
      "Epoch: 380, Loss: 54640.3477, Train: 76.22%, Valid: 78.53% Test: 76.03%\n",
      "Epoch: 381, Loss: 54635.6055, Train: 76.27%, Valid: 78.53% Test: 76.03%\n",
      "Epoch: 382, Loss: 54629.3086, Train: 76.29%, Valid: 78.53% Test: 76.03%\n",
      "Epoch: 383, Loss: 54638.7773, Train: 76.29%, Valid: 78.60% Test: 76.17%\n",
      "Epoch: 384, Loss: 54615.7031, Train: 76.29%, Valid: 78.60% Test: 76.17%\n",
      "Epoch: 385, Loss: 54619.0898, Train: 76.30%, Valid: 78.60% Test: 76.17%\n",
      "Epoch: 386, Loss: 54639.2422, Train: 76.37%, Valid: 78.53% Test: 76.24%\n",
      "Epoch: 387, Loss: 54641.1094, Train: 76.39%, Valid: 78.53% Test: 76.58%\n",
      "Epoch: 388, Loss: 54623.3828, Train: 76.42%, Valid: 78.53% Test: 76.72%\n",
      "Epoch: 389, Loss: 54612.4805, Train: 76.43%, Valid: 78.53% Test: 76.72%\n",
      "Epoch: 390, Loss: 54606.7500, Train: 76.45%, Valid: 78.67% Test: 76.72%\n",
      "Epoch: 391, Loss: 54620.2031, Train: 76.45%, Valid: 78.74% Test: 76.72%\n",
      "Epoch: 392, Loss: 54621.6836, Train: 76.42%, Valid: 78.67% Test: 76.72%\n",
      "Epoch: 393, Loss: 54600.4844, Train: 76.42%, Valid: 78.67% Test: 76.65%\n",
      "Epoch: 394, Loss: 54599.6797, Train: 76.41%, Valid: 78.53% Test: 76.65%\n",
      "Epoch: 395, Loss: 54589.0430, Train: 76.42%, Valid: 78.60% Test: 76.58%\n",
      "Epoch: 396, Loss: 54600.3203, Train: 76.42%, Valid: 78.60% Test: 76.45%\n",
      "Epoch: 397, Loss: 54601.2578, Train: 76.41%, Valid: 78.60% Test: 76.38%\n",
      "Epoch: 398, Loss: 54590.8203, Train: 76.40%, Valid: 78.67% Test: 76.38%\n",
      "Epoch: 399, Loss: 54612.4414, Train: 76.41%, Valid: 78.67% Test: 76.45%\n",
      "Epoch: 400, Loss: 54587.8398, Train: 76.41%, Valid: 78.67% Test: 76.52%\n",
      "Epoch: 401, Loss: 54591.5195, Train: 76.41%, Valid: 78.67% Test: 76.58%\n",
      "Epoch: 402, Loss: 54591.9727, Train: 76.41%, Valid: 78.67% Test: 76.45%\n",
      "Epoch: 403, Loss: 54580.9375, Train: 76.42%, Valid: 78.67% Test: 76.45%\n",
      "Epoch: 404, Loss: 54593.1641, Train: 76.43%, Valid: 78.67% Test: 76.52%\n",
      "Epoch: 405, Loss: 54563.1328, Train: 76.42%, Valid: 78.67% Test: 76.52%\n",
      "Epoch: 406, Loss: 54587.8203, Train: 76.45%, Valid: 78.67% Test: 76.58%\n",
      "Epoch: 407, Loss: 54584.8164, Train: 76.46%, Valid: 78.60% Test: 76.58%\n",
      "Epoch: 408, Loss: 54575.6250, Train: 76.45%, Valid: 78.53% Test: 76.58%\n",
      "Epoch: 409, Loss: 54559.8242, Train: 76.43%, Valid: 78.60% Test: 76.58%\n",
      "Epoch: 410, Loss: 54578.0586, Train: 76.43%, Valid: 78.60% Test: 76.58%\n",
      "Epoch: 411, Loss: 54569.0469, Train: 76.45%, Valid: 78.53% Test: 76.65%\n",
      "Epoch: 412, Loss: 54557.6328, Train: 76.42%, Valid: 78.53% Test: 76.72%\n",
      "Epoch: 413, Loss: 54574.5156, Train: 76.40%, Valid: 78.53% Test: 76.72%\n",
      "Epoch: 414, Loss: 54560.8672, Train: 76.40%, Valid: 78.60% Test: 76.72%\n",
      "Epoch: 415, Loss: 54556.0156, Train: 76.48%, Valid: 78.81% Test: 76.93%\n",
      "Epoch: 416, Loss: 54567.4883, Train: 76.52%, Valid: 78.74% Test: 76.93%\n",
      "Epoch: 417, Loss: 54540.2734, Train: 76.54%, Valid: 78.81% Test: 76.93%\n",
      "Epoch: 418, Loss: 54549.5391, Train: 76.46%, Valid: 78.81% Test: 76.65%\n",
      "Epoch: 419, Loss: 54550.7812, Train: 76.47%, Valid: 78.81% Test: 76.58%\n",
      "Epoch: 420, Loss: 54556.7891, Train: 76.48%, Valid: 78.81% Test: 76.65%\n",
      "Epoch: 421, Loss: 54569.9844, Train: 76.48%, Valid: 78.74% Test: 76.65%\n",
      "Epoch: 422, Loss: 54545.4492, Train: 76.48%, Valid: 78.74% Test: 76.65%\n",
      "Epoch: 423, Loss: 54541.6406, Train: 76.48%, Valid: 78.74% Test: 76.72%\n",
      "Epoch: 424, Loss: 54543.8125, Train: 76.48%, Valid: 78.74% Test: 76.72%\n",
      "Epoch: 425, Loss: 54549.3828, Train: 76.47%, Valid: 78.74% Test: 76.72%\n",
      "Epoch: 426, Loss: 54541.7344, Train: 76.58%, Valid: 78.74% Test: 76.93%\n",
      "Epoch: 427, Loss: 54533.0352, Train: 76.64%, Valid: 78.88% Test: 77.00%\n",
      "Epoch: 428, Loss: 54528.4922, Train: 76.63%, Valid: 78.95% Test: 77.00%\n",
      "Epoch: 429, Loss: 54549.6055, Train: 76.61%, Valid: 79.02% Test: 76.93%\n",
      "Epoch: 430, Loss: 54521.0625, Train: 76.56%, Valid: 79.02% Test: 76.86%\n",
      "Epoch: 431, Loss: 54545.9531, Train: 76.55%, Valid: 78.88% Test: 76.86%\n",
      "Epoch: 432, Loss: 54533.2891, Train: 76.54%, Valid: 78.74% Test: 76.86%\n",
      "Epoch: 433, Loss: 54509.0195, Train: 76.47%, Valid: 78.67% Test: 76.79%\n",
      "Epoch: 434, Loss: 54534.4141, Train: 76.49%, Valid: 78.74% Test: 76.58%\n",
      "Epoch: 435, Loss: 54541.1094, Train: 76.52%, Valid: 78.74% Test: 76.52%\n",
      "Epoch: 436, Loss: 54512.4727, Train: 76.61%, Valid: 78.81% Test: 76.58%\n",
      "Epoch: 437, Loss: 54511.9570, Train: 76.74%, Valid: 78.88% Test: 76.72%\n",
      "Epoch: 438, Loss: 54511.6953, Train: 76.78%, Valid: 79.16% Test: 76.72%\n",
      "Epoch: 439, Loss: 54524.5352, Train: 76.79%, Valid: 79.16% Test: 76.79%\n",
      "Epoch: 440, Loss: 54514.0742, Train: 76.78%, Valid: 79.16% Test: 76.79%\n",
      "Epoch: 441, Loss: 54509.1602, Train: 76.79%, Valid: 79.16% Test: 76.72%\n",
      "Epoch: 442, Loss: 54527.6562, Train: 76.80%, Valid: 79.16% Test: 76.72%\n",
      "Epoch: 443, Loss: 54508.8984, Train: 76.82%, Valid: 79.16% Test: 76.72%\n",
      "Epoch: 444, Loss: 54496.7617, Train: 76.83%, Valid: 79.16% Test: 76.79%\n",
      "Epoch: 445, Loss: 54516.4531, Train: 76.92%, Valid: 79.29% Test: 77.00%\n",
      "Epoch: 446, Loss: 54508.9336, Train: 76.94%, Valid: 79.29% Test: 77.00%\n",
      "Epoch: 447, Loss: 54492.9727, Train: 76.99%, Valid: 79.22% Test: 77.00%\n",
      "Epoch: 448, Loss: 54518.4219, Train: 77.00%, Valid: 79.22% Test: 76.86%\n",
      "Epoch: 449, Loss: 54505.4727, Train: 77.00%, Valid: 79.22% Test: 76.86%\n",
      "Epoch: 450, Loss: 54479.2891, Train: 76.99%, Valid: 79.29% Test: 76.86%\n",
      "Epoch: 451, Loss: 54481.7891, Train: 76.98%, Valid: 79.29% Test: 76.79%\n",
      "Epoch: 452, Loss: 54496.6875, Train: 76.97%, Valid: 79.22% Test: 76.65%\n",
      "Epoch: 453, Loss: 54503.4609, Train: 76.98%, Valid: 79.22% Test: 76.79%\n",
      "Epoch: 454, Loss: 54485.8828, Train: 76.98%, Valid: 79.22% Test: 76.86%\n",
      "Epoch: 455, Loss: 54483.1875, Train: 76.92%, Valid: 79.16% Test: 76.86%\n",
      "Epoch: 456, Loss: 54473.6055, Train: 76.94%, Valid: 79.16% Test: 76.93%\n",
      "Epoch: 457, Loss: 54470.2734, Train: 76.94%, Valid: 79.09% Test: 77.00%\n",
      "Epoch: 458, Loss: 54475.5859, Train: 76.95%, Valid: 79.09% Test: 77.00%\n",
      "Epoch: 459, Loss: 54471.0430, Train: 76.95%, Valid: 79.02% Test: 76.93%\n",
      "Epoch: 460, Loss: 54480.1719, Train: 76.97%, Valid: 79.09% Test: 76.93%\n",
      "Epoch: 461, Loss: 54475.9688, Train: 76.98%, Valid: 79.16% Test: 76.93%\n",
      "Epoch: 462, Loss: 54473.9922, Train: 76.98%, Valid: 79.29% Test: 76.93%\n",
      "Epoch: 463, Loss: 54462.5352, Train: 76.98%, Valid: 79.29% Test: 76.86%\n",
      "Epoch: 464, Loss: 54487.6094, Train: 76.98%, Valid: 79.16% Test: 76.86%\n",
      "Epoch: 465, Loss: 54481.4492, Train: 76.96%, Valid: 79.16% Test: 76.86%\n",
      "Epoch: 466, Loss: 54473.9219, Train: 76.94%, Valid: 79.22% Test: 76.86%\n",
      "Epoch: 467, Loss: 54458.5156, Train: 76.92%, Valid: 79.29% Test: 76.86%\n",
      "Epoch: 468, Loss: 54482.2969, Train: 76.95%, Valid: 79.43% Test: 77.00%\n",
      "Epoch: 469, Loss: 54488.1992, Train: 76.93%, Valid: 79.36% Test: 77.00%\n",
      "Epoch: 470, Loss: 54439.8633, Train: 76.95%, Valid: 79.22% Test: 76.93%\n",
      "Epoch: 471, Loss: 54459.6016, Train: 76.98%, Valid: 79.16% Test: 76.93%\n",
      "Epoch: 472, Loss: 54443.4531, Train: 76.97%, Valid: 79.16% Test: 76.86%\n",
      "Epoch: 473, Loss: 54451.2734, Train: 76.92%, Valid: 79.09% Test: 76.86%\n",
      "Epoch: 474, Loss: 54474.9453, Train: 76.95%, Valid: 79.09% Test: 76.79%\n",
      "Epoch: 475, Loss: 54439.2266, Train: 76.95%, Valid: 79.16% Test: 76.79%\n",
      "Epoch: 476, Loss: 54454.8672, Train: 76.97%, Valid: 79.22% Test: 76.79%\n",
      "Epoch: 477, Loss: 54463.2695, Train: 76.98%, Valid: 79.29% Test: 77.00%\n",
      "Epoch: 478, Loss: 54437.1133, Train: 76.98%, Valid: 79.36% Test: 77.00%\n",
      "Epoch: 479, Loss: 54456.3750, Train: 76.98%, Valid: 79.36% Test: 77.00%\n",
      "Epoch: 480, Loss: 54449.3594, Train: 77.00%, Valid: 79.36% Test: 77.00%\n",
      "Epoch: 481, Loss: 54457.2656, Train: 76.99%, Valid: 79.36% Test: 77.13%\n",
      "Epoch: 482, Loss: 54448.8164, Train: 77.00%, Valid: 79.36% Test: 77.13%\n",
      "Epoch: 483, Loss: 54431.7266, Train: 77.00%, Valid: 79.36% Test: 77.00%\n",
      "Epoch: 484, Loss: 54448.4922, Train: 76.99%, Valid: 79.36% Test: 76.93%\n",
      "Epoch: 485, Loss: 54433.3164, Train: 76.98%, Valid: 79.36% Test: 76.93%\n",
      "Epoch: 486, Loss: 54450.4141, Train: 76.98%, Valid: 79.36% Test: 76.93%\n",
      "Epoch: 487, Loss: 54447.2070, Train: 76.97%, Valid: 79.29% Test: 76.93%\n",
      "Epoch: 488, Loss: 54444.2812, Train: 76.98%, Valid: 79.29% Test: 76.93%\n",
      "Epoch: 489, Loss: 54442.7773, Train: 76.98%, Valid: 79.29% Test: 76.86%\n",
      "Epoch: 490, Loss: 54436.8633, Train: 76.97%, Valid: 79.29% Test: 77.00%\n",
      "Epoch: 491, Loss: 54441.5000, Train: 76.98%, Valid: 79.29% Test: 77.07%\n",
      "Epoch: 492, Loss: 54461.6133, Train: 77.02%, Valid: 79.36% Test: 77.07%\n",
      "Epoch: 493, Loss: 54436.7461, Train: 77.01%, Valid: 79.36% Test: 77.07%\n",
      "Epoch: 494, Loss: 54434.9727, Train: 77.00%, Valid: 79.36% Test: 77.07%\n",
      "Epoch: 495, Loss: 54418.0781, Train: 77.03%, Valid: 79.36% Test: 77.07%\n",
      "Epoch: 496, Loss: 54425.7812, Train: 77.03%, Valid: 79.36% Test: 77.20%\n",
      "Epoch: 497, Loss: 54434.8203, Train: 77.05%, Valid: 79.36% Test: 77.13%\n",
      "Epoch: 498, Loss: 54417.6484, Train: 77.05%, Valid: 79.36% Test: 77.13%\n",
      "Epoch: 499, Loss: 54441.3125, Train: 77.02%, Valid: 79.36% Test: 77.13%\n",
      "Epoch: 500, Loss: 54433.8008, Train: 77.01%, Valid: 79.36% Test: 77.13%\n",
      "Epoch: 501, Loss: 54420.0000, Train: 77.01%, Valid: 79.36% Test: 77.07%\n",
      "Epoch: 502, Loss: 54414.2539, Train: 77.01%, Valid: 79.36% Test: 77.07%\n",
      "Epoch: 503, Loss: 54416.3672, Train: 76.96%, Valid: 79.36% Test: 77.07%\n",
      "Epoch: 504, Loss: 54418.1875, Train: 76.94%, Valid: 79.29% Test: 76.93%\n",
      "Epoch: 505, Loss: 54419.2031, Train: 76.95%, Valid: 79.29% Test: 76.93%\n",
      "Epoch: 506, Loss: 54426.7188, Train: 76.95%, Valid: 79.29% Test: 77.00%\n",
      "Epoch: 507, Loss: 54420.5938, Train: 76.98%, Valid: 79.36% Test: 77.00%\n",
      "Epoch: 508, Loss: 54426.7031, Train: 76.99%, Valid: 79.36% Test: 77.07%\n",
      "Epoch: 509, Loss: 54418.2227, Train: 77.00%, Valid: 79.29% Test: 77.07%\n",
      "Epoch: 510, Loss: 54413.6719, Train: 77.00%, Valid: 79.29% Test: 77.07%\n",
      "Epoch: 511, Loss: 54412.3164, Train: 77.01%, Valid: 79.29% Test: 77.00%\n",
      "Epoch: 512, Loss: 54408.2188, Train: 76.95%, Valid: 79.29% Test: 77.00%\n",
      "Epoch: 513, Loss: 54404.5625, Train: 76.94%, Valid: 79.29% Test: 76.86%\n",
      "Epoch: 514, Loss: 54411.9258, Train: 76.92%, Valid: 79.29% Test: 76.86%\n",
      "Epoch: 515, Loss: 54419.5938, Train: 76.89%, Valid: 79.22% Test: 76.93%\n",
      "Epoch: 516, Loss: 54415.4258, Train: 76.90%, Valid: 79.16% Test: 76.93%\n",
      "Epoch: 517, Loss: 54421.8203, Train: 76.91%, Valid: 79.22% Test: 76.93%\n",
      "Epoch: 518, Loss: 54416.4922, Train: 76.90%, Valid: 79.16% Test: 77.00%\n",
      "Epoch: 519, Loss: 54406.7734, Train: 76.92%, Valid: 79.09% Test: 77.07%\n",
      "Epoch: 520, Loss: 54394.3594, Train: 76.95%, Valid: 79.09% Test: 77.07%\n",
      "Epoch: 521, Loss: 54401.1289, Train: 76.95%, Valid: 79.16% Test: 77.13%\n",
      "Epoch: 522, Loss: 54397.4570, Train: 76.96%, Valid: 79.29% Test: 77.13%\n",
      "Epoch: 523, Loss: 54383.5078, Train: 76.95%, Valid: 79.29% Test: 77.13%\n",
      "Epoch: 524, Loss: 54405.3672, Train: 76.96%, Valid: 79.29% Test: 77.20%\n",
      "Epoch: 525, Loss: 54398.0156, Train: 77.00%, Valid: 79.36% Test: 77.27%\n",
      "Epoch: 526, Loss: 54419.3906, Train: 77.02%, Valid: 79.36% Test: 77.13%\n",
      "Epoch: 527, Loss: 54417.7969, Train: 77.04%, Valid: 79.36% Test: 77.13%\n",
      "Epoch: 528, Loss: 54403.6406, Train: 77.02%, Valid: 79.36% Test: 77.13%\n",
      "Epoch: 529, Loss: 54399.1328, Train: 76.99%, Valid: 79.29% Test: 77.07%\n",
      "Epoch: 530, Loss: 54393.1016, Train: 76.96%, Valid: 79.29% Test: 77.07%\n",
      "Epoch: 531, Loss: 54402.1250, Train: 76.95%, Valid: 79.29% Test: 76.93%\n",
      "Epoch: 532, Loss: 54407.7188, Train: 76.96%, Valid: 79.29% Test: 76.93%\n",
      "Epoch: 533, Loss: 54388.0078, Train: 76.96%, Valid: 79.29% Test: 76.79%\n",
      "Epoch: 534, Loss: 54407.9961, Train: 77.06%, Valid: 79.29% Test: 76.79%\n",
      "Epoch: 535, Loss: 54399.4297, Train: 77.08%, Valid: 79.22% Test: 76.79%\n",
      "Epoch: 536, Loss: 54396.6719, Train: 77.10%, Valid: 79.22% Test: 76.86%\n",
      "Epoch: 537, Loss: 54389.9180, Train: 77.22%, Valid: 79.50% Test: 76.93%\n",
      "Epoch: 538, Loss: 54370.7734, Train: 77.28%, Valid: 79.50% Test: 76.93%\n",
      "Epoch: 539, Loss: 54380.9609, Train: 77.32%, Valid: 79.43% Test: 77.13%\n",
      "Epoch: 540, Loss: 54375.8867, Train: 77.30%, Valid: 79.43% Test: 77.13%\n",
      "Epoch: 541, Loss: 54358.2031, Train: 77.24%, Valid: 79.43% Test: 77.13%\n",
      "Epoch: 542, Loss: 54370.8750, Train: 77.26%, Valid: 79.43% Test: 77.27%\n",
      "Epoch: 543, Loss: 54385.4219, Train: 77.35%, Valid: 79.50% Test: 77.34%\n",
      "Epoch: 544, Loss: 54358.2227, Train: 77.30%, Valid: 79.64% Test: 77.34%\n",
      "Epoch: 545, Loss: 54359.9609, Train: 77.30%, Valid: 79.64% Test: 77.27%\n",
      "Epoch: 546, Loss: 54359.9102, Train: 77.34%, Valid: 79.64% Test: 77.34%\n",
      "Epoch: 547, Loss: 54352.6016, Train: 77.35%, Valid: 79.64% Test: 77.34%\n",
      "Epoch: 548, Loss: 54367.5508, Train: 77.35%, Valid: 79.64% Test: 77.27%\n",
      "Epoch: 549, Loss: 54365.6406, Train: 77.38%, Valid: 79.64% Test: 77.27%\n",
      "Epoch: 550, Loss: 54362.4922, Train: 77.42%, Valid: 79.64% Test: 77.27%\n",
      "Epoch: 551, Loss: 54355.4766, Train: 77.43%, Valid: 79.64% Test: 77.34%\n",
      "Epoch: 552, Loss: 54368.6484, Train: 77.43%, Valid: 79.64% Test: 77.34%\n",
      "Epoch: 553, Loss: 54358.3438, Train: 77.43%, Valid: 79.64% Test: 77.41%\n",
      "Epoch: 554, Loss: 54347.3086, Train: 77.43%, Valid: 79.64% Test: 77.41%\n",
      "Epoch: 555, Loss: 54351.8125, Train: 77.45%, Valid: 79.64% Test: 77.41%\n",
      "Epoch: 556, Loss: 54352.8906, Train: 77.43%, Valid: 79.64% Test: 77.41%\n",
      "Epoch: 557, Loss: 54353.3398, Train: 77.43%, Valid: 79.64% Test: 77.41%\n",
      "Epoch: 558, Loss: 54348.8828, Train: 77.42%, Valid: 79.50% Test: 77.34%\n",
      "Epoch: 559, Loss: 54343.7227, Train: 77.42%, Valid: 79.50% Test: 77.27%\n",
      "Epoch: 560, Loss: 54336.2266, Train: 77.42%, Valid: 79.57% Test: 77.27%\n",
      "Epoch: 561, Loss: 54338.7852, Train: 77.43%, Valid: 79.64% Test: 77.27%\n",
      "Epoch: 562, Loss: 54353.4062, Train: 77.46%, Valid: 79.64% Test: 77.27%\n",
      "Epoch: 563, Loss: 54346.4688, Train: 77.46%, Valid: 79.57% Test: 77.27%\n",
      "Epoch: 564, Loss: 54348.4531, Train: 77.44%, Valid: 79.57% Test: 77.34%\n",
      "Epoch: 565, Loss: 54344.4102, Train: 77.47%, Valid: 79.57% Test: 77.41%\n",
      "Epoch: 566, Loss: 54337.4883, Train: 77.47%, Valid: 79.57% Test: 77.34%\n",
      "Epoch: 567, Loss: 54337.9062, Train: 77.47%, Valid: 79.57% Test: 77.34%\n",
      "Epoch: 568, Loss: 54347.9922, Train: 77.51%, Valid: 79.57% Test: 77.41%\n",
      "Epoch: 569, Loss: 54348.9648, Train: 77.54%, Valid: 79.64% Test: 77.41%\n",
      "Epoch: 570, Loss: 54327.8242, Train: 77.55%, Valid: 79.64% Test: 77.48%\n",
      "Epoch: 571, Loss: 54337.4336, Train: 77.61%, Valid: 79.71% Test: 77.55%\n",
      "Epoch: 572, Loss: 54344.3086, Train: 77.73%, Valid: 79.85% Test: 77.55%\n",
      "Epoch: 573, Loss: 54316.9336, Train: 77.73%, Valid: 79.92% Test: 77.62%\n",
      "Epoch: 574, Loss: 54341.6992, Train: 77.74%, Valid: 79.92% Test: 77.48%\n",
      "Epoch: 575, Loss: 54322.5781, Train: 77.72%, Valid: 79.92% Test: 77.48%\n",
      "Epoch: 576, Loss: 54317.0000, Train: 77.68%, Valid: 79.85% Test: 77.48%\n",
      "Epoch: 577, Loss: 54330.3594, Train: 77.68%, Valid: 79.78% Test: 77.34%\n",
      "Epoch: 578, Loss: 54298.5391, Train: 77.68%, Valid: 79.71% Test: 77.34%\n",
      "Epoch: 579, Loss: 54323.4453, Train: 77.68%, Valid: 79.64% Test: 77.41%\n",
      "Epoch: 580, Loss: 54298.2773, Train: 77.63%, Valid: 79.71% Test: 77.41%\n",
      "Epoch: 581, Loss: 54324.1797, Train: 77.65%, Valid: 79.71% Test: 77.34%\n",
      "Epoch: 582, Loss: 54303.3359, Train: 77.68%, Valid: 79.78% Test: 77.20%\n",
      "Epoch: 583, Loss: 54312.7344, Train: 77.68%, Valid: 79.78% Test: 77.34%\n",
      "Epoch: 584, Loss: 54327.9766, Train: 77.71%, Valid: 79.78% Test: 77.34%\n",
      "Epoch: 585, Loss: 54305.7109, Train: 77.73%, Valid: 79.85% Test: 77.41%\n",
      "Epoch: 586, Loss: 54305.1328, Train: 77.75%, Valid: 79.85% Test: 77.48%\n",
      "Epoch: 587, Loss: 54308.6406, Train: 77.74%, Valid: 79.85% Test: 77.48%\n",
      "Epoch: 588, Loss: 54315.0234, Train: 77.74%, Valid: 79.85% Test: 77.41%\n",
      "Epoch: 589, Loss: 54307.3242, Train: 77.76%, Valid: 79.85% Test: 77.34%\n",
      "Epoch: 590, Loss: 54301.9141, Train: 77.76%, Valid: 79.92% Test: 77.27%\n",
      "Epoch: 591, Loss: 54325.9609, Train: 77.74%, Valid: 79.92% Test: 77.27%\n",
      "Epoch: 592, Loss: 54305.7734, Train: 77.72%, Valid: 79.78% Test: 77.34%\n",
      "Epoch: 593, Loss: 54308.5273, Train: 77.68%, Valid: 79.78% Test: 77.34%\n",
      "Epoch: 594, Loss: 54289.3828, Train: 77.63%, Valid: 79.78% Test: 77.34%\n",
      "Epoch: 595, Loss: 54303.3359, Train: 77.66%, Valid: 79.78% Test: 77.27%\n",
      "Epoch: 596, Loss: 54316.2031, Train: 77.68%, Valid: 79.78% Test: 77.48%\n",
      "Epoch: 597, Loss: 54296.1094, Train: 77.68%, Valid: 79.78% Test: 77.55%\n",
      "Epoch: 598, Loss: 54300.2773, Train: 77.70%, Valid: 79.71% Test: 77.62%\n",
      "Epoch: 599, Loss: 54298.6875, Train: 77.72%, Valid: 79.78% Test: 77.62%\n",
      "Epoch: 600, Loss: 54307.0234, Train: 77.74%, Valid: 79.71% Test: 77.62%\n",
      "Epoch: 601, Loss: 54299.9922, Train: 77.74%, Valid: 79.78% Test: 77.55%\n",
      "Epoch: 602, Loss: 54291.7422, Train: 77.71%, Valid: 79.78% Test: 77.55%\n",
      "Epoch: 603, Loss: 54284.3633, Train: 77.71%, Valid: 79.78% Test: 77.55%\n",
      "Epoch: 604, Loss: 54295.3125, Train: 77.71%, Valid: 79.78% Test: 77.48%\n",
      "Epoch: 605, Loss: 54300.6289, Train: 77.69%, Valid: 79.78% Test: 77.34%\n",
      "Epoch: 606, Loss: 54298.2227, Train: 77.71%, Valid: 79.78% Test: 77.34%\n",
      "Epoch: 607, Loss: 54292.6523, Train: 77.71%, Valid: 79.78% Test: 77.41%\n",
      "Epoch: 608, Loss: 54287.0078, Train: 77.74%, Valid: 79.78% Test: 77.41%\n",
      "Epoch: 609, Loss: 54290.6953, Train: 77.73%, Valid: 79.78% Test: 77.41%\n",
      "Epoch: 610, Loss: 54281.9141, Train: 77.74%, Valid: 79.78% Test: 77.55%\n",
      "Epoch: 611, Loss: 54293.5820, Train: 77.74%, Valid: 79.78% Test: 77.62%\n",
      "Epoch: 612, Loss: 54293.0859, Train: 77.75%, Valid: 79.78% Test: 77.62%\n",
      "Epoch: 613, Loss: 54284.8125, Train: 77.74%, Valid: 79.78% Test: 77.55%\n",
      "Epoch: 614, Loss: 54282.9648, Train: 77.73%, Valid: 79.78% Test: 77.55%\n",
      "Epoch: 615, Loss: 54271.5430, Train: 77.74%, Valid: 79.78% Test: 77.48%\n",
      "Epoch: 616, Loss: 54303.6680, Train: 77.71%, Valid: 79.78% Test: 77.41%\n",
      "Epoch: 617, Loss: 54282.6641, Train: 77.68%, Valid: 79.71% Test: 77.34%\n",
      "Epoch: 618, Loss: 54279.7344, Train: 77.68%, Valid: 79.71% Test: 77.41%\n",
      "Epoch: 619, Loss: 54282.6562, Train: 77.69%, Valid: 79.64% Test: 77.34%\n",
      "Epoch: 620, Loss: 54281.9844, Train: 77.70%, Valid: 79.64% Test: 77.34%\n",
      "Epoch: 621, Loss: 54289.4883, Train: 77.71%, Valid: 79.64% Test: 77.41%\n",
      "Epoch: 622, Loss: 54303.1562, Train: 77.73%, Valid: 79.64% Test: 77.34%\n",
      "Epoch: 623, Loss: 54265.1758, Train: 77.72%, Valid: 79.64% Test: 77.41%\n",
      "Epoch: 624, Loss: 54287.2656, Train: 77.68%, Valid: 79.57% Test: 77.48%\n",
      "Epoch: 625, Loss: 54274.1562, Train: 77.68%, Valid: 79.64% Test: 77.48%\n",
      "Epoch: 626, Loss: 54287.7812, Train: 77.68%, Valid: 79.71% Test: 77.62%\n",
      "Epoch: 627, Loss: 54277.9531, Train: 77.62%, Valid: 79.78% Test: 77.62%\n",
      "Epoch: 628, Loss: 54277.3828, Train: 77.61%, Valid: 79.71% Test: 77.55%\n",
      "Epoch: 629, Loss: 54279.4609, Train: 77.60%, Valid: 79.57% Test: 77.55%\n",
      "Epoch: 630, Loss: 54280.6406, Train: 77.58%, Valid: 79.57% Test: 77.48%\n",
      "Epoch: 631, Loss: 54279.6641, Train: 77.65%, Valid: 79.57% Test: 77.62%\n",
      "Epoch: 632, Loss: 54271.8164, Train: 77.67%, Valid: 79.50% Test: 77.62%\n",
      "Epoch: 633, Loss: 54274.4258, Train: 77.70%, Valid: 79.57% Test: 77.55%\n",
      "Epoch: 634, Loss: 54279.9297, Train: 77.71%, Valid: 79.50% Test: 77.62%\n",
      "Epoch: 635, Loss: 54280.0078, Train: 77.73%, Valid: 79.57% Test: 77.55%\n",
      "Epoch: 636, Loss: 54279.5469, Train: 77.74%, Valid: 79.64% Test: 77.62%\n",
      "Epoch: 637, Loss: 54281.6953, Train: 77.74%, Valid: 79.64% Test: 77.55%\n",
      "Epoch: 638, Loss: 54273.6328, Train: 77.70%, Valid: 79.64% Test: 77.69%\n",
      "Epoch: 639, Loss: 54263.2578, Train: 77.69%, Valid: 79.57% Test: 77.55%\n",
      "Epoch: 640, Loss: 54270.7266, Train: 77.68%, Valid: 79.57% Test: 77.55%\n",
      "Epoch: 641, Loss: 54282.4922, Train: 77.68%, Valid: 79.57% Test: 77.48%\n",
      "Epoch: 642, Loss: 54268.9141, Train: 77.70%, Valid: 79.57% Test: 77.55%\n",
      "Epoch: 643, Loss: 54268.0859, Train: 77.75%, Valid: 79.57% Test: 77.41%\n",
      "Epoch: 644, Loss: 54289.7305, Train: 77.79%, Valid: 79.57% Test: 77.48%\n",
      "Epoch: 645, Loss: 54258.7734, Train: 77.80%, Valid: 79.57% Test: 77.62%\n",
      "Epoch: 646, Loss: 54268.0859, Train: 77.80%, Valid: 79.64% Test: 77.69%\n",
      "Epoch: 647, Loss: 54260.7891, Train: 77.82%, Valid: 79.50% Test: 77.69%\n",
      "Epoch: 648, Loss: 54248.2812, Train: 77.82%, Valid: 79.50% Test: 77.69%\n",
      "Epoch: 649, Loss: 54293.6875, Train: 77.83%, Valid: 79.57% Test: 77.75%\n",
      "Epoch: 650, Loss: 54266.7188, Train: 77.84%, Valid: 79.57% Test: 77.75%\n",
      "Epoch: 651, Loss: 54264.1914, Train: 77.80%, Valid: 79.64% Test: 77.69%\n",
      "Epoch: 652, Loss: 54280.3555, Train: 77.77%, Valid: 79.57% Test: 77.69%\n",
      "Epoch: 653, Loss: 54271.6797, Train: 77.73%, Valid: 79.57% Test: 77.55%\n",
      "Epoch: 654, Loss: 54246.4219, Train: 77.70%, Valid: 79.57% Test: 77.48%\n",
      "Epoch: 655, Loss: 54292.1289, Train: 77.71%, Valid: 79.50% Test: 77.48%\n",
      "Epoch: 656, Loss: 54260.0273, Train: 77.73%, Valid: 79.57% Test: 77.62%\n",
      "Epoch: 657, Loss: 54253.8203, Train: 77.75%, Valid: 79.43% Test: 77.55%\n",
      "Epoch: 658, Loss: 54255.2930, Train: 77.76%, Valid: 79.43% Test: 77.69%\n",
      "Epoch: 659, Loss: 54235.4844, Train: 77.76%, Valid: 79.43% Test: 77.69%\n",
      "Epoch: 660, Loss: 54269.3516, Train: 77.77%, Valid: 79.64% Test: 77.69%\n",
      "Epoch: 661, Loss: 54252.3359, Train: 77.79%, Valid: 79.64% Test: 77.69%\n",
      "Epoch: 662, Loss: 54267.2266, Train: 77.81%, Valid: 79.64% Test: 77.62%\n",
      "Epoch: 663, Loss: 54246.2109, Train: 77.80%, Valid: 79.64% Test: 77.62%\n",
      "Epoch: 664, Loss: 54256.7148, Train: 77.81%, Valid: 79.64% Test: 77.55%\n",
      "Epoch: 665, Loss: 54241.0938, Train: 77.80%, Valid: 79.64% Test: 77.41%\n",
      "Epoch: 666, Loss: 54268.1797, Train: 77.78%, Valid: 79.64% Test: 77.41%\n",
      "Epoch: 667, Loss: 54255.7227, Train: 77.76%, Valid: 79.50% Test: 77.55%\n",
      "Epoch: 668, Loss: 54257.1953, Train: 77.73%, Valid: 79.50% Test: 77.55%\n",
      "Epoch: 669, Loss: 54253.6016, Train: 77.75%, Valid: 79.50% Test: 77.55%\n",
      "Epoch: 670, Loss: 54247.7617, Train: 77.75%, Valid: 79.43% Test: 77.62%\n",
      "Epoch: 671, Loss: 54246.9609, Train: 77.77%, Valid: 79.43% Test: 77.69%\n",
      "Epoch: 672, Loss: 54226.8359, Train: 77.79%, Valid: 79.50% Test: 77.75%\n",
      "Epoch: 673, Loss: 54252.3906, Train: 77.76%, Valid: 79.50% Test: 77.75%\n",
      "Epoch: 674, Loss: 54238.4375, Train: 77.78%, Valid: 79.57% Test: 77.75%\n",
      "Epoch: 675, Loss: 54270.0781, Train: 77.83%, Valid: 79.50% Test: 77.69%\n",
      "Epoch: 676, Loss: 54242.7188, Train: 77.84%, Valid: 79.50% Test: 77.69%\n",
      "Epoch: 677, Loss: 54246.5703, Train: 77.85%, Valid: 79.57% Test: 77.69%\n",
      "Epoch: 678, Loss: 54248.8125, Train: 77.83%, Valid: 79.57% Test: 77.75%\n",
      "Epoch: 679, Loss: 54247.1055, Train: 77.84%, Valid: 79.57% Test: 77.62%\n",
      "Epoch: 680, Loss: 54247.5703, Train: 77.85%, Valid: 79.57% Test: 77.75%\n",
      "Epoch: 681, Loss: 54235.8906, Train: 77.87%, Valid: 79.57% Test: 77.75%\n",
      "Epoch: 682, Loss: 54239.9766, Train: 77.87%, Valid: 79.43% Test: 77.89%\n",
      "Epoch: 683, Loss: 54244.1641, Train: 77.86%, Valid: 79.50% Test: 77.96%\n",
      "Epoch: 684, Loss: 54233.1289, Train: 77.83%, Valid: 79.57% Test: 77.96%\n",
      "Epoch: 685, Loss: 54240.2852, Train: 77.80%, Valid: 79.57% Test: 77.89%\n",
      "Epoch: 686, Loss: 54243.8633, Train: 77.80%, Valid: 79.57% Test: 77.75%\n",
      "Epoch: 687, Loss: 54221.0391, Train: 77.83%, Valid: 79.50% Test: 77.62%\n",
      "Epoch: 688, Loss: 54228.7109, Train: 77.87%, Valid: 79.64% Test: 77.75%\n",
      "Epoch: 689, Loss: 54243.3516, Train: 77.89%, Valid: 79.71% Test: 77.82%\n",
      "Epoch: 690, Loss: 54249.8906, Train: 77.91%, Valid: 79.71% Test: 77.75%\n",
      "Epoch: 691, Loss: 54240.9141, Train: 77.92%, Valid: 79.71% Test: 77.89%\n",
      "Epoch: 692, Loss: 54232.2266, Train: 77.94%, Valid: 79.71% Test: 77.96%\n",
      "Epoch: 693, Loss: 54230.4688, Train: 77.97%, Valid: 79.78% Test: 77.96%\n",
      "Epoch: 694, Loss: 54249.0859, Train: 77.96%, Valid: 79.78% Test: 77.89%\n",
      "Epoch: 695, Loss: 54231.2734, Train: 77.95%, Valid: 79.78% Test: 77.82%\n",
      "Epoch: 696, Loss: 54214.9844, Train: 77.94%, Valid: 79.78% Test: 77.82%\n",
      "Epoch: 697, Loss: 54226.9531, Train: 77.91%, Valid: 79.71% Test: 77.82%\n",
      "Epoch: 698, Loss: 54237.9805, Train: 77.89%, Valid: 79.78% Test: 77.75%\n",
      "Epoch: 699, Loss: 54225.8867, Train: 77.88%, Valid: 79.78% Test: 77.75%\n",
      "Epoch: 700, Loss: 54223.6797, Train: 77.87%, Valid: 79.71% Test: 77.75%\n",
      "Epoch: 701, Loss: 54235.3594, Train: 77.85%, Valid: 79.71% Test: 77.69%\n",
      "Epoch: 702, Loss: 54234.3984, Train: 77.87%, Valid: 79.71% Test: 77.75%\n",
      "Epoch: 703, Loss: 54218.4609, Train: 77.89%, Valid: 79.71% Test: 77.75%\n",
      "Epoch: 704, Loss: 54233.5000, Train: 77.87%, Valid: 79.57% Test: 77.75%\n",
      "Epoch: 705, Loss: 54210.3750, Train: 77.87%, Valid: 79.43% Test: 77.75%\n",
      "Epoch: 706, Loss: 54229.1641, Train: 77.87%, Valid: 79.50% Test: 77.69%\n",
      "Epoch: 707, Loss: 54228.4570, Train: 77.82%, Valid: 79.50% Test: 77.82%\n",
      "Epoch: 708, Loss: 54222.7773, Train: 77.80%, Valid: 79.50% Test: 77.75%\n",
      "Epoch: 709, Loss: 54231.7227, Train: 77.80%, Valid: 79.50% Test: 77.75%\n",
      "Epoch: 710, Loss: 54222.6875, Train: 77.79%, Valid: 79.50% Test: 77.69%\n",
      "Epoch: 711, Loss: 54230.5430, Train: 77.84%, Valid: 79.50% Test: 77.69%\n",
      "Epoch: 712, Loss: 54212.6445, Train: 77.87%, Valid: 79.71% Test: 77.69%\n",
      "Epoch: 713, Loss: 54215.3633, Train: 77.87%, Valid: 79.78% Test: 77.69%\n",
      "Epoch: 714, Loss: 54221.7852, Train: 77.86%, Valid: 79.71% Test: 77.69%\n",
      "Epoch: 715, Loss: 54244.4766, Train: 77.87%, Valid: 79.64% Test: 77.75%\n",
      "Epoch: 716, Loss: 54216.7031, Train: 77.88%, Valid: 79.71% Test: 77.69%\n",
      "Epoch: 717, Loss: 54221.5312, Train: 77.89%, Valid: 79.71% Test: 77.69%\n",
      "Epoch: 718, Loss: 54212.3672, Train: 77.89%, Valid: 79.71% Test: 77.69%\n",
      "Epoch: 719, Loss: 54218.2344, Train: 77.90%, Valid: 79.71% Test: 77.89%\n",
      "Epoch: 720, Loss: 54200.0859, Train: 77.91%, Valid: 79.71% Test: 77.75%\n",
      "Epoch: 721, Loss: 54224.9922, Train: 77.93%, Valid: 79.71% Test: 77.75%\n",
      "Epoch: 722, Loss: 54199.8750, Train: 77.93%, Valid: 79.71% Test: 77.69%\n",
      "Epoch: 723, Loss: 54224.1953, Train: 77.93%, Valid: 79.71% Test: 77.62%\n",
      "Epoch: 724, Loss: 54205.8750, Train: 77.94%, Valid: 79.71% Test: 77.62%\n",
      "Epoch: 725, Loss: 54198.5547, Train: 77.94%, Valid: 79.71% Test: 77.69%\n",
      "Epoch: 726, Loss: 54220.9062, Train: 77.93%, Valid: 79.71% Test: 77.69%\n",
      "Epoch: 727, Loss: 54220.2891, Train: 77.92%, Valid: 79.71% Test: 77.75%\n",
      "Epoch: 728, Loss: 54216.6562, Train: 77.93%, Valid: 79.71% Test: 77.75%\n",
      "Epoch: 729, Loss: 54202.2500, Train: 77.92%, Valid: 79.71% Test: 77.75%\n",
      "Epoch: 730, Loss: 54203.3867, Train: 77.93%, Valid: 79.71% Test: 77.69%\n",
      "Epoch: 731, Loss: 54213.9727, Train: 77.93%, Valid: 79.71% Test: 77.75%\n",
      "Epoch: 732, Loss: 54210.6406, Train: 77.92%, Valid: 79.71% Test: 77.69%\n",
      "Epoch: 733, Loss: 54205.4883, Train: 77.93%, Valid: 79.64% Test: 77.62%\n",
      "Epoch: 734, Loss: 54234.0078, Train: 77.92%, Valid: 79.64% Test: 77.62%\n",
      "Epoch: 735, Loss: 54210.4883, Train: 77.92%, Valid: 79.57% Test: 77.75%\n",
      "Epoch: 736, Loss: 54189.1719, Train: 77.93%, Valid: 79.57% Test: 77.75%\n",
      "Epoch: 737, Loss: 54197.3125, Train: 77.93%, Valid: 79.57% Test: 77.82%\n",
      "Epoch: 738, Loss: 54204.1719, Train: 77.91%, Valid: 79.64% Test: 77.82%\n",
      "Epoch: 739, Loss: 54183.9883, Train: 77.87%, Valid: 79.64% Test: 77.69%\n",
      "Epoch: 740, Loss: 54205.7539, Train: 77.83%, Valid: 79.64% Test: 77.75%\n",
      "Epoch: 741, Loss: 54206.8047, Train: 77.84%, Valid: 79.64% Test: 77.75%\n",
      "Epoch: 742, Loss: 54204.3281, Train: 77.86%, Valid: 79.64% Test: 77.69%\n",
      "Epoch: 743, Loss: 54193.8359, Train: 77.85%, Valid: 79.64% Test: 77.69%\n",
      "Epoch: 744, Loss: 54200.6445, Train: 77.85%, Valid: 79.64% Test: 77.69%\n",
      "Epoch: 745, Loss: 54188.3477, Train: 77.84%, Valid: 79.64% Test: 77.69%\n",
      "Epoch: 746, Loss: 54182.8242, Train: 77.92%, Valid: 79.64% Test: 77.69%\n",
      "Epoch: 747, Loss: 54187.6562, Train: 77.91%, Valid: 79.64% Test: 77.75%\n",
      "Epoch: 748, Loss: 54176.2578, Train: 77.91%, Valid: 79.64% Test: 77.75%\n",
      "Epoch: 749, Loss: 54192.4453, Train: 77.91%, Valid: 79.64% Test: 77.75%\n",
      "Epoch: 750, Loss: 54189.3594, Train: 77.93%, Valid: 79.64% Test: 77.75%\n",
      "Epoch: 751, Loss: 54196.1797, Train: 77.92%, Valid: 79.64% Test: 77.89%\n",
      "Epoch: 752, Loss: 54194.3906, Train: 77.95%, Valid: 79.64% Test: 77.89%\n",
      "Epoch: 753, Loss: 54215.6680, Train: 77.93%, Valid: 79.64% Test: 77.89%\n",
      "Epoch: 754, Loss: 54192.7383, Train: 77.90%, Valid: 79.71% Test: 77.89%\n",
      "Epoch: 755, Loss: 54177.0781, Train: 77.87%, Valid: 79.64% Test: 77.69%\n",
      "Epoch: 756, Loss: 54175.8750, Train: 77.84%, Valid: 79.64% Test: 77.69%\n",
      "Epoch: 757, Loss: 54185.7734, Train: 77.83%, Valid: 79.64% Test: 77.62%\n",
      "Epoch: 758, Loss: 54182.9922, Train: 77.85%, Valid: 79.71% Test: 77.55%\n",
      "Epoch: 759, Loss: 54185.8594, Train: 77.83%, Valid: 79.71% Test: 77.62%\n",
      "Epoch: 760, Loss: 54193.5508, Train: 77.82%, Valid: 79.71% Test: 77.62%\n",
      "Epoch: 761, Loss: 54194.7227, Train: 77.85%, Valid: 79.71% Test: 77.62%\n",
      "Epoch: 762, Loss: 54164.6445, Train: 77.83%, Valid: 79.57% Test: 77.55%\n",
      "Epoch: 763, Loss: 54180.1875, Train: 77.85%, Valid: 79.64% Test: 77.62%\n",
      "Epoch: 764, Loss: 54159.1250, Train: 77.86%, Valid: 79.57% Test: 77.75%\n",
      "Epoch: 765, Loss: 54182.0898, Train: 77.87%, Valid: 79.57% Test: 77.75%\n",
      "Epoch: 766, Loss: 54152.2812, Train: 77.87%, Valid: 79.64% Test: 77.75%\n",
      "Epoch: 767, Loss: 54177.4258, Train: 77.86%, Valid: 79.64% Test: 77.69%\n",
      "Epoch: 768, Loss: 54169.8438, Train: 77.83%, Valid: 79.64% Test: 77.69%\n",
      "Epoch: 769, Loss: 54156.9414, Train: 77.80%, Valid: 79.57% Test: 77.62%\n",
      "Epoch: 770, Loss: 54163.3789, Train: 77.80%, Valid: 79.57% Test: 77.62%\n",
      "Epoch: 771, Loss: 54163.1445, Train: 77.77%, Valid: 79.50% Test: 77.55%\n",
      "Epoch: 772, Loss: 54165.4766, Train: 77.78%, Valid: 79.57% Test: 77.62%\n",
      "Epoch: 773, Loss: 54174.8945, Train: 77.77%, Valid: 79.64% Test: 77.62%\n",
      "Epoch: 774, Loss: 54154.0391, Train: 77.79%, Valid: 79.57% Test: 77.41%\n",
      "Epoch: 775, Loss: 54173.5859, Train: 77.79%, Valid: 79.50% Test: 77.34%\n",
      "Epoch: 776, Loss: 54166.7500, Train: 77.80%, Valid: 79.50% Test: 77.41%\n",
      "Epoch: 777, Loss: 54140.0938, Train: 77.79%, Valid: 79.50% Test: 77.27%\n",
      "Epoch: 778, Loss: 54138.2500, Train: 77.79%, Valid: 79.43% Test: 77.20%\n",
      "Epoch: 779, Loss: 54168.7812, Train: 77.80%, Valid: 79.36% Test: 77.34%\n",
      "Epoch: 780, Loss: 54162.1523, Train: 77.82%, Valid: 79.36% Test: 77.34%\n",
      "Epoch: 781, Loss: 54157.4453, Train: 77.83%, Valid: 79.50% Test: 77.55%\n",
      "Epoch: 782, Loss: 54135.9766, Train: 77.84%, Valid: 79.50% Test: 77.62%\n",
      "Epoch: 783, Loss: 54144.5391, Train: 77.84%, Valid: 79.64% Test: 77.62%\n",
      "Epoch: 784, Loss: 54130.5820, Train: 77.86%, Valid: 79.71% Test: 77.69%\n",
      "Epoch: 785, Loss: 54145.1133, Train: 77.85%, Valid: 79.71% Test: 77.69%\n",
      "Epoch: 786, Loss: 54152.0547, Train: 77.84%, Valid: 79.71% Test: 77.62%\n",
      "Epoch: 787, Loss: 54142.0547, Train: 77.85%, Valid: 79.71% Test: 77.62%\n",
      "Epoch: 788, Loss: 54155.8086, Train: 77.86%, Valid: 79.64% Test: 77.48%\n",
      "Epoch: 789, Loss: 54144.5703, Train: 77.81%, Valid: 79.64% Test: 77.48%\n",
      "Epoch: 790, Loss: 54150.3359, Train: 77.82%, Valid: 79.64% Test: 77.62%\n",
      "Epoch: 791, Loss: 54150.5156, Train: 77.87%, Valid: 79.71% Test: 77.62%\n",
      "Epoch: 792, Loss: 54139.8281, Train: 77.87%, Valid: 79.71% Test: 77.75%\n",
      "Epoch: 793, Loss: 54142.9766, Train: 77.87%, Valid: 79.78% Test: 77.82%\n",
      "Epoch: 794, Loss: 54152.5820, Train: 77.85%, Valid: 79.71% Test: 77.89%\n",
      "Epoch: 795, Loss: 54163.2578, Train: 77.76%, Valid: 79.57% Test: 77.62%\n",
      "Epoch: 796, Loss: 54142.9922, Train: 77.68%, Valid: 79.57% Test: 77.62%\n",
      "Epoch: 797, Loss: 54135.1289, Train: 77.58%, Valid: 79.57% Test: 77.62%\n",
      "Epoch: 798, Loss: 54150.5898, Train: 77.56%, Valid: 79.57% Test: 77.55%\n",
      "Epoch: 799, Loss: 54132.4141, Train: 77.54%, Valid: 79.50% Test: 77.34%\n",
      "Epoch: 800, Loss: 54131.3633, Train: 77.49%, Valid: 79.50% Test: 77.34%\n",
      "Epoch: 801, Loss: 54143.4375, Train: 77.49%, Valid: 79.43% Test: 77.34%\n",
      "Epoch: 802, Loss: 54136.2852, Train: 77.50%, Valid: 79.43% Test: 77.13%\n",
      "Epoch: 803, Loss: 54155.7734, Train: 77.54%, Valid: 79.43% Test: 77.13%\n",
      "Epoch: 804, Loss: 54122.2070, Train: 77.58%, Valid: 79.50% Test: 77.27%\n",
      "Epoch: 805, Loss: 54115.5859, Train: 77.61%, Valid: 79.50% Test: 77.34%\n",
      "Epoch: 806, Loss: 54117.9141, Train: 77.61%, Valid: 79.50% Test: 77.41%\n",
      "Epoch: 807, Loss: 54131.6367, Train: 77.66%, Valid: 79.50% Test: 77.55%\n",
      "Epoch: 808, Loss: 54130.7773, Train: 77.65%, Valid: 79.57% Test: 77.48%\n",
      "Epoch: 809, Loss: 54122.1562, Train: 77.66%, Valid: 79.64% Test: 77.69%\n",
      "Epoch: 810, Loss: 54139.8008, Train: 77.67%, Valid: 79.71% Test: 77.69%\n",
      "Epoch: 811, Loss: 54121.6289, Train: 77.66%, Valid: 79.71% Test: 77.69%\n",
      "Epoch: 812, Loss: 54123.8750, Train: 77.68%, Valid: 79.71% Test: 77.69%\n",
      "Epoch: 813, Loss: 54142.4297, Train: 77.67%, Valid: 79.71% Test: 77.62%\n",
      "Epoch: 814, Loss: 54121.7617, Train: 77.64%, Valid: 79.50% Test: 77.55%\n",
      "Epoch: 815, Loss: 54117.9609, Train: 77.61%, Valid: 79.43% Test: 77.48%\n",
      "Epoch: 816, Loss: 54122.9531, Train: 77.61%, Valid: 79.50% Test: 77.41%\n",
      "Epoch: 817, Loss: 54150.3594, Train: 77.64%, Valid: 79.43% Test: 77.48%\n",
      "Epoch: 818, Loss: 54131.2188, Train: 77.65%, Valid: 79.43% Test: 77.41%\n",
      "Epoch: 819, Loss: 54110.6094, Train: 77.64%, Valid: 79.43% Test: 77.41%\n",
      "Epoch: 820, Loss: 54129.8789, Train: 77.62%, Valid: 79.36% Test: 77.55%\n",
      "Epoch: 821, Loss: 54132.6953, Train: 77.61%, Valid: 79.36% Test: 77.41%\n",
      "Epoch: 822, Loss: 54103.1641, Train: 77.63%, Valid: 79.43% Test: 77.41%\n",
      "Epoch: 823, Loss: 54127.3164, Train: 77.63%, Valid: 79.50% Test: 77.34%\n",
      "Epoch: 824, Loss: 54130.2344, Train: 77.61%, Valid: 79.50% Test: 77.27%\n",
      "Epoch: 825, Loss: 54127.0508, Train: 77.63%, Valid: 79.57% Test: 77.27%\n",
      "Epoch: 826, Loss: 54101.1602, Train: 77.69%, Valid: 79.64% Test: 77.34%\n",
      "Epoch: 827, Loss: 54111.2578, Train: 77.70%, Valid: 79.57% Test: 77.34%\n",
      "Epoch: 828, Loss: 54125.2070, Train: 77.73%, Valid: 79.57% Test: 77.34%\n",
      "Epoch: 829, Loss: 54141.6680, Train: 77.72%, Valid: 79.57% Test: 77.48%\n",
      "Epoch: 830, Loss: 54114.4922, Train: 77.71%, Valid: 79.57% Test: 77.48%\n",
      "Epoch: 831, Loss: 54123.1406, Train: 77.71%, Valid: 79.57% Test: 77.55%\n",
      "Epoch: 832, Loss: 54113.6562, Train: 77.67%, Valid: 79.57% Test: 77.48%\n",
      "Epoch: 833, Loss: 54125.5703, Train: 77.68%, Valid: 79.64% Test: 77.27%\n",
      "Epoch: 834, Loss: 54113.8984, Train: 77.67%, Valid: 79.64% Test: 77.34%\n",
      "Epoch: 835, Loss: 54115.6719, Train: 77.63%, Valid: 79.64% Test: 77.34%\n",
      "Epoch: 836, Loss: 54089.8281, Train: 77.66%, Valid: 79.64% Test: 77.41%\n",
      "Epoch: 837, Loss: 54106.4219, Train: 77.63%, Valid: 79.43% Test: 77.41%\n",
      "Epoch: 838, Loss: 54109.3594, Train: 77.62%, Valid: 79.50% Test: 77.55%\n",
      "Epoch: 839, Loss: 54112.0547, Train: 77.65%, Valid: 79.57% Test: 77.55%\n",
      "Epoch: 840, Loss: 54119.3438, Train: 77.67%, Valid: 79.64% Test: 77.55%\n",
      "Epoch: 841, Loss: 54120.7188, Train: 77.69%, Valid: 79.57% Test: 77.48%\n",
      "Epoch: 842, Loss: 54095.9219, Train: 77.70%, Valid: 79.50% Test: 77.48%\n",
      "Epoch: 843, Loss: 54107.4531, Train: 77.74%, Valid: 79.57% Test: 77.55%\n",
      "Epoch: 844, Loss: 54122.2500, Train: 77.75%, Valid: 79.71% Test: 77.62%\n",
      "Epoch: 845, Loss: 54113.2344, Train: 77.77%, Valid: 79.71% Test: 77.69%\n",
      "Epoch: 846, Loss: 54128.6523, Train: 77.78%, Valid: 79.64% Test: 77.75%\n",
      "Epoch: 847, Loss: 54094.9062, Train: 77.76%, Valid: 79.50% Test: 77.75%\n",
      "Epoch: 848, Loss: 54102.1484, Train: 77.73%, Valid: 79.43% Test: 77.75%\n",
      "Epoch: 849, Loss: 54101.5977, Train: 77.71%, Valid: 79.50% Test: 77.75%\n",
      "Epoch: 850, Loss: 54104.1172, Train: 77.76%, Valid: 79.64% Test: 77.75%\n",
      "Epoch: 851, Loss: 54126.8164, Train: 77.75%, Valid: 79.64% Test: 77.75%\n",
      "Epoch: 852, Loss: 54084.4922, Train: 77.75%, Valid: 79.71% Test: 77.75%\n",
      "Epoch: 853, Loss: 54113.4102, Train: 77.78%, Valid: 79.78% Test: 77.75%\n",
      "Epoch: 854, Loss: 54104.9414, Train: 77.78%, Valid: 79.71% Test: 77.69%\n",
      "Epoch: 855, Loss: 54107.9141, Train: 77.77%, Valid: 79.64% Test: 77.55%\n",
      "Epoch: 856, Loss: 54108.4219, Train: 77.73%, Valid: 79.57% Test: 77.41%\n",
      "Epoch: 857, Loss: 54110.3789, Train: 77.76%, Valid: 79.64% Test: 77.27%\n",
      "Epoch: 858, Loss: 54103.2617, Train: 77.79%, Valid: 79.64% Test: 77.20%\n",
      "Epoch: 859, Loss: 54095.7422, Train: 77.77%, Valid: 79.71% Test: 77.27%\n",
      "Epoch: 860, Loss: 54108.0859, Train: 77.75%, Valid: 79.71% Test: 77.20%\n",
      "Epoch: 861, Loss: 54088.6484, Train: 77.75%, Valid: 79.64% Test: 77.27%\n",
      "Epoch: 862, Loss: 54100.6094, Train: 77.71%, Valid: 79.57% Test: 77.41%\n",
      "Epoch: 863, Loss: 54099.3711, Train: 77.70%, Valid: 79.71% Test: 77.41%\n",
      "Epoch: 864, Loss: 54093.4531, Train: 77.73%, Valid: 79.71% Test: 77.41%\n",
      "Epoch: 865, Loss: 54090.8477, Train: 77.72%, Valid: 79.71% Test: 77.55%\n",
      "Epoch: 866, Loss: 54103.7148, Train: 77.71%, Valid: 79.71% Test: 77.48%\n",
      "Epoch: 867, Loss: 54105.1875, Train: 77.74%, Valid: 79.64% Test: 77.48%\n",
      "Epoch: 868, Loss: 54091.7148, Train: 77.74%, Valid: 79.57% Test: 77.48%\n",
      "Epoch: 869, Loss: 54092.5703, Train: 77.77%, Valid: 79.57% Test: 77.48%\n",
      "Epoch: 870, Loss: 54077.4648, Train: 77.75%, Valid: 79.64% Test: 77.48%\n",
      "Epoch: 871, Loss: 54079.6875, Train: 77.75%, Valid: 79.57% Test: 77.62%\n",
      "Epoch: 872, Loss: 54086.7422, Train: 77.77%, Valid: 79.50% Test: 77.55%\n",
      "Epoch: 873, Loss: 54088.0312, Train: 77.79%, Valid: 79.57% Test: 77.48%\n",
      "Epoch: 874, Loss: 54087.9414, Train: 77.80%, Valid: 79.64% Test: 77.69%\n",
      "Epoch: 875, Loss: 54080.4375, Train: 77.91%, Valid: 79.64% Test: 77.69%\n",
      "Epoch: 876, Loss: 54083.5352, Train: 77.99%, Valid: 79.99% Test: 77.69%\n",
      "Epoch: 877, Loss: 54077.0469, Train: 78.01%, Valid: 79.99% Test: 77.75%\n",
      "Epoch: 878, Loss: 54061.3086, Train: 78.01%, Valid: 79.99% Test: 77.75%\n",
      "Epoch: 879, Loss: 54082.8125, Train: 78.00%, Valid: 79.99% Test: 77.69%\n",
      "Epoch: 880, Loss: 54073.0078, Train: 77.98%, Valid: 79.92% Test: 77.62%\n",
      "Epoch: 881, Loss: 54073.0156, Train: 77.97%, Valid: 79.78% Test: 77.48%\n",
      "Epoch: 882, Loss: 54087.2656, Train: 77.96%, Valid: 79.71% Test: 77.62%\n",
      "Epoch: 883, Loss: 54061.0273, Train: 77.97%, Valid: 79.78% Test: 77.69%\n",
      "Epoch: 884, Loss: 54064.3086, Train: 78.05%, Valid: 79.85% Test: 77.89%\n",
      "Epoch: 885, Loss: 54087.4883, Train: 78.05%, Valid: 79.85% Test: 77.82%\n",
      "Epoch: 886, Loss: 54068.1328, Train: 78.06%, Valid: 79.85% Test: 77.75%\n",
      "Epoch: 887, Loss: 54093.1797, Train: 78.05%, Valid: 79.85% Test: 77.82%\n",
      "Epoch: 888, Loss: 54069.9922, Train: 78.06%, Valid: 79.92% Test: 77.89%\n",
      "Epoch: 889, Loss: 54067.8750, Train: 78.05%, Valid: 79.92% Test: 77.96%\n",
      "Epoch: 890, Loss: 54047.2812, Train: 78.05%, Valid: 79.78% Test: 78.03%\n",
      "Epoch: 891, Loss: 54095.6836, Train: 78.02%, Valid: 79.78% Test: 77.89%\n",
      "Epoch: 892, Loss: 54082.8477, Train: 78.00%, Valid: 79.64% Test: 77.89%\n",
      "Epoch: 893, Loss: 54075.1406, Train: 77.98%, Valid: 79.64% Test: 77.82%\n",
      "Epoch: 894, Loss: 54055.0859, Train: 77.97%, Valid: 79.64% Test: 77.82%\n",
      "Epoch: 895, Loss: 54078.4453, Train: 77.99%, Valid: 79.71% Test: 77.89%\n",
      "Epoch: 896, Loss: 54069.1875, Train: 78.01%, Valid: 79.71% Test: 77.96%\n",
      "Epoch: 897, Loss: 54056.5859, Train: 78.02%, Valid: 79.78% Test: 77.82%\n",
      "Epoch: 898, Loss: 54065.6367, Train: 78.05%, Valid: 79.78% Test: 77.82%\n",
      "Epoch: 899, Loss: 54050.4219, Train: 78.05%, Valid: 79.85% Test: 77.89%\n",
      "Epoch: 900, Loss: 54079.2031, Train: 78.06%, Valid: 79.78% Test: 77.89%\n",
      "Epoch: 901, Loss: 54065.7188, Train: 78.07%, Valid: 79.78% Test: 77.96%\n",
      "Epoch: 902, Loss: 54041.9219, Train: 78.06%, Valid: 79.85% Test: 77.96%\n",
      "Epoch: 903, Loss: 54044.0898, Train: 78.05%, Valid: 79.78% Test: 78.10%\n",
      "Epoch: 904, Loss: 54057.7031, Train: 78.01%, Valid: 79.71% Test: 78.10%\n",
      "Epoch: 905, Loss: 54060.9375, Train: 78.02%, Valid: 79.71% Test: 77.96%\n",
      "Epoch: 906, Loss: 54046.9766, Train: 78.02%, Valid: 79.57% Test: 78.03%\n",
      "Epoch: 907, Loss: 54064.7422, Train: 77.99%, Valid: 79.50% Test: 77.82%\n",
      "Epoch: 908, Loss: 54064.5547, Train: 77.94%, Valid: 79.50% Test: 77.75%\n",
      "Epoch: 909, Loss: 54080.3633, Train: 77.96%, Valid: 79.64% Test: 77.82%\n",
      "Epoch: 910, Loss: 54030.9453, Train: 77.99%, Valid: 79.71% Test: 77.82%\n",
      "Epoch: 911, Loss: 54072.7891, Train: 77.98%, Valid: 79.71% Test: 77.89%\n",
      "Epoch: 912, Loss: 54075.7969, Train: 77.95%, Valid: 79.78% Test: 78.10%\n",
      "Epoch: 913, Loss: 54083.6406, Train: 77.94%, Valid: 79.71% Test: 78.10%\n",
      "Epoch: 914, Loss: 54041.0469, Train: 77.97%, Valid: 79.71% Test: 78.10%\n",
      "Epoch: 915, Loss: 54051.7188, Train: 77.96%, Valid: 79.78% Test: 78.03%\n",
      "Epoch: 916, Loss: 54040.1797, Train: 77.95%, Valid: 79.78% Test: 77.96%\n",
      "Epoch: 917, Loss: 54059.5547, Train: 77.97%, Valid: 79.71% Test: 77.96%\n",
      "Epoch: 918, Loss: 54063.0703, Train: 77.98%, Valid: 79.71% Test: 77.89%\n",
      "Epoch: 919, Loss: 54057.4141, Train: 77.95%, Valid: 79.71% Test: 77.89%\n",
      "Epoch: 920, Loss: 54071.6719, Train: 77.99%, Valid: 79.85% Test: 77.82%\n",
      "Epoch: 921, Loss: 54048.3203, Train: 78.05%, Valid: 79.92% Test: 77.82%\n",
      "Epoch: 922, Loss: 54064.4336, Train: 78.12%, Valid: 79.92% Test: 77.96%\n",
      "Epoch: 923, Loss: 54043.8477, Train: 78.15%, Valid: 79.92% Test: 78.10%\n",
      "Epoch: 924, Loss: 54067.9062, Train: 78.16%, Valid: 79.99% Test: 78.10%\n",
      "Epoch: 925, Loss: 54084.9688, Train: 78.15%, Valid: 79.99% Test: 77.96%\n",
      "Epoch: 926, Loss: 54063.0117, Train: 78.15%, Valid: 79.92% Test: 77.96%\n",
      "Epoch: 927, Loss: 54051.2812, Train: 78.12%, Valid: 79.92% Test: 77.89%\n",
      "Epoch: 928, Loss: 54054.8203, Train: 78.10%, Valid: 79.85% Test: 77.82%\n",
      "Epoch: 929, Loss: 54045.1406, Train: 78.05%, Valid: 79.78% Test: 77.89%\n",
      "Epoch: 930, Loss: 54038.1953, Train: 78.03%, Valid: 79.71% Test: 77.89%\n",
      "Epoch: 931, Loss: 54045.9258, Train: 78.03%, Valid: 79.71% Test: 77.96%\n",
      "Epoch: 932, Loss: 54054.3594, Train: 78.02%, Valid: 79.71% Test: 78.03%\n",
      "Epoch: 933, Loss: 54062.2578, Train: 78.05%, Valid: 79.64% Test: 78.10%\n",
      "Epoch: 934, Loss: 54053.6367, Train: 78.11%, Valid: 79.57% Test: 78.03%\n",
      "Epoch: 935, Loss: 54068.6367, Train: 78.12%, Valid: 79.50% Test: 78.03%\n",
      "Epoch: 936, Loss: 54043.9922, Train: 78.12%, Valid: 79.64% Test: 78.10%\n",
      "Epoch: 937, Loss: 54077.3867, Train: 78.24%, Valid: 79.92% Test: 78.24%\n",
      "Epoch: 938, Loss: 54052.3281, Train: 78.31%, Valid: 79.92% Test: 78.24%\n",
      "Epoch: 939, Loss: 54043.9688, Train: 78.34%, Valid: 79.99% Test: 78.24%\n",
      "Epoch: 940, Loss: 54035.2656, Train: 78.27%, Valid: 80.06% Test: 78.10%\n",
      "Epoch: 941, Loss: 54017.3750, Train: 78.31%, Valid: 80.06% Test: 78.10%\n",
      "Epoch: 942, Loss: 54043.7969, Train: 78.30%, Valid: 80.06% Test: 78.10%\n",
      "Epoch: 943, Loss: 54039.3398, Train: 78.28%, Valid: 80.12% Test: 78.10%\n",
      "Epoch: 944, Loss: 54036.4883, Train: 78.24%, Valid: 79.92% Test: 78.24%\n",
      "Epoch: 945, Loss: 54035.9922, Train: 78.24%, Valid: 79.92% Test: 78.24%\n",
      "Epoch: 946, Loss: 54047.0547, Train: 78.27%, Valid: 80.06% Test: 78.17%\n",
      "Epoch: 947, Loss: 54044.4297, Train: 78.26%, Valid: 79.99% Test: 78.17%\n",
      "Epoch: 948, Loss: 54034.4844, Train: 78.28%, Valid: 79.92% Test: 78.17%\n",
      "Epoch: 949, Loss: 54023.1875, Train: 78.34%, Valid: 79.99% Test: 78.17%\n",
      "Epoch: 950, Loss: 54035.5859, Train: 78.38%, Valid: 79.99% Test: 78.17%\n",
      "Epoch: 951, Loss: 54027.7656, Train: 78.40%, Valid: 79.99% Test: 78.17%\n",
      "Epoch: 952, Loss: 54020.7422, Train: 78.42%, Valid: 79.99% Test: 78.17%\n",
      "Epoch: 953, Loss: 54029.3750, Train: 78.42%, Valid: 79.99% Test: 78.17%\n",
      "Epoch: 954, Loss: 54019.0938, Train: 78.40%, Valid: 79.99% Test: 78.03%\n",
      "Epoch: 955, Loss: 54042.4961, Train: 78.38%, Valid: 79.99% Test: 77.96%\n",
      "Epoch: 956, Loss: 54047.1055, Train: 78.36%, Valid: 79.92% Test: 77.96%\n",
      "Epoch: 957, Loss: 54023.7695, Train: 78.32%, Valid: 79.85% Test: 77.96%\n",
      "Epoch: 958, Loss: 54028.9453, Train: 78.31%, Valid: 79.85% Test: 77.96%\n",
      "Epoch: 959, Loss: 54017.8789, Train: 78.32%, Valid: 79.85% Test: 78.03%\n",
      "Epoch: 960, Loss: 54006.4688, Train: 78.32%, Valid: 79.78% Test: 78.03%\n",
      "Epoch: 961, Loss: 54015.1953, Train: 78.31%, Valid: 79.78% Test: 78.17%\n",
      "Epoch: 962, Loss: 54038.3594, Train: 78.31%, Valid: 79.78% Test: 78.17%\n",
      "Epoch: 963, Loss: 54036.1484, Train: 78.32%, Valid: 79.92% Test: 78.24%\n",
      "Epoch: 964, Loss: 54006.6094, Train: 78.31%, Valid: 79.85% Test: 78.31%\n",
      "Epoch: 965, Loss: 54034.0859, Train: 78.33%, Valid: 79.92% Test: 78.24%\n",
      "Epoch: 966, Loss: 53985.3164, Train: 78.31%, Valid: 79.92% Test: 78.31%\n",
      "Epoch: 967, Loss: 54013.7539, Train: 78.28%, Valid: 79.85% Test: 78.24%\n",
      "Epoch: 968, Loss: 54016.4297, Train: 78.32%, Valid: 79.92% Test: 78.24%\n",
      "Epoch: 969, Loss: 54017.6562, Train: 78.34%, Valid: 79.92% Test: 78.17%\n",
      "Epoch: 970, Loss: 54021.7266, Train: 78.35%, Valid: 79.92% Test: 78.10%\n",
      "Epoch: 971, Loss: 54025.6641, Train: 78.37%, Valid: 79.99% Test: 78.10%\n",
      "Epoch: 972, Loss: 54014.6953, Train: 78.34%, Valid: 79.92% Test: 78.03%\n",
      "Epoch: 973, Loss: 54026.8594, Train: 78.33%, Valid: 79.92% Test: 78.03%\n",
      "Epoch: 974, Loss: 54024.3984, Train: 78.26%, Valid: 79.92% Test: 78.03%\n",
      "Epoch: 975, Loss: 54022.8164, Train: 78.18%, Valid: 79.85% Test: 78.10%\n",
      "Epoch: 976, Loss: 54010.8125, Train: 78.17%, Valid: 79.85% Test: 77.96%\n",
      "Epoch: 977, Loss: 54007.3320, Train: 78.22%, Valid: 79.99% Test: 78.10%\n",
      "Epoch: 978, Loss: 54016.7656, Train: 78.29%, Valid: 79.99% Test: 78.10%\n",
      "Epoch: 979, Loss: 54017.2031, Train: 78.33%, Valid: 79.92% Test: 78.10%\n",
      "Epoch: 980, Loss: 53999.7422, Train: 78.36%, Valid: 79.92% Test: 78.24%\n",
      "Epoch: 981, Loss: 54009.4609, Train: 78.40%, Valid: 79.99% Test: 78.37%\n",
      "Epoch: 982, Loss: 54003.6719, Train: 78.47%, Valid: 80.06% Test: 78.37%\n",
      "Epoch: 983, Loss: 54005.5430, Train: 78.48%, Valid: 80.12% Test: 78.37%\n",
      "Epoch: 984, Loss: 54021.8516, Train: 78.49%, Valid: 80.12% Test: 78.37%\n",
      "Epoch: 985, Loss: 54012.0117, Train: 78.49%, Valid: 80.19% Test: 78.31%\n",
      "Epoch: 986, Loss: 54006.4922, Train: 78.49%, Valid: 80.19% Test: 78.31%\n",
      "Epoch: 987, Loss: 54004.7344, Train: 78.50%, Valid: 80.19% Test: 78.24%\n",
      "Epoch: 988, Loss: 54008.8359, Train: 78.46%, Valid: 80.19% Test: 78.24%\n",
      "Epoch: 989, Loss: 54010.3125, Train: 78.46%, Valid: 80.19% Test: 78.17%\n",
      "Epoch: 990, Loss: 54000.7930, Train: 78.47%, Valid: 80.06% Test: 78.03%\n",
      "Epoch: 991, Loss: 54014.0078, Train: 78.53%, Valid: 80.26% Test: 78.10%\n",
      "Epoch: 992, Loss: 53979.8828, Train: 78.54%, Valid: 80.19% Test: 78.10%\n",
      "Epoch: 993, Loss: 54019.1250, Train: 78.56%, Valid: 80.19% Test: 78.24%\n",
      "Epoch: 994, Loss: 53998.2031, Train: 78.56%, Valid: 80.19% Test: 78.44%\n",
      "Epoch: 995, Loss: 53986.8086, Train: 78.55%, Valid: 80.19% Test: 78.44%\n",
      "Epoch: 996, Loss: 54016.0703, Train: 78.53%, Valid: 80.06% Test: 78.51%\n",
      "Epoch: 997, Loss: 54004.0664, Train: 78.49%, Valid: 80.06% Test: 78.37%\n",
      "Epoch: 998, Loss: 54015.2578, Train: 78.47%, Valid: 80.06% Test: 78.31%\n",
      "Epoch: 999, Loss: 53987.8359, Train: 78.44%, Valid: 80.06% Test: 78.24%\n",
      "Epoch: 1000, Loss: 54012.7656, Train: 78.42%, Valid: 80.12% Test: 78.24%\n",
      "Epoch: 1001, Loss: 53987.8633, Train: 78.42%, Valid: 80.06% Test: 78.17%\n",
      "Epoch: 1002, Loss: 53979.5859, Train: 78.45%, Valid: 80.06% Test: 78.17%\n",
      "Epoch: 1003, Loss: 53995.4492, Train: 78.47%, Valid: 80.06% Test: 78.17%\n",
      "Epoch: 1004, Loss: 53998.8672, Train: 78.57%, Valid: 80.06% Test: 78.31%\n",
      "Epoch: 1005, Loss: 53986.4922, Train: 78.63%, Valid: 79.99% Test: 78.31%\n",
      "Epoch: 1006, Loss: 54022.7656, Train: 78.74%, Valid: 80.12% Test: 78.37%\n",
      "Epoch: 1007, Loss: 54004.3125, Train: 78.78%, Valid: 80.12% Test: 78.37%\n",
      "Epoch: 1008, Loss: 54008.5859, Train: 78.82%, Valid: 80.12% Test: 78.44%\n",
      "Epoch: 1009, Loss: 53973.4531, Train: 78.87%, Valid: 80.12% Test: 78.51%\n",
      "Epoch: 1010, Loss: 53984.0469, Train: 78.87%, Valid: 80.19% Test: 78.44%\n",
      "Epoch: 1011, Loss: 53981.2773, Train: 78.85%, Valid: 80.19% Test: 78.37%\n",
      "Epoch: 1012, Loss: 53977.9766, Train: 78.83%, Valid: 80.12% Test: 78.51%\n",
      "Epoch: 1013, Loss: 53994.9844, Train: 78.85%, Valid: 80.12% Test: 78.51%\n",
      "Epoch: 1014, Loss: 53954.1875, Train: 78.83%, Valid: 80.12% Test: 78.58%\n",
      "Epoch: 1015, Loss: 53963.5000, Train: 78.83%, Valid: 80.12% Test: 78.51%\n",
      "Epoch: 1016, Loss: 53978.6445, Train: 78.85%, Valid: 80.19% Test: 78.37%\n",
      "Epoch: 1017, Loss: 53968.1719, Train: 78.85%, Valid: 80.26% Test: 78.31%\n",
      "Epoch: 1018, Loss: 53946.4531, Train: 78.82%, Valid: 80.26% Test: 78.31%\n",
      "Epoch: 1019, Loss: 53965.2773, Train: 78.80%, Valid: 80.26% Test: 78.31%\n",
      "Epoch: 1020, Loss: 53970.4648, Train: 78.78%, Valid: 80.33% Test: 78.37%\n",
      "Epoch: 1021, Loss: 53970.1250, Train: 78.78%, Valid: 80.33% Test: 78.44%\n",
      "Epoch: 1022, Loss: 53973.8516, Train: 78.76%, Valid: 80.33% Test: 78.44%\n",
      "Epoch: 1023, Loss: 53979.4531, Train: 78.78%, Valid: 80.40% Test: 78.44%\n",
      "Epoch: 1024, Loss: 53997.7656, Train: 78.81%, Valid: 80.40% Test: 78.44%\n",
      "Epoch: 1025, Loss: 53983.3594, Train: 78.86%, Valid: 80.40% Test: 78.51%\n",
      "Epoch: 1026, Loss: 53959.7148, Train: 78.86%, Valid: 80.40% Test: 78.51%\n",
      "Epoch: 1027, Loss: 53965.2070, Train: 78.85%, Valid: 80.40% Test: 78.51%\n",
      "Epoch: 1028, Loss: 53952.3516, Train: 78.85%, Valid: 80.40% Test: 78.51%\n",
      "Epoch: 1029, Loss: 53955.0820, Train: 78.85%, Valid: 80.40% Test: 78.51%\n",
      "Epoch: 1030, Loss: 53982.9727, Train: 78.87%, Valid: 80.40% Test: 78.37%\n",
      "Epoch: 1031, Loss: 53979.2344, Train: 78.85%, Valid: 80.40% Test: 78.44%\n",
      "Epoch: 1032, Loss: 53977.4141, Train: 78.84%, Valid: 80.33% Test: 78.51%\n",
      "Epoch: 1033, Loss: 53960.9961, Train: 78.86%, Valid: 80.33% Test: 78.51%\n",
      "Epoch: 1034, Loss: 53948.2266, Train: 78.81%, Valid: 80.26% Test: 78.58%\n",
      "Epoch: 1035, Loss: 53956.9297, Train: 78.81%, Valid: 80.12% Test: 78.44%\n",
      "Epoch: 1036, Loss: 53962.0781, Train: 78.78%, Valid: 80.12% Test: 78.51%\n",
      "Epoch: 1037, Loss: 53965.1250, Train: 78.79%, Valid: 80.12% Test: 78.51%\n",
      "Epoch: 1038, Loss: 53950.6719, Train: 78.79%, Valid: 80.12% Test: 78.58%\n",
      "Epoch: 1039, Loss: 53944.5234, Train: 78.82%, Valid: 80.26% Test: 78.58%\n",
      "Epoch: 1040, Loss: 53986.1484, Train: 78.89%, Valid: 80.33% Test: 78.65%\n",
      "Epoch: 1041, Loss: 53959.1953, Train: 78.94%, Valid: 80.40% Test: 78.65%\n",
      "Epoch: 1042, Loss: 53959.4922, Train: 78.97%, Valid: 80.40% Test: 78.65%\n",
      "Epoch: 1043, Loss: 53933.3477, Train: 78.96%, Valid: 80.40% Test: 78.65%\n",
      "Epoch: 1044, Loss: 53956.7070, Train: 78.94%, Valid: 80.40% Test: 78.65%\n",
      "Epoch: 1045, Loss: 53956.6875, Train: 78.94%, Valid: 80.33% Test: 78.51%\n",
      "Epoch: 1046, Loss: 53947.1641, Train: 78.95%, Valid: 80.33% Test: 78.51%\n",
      "Epoch: 1047, Loss: 53937.1641, Train: 78.96%, Valid: 80.40% Test: 78.44%\n",
      "Epoch: 1048, Loss: 53955.5547, Train: 78.90%, Valid: 80.40% Test: 78.44%\n",
      "Epoch: 1049, Loss: 53962.6797, Train: 78.83%, Valid: 80.26% Test: 78.37%\n",
      "Epoch: 1050, Loss: 53959.5039, Train: 78.84%, Valid: 80.26% Test: 78.37%\n",
      "Epoch: 1051, Loss: 53959.5859, Train: 78.83%, Valid: 80.26% Test: 78.37%\n",
      "Epoch: 1052, Loss: 53967.9453, Train: 78.83%, Valid: 80.26% Test: 78.31%\n",
      "Epoch: 1053, Loss: 53960.6172, Train: 78.85%, Valid: 80.19% Test: 78.37%\n",
      "Epoch: 1054, Loss: 53946.4844, Train: 78.84%, Valid: 80.19% Test: 78.37%\n",
      "Epoch: 1055, Loss: 53944.1953, Train: 78.84%, Valid: 80.12% Test: 78.51%\n",
      "Epoch: 1056, Loss: 53958.4375, Train: 78.87%, Valid: 80.19% Test: 78.58%\n",
      "Epoch: 1057, Loss: 53951.2656, Train: 78.89%, Valid: 80.26% Test: 78.58%\n",
      "Epoch: 1058, Loss: 53951.6797, Train: 78.87%, Valid: 80.26% Test: 78.51%\n",
      "Epoch: 1059, Loss: 53953.9375, Train: 78.87%, Valid: 80.19% Test: 78.51%\n",
      "Epoch: 1060, Loss: 53955.7031, Train: 78.88%, Valid: 80.19% Test: 78.44%\n",
      "Epoch: 1061, Loss: 53949.2344, Train: 78.88%, Valid: 80.19% Test: 78.44%\n",
      "Epoch: 1062, Loss: 53941.0664, Train: 78.91%, Valid: 80.26% Test: 78.51%\n",
      "Epoch: 1063, Loss: 53936.4062, Train: 78.89%, Valid: 80.33% Test: 78.51%\n",
      "Epoch: 1064, Loss: 53931.5078, Train: 78.88%, Valid: 80.33% Test: 78.51%\n",
      "Epoch: 1065, Loss: 53940.1797, Train: 78.91%, Valid: 80.40% Test: 78.58%\n",
      "Epoch: 1066, Loss: 53950.4102, Train: 78.91%, Valid: 80.54% Test: 78.58%\n",
      "Epoch: 1067, Loss: 53958.5195, Train: 78.89%, Valid: 80.54% Test: 78.51%\n",
      "Epoch: 1068, Loss: 53947.5703, Train: 78.91%, Valid: 80.54% Test: 78.58%\n",
      "Epoch: 1069, Loss: 53933.5000, Train: 78.91%, Valid: 80.54% Test: 78.65%\n",
      "Epoch: 1070, Loss: 53951.4805, Train: 78.95%, Valid: 80.54% Test: 78.72%\n",
      "Epoch: 1071, Loss: 53934.5547, Train: 79.00%, Valid: 80.54% Test: 78.72%\n",
      "Epoch: 1072, Loss: 53937.5586, Train: 79.01%, Valid: 80.54% Test: 78.72%\n",
      "Epoch: 1073, Loss: 53917.9141, Train: 79.02%, Valid: 80.54% Test: 78.58%\n",
      "Epoch: 1074, Loss: 53923.8594, Train: 79.03%, Valid: 80.54% Test: 78.51%\n",
      "Epoch: 1075, Loss: 53948.5469, Train: 79.01%, Valid: 80.54% Test: 78.51%\n",
      "Epoch: 1076, Loss: 53950.9922, Train: 78.98%, Valid: 80.47% Test: 78.51%\n",
      "Epoch: 1077, Loss: 53944.8359, Train: 78.96%, Valid: 80.47% Test: 78.51%\n",
      "Epoch: 1078, Loss: 53925.4883, Train: 78.95%, Valid: 80.47% Test: 78.58%\n",
      "Epoch: 1079, Loss: 53942.3867, Train: 78.96%, Valid: 80.47% Test: 78.65%\n",
      "Epoch: 1080, Loss: 53934.3711, Train: 78.98%, Valid: 80.47% Test: 78.65%\n",
      "Epoch: 1081, Loss: 53951.9336, Train: 78.94%, Valid: 80.40% Test: 78.65%\n",
      "Epoch: 1082, Loss: 53956.8047, Train: 78.98%, Valid: 80.40% Test: 78.65%\n",
      "Epoch: 1083, Loss: 53932.0625, Train: 78.99%, Valid: 80.40% Test: 78.72%\n",
      "Epoch: 1084, Loss: 53957.8750, Train: 78.97%, Valid: 80.40% Test: 78.72%\n",
      "Epoch: 1085, Loss: 53916.2109, Train: 78.96%, Valid: 80.40% Test: 78.86%\n",
      "Epoch: 1086, Loss: 53942.2891, Train: 78.94%, Valid: 80.40% Test: 78.86%\n",
      "Epoch: 1087, Loss: 53964.0391, Train: 78.89%, Valid: 80.47% Test: 78.86%\n",
      "Epoch: 1088, Loss: 53962.8281, Train: 78.90%, Valid: 80.47% Test: 78.72%\n",
      "Epoch: 1089, Loss: 53966.7109, Train: 78.92%, Valid: 80.47% Test: 78.72%\n",
      "Epoch: 1090, Loss: 53929.1250, Train: 78.90%, Valid: 80.40% Test: 78.65%\n",
      "Epoch: 1091, Loss: 53931.0078, Train: 78.92%, Valid: 80.33% Test: 78.58%\n",
      "Epoch: 1092, Loss: 53944.9805, Train: 78.93%, Valid: 80.33% Test: 78.65%\n",
      "Epoch: 1093, Loss: 53915.7188, Train: 78.90%, Valid: 80.26% Test: 78.58%\n",
      "Epoch: 1094, Loss: 53960.3438, Train: 78.91%, Valid: 80.26% Test: 78.58%\n",
      "Epoch: 1095, Loss: 53934.1016, Train: 78.94%, Valid: 80.26% Test: 78.58%\n",
      "Epoch: 1096, Loss: 53932.4375, Train: 78.97%, Valid: 80.26% Test: 78.58%\n",
      "Epoch: 1097, Loss: 53927.7500, Train: 78.97%, Valid: 80.26% Test: 78.58%\n",
      "Epoch: 1098, Loss: 53965.7461, Train: 78.96%, Valid: 80.26% Test: 78.58%\n",
      "Epoch: 1099, Loss: 53934.9453, Train: 78.96%, Valid: 80.26% Test: 78.58%\n",
      "Epoch: 1100, Loss: 53932.7852, Train: 78.98%, Valid: 80.26% Test: 78.65%\n",
      "Epoch: 1101, Loss: 53914.6016, Train: 79.00%, Valid: 80.26% Test: 78.65%\n",
      "Epoch: 1102, Loss: 53942.9453, Train: 79.15%, Valid: 80.40% Test: 78.72%\n",
      "Epoch: 1103, Loss: 53920.3633, Train: 79.22%, Valid: 80.40% Test: 78.72%\n",
      "Epoch: 1104, Loss: 53949.0391, Train: 79.25%, Valid: 80.40% Test: 78.72%\n",
      "Epoch: 1105, Loss: 53928.7500, Train: 79.24%, Valid: 80.40% Test: 78.72%\n",
      "Epoch: 1106, Loss: 53943.8477, Train: 79.18%, Valid: 80.33% Test: 78.65%\n",
      "Epoch: 1107, Loss: 53921.3281, Train: 79.19%, Valid: 80.33% Test: 78.79%\n",
      "Epoch: 1108, Loss: 53938.7812, Train: 79.19%, Valid: 80.33% Test: 78.58%\n",
      "Epoch: 1109, Loss: 53933.5859, Train: 79.17%, Valid: 80.33% Test: 78.51%\n",
      "Epoch: 1110, Loss: 53903.0703, Train: 79.13%, Valid: 80.33% Test: 78.51%\n",
      "Epoch: 1111, Loss: 53920.7969, Train: 79.12%, Valid: 80.33% Test: 78.51%\n",
      "Epoch: 1112, Loss: 53926.7422, Train: 79.13%, Valid: 80.33% Test: 78.58%\n",
      "Epoch: 1113, Loss: 53928.6016, Train: 79.16%, Valid: 80.40% Test: 78.65%\n",
      "Epoch: 1114, Loss: 53926.2773, Train: 79.15%, Valid: 80.40% Test: 78.65%\n",
      "Epoch: 1115, Loss: 53930.1250, Train: 79.16%, Valid: 80.40% Test: 78.65%\n",
      "Epoch: 1116, Loss: 53926.6523, Train: 79.19%, Valid: 80.40% Test: 78.72%\n",
      "Epoch: 1117, Loss: 53907.9688, Train: 79.19%, Valid: 80.33% Test: 78.72%\n",
      "Epoch: 1118, Loss: 53943.1758, Train: 79.14%, Valid: 80.40% Test: 78.72%\n",
      "Epoch: 1119, Loss: 53908.9062, Train: 79.12%, Valid: 80.40% Test: 78.65%\n",
      "Epoch: 1120, Loss: 53895.4805, Train: 79.13%, Valid: 80.40% Test: 78.58%\n",
      "Epoch: 1121, Loss: 53922.3125, Train: 79.13%, Valid: 80.33% Test: 78.58%\n",
      "Epoch: 1122, Loss: 53943.7656, Train: 79.12%, Valid: 80.33% Test: 78.72%\n",
      "Epoch: 1123, Loss: 53928.8672, Train: 79.17%, Valid: 80.33% Test: 78.79%\n",
      "Epoch: 1124, Loss: 53933.2031, Train: 79.19%, Valid: 80.40% Test: 78.86%\n",
      "Epoch: 1125, Loss: 53913.2695, Train: 79.19%, Valid: 80.40% Test: 78.93%\n",
      "Epoch: 1126, Loss: 53909.6641, Train: 79.19%, Valid: 80.47% Test: 78.93%\n",
      "Epoch: 1127, Loss: 53942.0391, Train: 79.19%, Valid: 80.40% Test: 78.86%\n",
      "Epoch: 1128, Loss: 53918.4922, Train: 79.21%, Valid: 80.40% Test: 78.86%\n",
      "Epoch: 1129, Loss: 53926.9766, Train: 79.22%, Valid: 80.33% Test: 78.86%\n",
      "Epoch: 1130, Loss: 53944.4297, Train: 79.20%, Valid: 80.33% Test: 78.79%\n",
      "Epoch: 1131, Loss: 53892.0156, Train: 79.18%, Valid: 80.33% Test: 78.79%\n",
      "Epoch: 1132, Loss: 53913.0078, Train: 79.17%, Valid: 80.33% Test: 78.79%\n",
      "Epoch: 1133, Loss: 53932.0312, Train: 79.15%, Valid: 80.40% Test: 78.79%\n",
      "Epoch: 1134, Loss: 53892.3203, Train: 79.16%, Valid: 80.40% Test: 78.86%\n",
      "Epoch: 1135, Loss: 53920.6016, Train: 79.17%, Valid: 80.47% Test: 78.93%\n",
      "Epoch: 1136, Loss: 53935.5391, Train: 79.16%, Valid: 80.47% Test: 78.93%\n",
      "Epoch: 1137, Loss: 53893.8359, Train: 79.18%, Valid: 80.47% Test: 78.93%\n",
      "Epoch: 1138, Loss: 53906.1328, Train: 79.19%, Valid: 80.40% Test: 78.93%\n",
      "Epoch: 1139, Loss: 53897.0195, Train: 79.12%, Valid: 80.40% Test: 78.93%\n",
      "Epoch: 1140, Loss: 53917.5273, Train: 79.13%, Valid: 80.33% Test: 78.93%\n",
      "Epoch: 1141, Loss: 53926.9531, Train: 79.14%, Valid: 80.47% Test: 78.79%\n",
      "Epoch: 1142, Loss: 53916.3633, Train: 79.20%, Valid: 80.47% Test: 78.79%\n",
      "Epoch: 1143, Loss: 53918.4375, Train: 79.25%, Valid: 80.33% Test: 78.72%\n",
      "Epoch: 1144, Loss: 53895.9766, Train: 79.26%, Valid: 80.33% Test: 78.72%\n",
      "Epoch: 1145, Loss: 53902.3281, Train: 79.27%, Valid: 80.33% Test: 78.65%\n",
      "Epoch: 1146, Loss: 53926.8594, Train: 79.26%, Valid: 80.40% Test: 78.65%\n",
      "Epoch: 1147, Loss: 53906.8633, Train: 79.26%, Valid: 80.40% Test: 78.58%\n",
      "Epoch: 1148, Loss: 53888.9062, Train: 79.28%, Valid: 80.40% Test: 78.51%\n",
      "Epoch: 1149, Loss: 53908.1992, Train: 79.29%, Valid: 80.33% Test: 78.51%\n",
      "Epoch: 1150, Loss: 53904.8984, Train: 79.26%, Valid: 80.26% Test: 78.51%\n",
      "Epoch: 1151, Loss: 53905.3945, Train: 79.22%, Valid: 80.33% Test: 78.51%\n",
      "Epoch: 1152, Loss: 53907.3711, Train: 79.22%, Valid: 80.33% Test: 78.44%\n",
      "Epoch: 1153, Loss: 53904.1094, Train: 79.22%, Valid: 80.33% Test: 78.65%\n",
      "Epoch: 1154, Loss: 53898.3047, Train: 79.21%, Valid: 80.33% Test: 78.72%\n",
      "Epoch: 1155, Loss: 53924.6875, Train: 79.19%, Valid: 80.40% Test: 78.79%\n",
      "Epoch: 1156, Loss: 53911.9141, Train: 79.16%, Valid: 80.40% Test: 78.93%\n",
      "Epoch: 1157, Loss: 53922.4883, Train: 79.26%, Valid: 80.61% Test: 79.06%\n",
      "Epoch: 1158, Loss: 53904.6875, Train: 79.27%, Valid: 80.61% Test: 79.06%\n",
      "Epoch: 1159, Loss: 53912.6211, Train: 79.25%, Valid: 80.61% Test: 79.06%\n",
      "Epoch: 1160, Loss: 53875.9062, Train: 79.30%, Valid: 80.61% Test: 79.20%\n",
      "Epoch: 1161, Loss: 53892.6328, Train: 79.38%, Valid: 80.54% Test: 79.34%\n",
      "Epoch: 1162, Loss: 53861.3359, Train: 79.38%, Valid: 80.47% Test: 79.27%\n",
      "Epoch: 1163, Loss: 53906.3633, Train: 79.37%, Valid: 80.47% Test: 79.27%\n",
      "Epoch: 1164, Loss: 53908.8945, Train: 79.33%, Valid: 80.47% Test: 79.27%\n",
      "Epoch: 1165, Loss: 53895.6211, Train: 79.33%, Valid: 80.61% Test: 79.20%\n",
      "Epoch: 1166, Loss: 53891.3750, Train: 79.33%, Valid: 80.61% Test: 79.20%\n",
      "Epoch: 1167, Loss: 53891.2812, Train: 79.36%, Valid: 80.68% Test: 79.20%\n",
      "Epoch: 1168, Loss: 53881.5703, Train: 79.36%, Valid: 80.68% Test: 79.13%\n",
      "Epoch: 1169, Loss: 53901.3047, Train: 79.38%, Valid: 80.68% Test: 79.13%\n",
      "Epoch: 1170, Loss: 53894.3984, Train: 79.41%, Valid: 80.54% Test: 79.13%\n",
      "Epoch: 1171, Loss: 53878.6953, Train: 79.44%, Valid: 80.61% Test: 79.20%\n",
      "Epoch: 1172, Loss: 53869.6484, Train: 79.43%, Valid: 80.54% Test: 79.27%\n",
      "Epoch: 1173, Loss: 53881.3594, Train: 79.41%, Valid: 80.54% Test: 79.27%\n",
      "Epoch: 1174, Loss: 53882.6953, Train: 79.38%, Valid: 80.47% Test: 79.27%\n",
      "Epoch: 1175, Loss: 53885.8008, Train: 79.44%, Valid: 80.40% Test: 79.34%\n",
      "Epoch: 1176, Loss: 53910.1953, Train: 79.46%, Valid: 80.40% Test: 79.27%\n",
      "Epoch: 1177, Loss: 53889.0312, Train: 79.49%, Valid: 80.40% Test: 79.20%\n",
      "Epoch: 1178, Loss: 53887.8789, Train: 79.49%, Valid: 80.40% Test: 79.27%\n",
      "Epoch: 1179, Loss: 53880.7656, Train: 79.48%, Valid: 80.40% Test: 79.27%\n",
      "Epoch: 1180, Loss: 53898.5156, Train: 79.46%, Valid: 80.47% Test: 79.27%\n",
      "Epoch: 1181, Loss: 53899.2031, Train: 79.46%, Valid: 80.47% Test: 79.27%\n",
      "Epoch: 1182, Loss: 53887.5547, Train: 79.45%, Valid: 80.47% Test: 79.20%\n",
      "Epoch: 1183, Loss: 53895.0938, Train: 79.45%, Valid: 80.54% Test: 79.20%\n",
      "Epoch: 1184, Loss: 53866.6562, Train: 79.44%, Valid: 80.54% Test: 79.13%\n",
      "Epoch: 1185, Loss: 53889.1016, Train: 79.41%, Valid: 80.47% Test: 79.13%\n",
      "Epoch: 1186, Loss: 53880.4414, Train: 79.40%, Valid: 80.47% Test: 79.20%\n",
      "Epoch: 1187, Loss: 53877.2812, Train: 79.38%, Valid: 80.47% Test: 79.13%\n",
      "Epoch: 1188, Loss: 53878.4727, Train: 79.38%, Valid: 80.47% Test: 79.06%\n",
      "Epoch: 1189, Loss: 53891.2969, Train: 79.39%, Valid: 80.47% Test: 79.13%\n",
      "Epoch: 1190, Loss: 53900.7812, Train: 79.41%, Valid: 80.40% Test: 79.13%\n",
      "Epoch: 1191, Loss: 53888.5508, Train: 79.39%, Valid: 80.47% Test: 79.13%\n",
      "Epoch: 1192, Loss: 53887.5938, Train: 79.39%, Valid: 80.47% Test: 79.20%\n",
      "Epoch: 1193, Loss: 53880.1484, Train: 79.40%, Valid: 80.47% Test: 79.20%\n",
      "Epoch: 1194, Loss: 53903.9453, Train: 79.42%, Valid: 80.47% Test: 79.20%\n",
      "Epoch: 1195, Loss: 53902.1016, Train: 79.41%, Valid: 80.40% Test: 79.20%\n",
      "Epoch: 1196, Loss: 53878.6250, Train: 79.36%, Valid: 80.40% Test: 79.20%\n",
      "Epoch: 1197, Loss: 53883.3438, Train: 79.43%, Valid: 80.40% Test: 79.27%\n",
      "Epoch: 1198, Loss: 53875.6094, Train: 79.49%, Valid: 80.47% Test: 79.20%\n",
      "Epoch: 1199, Loss: 53882.3711, Train: 79.49%, Valid: 80.40% Test: 79.13%\n",
      "Epoch: 1200, Loss: 53875.9297, Train: 79.49%, Valid: 80.40% Test: 79.13%\n",
      "Epoch: 1201, Loss: 53885.3555, Train: 79.49%, Valid: 80.40% Test: 79.13%\n",
      "Epoch: 1202, Loss: 53883.3750, Train: 79.49%, Valid: 80.47% Test: 78.93%\n",
      "Epoch: 1203, Loss: 53885.2031, Train: 79.49%, Valid: 80.54% Test: 78.99%\n",
      "Epoch: 1204, Loss: 53906.2969, Train: 79.48%, Valid: 80.61% Test: 79.13%\n",
      "Epoch: 1205, Loss: 53891.0273, Train: 79.48%, Valid: 80.61% Test: 79.20%\n",
      "Epoch: 1206, Loss: 53884.2695, Train: 79.46%, Valid: 80.47% Test: 79.27%\n",
      "Epoch: 1207, Loss: 53891.2773, Train: 79.46%, Valid: 80.54% Test: 79.27%\n",
      "Epoch: 1208, Loss: 53906.3203, Train: 79.45%, Valid: 80.47% Test: 79.27%\n",
      "Epoch: 1209, Loss: 53896.7148, Train: 79.44%, Valid: 80.40% Test: 79.27%\n",
      "Epoch: 1210, Loss: 53885.5000, Train: 79.44%, Valid: 80.40% Test: 79.27%\n",
      "Epoch: 1211, Loss: 53888.6719, Train: 79.38%, Valid: 80.40% Test: 79.20%\n",
      "Epoch: 1212, Loss: 53883.3438, Train: 79.38%, Valid: 80.40% Test: 79.13%\n",
      "Epoch: 1213, Loss: 53874.8672, Train: 79.38%, Valid: 80.47% Test: 79.20%\n",
      "Epoch: 1214, Loss: 53897.5781, Train: 79.44%, Valid: 80.33% Test: 79.13%\n",
      "Epoch: 1215, Loss: 53898.2031, Train: 79.48%, Valid: 80.40% Test: 78.99%\n",
      "Epoch: 1216, Loss: 53863.7266, Train: 79.49%, Valid: 80.33% Test: 79.06%\n",
      "Epoch: 1217, Loss: 53870.7578, Train: 79.49%, Valid: 80.33% Test: 79.06%\n",
      "Epoch: 1218, Loss: 53895.0156, Train: 79.49%, Valid: 80.33% Test: 79.06%\n",
      "Epoch: 1219, Loss: 53880.9219, Train: 79.49%, Valid: 80.33% Test: 79.20%\n",
      "Epoch: 1220, Loss: 53868.5000, Train: 79.50%, Valid: 80.33% Test: 79.20%\n",
      "Epoch: 1221, Loss: 53871.3672, Train: 79.44%, Valid: 80.40% Test: 79.13%\n",
      "Epoch: 1222, Loss: 53869.5938, Train: 79.43%, Valid: 80.47% Test: 79.13%\n",
      "Epoch: 1223, Loss: 53887.3594, Train: 79.44%, Valid: 80.47% Test: 79.06%\n",
      "Epoch: 1224, Loss: 53887.2852, Train: 79.43%, Valid: 80.33% Test: 78.99%\n",
      "Epoch: 1225, Loss: 53883.3203, Train: 79.44%, Valid: 80.33% Test: 78.99%\n",
      "Epoch: 1226, Loss: 53877.2500, Train: 79.44%, Valid: 80.40% Test: 79.13%\n",
      "Epoch: 1227, Loss: 53877.5312, Train: 79.49%, Valid: 80.54% Test: 79.20%\n",
      "Epoch: 1228, Loss: 53871.8516, Train: 79.47%, Valid: 80.61% Test: 79.20%\n",
      "Epoch: 1229, Loss: 53860.6016, Train: 79.45%, Valid: 80.61% Test: 79.13%\n",
      "Epoch: 1230, Loss: 53888.5898, Train: 79.47%, Valid: 80.61% Test: 79.20%\n",
      "Epoch: 1231, Loss: 53870.3125, Train: 79.49%, Valid: 80.54% Test: 79.27%\n",
      "Epoch: 1232, Loss: 53885.2344, Train: 79.47%, Valid: 80.61% Test: 79.27%\n",
      "Epoch: 1233, Loss: 53860.8984, Train: 79.44%, Valid: 80.61% Test: 79.27%\n",
      "Epoch: 1234, Loss: 53887.2812, Train: 79.44%, Valid: 80.54% Test: 79.27%\n",
      "Epoch: 1235, Loss: 53850.5781, Train: 79.40%, Valid: 80.47% Test: 79.27%\n",
      "Epoch: 1236, Loss: 53869.9102, Train: 79.41%, Valid: 80.47% Test: 79.27%\n",
      "Epoch: 1237, Loss: 53867.8633, Train: 79.42%, Valid: 80.33% Test: 79.20%\n",
      "Epoch: 1238, Loss: 53889.2734, Train: 79.41%, Valid: 80.40% Test: 79.27%\n",
      "Epoch: 1239, Loss: 53858.7773, Train: 79.42%, Valid: 80.47% Test: 79.20%\n",
      "Epoch: 1240, Loss: 53870.4180, Train: 79.43%, Valid: 80.40% Test: 79.13%\n",
      "Epoch: 1241, Loss: 53885.5039, Train: 79.42%, Valid: 80.40% Test: 79.06%\n",
      "Epoch: 1242, Loss: 53877.2109, Train: 79.43%, Valid: 80.40% Test: 79.06%\n",
      "Epoch: 1243, Loss: 53888.2344, Train: 79.44%, Valid: 80.47% Test: 79.13%\n",
      "Epoch: 1244, Loss: 53874.1250, Train: 79.47%, Valid: 80.54% Test: 79.13%\n",
      "Epoch: 1245, Loss: 53866.3438, Train: 79.46%, Valid: 80.54% Test: 79.20%\n",
      "Epoch: 1246, Loss: 53864.8438, Train: 79.50%, Valid: 80.54% Test: 79.27%\n",
      "Epoch: 1247, Loss: 53865.5977, Train: 79.53%, Valid: 80.47% Test: 79.27%\n",
      "Epoch: 1248, Loss: 53856.1914, Train: 79.54%, Valid: 80.47% Test: 79.27%\n",
      "Epoch: 1249, Loss: 53875.6484, Train: 79.53%, Valid: 80.47% Test: 79.27%\n",
      "Epoch: 1250, Loss: 53875.7031, Train: 79.52%, Valid: 80.47% Test: 79.27%\n",
      "Epoch: 1251, Loss: 53859.7578, Train: 79.53%, Valid: 80.54% Test: 79.20%\n",
      "Epoch: 1252, Loss: 53885.4766, Train: 79.55%, Valid: 80.54% Test: 79.20%\n",
      "Epoch: 1253, Loss: 53884.7969, Train: 79.53%, Valid: 80.54% Test: 79.20%\n",
      "Epoch: 1254, Loss: 53877.7461, Train: 79.53%, Valid: 80.54% Test: 79.13%\n",
      "Epoch: 1255, Loss: 53886.6562, Train: 79.53%, Valid: 80.54% Test: 79.06%\n",
      "Epoch: 1256, Loss: 53870.0430, Train: 79.53%, Valid: 80.54% Test: 79.06%\n",
      "Epoch: 1257, Loss: 53869.3828, Train: 79.51%, Valid: 80.47% Test: 79.06%\n",
      "Epoch: 1258, Loss: 53882.6484, Train: 79.49%, Valid: 80.47% Test: 78.99%\n",
      "Epoch: 1259, Loss: 53887.9766, Train: 79.48%, Valid: 80.54% Test: 79.06%\n",
      "Epoch: 1260, Loss: 53870.9766, Train: 79.47%, Valid: 80.54% Test: 79.06%\n",
      "Epoch: 1261, Loss: 53872.3867, Train: 79.44%, Valid: 80.54% Test: 79.13%\n",
      "Epoch: 1262, Loss: 53876.0547, Train: 79.43%, Valid: 80.54% Test: 79.13%\n",
      "Epoch: 1263, Loss: 53854.6797, Train: 79.44%, Valid: 80.47% Test: 79.13%\n",
      "Epoch: 1264, Loss: 53851.1797, Train: 79.44%, Valid: 80.47% Test: 79.20%\n",
      "Epoch: 1265, Loss: 53860.9609, Train: 79.46%, Valid: 80.47% Test: 79.20%\n",
      "Epoch: 1266, Loss: 53876.7500, Train: 79.44%, Valid: 80.47% Test: 79.13%\n",
      "Epoch: 1267, Loss: 53856.4297, Train: 79.46%, Valid: 80.54% Test: 79.20%\n",
      "Epoch: 1268, Loss: 53850.9453, Train: 79.45%, Valid: 80.47% Test: 79.13%\n",
      "Epoch: 1269, Loss: 53855.6016, Train: 79.47%, Valid: 80.47% Test: 79.06%\n",
      "Epoch: 1270, Loss: 53878.3672, Train: 79.50%, Valid: 80.47% Test: 79.20%\n",
      "Epoch: 1271, Loss: 53871.1172, Train: 79.53%, Valid: 80.54% Test: 79.34%\n",
      "Epoch: 1272, Loss: 53863.7578, Train: 79.52%, Valid: 80.54% Test: 79.27%\n",
      "Epoch: 1273, Loss: 53874.7070, Train: 79.52%, Valid: 80.54% Test: 79.27%\n",
      "Epoch: 1274, Loss: 53875.9180, Train: 79.52%, Valid: 80.61% Test: 79.27%\n",
      "Epoch: 1275, Loss: 53852.4766, Train: 79.50%, Valid: 80.68% Test: 79.27%\n",
      "Epoch: 1276, Loss: 53865.7578, Train: 79.50%, Valid: 80.68% Test: 79.20%\n",
      "Epoch: 1277, Loss: 53859.4688, Train: 79.49%, Valid: 80.68% Test: 79.27%\n",
      "Epoch: 1278, Loss: 53866.9375, Train: 79.50%, Valid: 80.68% Test: 79.27%\n",
      "Epoch: 1279, Loss: 53846.6172, Train: 79.47%, Valid: 80.68% Test: 79.27%\n",
      "Epoch: 1280, Loss: 53844.7891, Train: 79.47%, Valid: 80.75% Test: 79.13%\n",
      "Epoch: 1281, Loss: 53881.9062, Train: 79.46%, Valid: 80.68% Test: 79.06%\n",
      "Epoch: 1282, Loss: 53849.9766, Train: 79.45%, Valid: 80.61% Test: 79.06%\n",
      "Epoch: 1283, Loss: 53870.7266, Train: 79.47%, Valid: 80.61% Test: 78.99%\n",
      "Epoch: 1284, Loss: 53871.5391, Train: 79.47%, Valid: 80.61% Test: 79.06%\n",
      "Epoch: 1285, Loss: 53854.0156, Train: 79.47%, Valid: 80.68% Test: 78.99%\n",
      "Epoch: 1286, Loss: 53854.0938, Train: 79.48%, Valid: 80.68% Test: 79.06%\n",
      "Epoch: 1287, Loss: 53883.7031, Train: 79.50%, Valid: 80.68% Test: 79.06%\n",
      "Epoch: 1288, Loss: 53874.8984, Train: 79.46%, Valid: 80.68% Test: 79.06%\n",
      "Epoch: 1289, Loss: 53874.8125, Train: 79.41%, Valid: 80.68% Test: 79.06%\n",
      "Epoch: 1290, Loss: 53868.0859, Train: 79.41%, Valid: 80.68% Test: 78.99%\n",
      "Epoch: 1291, Loss: 53867.0430, Train: 79.42%, Valid: 80.68% Test: 78.99%\n",
      "Epoch: 1292, Loss: 53852.6250, Train: 79.47%, Valid: 80.61% Test: 78.99%\n",
      "Epoch: 1293, Loss: 53851.1797, Train: 79.47%, Valid: 80.68% Test: 79.06%\n",
      "Epoch: 1294, Loss: 53868.8320, Train: 79.46%, Valid: 80.61% Test: 79.13%\n",
      "Epoch: 1295, Loss: 53863.3320, Train: 79.47%, Valid: 80.61% Test: 79.20%\n",
      "Epoch: 1296, Loss: 53841.9375, Train: 79.50%, Valid: 80.61% Test: 79.27%\n",
      "Epoch: 1297, Loss: 53842.4375, Train: 79.51%, Valid: 80.54% Test: 79.27%\n",
      "Epoch: 1298, Loss: 53851.9688, Train: 79.50%, Valid: 80.54% Test: 79.27%\n",
      "Epoch: 1299, Loss: 53829.1719, Train: 79.52%, Valid: 80.47% Test: 79.20%\n",
      "Epoch: 1300, Loss: 53859.0625, Train: 79.52%, Valid: 80.40% Test: 79.13%\n",
      "Epoch: 1301, Loss: 53874.0859, Train: 79.52%, Valid: 80.47% Test: 79.06%\n",
      "Epoch: 1302, Loss: 53869.0625, Train: 79.50%, Valid: 80.47% Test: 79.06%\n",
      "Epoch: 1303, Loss: 53871.9453, Train: 79.50%, Valid: 80.47% Test: 78.99%\n",
      "Epoch: 1304, Loss: 53852.3906, Train: 79.47%, Valid: 80.40% Test: 78.79%\n",
      "Epoch: 1305, Loss: 53858.0625, Train: 79.46%, Valid: 80.40% Test: 78.86%\n",
      "Epoch: 1306, Loss: 53865.5977, Train: 79.47%, Valid: 80.47% Test: 78.79%\n",
      "Epoch: 1307, Loss: 53852.0234, Train: 79.48%, Valid: 80.54% Test: 78.93%\n",
      "Epoch: 1308, Loss: 53851.5898, Train: 79.48%, Valid: 80.61% Test: 78.86%\n",
      "Epoch: 1309, Loss: 53827.3828, Train: 79.50%, Valid: 80.54% Test: 78.86%\n",
      "Epoch: 1310, Loss: 53841.2461, Train: 79.52%, Valid: 80.54% Test: 79.06%\n",
      "Epoch: 1311, Loss: 53861.8828, Train: 79.50%, Valid: 80.54% Test: 79.06%\n",
      "Epoch: 1312, Loss: 53857.9375, Train: 79.50%, Valid: 80.54% Test: 79.13%\n",
      "Epoch: 1313, Loss: 53841.9375, Train: 79.51%, Valid: 80.54% Test: 79.20%\n",
      "Epoch: 1314, Loss: 53865.4258, Train: 79.55%, Valid: 80.54% Test: 79.13%\n",
      "Epoch: 1315, Loss: 53852.6797, Train: 79.56%, Valid: 80.47% Test: 79.13%\n",
      "Epoch: 1316, Loss: 53844.3984, Train: 79.56%, Valid: 80.54% Test: 79.06%\n",
      "Epoch: 1317, Loss: 53847.2070, Train: 79.56%, Valid: 80.47% Test: 79.20%\n",
      "Epoch: 1318, Loss: 53868.4375, Train: 79.56%, Valid: 80.47% Test: 79.20%\n",
      "Epoch: 1319, Loss: 53862.7188, Train: 79.50%, Valid: 80.47% Test: 79.13%\n",
      "Epoch: 1320, Loss: 53847.4492, Train: 79.49%, Valid: 80.47% Test: 79.06%\n",
      "Epoch: 1321, Loss: 53872.0625, Train: 79.48%, Valid: 80.47% Test: 79.06%\n",
      "Epoch: 1322, Loss: 53862.1133, Train: 79.48%, Valid: 80.40% Test: 79.06%\n",
      "Epoch: 1323, Loss: 53864.0703, Train: 79.48%, Valid: 80.47% Test: 79.06%\n",
      "Epoch: 1324, Loss: 53854.7852, Train: 79.47%, Valid: 80.47% Test: 79.06%\n",
      "Epoch: 1325, Loss: 53843.4141, Train: 79.48%, Valid: 80.47% Test: 79.13%\n",
      "Epoch: 1326, Loss: 53851.5859, Train: 79.48%, Valid: 80.47% Test: 79.13%\n",
      "Epoch: 1327, Loss: 53860.0547, Train: 79.49%, Valid: 80.54% Test: 79.27%\n",
      "Epoch: 1328, Loss: 53864.5781, Train: 79.50%, Valid: 80.61% Test: 79.27%\n",
      "Epoch: 1329, Loss: 53871.4922, Train: 79.49%, Valid: 80.61% Test: 79.27%\n",
      "Epoch: 1330, Loss: 53863.8164, Train: 79.46%, Valid: 80.61% Test: 79.27%\n",
      "Epoch: 1331, Loss: 53847.4609, Train: 79.50%, Valid: 80.61% Test: 79.27%\n",
      "Epoch: 1332, Loss: 53850.6133, Train: 79.51%, Valid: 80.61% Test: 79.20%\n",
      "Epoch: 1333, Loss: 53859.8984, Train: 79.53%, Valid: 80.68% Test: 79.20%\n",
      "Epoch: 1334, Loss: 53863.8945, Train: 79.51%, Valid: 80.68% Test: 79.13%\n",
      "Epoch: 1335, Loss: 53864.4297, Train: 79.52%, Valid: 80.68% Test: 79.13%\n",
      "Epoch: 1336, Loss: 53853.9258, Train: 79.52%, Valid: 80.68% Test: 79.13%\n",
      "Epoch: 1337, Loss: 53835.1797, Train: 79.52%, Valid: 80.61% Test: 79.06%\n",
      "Epoch: 1338, Loss: 53860.8281, Train: 79.54%, Valid: 80.54% Test: 79.06%\n",
      "Epoch: 1339, Loss: 53851.4297, Train: 79.53%, Valid: 80.54% Test: 79.06%\n",
      "Epoch: 1340, Loss: 53849.7266, Train: 79.51%, Valid: 80.47% Test: 79.06%\n",
      "Epoch: 1341, Loss: 53842.1719, Train: 79.50%, Valid: 80.47% Test: 79.06%\n",
      "Epoch: 1342, Loss: 53858.4531, Train: 79.49%, Valid: 80.40% Test: 79.06%\n",
      "Epoch: 1343, Loss: 53849.3789, Train: 79.48%, Valid: 80.47% Test: 79.06%\n",
      "Epoch: 1344, Loss: 53858.8086, Train: 79.45%, Valid: 80.47% Test: 78.86%\n",
      "Epoch: 1345, Loss: 53847.8984, Train: 79.46%, Valid: 80.47% Test: 79.06%\n",
      "Epoch: 1346, Loss: 53842.1328, Train: 79.45%, Valid: 80.47% Test: 78.99%\n",
      "Epoch: 1347, Loss: 53855.4844, Train: 79.44%, Valid: 80.47% Test: 78.99%\n",
      "Epoch: 1348, Loss: 53842.8047, Train: 79.43%, Valid: 80.47% Test: 79.06%\n",
      "Epoch: 1349, Loss: 53864.4453, Train: 79.43%, Valid: 80.47% Test: 79.13%\n",
      "Epoch: 1350, Loss: 53859.5703, Train: 79.42%, Valid: 80.47% Test: 79.20%\n",
      "Epoch: 1351, Loss: 53854.7969, Train: 79.50%, Valid: 80.47% Test: 79.06%\n",
      "Epoch: 1352, Loss: 53844.8672, Train: 79.52%, Valid: 80.47% Test: 79.06%\n",
      "Epoch: 1353, Loss: 53844.4219, Train: 79.53%, Valid: 80.54% Test: 79.06%\n",
      "Epoch: 1354, Loss: 53852.1406, Train: 79.56%, Valid: 80.54% Test: 78.99%\n",
      "Epoch: 1355, Loss: 53833.8984, Train: 79.54%, Valid: 80.61% Test: 79.13%\n",
      "Epoch: 1356, Loss: 53872.8594, Train: 79.53%, Valid: 80.61% Test: 79.13%\n",
      "Epoch: 1357, Loss: 53849.0625, Train: 79.55%, Valid: 80.61% Test: 79.13%\n",
      "Epoch: 1358, Loss: 53843.7109, Train: 79.55%, Valid: 80.61% Test: 79.13%\n",
      "Epoch: 1359, Loss: 53872.1875, Train: 79.56%, Valid: 80.61% Test: 79.13%\n",
      "Epoch: 1360, Loss: 53853.5234, Train: 79.57%, Valid: 80.61% Test: 79.06%\n",
      "Epoch: 1361, Loss: 53860.9297, Train: 79.55%, Valid: 80.61% Test: 79.06%\n",
      "Epoch: 1362, Loss: 53869.9766, Train: 79.55%, Valid: 80.47% Test: 79.06%\n",
      "Epoch: 1363, Loss: 53841.9609, Train: 79.54%, Valid: 80.40% Test: 78.99%\n",
      "Epoch: 1364, Loss: 53856.2500, Train: 79.51%, Valid: 80.40% Test: 79.06%\n",
      "Epoch: 1365, Loss: 53842.8438, Train: 79.44%, Valid: 80.40% Test: 78.99%\n",
      "Epoch: 1366, Loss: 53850.5039, Train: 79.40%, Valid: 80.47% Test: 78.99%\n",
      "Epoch: 1367, Loss: 53857.9688, Train: 79.42%, Valid: 80.47% Test: 78.99%\n",
      "Epoch: 1368, Loss: 53856.2070, Train: 79.44%, Valid: 80.47% Test: 78.93%\n",
      "Epoch: 1369, Loss: 53844.2031, Train: 79.50%, Valid: 80.47% Test: 78.93%\n",
      "Epoch: 1370, Loss: 53842.2188, Train: 79.52%, Valid: 80.47% Test: 78.93%\n",
      "Epoch: 1371, Loss: 53847.0039, Train: 79.53%, Valid: 80.47% Test: 78.93%\n",
      "Epoch: 1372, Loss: 53857.3008, Train: 79.53%, Valid: 80.47% Test: 78.86%\n",
      "Epoch: 1373, Loss: 53830.4297, Train: 79.53%, Valid: 80.54% Test: 78.86%\n",
      "Epoch: 1374, Loss: 53849.4297, Train: 79.52%, Valid: 80.54% Test: 78.79%\n",
      "Epoch: 1375, Loss: 53846.1562, Train: 79.53%, Valid: 80.54% Test: 78.79%\n",
      "Epoch: 1376, Loss: 53829.3594, Train: 79.52%, Valid: 80.47% Test: 78.79%\n",
      "Epoch: 1377, Loss: 53846.0703, Train: 79.53%, Valid: 80.47% Test: 78.99%\n",
      "Epoch: 1378, Loss: 53839.6914, Train: 79.51%, Valid: 80.54% Test: 79.06%\n",
      "Epoch: 1379, Loss: 53856.7109, Train: 79.53%, Valid: 80.54% Test: 79.13%\n",
      "Epoch: 1380, Loss: 53835.0625, Train: 79.57%, Valid: 80.68% Test: 79.13%\n",
      "Epoch: 1381, Loss: 53856.2969, Train: 79.56%, Valid: 80.75% Test: 79.20%\n",
      "Epoch: 1382, Loss: 53855.9141, Train: 79.55%, Valid: 80.75% Test: 79.20%\n",
      "Epoch: 1383, Loss: 53846.0391, Train: 79.56%, Valid: 80.68% Test: 79.13%\n",
      "Epoch: 1384, Loss: 53866.9531, Train: 79.57%, Valid: 80.68% Test: 79.13%\n",
      "Epoch: 1385, Loss: 53858.2422, Train: 79.60%, Valid: 80.75% Test: 79.13%\n",
      "Epoch: 1386, Loss: 53829.8281, Train: 79.72%, Valid: 80.89% Test: 79.13%\n",
      "Epoch: 1387, Loss: 53850.6094, Train: 79.77%, Valid: 80.89% Test: 79.41%\n",
      "Epoch: 1388, Loss: 53809.8281, Train: 79.76%, Valid: 80.82% Test: 79.27%\n",
      "Epoch: 1389, Loss: 53828.5391, Train: 79.78%, Valid: 81.09% Test: 79.27%\n",
      "Epoch: 1390, Loss: 53811.2031, Train: 79.75%, Valid: 81.09% Test: 79.27%\n",
      "Epoch: 1391, Loss: 53834.4062, Train: 79.73%, Valid: 80.96% Test: 79.34%\n",
      "Epoch: 1392, Loss: 53836.8164, Train: 79.75%, Valid: 81.02% Test: 79.34%\n",
      "Epoch: 1393, Loss: 53825.8789, Train: 79.75%, Valid: 80.89% Test: 79.27%\n",
      "Epoch: 1394, Loss: 53825.5273, Train: 79.75%, Valid: 80.82% Test: 79.20%\n",
      "Epoch: 1395, Loss: 53851.0469, Train: 79.74%, Valid: 80.75% Test: 79.27%\n",
      "Epoch: 1396, Loss: 53804.6289, Train: 79.73%, Valid: 80.61% Test: 79.34%\n",
      "Epoch: 1397, Loss: 53837.3789, Train: 79.71%, Valid: 80.61% Test: 79.27%\n",
      "Epoch: 1398, Loss: 53825.4844, Train: 79.73%, Valid: 80.82% Test: 79.34%\n",
      "Epoch: 1399, Loss: 53846.0391, Train: 79.70%, Valid: 80.75% Test: 79.27%\n",
      "Epoch: 1400, Loss: 53840.6992, Train: 79.70%, Valid: 80.75% Test: 79.34%\n",
      "Epoch: 1401, Loss: 53830.7266, Train: 79.71%, Valid: 80.75% Test: 79.34%\n",
      "Epoch: 1402, Loss: 53832.3945, Train: 79.69%, Valid: 80.75% Test: 79.20%\n",
      "Epoch: 1403, Loss: 53813.5156, Train: 79.69%, Valid: 80.82% Test: 79.20%\n",
      "Epoch: 1404, Loss: 53829.6328, Train: 79.68%, Valid: 80.75% Test: 79.13%\n",
      "Epoch: 1405, Loss: 53813.2930, Train: 79.68%, Valid: 80.68% Test: 79.13%\n",
      "Epoch: 1406, Loss: 53816.2930, Train: 79.68%, Valid: 80.68% Test: 79.13%\n",
      "Epoch: 1407, Loss: 53811.9453, Train: 79.69%, Valid: 80.68% Test: 79.20%\n",
      "Epoch: 1408, Loss: 53826.9453, Train: 79.69%, Valid: 80.82% Test: 79.27%\n",
      "Epoch: 1409, Loss: 53845.2969, Train: 79.68%, Valid: 80.82% Test: 79.20%\n",
      "Epoch: 1410, Loss: 53838.0078, Train: 79.66%, Valid: 80.82% Test: 79.20%\n",
      "Epoch: 1411, Loss: 53832.7500, Train: 79.67%, Valid: 80.82% Test: 79.13%\n",
      "Epoch: 1412, Loss: 53831.3750, Train: 79.69%, Valid: 80.82% Test: 79.13%\n",
      "Epoch: 1413, Loss: 53848.4570, Train: 79.73%, Valid: 80.82% Test: 79.06%\n",
      "Epoch: 1414, Loss: 53844.6406, Train: 79.74%, Valid: 80.82% Test: 79.13%\n",
      "Epoch: 1415, Loss: 53830.4062, Train: 79.74%, Valid: 80.82% Test: 79.20%\n",
      "Epoch: 1416, Loss: 53826.7227, Train: 79.73%, Valid: 80.89% Test: 79.34%\n",
      "Epoch: 1417, Loss: 53827.8594, Train: 79.70%, Valid: 80.89% Test: 79.27%\n",
      "Epoch: 1418, Loss: 53827.6992, Train: 79.72%, Valid: 80.89% Test: 79.27%\n",
      "Epoch: 1419, Loss: 53823.8477, Train: 79.72%, Valid: 80.89% Test: 79.27%\n",
      "Epoch: 1420, Loss: 53818.6680, Train: 79.72%, Valid: 80.89% Test: 79.20%\n",
      "Epoch: 1421, Loss: 53825.6250, Train: 79.72%, Valid: 80.89% Test: 79.20%\n",
      "Epoch: 1422, Loss: 53829.0156, Train: 79.71%, Valid: 80.89% Test: 79.13%\n",
      "Epoch: 1423, Loss: 53829.1406, Train: 79.72%, Valid: 80.82% Test: 79.20%\n",
      "Epoch: 1424, Loss: 53807.6484, Train: 79.73%, Valid: 80.75% Test: 79.13%\n",
      "Epoch: 1425, Loss: 53826.7656, Train: 79.72%, Valid: 80.89% Test: 79.13%\n",
      "Epoch: 1426, Loss: 53832.9492, Train: 79.73%, Valid: 80.89% Test: 79.27%\n",
      "Epoch: 1427, Loss: 53817.3828, Train: 79.75%, Valid: 80.89% Test: 79.27%\n",
      "Epoch: 1428, Loss: 53834.9648, Train: 79.74%, Valid: 80.89% Test: 79.34%\n",
      "Epoch: 1429, Loss: 53808.6016, Train: 79.73%, Valid: 80.89% Test: 79.34%\n",
      "Epoch: 1430, Loss: 53828.7773, Train: 79.74%, Valid: 80.89% Test: 79.34%\n",
      "Epoch: 1431, Loss: 53845.7422, Train: 79.74%, Valid: 80.82% Test: 79.34%\n",
      "Epoch: 1432, Loss: 53811.4414, Train: 79.75%, Valid: 80.82% Test: 79.41%\n",
      "Epoch: 1433, Loss: 53835.3945, Train: 79.74%, Valid: 80.75% Test: 79.41%\n",
      "Epoch: 1434, Loss: 53823.5273, Train: 79.72%, Valid: 80.75% Test: 79.34%\n",
      "Epoch: 1435, Loss: 53842.2148, Train: 79.73%, Valid: 80.61% Test: 79.41%\n",
      "Epoch: 1436, Loss: 53828.9180, Train: 79.73%, Valid: 80.61% Test: 79.48%\n",
      "Epoch: 1437, Loss: 53824.2578, Train: 79.73%, Valid: 80.61% Test: 79.48%\n",
      "Epoch: 1438, Loss: 53820.4531, Train: 79.71%, Valid: 80.61% Test: 79.48%\n",
      "Epoch: 1439, Loss: 53831.1602, Train: 79.70%, Valid: 80.61% Test: 79.48%\n",
      "Epoch: 1440, Loss: 53829.4062, Train: 79.70%, Valid: 80.54% Test: 79.48%\n",
      "Epoch: 1441, Loss: 53804.9922, Train: 79.69%, Valid: 80.61% Test: 79.41%\n",
      "Epoch: 1442, Loss: 53834.1367, Train: 79.67%, Valid: 80.61% Test: 79.34%\n",
      "Epoch: 1443, Loss: 53813.9922, Train: 79.68%, Valid: 80.54% Test: 79.34%\n",
      "Epoch: 1444, Loss: 53823.1719, Train: 79.69%, Valid: 80.54% Test: 79.20%\n",
      "Epoch: 1445, Loss: 53811.5391, Train: 79.68%, Valid: 80.54% Test: 78.99%\n",
      "Epoch: 1446, Loss: 53818.1875, Train: 79.68%, Valid: 80.68% Test: 78.99%\n",
      "Epoch: 1447, Loss: 53817.3359, Train: 79.70%, Valid: 80.68% Test: 79.13%\n",
      "Epoch: 1448, Loss: 53833.3477, Train: 79.70%, Valid: 80.75% Test: 79.20%\n",
      "Epoch: 1449, Loss: 53812.1797, Train: 79.71%, Valid: 80.75% Test: 79.27%\n",
      "Epoch: 1450, Loss: 53822.9453, Train: 79.74%, Valid: 80.75% Test: 79.34%\n",
      "Epoch: 1451, Loss: 53811.4609, Train: 79.76%, Valid: 80.75% Test: 79.34%\n",
      "Epoch: 1452, Loss: 53827.1289, Train: 79.76%, Valid: 80.75% Test: 79.20%\n",
      "Epoch: 1453, Loss: 53826.3750, Train: 79.75%, Valid: 80.68% Test: 79.20%\n",
      "Epoch: 1454, Loss: 53804.2969, Train: 79.74%, Valid: 80.68% Test: 79.20%\n",
      "Epoch: 1455, Loss: 53812.7422, Train: 79.73%, Valid: 80.68% Test: 79.27%\n",
      "Epoch: 1456, Loss: 53809.7188, Train: 79.72%, Valid: 80.68% Test: 79.34%\n",
      "Epoch: 1457, Loss: 53828.6797, Train: 79.72%, Valid: 80.68% Test: 79.27%\n",
      "Epoch: 1458, Loss: 53807.2461, Train: 79.72%, Valid: 80.61% Test: 79.27%\n",
      "Epoch: 1459, Loss: 53841.9453, Train: 79.74%, Valid: 80.68% Test: 79.34%\n",
      "Epoch: 1460, Loss: 53828.9609, Train: 79.75%, Valid: 80.75% Test: 79.41%\n",
      "Epoch: 1461, Loss: 53818.4766, Train: 79.82%, Valid: 80.89% Test: 79.55%\n",
      "Epoch: 1462, Loss: 53822.9922, Train: 79.82%, Valid: 80.96% Test: 79.48%\n",
      "Epoch: 1463, Loss: 53811.5352, Train: 79.82%, Valid: 81.02% Test: 79.48%\n",
      "Epoch: 1464, Loss: 53822.0977, Train: 79.81%, Valid: 81.02% Test: 79.48%\n",
      "Epoch: 1465, Loss: 53819.6641, Train: 79.78%, Valid: 81.09% Test: 79.48%\n",
      "Epoch: 1466, Loss: 53810.8672, Train: 79.77%, Valid: 81.02% Test: 79.41%\n",
      "Epoch: 1467, Loss: 53802.2969, Train: 79.76%, Valid: 80.96% Test: 79.34%\n",
      "Epoch: 1468, Loss: 53808.4453, Train: 79.75%, Valid: 80.96% Test: 79.34%\n",
      "Epoch: 1469, Loss: 53831.4219, Train: 79.79%, Valid: 80.96% Test: 79.27%\n",
      "Epoch: 1470, Loss: 53829.4375, Train: 79.80%, Valid: 80.96% Test: 79.20%\n",
      "Epoch: 1471, Loss: 53805.7031, Train: 79.79%, Valid: 80.96% Test: 78.99%\n",
      "Epoch: 1472, Loss: 53826.7578, Train: 79.77%, Valid: 80.89% Test: 79.06%\n",
      "Epoch: 1473, Loss: 53825.5234, Train: 79.77%, Valid: 80.82% Test: 79.06%\n",
      "Epoch: 1474, Loss: 53820.9688, Train: 79.75%, Valid: 80.75% Test: 78.99%\n",
      "Epoch: 1475, Loss: 53807.0391, Train: 79.74%, Valid: 80.82% Test: 78.99%\n",
      "Epoch: 1476, Loss: 53778.4531, Train: 79.74%, Valid: 80.82% Test: 78.99%\n",
      "Epoch: 1477, Loss: 53808.0859, Train: 79.71%, Valid: 80.68% Test: 79.06%\n",
      "Epoch: 1478, Loss: 53811.1641, Train: 79.71%, Valid: 80.68% Test: 79.20%\n",
      "Epoch: 1479, Loss: 53794.0859, Train: 79.72%, Valid: 80.68% Test: 79.20%\n",
      "Epoch: 1480, Loss: 53836.3359, Train: 79.74%, Valid: 80.82% Test: 79.20%\n",
      "Epoch: 1481, Loss: 53815.6016, Train: 79.75%, Valid: 80.82% Test: 79.20%\n",
      "Epoch: 1482, Loss: 53824.1328, Train: 79.75%, Valid: 80.82% Test: 79.20%\n",
      "Epoch: 1483, Loss: 53809.0000, Train: 79.75%, Valid: 80.75% Test: 79.34%\n",
      "Epoch: 1484, Loss: 53822.7656, Train: 79.75%, Valid: 80.75% Test: 79.34%\n",
      "Epoch: 1485, Loss: 53826.1172, Train: 79.75%, Valid: 80.82% Test: 79.34%\n",
      "Epoch: 1486, Loss: 53816.4531, Train: 79.75%, Valid: 80.82% Test: 79.27%\n",
      "Epoch: 1487, Loss: 53821.8438, Train: 79.70%, Valid: 80.82% Test: 79.27%\n",
      "Epoch: 1488, Loss: 53809.8516, Train: 79.69%, Valid: 80.75% Test: 79.34%\n",
      "Epoch: 1489, Loss: 53815.1641, Train: 79.69%, Valid: 80.75% Test: 79.34%\n",
      "Epoch: 1490, Loss: 53815.1992, Train: 79.74%, Valid: 80.68% Test: 79.41%\n",
      "Epoch: 1491, Loss: 53835.4062, Train: 79.78%, Valid: 80.68% Test: 79.34%\n",
      "Epoch: 1492, Loss: 53827.3594, Train: 79.75%, Valid: 80.68% Test: 79.20%\n",
      "Epoch: 1493, Loss: 53807.8672, Train: 79.77%, Valid: 80.82% Test: 79.34%\n",
      "Epoch: 1494, Loss: 53796.9766, Train: 79.82%, Valid: 80.89% Test: 79.41%\n",
      "Epoch: 1495, Loss: 53826.8320, Train: 79.78%, Valid: 80.96% Test: 79.34%\n",
      "Epoch: 1496, Loss: 53845.5859, Train: 79.76%, Valid: 80.96% Test: 79.48%\n",
      "Epoch: 1497, Loss: 53827.3906, Train: 79.76%, Valid: 81.02% Test: 79.48%\n",
      "Epoch: 1498, Loss: 53808.1016, Train: 79.79%, Valid: 80.96% Test: 79.41%\n",
      "Epoch: 1499, Loss: 53797.6797, Train: 79.82%, Valid: 81.02% Test: 79.48%\n",
      "Epoch: 1500, Loss: 53825.7227, Train: 79.85%, Valid: 81.02% Test: 79.48%\n",
      "Epoch: 1501, Loss: 53819.2656, Train: 79.85%, Valid: 81.02% Test: 79.48%\n",
      "Epoch: 1502, Loss: 53805.5039, Train: 79.85%, Valid: 81.09% Test: 79.48%\n",
      "Epoch: 1503, Loss: 53840.3125, Train: 79.82%, Valid: 81.09% Test: 79.48%\n",
      "Epoch: 1504, Loss: 53802.9688, Train: 79.82%, Valid: 81.02% Test: 79.41%\n",
      "Epoch: 1505, Loss: 53803.4844, Train: 79.83%, Valid: 81.02% Test: 79.34%\n",
      "Epoch: 1506, Loss: 53820.7500, Train: 79.82%, Valid: 81.09% Test: 79.20%\n",
      "Epoch: 1507, Loss: 53823.1719, Train: 79.82%, Valid: 81.16% Test: 79.27%\n",
      "Epoch: 1508, Loss: 53820.3086, Train: 79.82%, Valid: 81.23% Test: 79.34%\n",
      "Epoch: 1509, Loss: 53832.3984, Train: 79.81%, Valid: 81.23% Test: 79.20%\n",
      "Epoch: 1510, Loss: 53797.2188, Train: 79.82%, Valid: 81.23% Test: 79.13%\n",
      "Epoch: 1511, Loss: 53797.2188, Train: 79.83%, Valid: 81.30% Test: 79.27%\n",
      "Epoch: 1512, Loss: 53815.9062, Train: 79.83%, Valid: 81.30% Test: 79.13%\n",
      "Epoch: 1513, Loss: 53809.4570, Train: 79.82%, Valid: 81.30% Test: 79.20%\n",
      "Epoch: 1514, Loss: 53819.3867, Train: 79.83%, Valid: 81.30% Test: 79.20%\n",
      "Epoch: 1515, Loss: 53806.0898, Train: 79.82%, Valid: 81.30% Test: 79.13%\n",
      "Epoch: 1516, Loss: 53821.2734, Train: 79.83%, Valid: 81.37% Test: 79.27%\n",
      "Epoch: 1517, Loss: 53822.6562, Train: 79.86%, Valid: 81.44% Test: 79.20%\n",
      "Epoch: 1518, Loss: 53806.1250, Train: 79.82%, Valid: 81.37% Test: 79.27%\n",
      "Epoch: 1519, Loss: 53801.5469, Train: 79.82%, Valid: 81.30% Test: 79.27%\n",
      "Epoch: 1520, Loss: 53795.6484, Train: 79.79%, Valid: 81.23% Test: 79.20%\n",
      "Epoch: 1521, Loss: 53819.9297, Train: 79.76%, Valid: 81.09% Test: 79.20%\n",
      "Epoch: 1522, Loss: 53784.2031, Train: 79.76%, Valid: 81.16% Test: 79.20%\n",
      "Epoch: 1523, Loss: 53793.4766, Train: 79.81%, Valid: 81.16% Test: 79.27%\n",
      "Epoch: 1524, Loss: 53800.8359, Train: 79.79%, Valid: 81.23% Test: 79.27%\n",
      "Epoch: 1525, Loss: 53811.6484, Train: 79.76%, Valid: 81.09% Test: 79.27%\n",
      "Epoch: 1526, Loss: 53806.4609, Train: 79.76%, Valid: 81.09% Test: 79.20%\n",
      "Epoch: 1527, Loss: 53825.8203, Train: 79.76%, Valid: 81.02% Test: 79.20%\n",
      "Epoch: 1528, Loss: 53801.0234, Train: 79.78%, Valid: 80.96% Test: 79.13%\n",
      "Epoch: 1529, Loss: 53799.5781, Train: 79.77%, Valid: 80.82% Test: 79.13%\n",
      "Epoch: 1530, Loss: 53795.2461, Train: 79.77%, Valid: 80.82% Test: 79.20%\n",
      "Epoch: 1531, Loss: 53821.4688, Train: 79.80%, Valid: 80.82% Test: 79.20%\n",
      "Epoch: 1532, Loss: 53797.9023, Train: 79.82%, Valid: 80.89% Test: 79.41%\n",
      "Epoch: 1533, Loss: 53803.4648, Train: 79.82%, Valid: 80.96% Test: 79.48%\n",
      "Epoch: 1534, Loss: 53811.0742, Train: 79.82%, Valid: 80.96% Test: 79.55%\n",
      "Epoch: 1535, Loss: 53795.4492, Train: 79.84%, Valid: 81.02% Test: 79.41%\n",
      "Epoch: 1536, Loss: 53803.2500, Train: 79.85%, Valid: 81.23% Test: 79.34%\n",
      "Epoch: 1537, Loss: 53795.9688, Train: 79.85%, Valid: 81.23% Test: 79.34%\n",
      "Epoch: 1538, Loss: 53803.7070, Train: 79.84%, Valid: 81.37% Test: 79.41%\n",
      "Epoch: 1539, Loss: 53813.4922, Train: 79.84%, Valid: 81.44% Test: 79.34%\n",
      "Epoch: 1540, Loss: 53827.5195, Train: 79.82%, Valid: 81.44% Test: 79.34%\n",
      "Epoch: 1541, Loss: 53820.8750, Train: 79.79%, Valid: 81.44% Test: 79.41%\n",
      "Epoch: 1542, Loss: 53810.6875, Train: 79.80%, Valid: 81.44% Test: 79.41%\n",
      "Epoch: 1543, Loss: 53820.6406, Train: 79.80%, Valid: 81.44% Test: 79.41%\n",
      "Epoch: 1544, Loss: 53809.0195, Train: 79.83%, Valid: 81.37% Test: 79.41%\n",
      "Epoch: 1545, Loss: 53813.8789, Train: 79.82%, Valid: 81.30% Test: 79.41%\n",
      "Epoch: 1546, Loss: 53811.9062, Train: 79.82%, Valid: 81.23% Test: 79.41%\n",
      "Epoch: 1547, Loss: 53794.3867, Train: 79.83%, Valid: 81.16% Test: 79.34%\n",
      "Epoch: 1548, Loss: 53819.5625, Train: 79.86%, Valid: 81.16% Test: 79.27%\n",
      "Epoch: 1549, Loss: 53811.3594, Train: 79.89%, Valid: 81.16% Test: 79.20%\n",
      "Epoch: 1550, Loss: 53829.3594, Train: 79.90%, Valid: 81.16% Test: 79.34%\n",
      "Epoch: 1551, Loss: 53810.3516, Train: 79.90%, Valid: 81.16% Test: 79.41%\n",
      "Epoch: 1552, Loss: 53846.9453, Train: 79.89%, Valid: 81.23% Test: 79.48%\n",
      "Epoch: 1553, Loss: 53803.9219, Train: 79.88%, Valid: 81.30% Test: 79.48%\n",
      "Epoch: 1554, Loss: 53806.0000, Train: 79.87%, Valid: 81.30% Test: 79.48%\n",
      "Epoch: 1555, Loss: 53820.1875, Train: 79.86%, Valid: 81.16% Test: 79.41%\n",
      "Epoch: 1556, Loss: 53832.3945, Train: 79.82%, Valid: 81.16% Test: 79.34%\n",
      "Epoch: 1557, Loss: 53837.0000, Train: 79.85%, Valid: 81.16% Test: 79.41%\n",
      "Epoch: 1558, Loss: 53788.6992, Train: 79.83%, Valid: 81.02% Test: 79.48%\n",
      "Epoch: 1559, Loss: 53799.0898, Train: 79.83%, Valid: 81.09% Test: 79.48%\n",
      "Epoch: 1560, Loss: 53798.1484, Train: 79.82%, Valid: 81.09% Test: 79.55%\n",
      "Epoch: 1561, Loss: 53812.0195, Train: 79.84%, Valid: 81.09% Test: 79.48%\n",
      "Epoch: 1562, Loss: 53811.1289, Train: 79.86%, Valid: 81.09% Test: 79.34%\n",
      "Epoch: 1563, Loss: 53801.9688, Train: 79.89%, Valid: 81.09% Test: 79.41%\n",
      "Epoch: 1564, Loss: 53812.0547, Train: 79.90%, Valid: 81.09% Test: 79.48%\n",
      "Epoch: 1565, Loss: 53800.6992, Train: 79.92%, Valid: 81.09% Test: 79.41%\n",
      "Epoch: 1566, Loss: 53809.8984, Train: 79.92%, Valid: 81.23% Test: 79.41%\n",
      "Epoch: 1567, Loss: 53802.0625, Train: 79.92%, Valid: 81.23% Test: 79.41%\n",
      "Epoch: 1568, Loss: 53818.0859, Train: 79.92%, Valid: 81.16% Test: 79.34%\n",
      "Epoch: 1569, Loss: 53813.2461, Train: 79.94%, Valid: 81.16% Test: 79.34%\n",
      "Epoch: 1570, Loss: 53803.2656, Train: 79.94%, Valid: 81.16% Test: 79.34%\n",
      "Epoch: 1571, Loss: 53803.0234, Train: 79.94%, Valid: 81.16% Test: 79.41%\n",
      "Epoch: 1572, Loss: 53812.9453, Train: 79.94%, Valid: 81.09% Test: 79.41%\n",
      "Epoch: 1573, Loss: 53799.5820, Train: 79.96%, Valid: 81.16% Test: 79.41%\n",
      "Epoch: 1574, Loss: 53793.2227, Train: 80.00%, Valid: 81.16% Test: 79.48%\n",
      "Epoch: 1575, Loss: 53807.1289, Train: 79.99%, Valid: 81.16% Test: 79.48%\n",
      "Epoch: 1576, Loss: 53796.2109, Train: 80.00%, Valid: 81.16% Test: 79.48%\n",
      "Epoch: 1577, Loss: 53807.1172, Train: 79.94%, Valid: 81.16% Test: 79.61%\n",
      "Epoch: 1578, Loss: 53784.3516, Train: 79.93%, Valid: 81.16% Test: 79.48%\n",
      "Epoch: 1579, Loss: 53814.8555, Train: 79.92%, Valid: 81.16% Test: 79.48%\n",
      "Epoch: 1580, Loss: 53797.5586, Train: 79.92%, Valid: 81.16% Test: 79.48%\n",
      "Epoch: 1581, Loss: 53807.6797, Train: 79.91%, Valid: 81.09% Test: 79.27%\n",
      "Epoch: 1582, Loss: 53788.7031, Train: 79.94%, Valid: 80.96% Test: 79.27%\n",
      "Epoch: 1583, Loss: 53797.6367, Train: 79.96%, Valid: 80.96% Test: 79.34%\n",
      "Epoch: 1584, Loss: 53798.5469, Train: 80.01%, Valid: 80.96% Test: 79.41%\n",
      "Epoch: 1585, Loss: 53782.5781, Train: 80.01%, Valid: 80.96% Test: 79.41%\n",
      "Epoch: 1586, Loss: 53766.8125, Train: 79.99%, Valid: 81.09% Test: 79.55%\n",
      "Epoch: 1587, Loss: 53786.0391, Train: 79.98%, Valid: 81.09% Test: 79.61%\n",
      "Epoch: 1588, Loss: 53795.3359, Train: 79.96%, Valid: 81.09% Test: 79.61%\n",
      "Epoch: 1589, Loss: 53815.0781, Train: 79.95%, Valid: 81.09% Test: 79.61%\n",
      "Epoch: 1590, Loss: 53793.4766, Train: 79.96%, Valid: 81.09% Test: 79.61%\n",
      "Epoch: 1591, Loss: 53792.8633, Train: 79.94%, Valid: 81.16% Test: 79.61%\n",
      "Epoch: 1592, Loss: 53785.1094, Train: 79.94%, Valid: 81.16% Test: 79.61%\n",
      "Epoch: 1593, Loss: 53792.8047, Train: 79.93%, Valid: 81.16% Test: 79.61%\n",
      "Epoch: 1594, Loss: 53795.1055, Train: 79.92%, Valid: 81.16% Test: 79.61%\n",
      "Epoch: 1595, Loss: 53810.9844, Train: 79.95%, Valid: 81.16% Test: 79.68%\n",
      "Epoch: 1596, Loss: 53802.2109, Train: 79.98%, Valid: 81.16% Test: 79.68%\n",
      "Epoch: 1597, Loss: 53808.1680, Train: 80.02%, Valid: 81.16% Test: 79.68%\n",
      "Epoch: 1598, Loss: 53805.4336, Train: 80.04%, Valid: 81.16% Test: 79.61%\n",
      "Epoch: 1599, Loss: 53793.4688, Train: 80.06%, Valid: 81.09% Test: 79.61%\n",
      "Epoch: 1600, Loss: 53799.3594, Train: 80.07%, Valid: 81.23% Test: 79.68%\n",
      "Epoch: 1601, Loss: 53802.4062, Train: 80.08%, Valid: 81.23% Test: 79.68%\n",
      "Epoch: 1602, Loss: 53795.5859, Train: 80.09%, Valid: 81.23% Test: 79.68%\n",
      "Epoch: 1603, Loss: 53791.0664, Train: 80.13%, Valid: 81.37% Test: 79.68%\n",
      "Epoch: 1604, Loss: 53777.3203, Train: 80.14%, Valid: 81.44% Test: 79.75%\n",
      "Epoch: 1605, Loss: 53774.0742, Train: 80.12%, Valid: 81.44% Test: 79.75%\n",
      "Epoch: 1606, Loss: 53789.4141, Train: 80.11%, Valid: 81.44% Test: 79.75%\n",
      "Epoch: 1607, Loss: 53775.2500, Train: 80.14%, Valid: 81.44% Test: 79.75%\n",
      "Epoch: 1608, Loss: 53810.6758, Train: 80.13%, Valid: 81.37% Test: 79.68%\n",
      "Epoch: 1609, Loss: 53796.1250, Train: 80.18%, Valid: 81.37% Test: 79.75%\n",
      "Epoch: 1610, Loss: 53771.9336, Train: 80.16%, Valid: 81.37% Test: 79.75%\n",
      "Epoch: 1611, Loss: 53780.8438, Train: 80.15%, Valid: 81.37% Test: 79.75%\n",
      "Epoch: 1612, Loss: 53793.5078, Train: 80.15%, Valid: 81.37% Test: 79.75%\n",
      "Epoch: 1613, Loss: 53791.1094, Train: 80.16%, Valid: 81.30% Test: 79.68%\n",
      "Epoch: 1614, Loss: 53761.2500, Train: 80.17%, Valid: 81.30% Test: 79.61%\n",
      "Epoch: 1615, Loss: 53804.3164, Train: 80.13%, Valid: 81.23% Test: 79.61%\n",
      "Epoch: 1616, Loss: 53781.4375, Train: 80.15%, Valid: 81.23% Test: 79.55%\n",
      "Epoch: 1617, Loss: 53800.5859, Train: 80.13%, Valid: 81.16% Test: 79.55%\n",
      "Epoch: 1618, Loss: 53791.7656, Train: 80.13%, Valid: 81.16% Test: 79.61%\n",
      "Epoch: 1619, Loss: 53792.2773, Train: 80.12%, Valid: 81.23% Test: 79.55%\n",
      "Epoch: 1620, Loss: 53792.9219, Train: 80.10%, Valid: 81.23% Test: 79.48%\n",
      "Epoch: 1621, Loss: 53764.2656, Train: 80.08%, Valid: 81.23% Test: 79.34%\n",
      "Epoch: 1622, Loss: 53807.7266, Train: 80.06%, Valid: 81.23% Test: 79.34%\n",
      "Epoch: 1623, Loss: 53781.9336, Train: 80.09%, Valid: 81.23% Test: 79.34%\n",
      "Epoch: 1624, Loss: 53784.1523, Train: 80.10%, Valid: 81.23% Test: 79.27%\n",
      "Epoch: 1625, Loss: 53791.5156, Train: 80.10%, Valid: 81.30% Test: 79.20%\n",
      "Epoch: 1626, Loss: 53790.3203, Train: 80.11%, Valid: 81.30% Test: 79.13%\n",
      "Epoch: 1627, Loss: 53792.6328, Train: 80.11%, Valid: 81.44% Test: 79.27%\n",
      "Epoch: 1628, Loss: 53771.6016, Train: 80.12%, Valid: 81.44% Test: 79.34%\n",
      "Epoch: 1629, Loss: 53778.0195, Train: 80.10%, Valid: 81.51% Test: 79.27%\n",
      "Epoch: 1630, Loss: 53803.8438, Train: 80.12%, Valid: 81.44% Test: 79.41%\n",
      "Epoch: 1631, Loss: 53790.8672, Train: 80.13%, Valid: 81.44% Test: 79.41%\n",
      "Epoch: 1632, Loss: 53766.3125, Train: 80.13%, Valid: 81.58% Test: 79.61%\n",
      "Epoch: 1633, Loss: 53775.0703, Train: 80.11%, Valid: 81.58% Test: 79.75%\n",
      "Epoch: 1634, Loss: 53775.8789, Train: 80.10%, Valid: 81.58% Test: 79.75%\n",
      "Epoch: 1635, Loss: 53788.1602, Train: 80.11%, Valid: 81.51% Test: 79.68%\n",
      "Epoch: 1636, Loss: 53790.1953, Train: 80.13%, Valid: 81.58% Test: 79.75%\n",
      "Epoch: 1637, Loss: 53787.0625, Train: 80.12%, Valid: 81.44% Test: 79.75%\n",
      "Epoch: 1638, Loss: 53750.7734, Train: 80.14%, Valid: 81.44% Test: 79.75%\n",
      "Epoch: 1639, Loss: 53766.9531, Train: 80.14%, Valid: 81.30% Test: 79.75%\n",
      "Epoch: 1640, Loss: 53796.4922, Train: 80.13%, Valid: 81.23% Test: 79.75%\n",
      "Epoch: 1641, Loss: 53769.5078, Train: 80.13%, Valid: 81.16% Test: 79.68%\n",
      "Epoch: 1642, Loss: 53760.2305, Train: 80.12%, Valid: 81.23% Test: 79.55%\n",
      "Epoch: 1643, Loss: 53779.9453, Train: 80.14%, Valid: 81.23% Test: 79.55%\n",
      "Epoch: 1644, Loss: 53763.7656, Train: 80.14%, Valid: 81.16% Test: 79.48%\n",
      "Epoch: 1645, Loss: 53758.6055, Train: 80.13%, Valid: 81.09% Test: 79.48%\n",
      "Epoch: 1646, Loss: 53794.5859, Train: 80.13%, Valid: 81.16% Test: 79.55%\n",
      "Epoch: 1647, Loss: 53795.0898, Train: 80.15%, Valid: 81.23% Test: 79.48%\n",
      "Epoch: 1648, Loss: 53789.1250, Train: 80.13%, Valid: 81.23% Test: 79.55%\n",
      "Epoch: 1649, Loss: 53773.7500, Train: 80.14%, Valid: 81.30% Test: 79.55%\n",
      "Epoch: 1650, Loss: 53776.1562, Train: 80.14%, Valid: 81.30% Test: 79.55%\n",
      "Epoch: 1651, Loss: 53770.1523, Train: 80.14%, Valid: 81.30% Test: 79.55%\n",
      "Epoch: 1652, Loss: 53778.3438, Train: 80.14%, Valid: 81.30% Test: 79.41%\n",
      "Epoch: 1653, Loss: 53769.5234, Train: 80.13%, Valid: 81.37% Test: 79.34%\n",
      "Epoch: 1654, Loss: 53751.0703, Train: 80.13%, Valid: 81.37% Test: 79.41%\n",
      "Epoch: 1655, Loss: 53782.2266, Train: 80.12%, Valid: 81.37% Test: 79.55%\n",
      "Epoch: 1656, Loss: 53776.3125, Train: 80.11%, Valid: 81.44% Test: 79.61%\n",
      "Epoch: 1657, Loss: 53788.2852, Train: 80.12%, Valid: 81.44% Test: 79.61%\n",
      "Epoch: 1658, Loss: 53764.5391, Train: 80.12%, Valid: 81.44% Test: 79.55%\n",
      "Epoch: 1659, Loss: 53777.3789, Train: 80.14%, Valid: 81.44% Test: 79.55%\n",
      "Epoch: 1660, Loss: 53758.1250, Train: 80.13%, Valid: 81.37% Test: 79.55%\n",
      "Epoch: 1661, Loss: 53780.4375, Train: 80.12%, Valid: 81.37% Test: 79.41%\n",
      "Epoch: 1662, Loss: 53765.2109, Train: 80.10%, Valid: 81.37% Test: 79.41%\n",
      "Epoch: 1663, Loss: 53758.4570, Train: 80.10%, Valid: 81.37% Test: 79.41%\n",
      "Epoch: 1664, Loss: 53778.2656, Train: 80.10%, Valid: 81.44% Test: 79.48%\n",
      "Epoch: 1665, Loss: 53801.5938, Train: 80.13%, Valid: 81.44% Test: 79.41%\n",
      "Epoch: 1666, Loss: 53779.6719, Train: 80.13%, Valid: 81.37% Test: 79.41%\n",
      "Epoch: 1667, Loss: 53767.8906, Train: 80.13%, Valid: 81.23% Test: 79.55%\n",
      "Epoch: 1668, Loss: 53791.7109, Train: 80.12%, Valid: 81.23% Test: 79.48%\n",
      "Epoch: 1669, Loss: 53775.5234, Train: 80.13%, Valid: 81.23% Test: 79.48%\n",
      "Epoch: 1670, Loss: 53764.2031, Train: 80.13%, Valid: 81.23% Test: 79.48%\n",
      "Epoch: 1671, Loss: 53767.4297, Train: 80.13%, Valid: 81.23% Test: 79.41%\n",
      "Epoch: 1672, Loss: 53789.9180, Train: 80.12%, Valid: 81.23% Test: 79.41%\n",
      "Epoch: 1673, Loss: 53782.8828, Train: 80.10%, Valid: 81.23% Test: 79.41%\n",
      "Epoch: 1674, Loss: 53774.7969, Train: 80.10%, Valid: 81.23% Test: 79.41%\n",
      "Epoch: 1675, Loss: 53763.4141, Train: 80.11%, Valid: 81.23% Test: 79.48%\n",
      "Epoch: 1676, Loss: 53772.6016, Train: 80.13%, Valid: 81.30% Test: 79.48%\n",
      "Epoch: 1677, Loss: 53781.4688, Train: 80.13%, Valid: 81.30% Test: 79.48%\n",
      "Epoch: 1678, Loss: 53781.0898, Train: 80.12%, Valid: 81.30% Test: 79.48%\n",
      "Epoch: 1679, Loss: 53754.3047, Train: 80.11%, Valid: 81.23% Test: 79.48%\n",
      "Epoch: 1680, Loss: 53767.4922, Train: 80.12%, Valid: 81.30% Test: 79.55%\n",
      "Epoch: 1681, Loss: 53786.4062, Train: 80.13%, Valid: 81.37% Test: 79.55%\n",
      "Epoch: 1682, Loss: 53799.4883, Train: 80.13%, Valid: 81.37% Test: 79.48%\n",
      "Epoch: 1683, Loss: 53774.8789, Train: 80.12%, Valid: 81.30% Test: 79.48%\n",
      "Epoch: 1684, Loss: 53767.8555, Train: 80.11%, Valid: 81.30% Test: 79.55%\n",
      "Epoch: 1685, Loss: 53770.0391, Train: 80.10%, Valid: 81.23% Test: 79.55%\n",
      "Epoch: 1686, Loss: 53769.6016, Train: 80.13%, Valid: 81.16% Test: 79.48%\n",
      "Epoch: 1687, Loss: 53768.3320, Train: 80.12%, Valid: 81.16% Test: 79.48%\n",
      "Epoch: 1688, Loss: 53776.8672, Train: 80.12%, Valid: 81.23% Test: 79.48%\n",
      "Epoch: 1689, Loss: 53776.4609, Train: 80.14%, Valid: 81.23% Test: 79.48%\n",
      "Epoch: 1690, Loss: 53776.5078, Train: 80.13%, Valid: 81.23% Test: 79.48%\n",
      "Epoch: 1691, Loss: 53755.1250, Train: 80.11%, Valid: 81.23% Test: 79.41%\n",
      "Epoch: 1692, Loss: 53774.2578, Train: 80.12%, Valid: 81.23% Test: 79.41%\n",
      "Epoch: 1693, Loss: 53774.5781, Train: 80.13%, Valid: 81.23% Test: 79.41%\n",
      "Epoch: 1694, Loss: 53762.4766, Train: 80.13%, Valid: 81.23% Test: 79.41%\n",
      "Epoch: 1695, Loss: 53790.8672, Train: 80.14%, Valid: 81.23% Test: 79.41%\n",
      "Epoch: 1696, Loss: 53784.9219, Train: 80.15%, Valid: 81.23% Test: 79.41%\n",
      "Epoch: 1697, Loss: 53767.8789, Train: 80.15%, Valid: 81.23% Test: 79.48%\n",
      "Epoch: 1698, Loss: 53766.6641, Train: 80.14%, Valid: 81.16% Test: 79.41%\n",
      "Epoch: 1699, Loss: 53788.3125, Train: 80.11%, Valid: 81.16% Test: 79.20%\n",
      "Epoch: 1700, Loss: 53762.7109, Train: 80.11%, Valid: 81.09% Test: 79.20%\n",
      "Epoch: 1701, Loss: 53778.3711, Train: 80.08%, Valid: 81.02% Test: 79.20%\n",
      "Epoch: 1702, Loss: 53764.8750, Train: 80.03%, Valid: 80.82% Test: 79.06%\n",
      "Epoch: 1703, Loss: 53772.8086, Train: 80.06%, Valid: 80.96% Test: 79.13%\n",
      "Epoch: 1704, Loss: 53768.4375, Train: 80.07%, Valid: 81.09% Test: 79.13%\n",
      "Epoch: 1705, Loss: 53772.7578, Train: 80.11%, Valid: 81.16% Test: 79.27%\n",
      "Epoch: 1706, Loss: 53762.7461, Train: 80.16%, Valid: 81.23% Test: 79.34%\n",
      "Epoch: 1707, Loss: 53789.2656, Train: 80.18%, Valid: 81.37% Test: 79.61%\n",
      "Epoch: 1708, Loss: 53773.6914, Train: 80.19%, Valid: 81.37% Test: 79.68%\n",
      "Epoch: 1709, Loss: 53787.8711, Train: 80.16%, Valid: 81.30% Test: 79.68%\n",
      "Epoch: 1710, Loss: 53775.2578, Train: 80.12%, Valid: 81.30% Test: 79.68%\n",
      "Epoch: 1711, Loss: 53774.5391, Train: 80.13%, Valid: 81.30% Test: 79.68%\n",
      "Epoch: 1712, Loss: 53784.7734, Train: 80.13%, Valid: 81.30% Test: 79.48%\n",
      "Epoch: 1713, Loss: 53766.5469, Train: 80.11%, Valid: 81.23% Test: 79.48%\n",
      "Epoch: 1714, Loss: 53765.5547, Train: 80.09%, Valid: 81.23% Test: 79.48%\n",
      "Epoch: 1715, Loss: 53777.9531, Train: 80.06%, Valid: 81.23% Test: 79.41%\n",
      "Epoch: 1716, Loss: 53794.2500, Train: 80.08%, Valid: 81.23% Test: 79.41%\n",
      "Epoch: 1717, Loss: 53763.5391, Train: 80.10%, Valid: 81.23% Test: 79.41%\n",
      "Epoch: 1718, Loss: 53759.6250, Train: 80.12%, Valid: 81.23% Test: 79.34%\n",
      "Epoch: 1719, Loss: 53779.9141, Train: 80.13%, Valid: 81.23% Test: 79.48%\n",
      "Epoch: 1720, Loss: 53772.3203, Train: 80.13%, Valid: 81.30% Test: 79.48%\n",
      "Epoch: 1721, Loss: 53774.8984, Train: 80.13%, Valid: 81.23% Test: 79.48%\n",
      "Epoch: 1722, Loss: 53772.1641, Train: 80.13%, Valid: 81.23% Test: 79.48%\n",
      "Epoch: 1723, Loss: 53769.7070, Train: 80.13%, Valid: 81.23% Test: 79.48%\n",
      "Epoch: 1724, Loss: 53763.0781, Train: 80.12%, Valid: 81.30% Test: 79.41%\n",
      "Epoch: 1725, Loss: 53770.1250, Train: 80.10%, Valid: 81.30% Test: 79.34%\n",
      "Epoch: 1726, Loss: 53765.5391, Train: 80.09%, Valid: 81.16% Test: 79.34%\n",
      "Epoch: 1727, Loss: 53767.4453, Train: 80.08%, Valid: 81.23% Test: 79.41%\n",
      "Epoch: 1728, Loss: 53763.8828, Train: 80.07%, Valid: 81.23% Test: 79.48%\n",
      "Epoch: 1729, Loss: 53787.2969, Train: 80.06%, Valid: 81.23% Test: 79.61%\n",
      "Epoch: 1730, Loss: 53753.2109, Train: 80.06%, Valid: 81.23% Test: 79.61%\n",
      "Epoch: 1731, Loss: 53754.2383, Train: 80.07%, Valid: 81.23% Test: 79.41%\n",
      "Epoch: 1732, Loss: 53771.7422, Train: 80.11%, Valid: 81.23% Test: 79.48%\n",
      "Epoch: 1733, Loss: 53759.3750, Train: 80.12%, Valid: 81.30% Test: 79.48%\n",
      "Epoch: 1734, Loss: 53772.2266, Train: 80.13%, Valid: 81.23% Test: 79.55%\n",
      "Epoch: 1735, Loss: 53779.1602, Train: 80.14%, Valid: 81.23% Test: 79.55%\n",
      "Epoch: 1736, Loss: 53796.0625, Train: 80.18%, Valid: 81.44% Test: 79.55%\n",
      "Epoch: 1737, Loss: 53788.6328, Train: 80.19%, Valid: 81.44% Test: 79.55%\n",
      "Epoch: 1738, Loss: 53778.3320, Train: 80.19%, Valid: 81.44% Test: 79.55%\n",
      "Epoch: 1739, Loss: 53762.5000, Train: 80.19%, Valid: 81.44% Test: 79.48%\n",
      "Epoch: 1740, Loss: 53763.3906, Train: 80.19%, Valid: 81.37% Test: 79.48%\n",
      "Epoch: 1741, Loss: 53747.0820, Train: 80.15%, Valid: 81.37% Test: 79.41%\n",
      "Epoch: 1742, Loss: 53753.3828, Train: 80.15%, Valid: 81.37% Test: 79.55%\n",
      "Epoch: 1743, Loss: 53762.6250, Train: 80.14%, Valid: 81.37% Test: 79.55%\n",
      "Epoch: 1744, Loss: 53785.7734, Train: 80.12%, Valid: 81.23% Test: 79.48%\n",
      "Epoch: 1745, Loss: 53770.2539, Train: 80.11%, Valid: 81.23% Test: 79.34%\n",
      "Epoch: 1746, Loss: 53779.5781, Train: 80.09%, Valid: 81.23% Test: 79.06%\n",
      "Epoch: 1747, Loss: 53778.7617, Train: 80.07%, Valid: 81.23% Test: 78.93%\n",
      "Epoch: 1748, Loss: 53740.8672, Train: 80.09%, Valid: 81.23% Test: 79.13%\n",
      "Epoch: 1749, Loss: 53764.5352, Train: 80.11%, Valid: 81.23% Test: 79.20%\n",
      "Epoch: 1750, Loss: 53754.8516, Train: 80.13%, Valid: 81.30% Test: 79.20%\n",
      "Epoch: 1751, Loss: 53766.0469, Train: 80.15%, Valid: 81.30% Test: 79.27%\n",
      "Epoch: 1752, Loss: 53782.3906, Train: 80.15%, Valid: 81.30% Test: 79.27%\n",
      "Epoch: 1753, Loss: 53770.1523, Train: 80.16%, Valid: 81.30% Test: 79.20%\n",
      "Epoch: 1754, Loss: 53760.6680, Train: 80.15%, Valid: 81.30% Test: 79.20%\n",
      "Epoch: 1755, Loss: 53747.9531, Train: 80.16%, Valid: 81.37% Test: 79.20%\n",
      "Epoch: 1756, Loss: 53764.0703, Train: 80.19%, Valid: 81.44% Test: 79.20%\n",
      "Epoch: 1757, Loss: 53793.5547, Train: 80.17%, Valid: 81.37% Test: 79.34%\n",
      "Epoch: 1758, Loss: 53755.8516, Train: 80.17%, Valid: 81.30% Test: 79.20%\n",
      "Epoch: 1759, Loss: 53763.9453, Train: 80.15%, Valid: 81.30% Test: 79.20%\n",
      "Epoch: 1760, Loss: 53787.2578, Train: 80.12%, Valid: 81.23% Test: 79.13%\n",
      "Epoch: 1761, Loss: 53759.9023, Train: 80.11%, Valid: 81.23% Test: 79.13%\n",
      "Epoch: 1762, Loss: 53773.0977, Train: 80.09%, Valid: 81.23% Test: 79.13%\n",
      "Epoch: 1763, Loss: 53779.6016, Train: 80.08%, Valid: 81.23% Test: 79.13%\n",
      "Epoch: 1764, Loss: 53753.9062, Train: 80.07%, Valid: 81.16% Test: 79.13%\n",
      "Epoch: 1765, Loss: 53767.6055, Train: 80.10%, Valid: 81.16% Test: 79.20%\n",
      "Epoch: 1766, Loss: 53781.7656, Train: 80.10%, Valid: 81.16% Test: 79.20%\n",
      "Epoch: 1767, Loss: 53769.0586, Train: 80.09%, Valid: 81.23% Test: 79.41%\n",
      "Epoch: 1768, Loss: 53755.0430, Train: 80.10%, Valid: 81.23% Test: 79.61%\n",
      "Epoch: 1769, Loss: 53769.5859, Train: 80.12%, Valid: 81.16% Test: 79.61%\n",
      "Epoch: 1770, Loss: 53763.5156, Train: 80.11%, Valid: 81.16% Test: 79.61%\n",
      "Epoch: 1771, Loss: 53776.6094, Train: 80.11%, Valid: 81.16% Test: 79.61%\n",
      "Epoch: 1772, Loss: 53773.8203, Train: 80.13%, Valid: 81.37% Test: 79.68%\n",
      "Epoch: 1773, Loss: 53810.5391, Train: 80.13%, Valid: 81.30% Test: 79.68%\n",
      "Epoch: 1774, Loss: 53748.0078, Train: 80.13%, Valid: 81.30% Test: 79.68%\n",
      "Epoch: 1775, Loss: 53776.5391, Train: 80.12%, Valid: 81.30% Test: 79.68%\n",
      "Epoch: 1776, Loss: 53775.0703, Train: 80.14%, Valid: 81.30% Test: 79.68%\n",
      "Epoch: 1777, Loss: 53769.7031, Train: 80.13%, Valid: 81.23% Test: 79.68%\n",
      "Epoch: 1778, Loss: 53765.6953, Train: 80.14%, Valid: 81.30% Test: 79.75%\n",
      "Epoch: 1779, Loss: 53778.7539, Train: 80.14%, Valid: 81.30% Test: 79.68%\n",
      "Epoch: 1780, Loss: 53786.6016, Train: 80.14%, Valid: 81.30% Test: 79.61%\n",
      "Epoch: 1781, Loss: 53784.9961, Train: 80.14%, Valid: 81.23% Test: 79.61%\n",
      "Epoch: 1782, Loss: 53759.0938, Train: 80.15%, Valid: 81.30% Test: 79.61%\n",
      "Epoch: 1783, Loss: 53796.2188, Train: 80.13%, Valid: 81.30% Test: 79.61%\n",
      "Epoch: 1784, Loss: 53768.1641, Train: 80.13%, Valid: 81.23% Test: 79.61%\n",
      "Epoch: 1785, Loss: 53785.2500, Train: 80.13%, Valid: 81.23% Test: 79.61%\n",
      "Epoch: 1786, Loss: 53752.4180, Train: 80.13%, Valid: 81.16% Test: 79.48%\n",
      "Epoch: 1787, Loss: 53789.2891, Train: 80.19%, Valid: 81.30% Test: 79.55%\n",
      "Epoch: 1788, Loss: 53767.6250, Train: 80.25%, Valid: 81.30% Test: 79.48%\n",
      "Epoch: 1789, Loss: 53783.2969, Train: 80.30%, Valid: 81.30% Test: 79.48%\n",
      "Epoch: 1790, Loss: 53747.7852, Train: 80.38%, Valid: 81.30% Test: 79.55%\n",
      "Epoch: 1791, Loss: 53744.2500, Train: 80.38%, Valid: 81.30% Test: 79.48%\n",
      "Epoch: 1792, Loss: 53751.4219, Train: 80.38%, Valid: 81.23% Test: 79.55%\n",
      "Epoch: 1793, Loss: 53751.8672, Train: 80.35%, Valid: 81.30% Test: 79.61%\n",
      "Epoch: 1794, Loss: 53742.2109, Train: 80.35%, Valid: 81.30% Test: 79.61%\n",
      "Epoch: 1795, Loss: 53764.0078, Train: 80.41%, Valid: 81.30% Test: 79.68%\n",
      "Epoch: 1796, Loss: 53736.9531, Train: 80.40%, Valid: 81.37% Test: 79.75%\n",
      "Epoch: 1797, Loss: 53763.1094, Train: 80.42%, Valid: 81.44% Test: 79.75%\n",
      "Epoch: 1798, Loss: 53767.9023, Train: 80.46%, Valid: 81.44% Test: 79.61%\n",
      "Epoch: 1799, Loss: 53766.8320, Train: 80.46%, Valid: 81.44% Test: 79.61%\n",
      "Epoch: 1800, Loss: 53734.1719, Train: 80.41%, Valid: 81.51% Test: 79.68%\n",
      "Epoch: 1801, Loss: 53743.4297, Train: 80.40%, Valid: 81.58% Test: 79.61%\n",
      "Epoch: 1802, Loss: 53765.8594, Train: 80.38%, Valid: 81.58% Test: 79.48%\n",
      "Epoch: 1803, Loss: 53747.1758, Train: 80.36%, Valid: 81.58% Test: 79.34%\n",
      "Epoch: 1804, Loss: 53758.2812, Train: 80.33%, Valid: 81.58% Test: 79.41%\n",
      "Epoch: 1805, Loss: 53760.6562, Train: 80.38%, Valid: 81.51% Test: 79.41%\n",
      "Epoch: 1806, Loss: 53736.0391, Train: 80.38%, Valid: 81.44% Test: 79.27%\n",
      "Epoch: 1807, Loss: 53764.6250, Train: 80.44%, Valid: 81.44% Test: 79.27%\n",
      "Epoch: 1808, Loss: 53769.9453, Train: 80.47%, Valid: 81.44% Test: 79.34%\n",
      "Epoch: 1809, Loss: 53733.4961, Train: 80.45%, Valid: 81.44% Test: 79.48%\n",
      "Epoch: 1810, Loss: 53751.7891, Train: 80.45%, Valid: 81.44% Test: 79.61%\n",
      "Epoch: 1811, Loss: 53764.6484, Train: 80.46%, Valid: 81.37% Test: 79.82%\n",
      "Epoch: 1812, Loss: 53740.7227, Train: 80.47%, Valid: 81.44% Test: 79.82%\n",
      "Epoch: 1813, Loss: 53754.5273, Train: 80.48%, Valid: 81.44% Test: 79.75%\n",
      "Epoch: 1814, Loss: 53742.2969, Train: 80.47%, Valid: 81.51% Test: 79.82%\n",
      "Epoch: 1815, Loss: 53746.6562, Train: 80.49%, Valid: 81.51% Test: 79.82%\n",
      "Epoch: 1816, Loss: 53758.6562, Train: 80.50%, Valid: 81.51% Test: 79.82%\n",
      "Epoch: 1817, Loss: 53742.1836, Train: 80.47%, Valid: 81.51% Test: 79.75%\n",
      "Epoch: 1818, Loss: 53747.1719, Train: 80.44%, Valid: 81.51% Test: 79.82%\n",
      "Epoch: 1819, Loss: 53733.5469, Train: 80.44%, Valid: 81.44% Test: 79.75%\n",
      "Epoch: 1820, Loss: 53723.1562, Train: 80.45%, Valid: 81.30% Test: 79.75%\n",
      "Epoch: 1821, Loss: 53784.7188, Train: 80.42%, Valid: 81.23% Test: 79.68%\n",
      "Epoch: 1822, Loss: 53739.0391, Train: 80.45%, Valid: 81.23% Test: 79.61%\n",
      "Epoch: 1823, Loss: 53741.7031, Train: 80.45%, Valid: 81.23% Test: 79.55%\n",
      "Epoch: 1824, Loss: 53757.5977, Train: 80.45%, Valid: 81.23% Test: 79.61%\n",
      "Epoch: 1825, Loss: 53763.9219, Train: 80.45%, Valid: 81.16% Test: 79.61%\n",
      "Epoch: 1826, Loss: 53749.7422, Train: 80.46%, Valid: 81.23% Test: 79.61%\n",
      "Epoch: 1827, Loss: 53734.5156, Train: 80.41%, Valid: 81.23% Test: 79.68%\n",
      "Epoch: 1828, Loss: 53741.8008, Train: 80.43%, Valid: 81.16% Test: 79.68%\n",
      "Epoch: 1829, Loss: 53747.5039, Train: 80.49%, Valid: 81.30% Test: 79.68%\n",
      "Epoch: 1830, Loss: 53736.0391, Train: 80.48%, Valid: 81.44% Test: 79.75%\n",
      "Epoch: 1831, Loss: 53719.8750, Train: 80.46%, Valid: 81.44% Test: 79.82%\n",
      "Epoch: 1832, Loss: 53759.5430, Train: 80.47%, Valid: 81.37% Test: 79.89%\n",
      "Epoch: 1833, Loss: 53754.4805, Train: 80.46%, Valid: 81.37% Test: 79.89%\n",
      "Epoch: 1834, Loss: 53732.5078, Train: 80.45%, Valid: 81.37% Test: 79.82%\n",
      "Epoch: 1835, Loss: 53768.5039, Train: 80.45%, Valid: 81.30% Test: 79.82%\n",
      "Epoch: 1836, Loss: 53743.7031, Train: 80.41%, Valid: 81.23% Test: 79.75%\n",
      "Epoch: 1837, Loss: 53738.9219, Train: 80.43%, Valid: 81.23% Test: 79.75%\n",
      "Epoch: 1838, Loss: 53755.1875, Train: 80.44%, Valid: 81.23% Test: 79.82%\n",
      "Epoch: 1839, Loss: 53756.3203, Train: 80.47%, Valid: 81.23% Test: 79.96%\n",
      "Epoch: 1840, Loss: 53737.4141, Train: 80.46%, Valid: 81.23% Test: 79.82%\n",
      "Epoch: 1841, Loss: 53742.1016, Train: 80.47%, Valid: 81.23% Test: 79.82%\n",
      "Epoch: 1842, Loss: 53735.4062, Train: 80.49%, Valid: 81.23% Test: 79.75%\n",
      "Epoch: 1843, Loss: 53756.6172, Train: 80.48%, Valid: 81.30% Test: 79.75%\n",
      "Epoch: 1844, Loss: 53755.7656, Train: 80.48%, Valid: 81.30% Test: 79.75%\n",
      "Epoch: 1845, Loss: 53752.4688, Train: 80.45%, Valid: 81.30% Test: 79.68%\n",
      "Epoch: 1846, Loss: 53735.4688, Train: 80.45%, Valid: 81.30% Test: 79.61%\n",
      "Epoch: 1847, Loss: 53744.3516, Train: 80.45%, Valid: 81.30% Test: 79.61%\n",
      "Epoch: 1848, Loss: 53738.7891, Train: 80.47%, Valid: 81.30% Test: 79.61%\n",
      "Epoch: 1849, Loss: 53749.7617, Train: 80.47%, Valid: 81.30% Test: 79.61%\n",
      "Epoch: 1850, Loss: 53727.9844, Train: 80.47%, Valid: 81.30% Test: 79.61%\n",
      "Epoch: 1851, Loss: 53736.5898, Train: 80.48%, Valid: 81.37% Test: 79.55%\n",
      "Epoch: 1852, Loss: 53739.3047, Train: 80.48%, Valid: 81.44% Test: 79.48%\n",
      "Epoch: 1853, Loss: 53743.4609, Train: 80.45%, Valid: 81.44% Test: 79.34%\n",
      "Epoch: 1854, Loss: 53744.9648, Train: 80.47%, Valid: 81.44% Test: 79.34%\n",
      "Epoch: 1855, Loss: 53762.4219, Train: 80.46%, Valid: 81.30% Test: 79.41%\n",
      "Epoch: 1856, Loss: 53748.4648, Train: 80.47%, Valid: 81.30% Test: 79.48%\n",
      "Epoch: 1857, Loss: 53725.0938, Train: 80.45%, Valid: 81.37% Test: 79.55%\n",
      "Epoch: 1858, Loss: 53738.9219, Train: 80.45%, Valid: 81.37% Test: 79.55%\n",
      "Epoch: 1859, Loss: 53725.5000, Train: 80.45%, Valid: 81.30% Test: 79.55%\n",
      "Epoch: 1860, Loss: 53749.5156, Train: 80.45%, Valid: 81.37% Test: 79.55%\n",
      "Epoch: 1861, Loss: 53732.2617, Train: 80.45%, Valid: 81.30% Test: 79.55%\n",
      "Epoch: 1862, Loss: 53754.2148, Train: 80.43%, Valid: 81.30% Test: 79.48%\n",
      "Epoch: 1863, Loss: 53740.9609, Train: 80.41%, Valid: 81.23% Test: 79.48%\n",
      "Epoch: 1864, Loss: 53732.1172, Train: 80.43%, Valid: 81.23% Test: 79.48%\n",
      "Epoch: 1865, Loss: 53746.5547, Train: 80.45%, Valid: 81.23% Test: 79.55%\n",
      "Epoch: 1866, Loss: 53734.5781, Train: 80.45%, Valid: 81.23% Test: 79.48%\n",
      "Epoch: 1867, Loss: 53721.3828, Train: 80.45%, Valid: 81.23% Test: 79.61%\n",
      "Epoch: 1868, Loss: 53750.3750, Train: 80.44%, Valid: 81.23% Test: 79.68%\n",
      "Epoch: 1869, Loss: 53752.7930, Train: 80.42%, Valid: 81.30% Test: 79.61%\n",
      "Epoch: 1870, Loss: 53720.2188, Train: 80.42%, Valid: 81.37% Test: 79.75%\n",
      "Epoch: 1871, Loss: 53738.6641, Train: 80.45%, Valid: 81.37% Test: 79.75%\n",
      "Epoch: 1872, Loss: 53734.9258, Train: 80.45%, Valid: 81.37% Test: 79.61%\n",
      "Epoch: 1873, Loss: 53757.2969, Train: 80.46%, Valid: 81.37% Test: 79.55%\n",
      "Epoch: 1874, Loss: 53756.7812, Train: 80.46%, Valid: 81.37% Test: 79.55%\n",
      "Epoch: 1875, Loss: 53743.9062, Train: 80.47%, Valid: 81.37% Test: 79.41%\n",
      "Epoch: 1876, Loss: 53739.6328, Train: 80.44%, Valid: 81.37% Test: 79.61%\n",
      "Epoch: 1877, Loss: 53725.8633, Train: 80.45%, Valid: 81.37% Test: 79.61%\n",
      "Epoch: 1878, Loss: 53730.7227, Train: 80.45%, Valid: 81.44% Test: 79.61%\n",
      "Epoch: 1879, Loss: 53759.7734, Train: 80.45%, Valid: 81.37% Test: 79.61%\n",
      "Epoch: 1880, Loss: 53736.8750, Train: 80.45%, Valid: 81.37% Test: 79.68%\n",
      "Epoch: 1881, Loss: 53729.9844, Train: 80.45%, Valid: 81.37% Test: 79.75%\n",
      "Epoch: 1882, Loss: 53738.2695, Train: 80.45%, Valid: 81.37% Test: 79.82%\n",
      "Epoch: 1883, Loss: 53756.8828, Train: 80.45%, Valid: 81.37% Test: 79.82%\n",
      "Epoch: 1884, Loss: 53753.0742, Train: 80.44%, Valid: 81.37% Test: 79.82%\n",
      "Epoch: 1885, Loss: 53745.0586, Train: 80.44%, Valid: 81.30% Test: 79.75%\n",
      "Epoch: 1886, Loss: 53744.4922, Train: 80.43%, Valid: 81.30% Test: 79.75%\n",
      "Epoch: 1887, Loss: 53758.6836, Train: 80.45%, Valid: 81.30% Test: 79.68%\n",
      "Epoch: 1888, Loss: 53743.8281, Train: 80.41%, Valid: 81.37% Test: 79.61%\n",
      "Epoch: 1889, Loss: 53718.2812, Train: 80.39%, Valid: 81.37% Test: 79.55%\n",
      "Epoch: 1890, Loss: 53742.0859, Train: 80.39%, Valid: 81.37% Test: 79.48%\n",
      "Epoch: 1891, Loss: 53756.7539, Train: 80.38%, Valid: 81.37% Test: 79.34%\n",
      "Epoch: 1892, Loss: 53754.8281, Train: 80.40%, Valid: 81.44% Test: 79.34%\n",
      "Epoch: 1893, Loss: 53763.1328, Train: 80.40%, Valid: 81.44% Test: 79.34%\n",
      "Epoch: 1894, Loss: 53724.1484, Train: 80.41%, Valid: 81.44% Test: 79.41%\n",
      "Epoch: 1895, Loss: 53747.8750, Train: 80.42%, Valid: 81.37% Test: 79.55%\n",
      "Epoch: 1896, Loss: 53734.4844, Train: 80.41%, Valid: 81.37% Test: 79.48%\n",
      "Epoch: 1897, Loss: 53747.6719, Train: 80.42%, Valid: 81.37% Test: 79.48%\n",
      "Epoch: 1898, Loss: 53731.0508, Train: 80.42%, Valid: 81.30% Test: 79.48%\n",
      "Epoch: 1899, Loss: 53746.7578, Train: 80.45%, Valid: 81.37% Test: 79.68%\n",
      "Epoch: 1900, Loss: 53746.1250, Train: 80.45%, Valid: 81.23% Test: 79.68%\n",
      "Epoch: 1901, Loss: 53734.6797, Train: 80.45%, Valid: 81.23% Test: 79.68%\n",
      "Epoch: 1902, Loss: 53720.4062, Train: 80.39%, Valid: 81.23% Test: 79.75%\n",
      "Epoch: 1903, Loss: 53745.0000, Train: 80.38%, Valid: 81.23% Test: 79.68%\n",
      "Epoch: 1904, Loss: 53729.8672, Train: 80.39%, Valid: 81.23% Test: 79.68%\n",
      "Epoch: 1905, Loss: 53738.9414, Train: 80.38%, Valid: 81.30% Test: 79.55%\n",
      "Epoch: 1906, Loss: 53735.9531, Train: 80.41%, Valid: 81.30% Test: 79.61%\n",
      "Epoch: 1907, Loss: 53742.7227, Train: 80.45%, Valid: 81.37% Test: 79.55%\n",
      "Epoch: 1908, Loss: 53741.3906, Train: 80.48%, Valid: 81.44% Test: 79.75%\n",
      "Epoch: 1909, Loss: 53735.0508, Train: 80.46%, Valid: 81.44% Test: 79.75%\n",
      "Epoch: 1910, Loss: 53754.5898, Train: 80.44%, Valid: 81.37% Test: 79.68%\n",
      "Epoch: 1911, Loss: 53729.8984, Train: 80.41%, Valid: 81.37% Test: 79.61%\n",
      "Epoch: 1912, Loss: 53747.3516, Train: 80.42%, Valid: 81.37% Test: 79.61%\n",
      "Epoch: 1913, Loss: 53734.5742, Train: 80.40%, Valid: 81.37% Test: 79.55%\n",
      "Epoch: 1914, Loss: 53739.8594, Train: 80.41%, Valid: 81.30% Test: 79.68%\n",
      "Epoch: 1915, Loss: 53744.5469, Train: 80.43%, Valid: 81.30% Test: 79.82%\n",
      "Epoch: 1916, Loss: 53726.0586, Train: 80.46%, Valid: 81.30% Test: 79.82%\n",
      "Epoch: 1917, Loss: 53734.4922, Train: 80.48%, Valid: 81.44% Test: 79.89%\n",
      "Epoch: 1918, Loss: 53727.4961, Train: 80.49%, Valid: 81.51% Test: 79.89%\n",
      "Epoch: 1919, Loss: 53736.1953, Train: 80.51%, Valid: 81.44% Test: 79.89%\n",
      "Epoch: 1920, Loss: 53737.0156, Train: 80.51%, Valid: 81.44% Test: 79.96%\n",
      "Epoch: 1921, Loss: 53723.9141, Train: 80.51%, Valid: 81.51% Test: 80.03%\n",
      "Epoch: 1922, Loss: 53724.2734, Train: 80.50%, Valid: 81.44% Test: 80.03%\n",
      "Epoch: 1923, Loss: 53754.0078, Train: 80.51%, Valid: 81.44% Test: 79.96%\n",
      "Epoch: 1924, Loss: 53726.5391, Train: 80.49%, Valid: 81.44% Test: 79.89%\n",
      "Epoch: 1925, Loss: 53748.3594, Train: 80.49%, Valid: 81.37% Test: 79.75%\n",
      "Epoch: 1926, Loss: 53735.4375, Train: 80.48%, Valid: 81.37% Test: 79.55%\n",
      "Epoch: 1927, Loss: 53722.7070, Train: 80.45%, Valid: 81.37% Test: 79.55%\n",
      "Epoch: 1928, Loss: 53720.9453, Train: 80.42%, Valid: 81.44% Test: 79.68%\n",
      "Epoch: 1929, Loss: 53740.6953, Train: 80.43%, Valid: 81.51% Test: 79.68%\n",
      "Epoch: 1930, Loss: 53758.1562, Train: 80.44%, Valid: 81.51% Test: 79.75%\n",
      "Epoch: 1931, Loss: 53724.1133, Train: 80.43%, Valid: 81.51% Test: 79.75%\n",
      "Epoch: 1932, Loss: 53726.8242, Train: 80.42%, Valid: 81.51% Test: 79.82%\n",
      "Epoch: 1933, Loss: 53751.8750, Train: 80.42%, Valid: 81.51% Test: 79.89%\n",
      "Epoch: 1934, Loss: 53746.6172, Train: 80.43%, Valid: 81.51% Test: 79.89%\n",
      "Epoch: 1935, Loss: 53746.0938, Train: 80.44%, Valid: 81.51% Test: 79.89%\n",
      "Epoch: 1936, Loss: 53725.0703, Train: 80.45%, Valid: 81.51% Test: 79.96%\n",
      "Epoch: 1937, Loss: 53723.0312, Train: 80.45%, Valid: 81.51% Test: 79.82%\n",
      "Epoch: 1938, Loss: 53726.9531, Train: 80.45%, Valid: 81.51% Test: 79.82%\n",
      "Epoch: 1939, Loss: 53691.5547, Train: 80.46%, Valid: 81.51% Test: 79.82%\n",
      "Epoch: 1940, Loss: 53731.6211, Train: 80.46%, Valid: 81.51% Test: 79.82%\n",
      "Epoch: 1941, Loss: 53739.2969, Train: 80.49%, Valid: 81.51% Test: 79.82%\n",
      "Epoch: 1942, Loss: 53727.3398, Train: 80.51%, Valid: 81.51% Test: 79.75%\n",
      "Epoch: 1943, Loss: 53739.2578, Train: 80.49%, Valid: 81.51% Test: 79.75%\n",
      "Epoch: 1944, Loss: 53733.2891, Train: 80.49%, Valid: 81.51% Test: 79.75%\n",
      "Epoch: 1945, Loss: 53710.6445, Train: 80.45%, Valid: 81.51% Test: 79.68%\n",
      "Epoch: 1946, Loss: 53742.1445, Train: 80.44%, Valid: 81.51% Test: 79.68%\n",
      "Epoch: 1947, Loss: 53758.7500, Train: 80.45%, Valid: 81.44% Test: 79.61%\n",
      "Epoch: 1948, Loss: 53756.2812, Train: 80.46%, Valid: 81.51% Test: 79.75%\n",
      "Epoch: 1949, Loss: 53734.9062, Train: 80.46%, Valid: 81.51% Test: 79.75%\n",
      "Epoch: 1950, Loss: 53719.5859, Train: 80.47%, Valid: 81.51% Test: 79.75%\n",
      "Epoch: 1951, Loss: 53732.7500, Train: 80.46%, Valid: 81.51% Test: 79.68%\n",
      "Epoch: 1952, Loss: 53716.0547, Train: 80.48%, Valid: 81.44% Test: 79.68%\n",
      "Epoch: 1953, Loss: 53720.8438, Train: 80.48%, Valid: 81.44% Test: 79.82%\n",
      "Epoch: 1954, Loss: 53705.5938, Train: 80.48%, Valid: 81.51% Test: 79.89%\n",
      "Epoch: 1955, Loss: 53740.2578, Train: 80.51%, Valid: 81.51% Test: 79.89%\n",
      "Epoch: 1956, Loss: 53742.5312, Train: 80.51%, Valid: 81.51% Test: 79.96%\n",
      "Epoch: 1957, Loss: 53732.6406, Train: 80.51%, Valid: 81.51% Test: 80.03%\n",
      "Epoch: 1958, Loss: 53734.7266, Train: 80.51%, Valid: 81.51% Test: 80.03%\n",
      "Epoch: 1959, Loss: 53770.8555, Train: 80.52%, Valid: 81.51% Test: 80.03%\n",
      "Epoch: 1960, Loss: 53764.0078, Train: 80.51%, Valid: 81.51% Test: 80.03%\n",
      "Epoch: 1961, Loss: 53756.9453, Train: 80.51%, Valid: 81.51% Test: 80.03%\n",
      "Epoch: 1962, Loss: 53729.0273, Train: 80.52%, Valid: 81.51% Test: 79.96%\n",
      "Epoch: 1963, Loss: 53728.0547, Train: 80.51%, Valid: 81.51% Test: 79.82%\n",
      "Epoch: 1964, Loss: 53725.5312, Train: 80.53%, Valid: 81.51% Test: 79.82%\n",
      "Epoch: 1965, Loss: 53733.1094, Train: 80.54%, Valid: 81.51% Test: 79.75%\n",
      "Epoch: 1966, Loss: 53718.2656, Train: 80.53%, Valid: 81.44% Test: 79.68%\n",
      "Epoch: 1967, Loss: 53721.8281, Train: 80.51%, Valid: 81.37% Test: 79.55%\n",
      "Epoch: 1968, Loss: 53736.8203, Train: 80.51%, Valid: 81.37% Test: 79.55%\n",
      "Epoch: 1969, Loss: 53730.8281, Train: 80.49%, Valid: 81.37% Test: 79.55%\n",
      "Epoch: 1970, Loss: 53749.5312, Train: 80.49%, Valid: 81.37% Test: 79.55%\n",
      "Epoch: 1971, Loss: 53729.2812, Train: 80.51%, Valid: 81.44% Test: 79.48%\n",
      "Epoch: 1972, Loss: 53757.6406, Train: 80.51%, Valid: 81.44% Test: 79.75%\n",
      "Epoch: 1973, Loss: 53736.3594, Train: 80.53%, Valid: 81.44% Test: 79.75%\n",
      "Epoch: 1974, Loss: 53731.9766, Train: 80.54%, Valid: 81.51% Test: 79.82%\n",
      "Epoch: 1975, Loss: 53725.4258, Train: 80.53%, Valid: 81.51% Test: 79.89%\n",
      "Epoch: 1976, Loss: 53704.9609, Train: 80.53%, Valid: 81.44% Test: 79.89%\n",
      "Epoch: 1977, Loss: 53749.8984, Train: 80.52%, Valid: 81.51% Test: 79.89%\n",
      "Epoch: 1978, Loss: 53715.5078, Train: 80.54%, Valid: 81.51% Test: 80.03%\n",
      "Epoch: 1979, Loss: 53727.0938, Train: 80.51%, Valid: 81.51% Test: 80.03%\n",
      "Epoch: 1980, Loss: 53737.6484, Train: 80.53%, Valid: 81.51% Test: 79.96%\n",
      "Epoch: 1981, Loss: 53733.9531, Train: 80.51%, Valid: 81.51% Test: 79.96%\n",
      "Epoch: 1982, Loss: 53730.2891, Train: 80.49%, Valid: 81.51% Test: 79.75%\n",
      "Epoch: 1983, Loss: 53738.5234, Train: 80.47%, Valid: 81.44% Test: 79.82%\n",
      "Epoch: 1984, Loss: 53729.8320, Train: 80.48%, Valid: 81.30% Test: 79.75%\n",
      "Epoch: 1985, Loss: 53702.3672, Train: 80.47%, Valid: 81.37% Test: 79.75%\n",
      "Epoch: 1986, Loss: 53736.6250, Train: 80.47%, Valid: 81.37% Test: 79.68%\n",
      "Epoch: 1987, Loss: 53724.0898, Train: 80.45%, Valid: 81.37% Test: 79.55%\n",
      "Epoch: 1988, Loss: 53721.7227, Train: 80.40%, Valid: 81.37% Test: 79.48%\n",
      "Epoch: 1989, Loss: 53752.2188, Train: 80.43%, Valid: 81.37% Test: 79.48%\n",
      "Epoch: 1990, Loss: 53740.1133, Train: 80.45%, Valid: 81.37% Test: 79.48%\n",
      "Epoch: 1991, Loss: 53740.3320, Train: 80.45%, Valid: 81.51% Test: 79.55%\n",
      "Epoch: 1992, Loss: 53674.7266, Train: 80.47%, Valid: 81.44% Test: 79.61%\n",
      "Epoch: 1993, Loss: 53700.4766, Train: 80.47%, Valid: 81.51% Test: 79.61%\n",
      "Epoch: 1994, Loss: 53732.9688, Train: 80.50%, Valid: 81.51% Test: 79.61%\n",
      "Epoch: 1995, Loss: 53723.5664, Train: 80.48%, Valid: 81.51% Test: 79.61%\n",
      "Epoch: 1996, Loss: 53740.6328, Train: 80.49%, Valid: 81.44% Test: 79.55%\n",
      "Epoch: 1997, Loss: 53748.2422, Train: 80.51%, Valid: 81.44% Test: 79.55%\n",
      "Epoch: 1998, Loss: 53722.0234, Train: 80.51%, Valid: 81.44% Test: 79.55%\n",
      "Epoch: 1999, Loss: 53744.2422, Train: 80.52%, Valid: 81.44% Test: 79.55%\n",
      "Epoch: 2000, Loss: 53716.8398, Train: 80.50%, Valid: 81.44% Test: 79.61%\n"
     ]
    }
   ],
   "source": [
    "n2vnet_model.reset_parameters()\n",
    "\n",
    "optimizer = torch.optim.Adam(n2vnet_model.parameters(), lr=n2vnet_args['lr'])\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=None , reduction=\"sum\")\n",
    "\n",
    "best_model = None\n",
    "best_valid_acc = 0\n",
    "\n",
    "for epoch in range(1, 1 + n2vnet_args[\"epochs\"]):\n",
    "  \n",
    "  loss = train_n2v(n2vnet_model , embeddings , data , optimizer, loss_fn)\n",
    "  result = test_n2v(n2vnet_model, embeddings , data)\n",
    "\n",
    "  c_train , c_val , c_test = result\n",
    "\n",
    "  if acc(c_val) > best_valid_acc:\n",
    "      best_valid_acc = acc(c_val)\n",
    "      best_model = copy.deepcopy(n2vnet_model)\n",
    "        \n",
    "  n2vnet_logger.info(f'Epoch {epoch:02d} '\n",
    "      f'Loss {loss:.4f} '\n",
    "      f'Train {c_train[0][0]:02d} {c_train[0][1]:02d} {c_train[1][0]:02d} {c_train[1][1]:02d} '\n",
    "      f'Valid {c_val[0][0]:02d} {c_val[0][1]:02d} {c_val[1][0]:02d} {c_val[1][1]:02d} '\n",
    "      f'Test {c_val[0][0]:02d} {c_val[0][1]:02d} {c_val[1][0]:02d} {c_val[1][1]:02d} ')\n",
    "  \n",
    "  print((f'Epoch: {epoch:02d}, '\n",
    "        f'Loss: {loss:.4f}, '\n",
    "        f'Train: {100 * acc(c_train):.2f}%, '\n",
    "        f'Valid: {100 * acc(c_val):.2f}% '\n",
    "        f'Test: {100 * acc(c_test):.2f}%'))\n",
    "  \n",
    "handlers = n2vnet_logger.handlers[:]\n",
    "for handler in handlers:\n",
    "    n2vnet_logger.removeHandler(handler)\n",
    "    handler.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../models/n2vnet_200.pt\"\n",
    "torch.save(best_model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model = n2vnet(data.g , input_dim = n2vnet_args[\"embedding_dim\"], hidden_dim = n2vnet_args[\"hidden_dim\"], output_dim = data.y.shape[1], num_layers = n2vnet_args[\"num_layers\"], dropout = n2vnet_args['dropout']).to(device)\n",
    "load_model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n2vnet(\n",
       "  (dense_layers): ModuleList(\n",
       "    (0-2): 3 x Linear(in_features=16, out_features=16, bias=True)\n",
       "    (3): Linear(in_features=16, out_features=200, bias=True)\n",
       "  )\n",
       "  (output): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9224, device='mps:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((load_model(embeddings)>0.5) == data.y).sum()/(data.y.shape[0]*data.y.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array(data.g.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33380, 33380)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.eye(len(a))[a]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    8,    7, ..., 1904, 1903, 1902])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DegreeView({0: 0, 8: 3, 7: 6, 6: 0, 5: 0, 4: 1, 3: 1, 2: 1, 1: 1, 80: 2, 79: 2, 78: 4, 77: 1, 76: 2, 75: 3, 74: 6, 73: 2, 72: 6, 71: 4, 70: 2, 69: 3, 68: 2, 67: 7, 66: 2, 65: 1, 64: 1, 63: 7, 62: 2, 61: 5, 60: 5, 59: 23, 58: 3, 57: 1, 56: 9, 55: 8, 54: 1, 53: 6, 52: 3, 51: 4, 50: 1, 49: 0, 48: 5, 47: 2, 46: 0, 45: 1, 44: 1, 43: 4, 42: 2, 41: 1, 40: 4, 39: 4, 38: 2, 37: 3, 36: 4, 35: 4, 34: 4, 33: 6, 32: 4, 31: 1, 30: 3, 29: 1, 28: 3, 27: 0, 26: 2, 25: 1, 24: 1, 23: 1, 22: 0, 21: 1, 20: 1, 19: 4, 18: 0, 17: 3, 16: 2, 15: 1, 14: 2, 13: 1, 12: 2, 11: 6, 10: 2, 9: 4, 1901: 5, 1900: 2, 1899: 8, 1898: 4, 1897: 4, 1896: 1, 1895: 1, 1894: 7, 1893: 16, 1892: 3, 1891: 2, 1890: 1, 1889: 19, 1888: 3, 1887: 7, 1886: 22, 1885: 2, 1884: 6, 1883: 3, 1882: 1, 1881: 8, 1880: 12, 1879: 5, 1878: 11, 1877: 9, 1876: 2, 1875: 6, 1874: 13, 1873: 3, 1872: 5, 1871: 6, 1870: 5, 1869: 5, 1868: 1, 1867: 6, 1866: 3, 1865: 1, 1864: 5, 1863: 1, 1862: 4, 1861: 5, 1860: 0, 1859: 4, 1858: 1, 1857: 5, 1856: 7, 1855: 4, 1854: 2, 1853: 3, 1852: 1, 1851: 3, 1850: 0, 1849: 1, 1848: 5, 1847: 3, 1846: 2, 1845: 2, 1844: 1, 1843: 7, 1842: 8, 1841: 14, 1840: 9, 1839: 10, 1838: 32, 1837: 0, 1836: 3, 1835: 11, 1834: 1, 1833: 0, 1832: 5, 1831: 0, 1830: 3, 1829: 4, 1828: 2, 1827: 3, 1826: 0, 1825: 5, 1824: 2, 1823: 2, 1822: 2, 1821: 1, 1820: 16, 1819: 4, 1818: 2, 1817: 2, 1816: 1, 1815: 4, 1814: 5, 1813: 6, 1812: 5, 1811: 4, 1810: 0, 1809: 7, 1808: 0, 1807: 2, 1806: 1, 1805: 2, 1804: 8, 1803: 6, 1802: 4, 1801: 2, 1800: 14, 1799: 3, 1798: 6, 1797: 11, 1796: 5, 1795: 1, 1794: 29, 1793: 4, 1792: 1, 1791: 4, 1790: 1, 1789: 8, 1788: 7, 1787: 3, 1786: 7, 1785: 5, 1784: 4, 1783: 14, 1782: 4, 1781: 3, 1780: 3, 1779: 1, 1778: 0, 1777: 20, 1776: 8, 1775: 16, 1774: 6, 1773: 0, 1772: 3, 1771: 18, 1770: 16, 1769: 9, 1768: 1, 1767: 6, 1766: 2, 1765: 6, 1764: 4, 1763: 27, 1762: 1, 1761: 1, 1760: 3, 1759: 12, 1758: 5, 1757: 6, 1756: 9, 1755: 0, 1754: 2, 1753: 3, 1752: 3, 1751: 7, 1750: 8, 1749: 15, 1748: 2, 1747: 1, 1746: 2, 1745: 4, 1744: 1, 1743: 3, 1742: 3, 1741: 4, 1740: 3, 1739: 2, 1738: 5, 1737: 5, 1736: 6, 1735: 10, 1734: 1, 1733: 1, 1732: 5, 1731: 9, 1730: 3, 1729: 2, 1728: 9, 1727: 1, 1726: 1, 1725: 0, 1724: 7, 1723: 22, 1722: 10, 1721: 3, 1720: 6, 1719: 6, 1718: 1, 1717: 4, 1716: 1, 1715: 2, 1714: 7, 1713: 17, 1712: 1, 1711: 7, 1710: 4, 1709: 3, 1708: 2, 1707: 4, 1706: 18, 1705: 2, 1704: 3, 1703: 5, 1702: 3, 1701: 7, 1700: 5, 1699: 2, 1698: 6, 1697: 1, 1696: 9, 1695: 1, 1694: 0, 1693: 14, 1692: 10, 1691: 7, 1690: 0, 1689: 0, 1688: 10, 1687: 18, 1686: 5, 1685: 9, 1684: 15, 1683: 12, 1682: 13, 1681: 11, 1680: 9, 1679: 8, 1678: 8, 1677: 11, 1676: 5, 1675: 7, 1674: 18, 1673: 3, 1672: 3, 1671: 4, 1670: 2, 1669: 1, 1668: 12, 1667: 1, 1666: 1, 1665: 11, 1664: 4, 1663: 11, 1662: 3, 1661: 1, 1660: 1, 1659: 11, 1658: 3, 1657: 20, 1656: 2, 1655: 10, 1654: 1, 1653: 2, 1652: 5, 1651: 1, 1650: 4, 1649: 2, 1648: 5, 1647: 4, 1646: 6, 1645: 2, 1644: 1, 1643: 4, 1642: 4, 1641: 8, 1640: 0, 1639: 3, 1638: 0, 1637: 2, 1636: 2, 1635: 1, 1634: 19, 1633: 14, 1632: 1, 1631: 1, 1630: 14, 1629: 6, 1628: 4, 1627: 0, 1626: 52, 1625: 5, 1624: 0, 1623: 2, 1622: 0, 1621: 3, 1620: 10, 1619: 0, 1618: 13, 1617: 3, 1616: 3, 1615: 3, 1614: 24, 1613: 3, 1612: 11, 1611: 3, 1610: 2, 1609: 19, 1608: 4, 1607: 2, 1606: 5, 1605: 1, 1604: 1, 1603: 6, 1602: 3, 1601: 2, 1600: 3, 1599: 1, 1598: 19, 1597: 3, 1596: 1, 1595: 1, 1594: 6, 1593: 6, 1592: 8, 1591: 4, 1590: 1, 1589: 0, 1588: 4, 1587: 3, 1586: 8, 1585: 12, 1584: 13, 1583: 3, 1582: 16, 1581: 1, 1580: 5, 1579: 2, 1578: 8, 1577: 9, 1576: 9, 1575: 6, 1574: 2, 1573: 5, 1572: 4, 1571: 3, 1570: 12, 1569: 11, 1568: 33, 1567: 2, 1566: 2, 1565: 2, 1564: 4, 1563: 4, 1562: 5, 1561: 1, 1560: 30, 1559: 43, 1558: 3, 1557: 7, 1556: 3, 1555: 6, 1554: 6, 1553: 2, 1552: 7, 1551: 10, 1550: 3, 1549: 2, 1548: 8, 1547: 1, 1546: 2, 1545: 2, 1544: 5, 1543: 1, 1542: 4, 1541: 9, 1540: 4, 1539: 2, 1538: 4, 1537: 3, 1536: 4, 1535: 0, 1534: 11, 1533: 1, 1532: 0, 1531: 4, 1530: 3, 1529: 1, 1528: 2, 1527: 0, 1526: 4, 1525: 15, 1524: 6, 1523: 1, 1522: 6, 1521: 1, 1520: 1, 1519: 3, 1518: 2, 1517: 2, 1516: 5, 1515: 4, 1514: 2, 1513: 13, 1512: 3, 1511: 3, 1510: 3, 1509: 4, 1508: 4, 1507: 1, 1506: 4, 1505: 7, 1504: 14, 1503: 4, 1502: 3, 1501: 12, 1500: 4, 1499: 10, 1498: 2, 1497: 1, 1496: 27, 1495: 1, 1494: 7, 1493: 0, 1492: 6, 1491: 6, 1490: 10, 1489: 3, 1488: 10, 1487: 5, 1486: 10, 1485: 11, 1484: 7, 1483: 3, 1482: 8, 1481: 1, 1480: 7, 1479: 1, 1478: 2, 1477: 5, 1476: 66, 1475: 14, 1474: 1, 1473: 1, 1472: 19, 1471: 7, 1470: 2, 1469: 5, 1468: 4, 1467: 6, 1466: 4, 1465: 3, 1464: 3, 1463: 3, 1462: 4, 1461: 2, 1460: 7, 1459: 1, 1458: 13, 1457: 6, 1456: 24, 1455: 1, 1454: 3, 1453: 6, 1452: 7, 1451: 6, 1450: 5, 1449: 9, 1448: 3, 1447: 0, 1446: 2, 1445: 10, 1444: 4, 1443: 5, 1442: 6, 1441: 1, 1440: 7, 1439: 6, 1438: 0, 1437: 30, 1436: 3, 1435: 2, 1434: 2, 1433: 13, 1432: 1, 1431: 7, 1430: 2, 1429: 2, 1428: 2, 1427: 3, 1426: 5, 1425: 10, 1424: 3, 1423: 1, 1422: 24, 1421: 2, 1420: 11, 1419: 2, 1418: 10, 1417: 8, 1416: 2, 1415: 18, 1414: 1, 1413: 6, 1412: 1, 1411: 4, 1410: 24, 1409: 5, 1408: 4, 1407: 1, 1406: 7, 1405: 12, 1404: 17, 1403: 4, 1402: 5, 1401: 5, 1400: 8, 1399: 9, 1398: 6, 1397: 2, 1396: 2, 1395: 9, 1394: 3, 1393: 5, 1392: 2, 1391: 15, 1390: 2, 1389: 3, 1388: 1, 1387: 5, 1386: 7, 1385: 12, 1384: 14, 1383: 11, 1382: 2, 1381: 8, 1380: 4, 1379: 2, 1378: 16, 1377: 13, 1376: 2, 1375: 4, 1374: 5, 1373: 4, 1372: 2, 1371: 4, 1370: 5, 1369: 1, 1368: 1, 1367: 3, 1366: 1, 1365: 2, 1364: 2, 1363: 0, 1362: 7, 1361: 1, 1360: 9, 1359: 26, 1358: 9, 1357: 2, 1356: 1, 1355: 5, 1354: 6, 1353: 6, 1352: 4, 1351: 3, 1350: 4, 1349: 16, 1348: 1, 1347: 1, 1346: 2, 1345: 1, 1344: 0, 1343: 9, 1342: 3, 1341: 13, 1340: 2, 1339: 22, 1338: 5, 1337: 7, 1336: 3, 1335: 3, 1334: 1, 1333: 6, 1332: 5, 1331: 3, 1330: 1, 1329: 2, 1328: 12, 1327: 2, 1326: 11, 1325: 17, 1324: 16, 1323: 2, 1322: 2, 1321: 17, 1320: 7, 1319: 14, 1318: 1, 1317: 2, 1316: 21, 1315: 18, 1314: 5, 1313: 3, 1312: 4, 1311: 2, 1310: 10, 1309: 5, 1308: 3, 1307: 6, 1306: 2, 1305: 1, 1304: 5, 1303: 5, 1302: 50, 1301: 7, 1300: 1, 1299: 9, 1298: 7, 1297: 7, 1296: 4, 1295: 1, 1294: 5, 1293: 0, 1292: 5, 1291: 0, 1290: 3, 1289: 2, 1288: 6, 1287: 19, 1286: 9, 1285: 0, 1284: 1, 1283: 2, 1282: 2, 1281: 1, 1280: 1, 1279: 14, 1278: 1, 1277: 4, 1276: 23, 1275: 4, 1274: 4, 1273: 5, 1272: 0, 1271: 15, 1270: 1, 1269: 2, 1268: 0, 1267: 4, 1266: 3, 1265: 2, 1264: 1, 1263: 26, 1262: 4, 1261: 3, 1260: 6, 1259: 4, 1258: 2, 1257: 0, 1256: 6, 1255: 5, 1254: 11, 1253: 5, 1252: 7, 1251: 9, 1250: 15, 1249: 0, 1248: 1, 1247: 4, 1246: 3, 1245: 7, 1244: 5, 1243: 0, 1242: 11, 1241: 2, 1240: 6, 1239: 7, 1238: 1, 1237: 1, 1236: 2, 1235: 11, 1234: 11, 1233: 7, 1232: 2, 1231: 6, 1230: 4, 1229: 2, 1228: 6, 1227: 8, 1226: 12, 1225: 3, 1224: 6, 1223: 7, 1222: 8, 1221: 3, 1220: 7, 1219: 15, 1218: 33, 1217: 5, 1216: 1, 1215: 6, 1214: 2, 1213: 6, 1212: 2, 1211: 3, 1210: 2, 1209: 3, 1208: 2, 1207: 4, 1206: 3, 1205: 14, 1204: 5, 1203: 2, 1202: 6, 1201: 3, 1200: 6, 1199: 7, 1198: 1, 1197: 3, 1196: 1, 1195: 2, 1194: 21, 1193: 6, 1192: 11, 1191: 5, 1190: 3, 1189: 3, 1188: 3, 1187: 7, 1186: 13, 1185: 3, 1184: 4, 1183: 4, 1182: 4, 1181: 8, 1180: 8, 1179: 0, 1178: 1, 1177: 1, 1176: 1, 1175: 40, 1174: 3, 1173: 7, 1172: 62, 1171: 3, 1170: 5, 1169: 1, 1168: 1, 1167: 0, 1166: 2, 1165: 1, 1164: 2, 1163: 0, 1162: 9, 1161: 19, 1160: 4, 1159: 4, 1158: 21, 1157: 7, 1156: 1, 1155: 1, 1154: 3, 1153: 3, 1152: 11, 1151: 10, 1150: 0, 1149: 6, 1148: 5, 1147: 0, 1146: 4, 1145: 6, 1144: 0, 1143: 0, 1142: 1, 1141: 2, 1140: 1, 1139: 0, 1138: 6, 1137: 17, 1136: 5, 1135: 1, 1134: 15, 1133: 11, 1132: 4, 1131: 3, 1130: 2, 1129: 3, 1128: 2, 1127: 13, 1126: 8, 1125: 4, 1124: 12, 1123: 1, 1122: 4, 1121: 2, 1120: 10, 1119: 1, 1118: 1, 1117: 6, 1116: 0, 1115: 7, 1114: 2, 1113: 5, 1112: 5, 1111: 6, 1110: 15, 1109: 0, 1108: 3, 1107: 10, 1106: 1, 1105: 2, 1104: 7, 1103: 4, 1102: 5, 1101: 5, 1100: 1, 1099: 1, 1098: 7, 1097: 6, 1096: 0, 1095: 1, 1094: 1, 1093: 5, 1092: 3, 1091: 7, 1090: 4, 1089: 3, 1088: 55, 1087: 14, 1086: 2, 1085: 6, 1084: 5, 1083: 4, 1082: 2, 1081: 4, 1080: 7, 1079: 8, 1078: 2, 1077: 1, 1076: 27, 1075: 6, 1074: 10, 1073: 2, 1072: 3, 1071: 41, 1070: 1, 1069: 0, 1068: 1, 1067: 1, 1066: 1, 1065: 4, 1064: 4, 1063: 2, 1062: 5, 1061: 6, 1060: 7, 1059: 13, 1058: 10, 1057: 0, 1056: 44, 1055: 8, 1054: 3, 1053: 10, 1052: 4, 1051: 2, 1050: 5, 1049: 0, 1048: 4, 1047: 3, 1046: 1, 1045: 2, 1044: 2, 1043: 0, 1042: 1, 1041: 4, 1040: 8, 1039: 5, 1038: 18, 1037: 2, 1036: 1, 1035: 4, 1034: 3, 1033: 1, 1032: 3, 1031: 3, 1030: 2, 1029: 7, 1028: 16, 1027: 6, 1026: 28, 1025: 3, 1024: 2, 1023: 9, 1022: 7, 1021: 2, 1020: 4, 1019: 0, 1018: 3, 1017: 2, 1016: 1, 1015: 17, 1014: 4, 1013: 5, 1012: 3, 1011: 3, 1010: 1, 1009: 3, 1008: 35, 1007: 12, 1006: 5, 1005: 2, 1004: 7, 1003: 4, 1002: 2, 1001: 4, 1000: 1, 999: 14, 998: 6, 997: 2, 996: 2, 995: 3, 994: 12, 993: 4, 992: 0, 991: 0, 990: 26, 989: 4, 988: 3, 987: 3, 986: 10, 985: 1, 984: 26, 983: 4, 982: 3, 981: 2, 980: 4, 979: 0, 978: 0, 977: 3, 976: 3, 975: 5, 974: 7, 973: 2, 972: 0, 971: 3, 970: 4, 969: 1, 968: 8, 967: 0, 966: 6, 965: 7, 964: 4, 963: 2, 962: 5, 961: 6, 960: 3, 959: 6, 958: 2, 957: 0, 956: 0, 955: 0, 954: 2, 953: 2, 952: 2, 951: 4, 950: 1, 949: 3, 948: 2, 947: 1, 946: 10, 945: 3, 944: 4, 943: 7, 942: 9, 941: 19, 940: 4, 939: 1, 938: 2, 937: 1, 936: 19, 935: 3, 934: 1, 933: 2, 932: 4, 931: 9, 930: 0, 929: 0, 928: 1, 927: 3, 926: 10, 925: 1, 924: 14, 923: 4, 922: 0, 921: 10, 920: 4, 919: 7, 918: 11, 917: 2, 916: 12, 915: 2, 914: 1, 913: 4, 912: 1, 911: 1, 910: 2, 909: 2, 908: 1, 907: 18, 906: 8, 905: 8, 904: 11, 903: 0, 902: 7, 901: 2, 900: 1, 899: 0, 898: 5, 897: 5, 896: 5, 895: 4, 894: 3, 893: 1, 892: 0, 891: 42, 890: 3, 889: 1, 888: 2, 887: 2, 886: 9, 885: 2, 884: 4, 883: 3, 882: 1, 881: 2, 880: 7, 879: 4, 878: 22, 877: 0, 876: 2, 875: 2, 874: 5, 873: 1, 872: 2, 871: 11, 870: 4, 869: 9, 868: 7, 867: 4, 866: 1, 865: 3, 864: 7, 863: 6, 862: 1, 861: 2, 860: 1, 859: 5, 858: 4, 857: 17, 856: 5, 855: 2, 854: 7, 853: 1, 852: 8, 851: 14, 850: 1, 849: 8, 848: 20, 847: 3, 846: 3, 845: 12, 844: 4, 843: 6, 842: 0, 841: 1, 840: 4, 839: 2, 838: 2, 837: 2, 836: 1, 835: 3, 834: 2, 833: 8, 832: 4, 831: 9, 830: 12, 829: 5, 828: 0, 827: 5, 826: 6, 825: 3, 824: 1, 823: 2, 822: 1, 821: 12, 820: 4, 819: 5, 818: 3, 817: 4, 816: 14, 815: 5, 814: 4, 813: 3, 812: 1, 811: 2, 810: 2, 809: 2, 808: 2, 807: 1, 806: 7, 805: 13, 804: 1, 803: 3, 802: 3, 801: 7, 800: 4, 799: 3, 798: 28, 797: 1, 796: 7, 795: 0, 794: 3, 793: 4, 792: 8, 791: 2, 790: 1, 789: 2, 788: 1, 787: 11, 786: 3, 785: 2, 784: 7, 783: 6, 782: 4, 781: 1, 780: 3, 779: 6, 778: 7, 777: 1, 776: 0, 775: 1, 774: 11, 773: 18, 772: 17, 771: 4, 770: 1, 769: 4, 768: 2, 767: 9, 766: 4, 765: 2, 764: 0, 763: 1, 762: 7, 761: 4, 760: 13, 759: 1, 758: 5, 757: 6, 756: 2, 755: 5, 754: 3, 753: 5, 752: 15, 751: 31, 750: 0, 749: 12, 748: 3, 747: 2, 746: 3, 745: 2, 744: 21, 743: 0, 742: 3, 741: 4, 740: 13, 739: 15, 738: 0, 737: 4, 736: 1, 735: 1, 734: 22, 733: 8, 732: 9, 731: 49, 730: 1, 729: 10, 728: 1, 727: 3, 726: 2, 725: 1, 724: 5, 723: 9, 722: 2, 721: 3, 720: 4, 719: 13, 718: 4, 717: 7, 716: 1, 715: 4, 714: 8, 713: 5, 712: 11, 711: 23, 710: 2, 709: 7, 708: 11, 707: 1, 706: 2, 705: 1, 704: 2, 703: 5, 702: 2, 701: 1, 700: 5, 699: 4, 698: 1, 697: 6, 696: 7, 695: 1, 694: 2, 693: 2, 692: 9, 691: 4, 690: 15, 689: 2, 688: 10, 687: 5, 686: 4, 685: 2, 684: 16, 683: 4, 682: 24, 681: 1, 680: 3, 679: 3, 678: 1, 677: 16, 676: 3, 675: 6, 674: 8, 673: 1, 672: 1, 671: 3, 670: 0, 669: 5, 668: 1, 667: 12, 666: 4, 665: 4, 664: 2, 663: 2, 662: 8, 661: 2, 660: 2, 659: 1, 658: 4, 657: 8, 656: 7, 655: 17, 654: 0, 653: 2, 652: 4, 651: 3, 650: 1, 649: 0, 648: 1, 647: 7, 646: 3, 645: 8, 644: 1, 643: 2, 642: 4, 641: 6, 640: 1, 639: 3, 638: 1, 637: 7, 636: 1, 635: 1, 634: 6, 633: 2, 632: 6, 631: 3, 630: 2, 629: 0, 628: 5, 627: 0, 626: 4, 625: 15, 624: 5, 623: 0, 622: 2, 621: 3, 620: 5, 619: 8, 618: 11, 617: 4, 616: 3, 615: 18, 614: 18, 613: 7, 612: 3, 611: 7, 610: 6, 609: 4, 608: 5, 607: 7, 606: 3, 605: 2, 604: 18, 603: 12, 602: 7, 601: 8, 600: 5, 599: 13, 598: 4, 597: 1, 596: 3, 595: 7, 594: 2, 593: 27, 592: 28, 591: 10, 590: 7, 589: 4, 588: 10, 587: 5, 586: 30, 585: 3, 584: 4, 583: 4, 582: 4, 581: 4, 580: 3, 579: 1, 578: 3, 577: 1, 576: 4, 575: 9, 574: 6, 573: 5, 572: 3, 571: 2, 570: 10, 569: 24, 568: 1, 567: 23, 566: 15, 565: 5, 564: 4, 563: 5, 562: 4, 561: 0, 560: 32, 559: 6, 558: 3, 557: 2, 556: 2, 555: 13, 554: 2, 553: 2, 552: 1, 551: 39, 550: 3, 549: 23, 548: 1, 547: 7, 546: 3, 545: 1, 544: 2, 543: 5, 542: 1, 541: 5, 540: 2, 539: 7, 538: 1, 537: 5, 536: 8, 535: 8, 534: 0, 533: 5, 532: 3, 531: 6, 530: 3, 529: 8, 528: 1, 527: 4, 526: 1, 525: 2, 524: 27, 523: 3, 522: 2, 521: 0, 520: 3, 519: 11, 518: 2, 517: 5, 516: 1, 515: 3, 514: 11, 513: 5, 512: 3, 511: 0, 510: 1, 509: 2, 508: 3, 507: 5, 506: 5, 505: 3, 504: 4, 503: 3, 502: 11, 501: 7, 500: 5, 499: 4, 498: 37, 497: 2, 496: 4, 495: 6, 494: 19, 493: 2, 492: 11, 491: 3, 490: 2, 489: 5, 488: 8, 487: 3, 486: 3, 485: 13, 484: 8, 483: 2, 482: 2, 481: 7, 480: 10, 479: 4, 478: 9, 477: 5, 476: 5, 475: 4, 474: 4, 473: 10, 472: 2, 471: 4, 470: 8, 469: 0, 468: 6, 467: 2, 466: 8, 465: 6, 464: 2, 463: 23, 462: 32, 461: 4, 460: 7, 459: 7, 458: 9, 457: 2, 456: 4, 455: 2, 454: 2, 453: 3, 452: 1, 451: 3, 450: 1, 449: 3, 448: 0, 447: 3, 446: 2, 445: 1, 444: 8, 443: 27, 442: 1, 441: 0, 440: 6, 439: 16, 438: 1, 437: 4, 436: 1, 435: 2, 434: 1, 433: 3, 432: 3, 431: 6, 430: 5, 429: 3, 428: 11, 427: 60, 426: 7, 425: 11, 424: 6, 423: 6, 422: 3, 421: 2, 420: 10, 419: 12, 418: 3, 417: 8, 416: 7, 415: 1, 414: 8, 413: 5, 412: 1, 411: 5, 410: 2, 409: 2, 408: 2, 407: 3, 406: 3, 405: 4, 404: 3, 403: 1, 402: 2, 401: 5, 400: 8, 399: 3, 398: 4, 397: 0, 396: 1, 395: 2, 394: 0, 393: 13, 392: 7, 391: 4, 390: 1, 389: 7, 388: 5, 387: 6, 386: 17, 385: 4, 384: 1, 383: 2, 382: 2, 381: 5, 380: 1, 379: 0, 378: 20, 377: 3, 376: 20, 375: 0, 374: 4, 373: 4, 372: 2, 371: 4, 370: 14, 369: 8, 368: 4, 367: 6, 366: 6, 365: 2, 364: 1, 363: 8, 362: 7, 361: 6, 360: 4, 359: 4, 358: 3, 357: 8, 356: 10, 355: 1, 354: 3, 353: 4, 352: 4, 351: 3, 350: 1, 349: 7, 348: 1, 347: 3, 346: 2, 345: 7, 344: 4, 343: 9, 342: 2, 341: 9, 340: 4, 339: 4, 338: 6, 337: 8, 336: 7, 335: 7, 334: 2, 333: 1, 332: 2, 331: 16, 330: 6, 329: 5, 328: 18, 327: 2, 326: 55, 325: 5, 324: 4, 323: 2, 322: 7, 321: 21, 320: 3, 319: 2, 318: 0, 317: 2, 316: 8, 315: 2, 314: 3, 313: 2, 312: 0, 311: 6, 310: 13, 309: 2, 308: 0, 307: 21, 306: 3, 305: 2, 304: 3, 303: 4, 302: 9, 301: 10, 300: 3, 299: 1, 298: 0, 297: 2, 296: 2, 295: 7, 294: 8, 293: 8, 292: 3, 291: 4, 290: 2, 289: 1, 288: 6, 287: 6, 286: 2, 285: 11, 284: 0, 283: 3, 282: 2, 281: 4, 280: 9, 279: 3, 278: 3, 277: 3, 276: 16, 275: 26, 274: 0, 273: 6, 272: 3, 271: 9, 270: 1, 269: 1, 268: 15, 267: 7, 266: 5, 265: 8, 264: 9, 263: 7, 262: 18, 261: 8, 260: 6, 259: 3, 258: 0, 257: 3, 256: 7, 255: 3, 254: 8, 253: 1, 252: 0, 251: 1, 250: 11, 249: 5, 248: 1, 247: 2, 246: 3, 245: 13, 244: 8, 243: 10, 242: 1, 241: 1, 240: 2, 239: 10, 238: 1, 237: 10, 236: 1, 235: 3, 234: 3, 233: 9, 232: 1, 231: 2, 230: 1, 229: 1, 228: 8, 227: 6, 226: 3, 225: 9, 224: 5, 223: 37, 222: 2, 221: 1, 220: 0, 219: 1, 218: 1, 217: 1, 216: 4, 215: 1, 214: 12, 213: 7, 212: 3, 211: 7, 210: 2, 209: 0, 208: 9, 207: 12, 206: 8, 205: 2, 204: 6, 203: 0, 202: 2, 201: 7, 200: 0, 199: 4, 198: 2, 197: 19, 196: 6, 195: 3, 194: 0, 193: 0, 192: 6, 191: 5, 190: 8, 189: 1, 188: 3, 187: 1, 186: 16, 185: 2, 184: 4, 183: 2, 182: 7, 181: 0, 180: 4, 179: 5, 178: 3, 177: 6, 176: 1, 175: 1, 174: 2, 173: 1, 172: 4, 171: 2, 170: 0, 169: 4, 168: 10, 167: 1, 166: 27, 165: 4, 164: 2, 163: 2, 162: 0, 161: 3, 160: 3, 159: 22, 158: 3, 157: 11, 156: 4, 155: 6, 154: 21, 153: 1, 152: 5, 151: 0, 150: 3, 149: 9, 148: 5, 147: 5, 146: 2, 145: 6, 144: 4, 143: 2, 142: 3, 141: 6, 140: 2, 139: 3, 138: 5, 137: 1, 136: 1, 135: 5, 134: 4, 133: 3, 132: 5, 131: 7, 130: 5, 129: 1, 128: 4, 127: 35, 126: 2, 125: 3, 124: 0, 123: 7, 122: 2, 121: 1, 120: 2, 119: 11, 118: 1, 117: 1, 116: 5, 115: 0, 114: 4, 113: 0, 112: 1, 111: 3, 110: 3, 109: 3, 108: 4, 107: 7, 106: 7, 105: 1, 104: 2, 103: 4, 102: 5, 101: 3, 100: 0, 99: 3, 98: 5, 97: 4, 96: 2, 95: 0, 94: 10, 93: 1, 92: 2, 91: 1, 90: 3, 89: 3, 88: 2, 87: 2, 86: 12, 85: 2, 84: 5, 83: 8, 82: 6, 81: 4, 33379: 2, 33378: 0, 33377: 4, 33376: 2, 33375: 1, 33374: 5, 33373: 2, 33372: 1, 33371: 1, 33370: 2, 33369: 0, 33368: 3, 33367: 0, 33366: 3, 33365: 5, 33364: 1, 33363: 1, 33362: 3, 33361: 3, 33360: 1, 33359: 1, 33358: 1, 33357: 2, 33356: 1, 33355: 2, 33354: 0, 33353: 7, 33352: 0, 33351: 2, 33350: 5, 33349: 1, 33348: 2, 33347: 1, 33346: 2, 33345: 6, 33344: 1, 33343: 2, 33342: 4, 33341: 4, 33340: 2, 33339: 0, 33338: 1, 33337: 1, 33336: 1, 33335: 6, 33334: 3, 33333: 2, 33332: 2, 33331: 0, 33330: 0, 33329: 1, 33328: 1, 33327: 0, 33326: 2, 33325: 2, 33324: 2, 33323: 3, 33322: 1, 33321: 3, 33320: 0, 33319: 5, 33318: 3, 33317: 2, 33316: 1, 33315: 1, 33314: 1, 33313: 1, 33312: 3, 33311: 2, 33310: 5, 33309: 0, 33308: 0, 33307: 0, 33306: 0, 33305: 1, 33304: 1, 33303: 2, 33302: 0, 33301: 2, 33300: 3, 33299: 3, 33298: 2, 33297: 2, 33296: 0, 33295: 0, 33294: 2, 33293: 0, 33292: 0, 33291: 0, 33290: 2, 33289: 3, 33288: 1, 33287: 0, 33286: 2, 33285: 2, 33284: 1, 33283: 0, 33282: 0, 33281: 3, 33280: 2, 33279: 1, 33278: 1, 33277: 2, 33276: 2, 33275: 3, 33274: 2, 33273: 4, 33272: 2, 33271: 1, 33270: 4, 33269: 1, 33268: 1, 33267: 3, 33266: 3, 33265: 1, 33264: 0, 33263: 4, 33262: 4, 33261: 1, 33260: 1, 33259: 2, 33258: 2, 33257: 1, 33256: 4, 33255: 3, 33254: 2, 33253: 1, 33252: 3, 33251: 0, 33250: 2, 33249: 2, 33248: 2, 33247: 1, 33246: 0, 33245: 1, 33244: 3, 33243: 2, 33242: 2, 33241: 0, 33240: 0, 33239: 1, 33238: 2, 33237: 2, 33236: 1, 33235: 1, 33234: 0, 33233: 1, 33232: 1, 33231: 0, 33230: 4, 33229: 3, 33228: 2, 33227: 1, 33226: 0, 33225: 3, 33224: 0, 33223: 0, 33222: 1, 33221: 3, 33220: 4, 33219: 2, 33218: 0, 33217: 1, 33216: 2, 33215: 1, 33214: 1, 33213: 1, 33212: 1, 33211: 1, 33210: 4, 33209: 6, 33208: 0, 33207: 2, 33206: 2, 33205: 1, 33204: 1, 33203: 3, 33202: 1, 33201: 2, 33200: 2, 33199: 4, 33198: 1, 33197: 0, 33196: 1, 33195: 3, 33194: 3, 33193: 2, 33192: 3, 33191: 4, 33190: 1, 33189: 0, 33188: 2, 33187: 5, 33186: 3, 33185: 4, 33184: 0, 33183: 4, 33182: 3, 33181: 1, 33180: 0, 33179: 6, 33178: 1, 33177: 2, 33176: 1, 33175: 3, 33174: 1, 33173: 1, 33172: 1, 33171: 0, 33170: 0, 33169: 0, 33168: 10, 33167: 3, 33166: 2, 33165: 4, 33164: 1, 33163: 4, 33162: 4, 33161: 5, 33160: 3, 33159: 3, 33158: 0, 33157: 1, 33156: 1, 33155: 1, 33154: 1, 33153: 5, 33152: 3, 33151: 3, 33150: 1, 33149: 4, 33148: 0, 33147: 1, 33146: 1, 33145: 1, 33144: 5, 33143: 2, 33142: 2, 33141: 1, 33140: 1, 33139: 2, 33138: 2, 33137: 2, 33136: 0, 33135: 0, 33134: 1, 33133: 1, 33132: 4, 33131: 3, 33130: 2, 33129: 0, 33128: 2, 33127: 4, 33126: 0, 33125: 2, 33124: 0, 33123: 3, 33122: 3, 33121: 0, 33120: 2, 33119: 3, 33118: 1, 33117: 3, 33116: 1, 33115: 0, 33114: 1, 33113: 2, 33112: 2, 33111: 0, 33110: 2, 33109: 1, 33108: 2, 33107: 1, 33106: 1, 33105: 4, 33104: 1, 33103: 6, 33102: 1, 33101: 3, 33100: 6, 33099: 1, 33098: 0, 33097: 2, 33096: 2, 33095: 3, 33094: 0, 33093: 1, 33092: 1, 33091: 3, 33090: 3, 33089: 3, 33088: 1, 33087: 1, 33086: 2, 33085: 4, 33084: 3, 33083: 3, 33082: 2, 33081: 3, 33080: 3, 33079: 3, 33078: 2, 33077: 0, 33076: 2, 33075: 1, 33074: 4, 33073: 1, 33072: 2, 33071: 3, 33070: 1, 33069: 0, 33068: 0, 33067: 6, 33066: 8, 33065: 6, 33064: 4, 33063: 3, 33062: 2, 33061: 3, 33060: 1, 33059: 2, 33058: 3, 33057: 3, 33056: 1, 33055: 2, 33054: 1, 33053: 8, 33052: 8, 33051: 2, 33050: 2, 33049: 1, 33048: 0, 33047: 1, 33046: 0, 33045: 2, 33044: 1, 33043: 2, 33042: 2, 33041: 2, 33040: 3, 33039: 2, 33038: 4, 33037: 2, 33036: 1, 33035: 0, 33034: 2, 33033: 2, 33032: 0, 33031: 2, 33030: 4, 33029: 4, 33028: 3, 33027: 3, 33026: 2, 33025: 5, 33024: 1, 33023: 3, 33022: 4, 33021: 1, 33020: 2, 33019: 2, 33018: 2, 33017: 4, 33016: 4, 33015: 2, 33014: 0, 33013: 1, 33012: 1, 33011: 3, 33010: 0, 33009: 1, 33008: 1, 33007: 0, 33006: 2, 33005: 0, 33004: 1, 33003: 1, 33002: 5, 33001: 6, 33000: 2, 32999: 1, 32998: 6, 32997: 3, 32996: 3, 32995: 2, 32994: 1, 32993: 0, 32992: 1, 32991: 4, 32990: 1, 32989: 1, 32988: 2, 32987: 4, 32986: 4, 32985: 7, 32984: 6, 32983: 5, 32982: 2, 32981: 1, 32980: 1, 32979: 1, 32978: 2, 32977: 4, 32976: 2, 32975: 2, 32974: 1, 32973: 3, 32972: 1, 32971: 2, 32970: 1, 32969: 1, 32968: 0, 32967: 3, 32966: 2, 32965: 0, 32964: 2, 32963: 4, 32962: 2, 32961: 0, 32960: 5, 32959: 4, 32958: 0, 32957: 1, 32956: 0, 32955: 2, 32954: 0, 32953: 3, 32952: 4, 32951: 0, 32950: 5, 32949: 5, 32948: 0, 32947: 0, 32946: 1, 32945: 4, 32944: 3, 32943: 3, 32942: 2, 32941: 2, 32940: 8, 32939: 9, 32938: 3, 32937: 1, 32936: 2, 32935: 4, 32934: 1, 32933: 4, 32932: 3, 32931: 2, 32930: 1, 32929: 3, 32928: 4, 32927: 5, 32926: 5, 32925: 4, 32924: 5, 32923: 5, 32922: 4, 32921: 3, 32920: 2, 32919: 1, 32918: 1, 32917: 2, 32916: 2, 32915: 1, 32914: 2, 32913: 0, 32912: 0, 32911: 1, 32910: 3, 32909: 2, 32908: 0, 32907: 2, 32906: 2, 32905: 7, 32904: 4, 32903: 5, 32902: 3, 32901: 4, 32900: 4, 32899: 2, 32898: 1, 32897: 1, 32896: 1, 32895: 4, 32894: 5, 32893: 7, 32892: 2, 32891: 2, 32890: 2, 32889: 1, 32888: 2, 32887: 3, 32886: 2, 32885: 2, 32884: 1, 32883: 1, 32882: 1, 32881: 3, 32880: 9, 32879: 7, 32878: 0, 32877: 1, 32876: 2, 32875: 1, 32874: 2, 32873: 1, 32872: 2, 32871: 3, 32870: 1, 32869: 1, 32868: 2, 32867: 2, 32866: 6, 32865: 3, 32864: 3, 32863: 3, 32862: 3, 32861: 2, 32860: 4, 32859: 0, 32858: 2, 32857: 3, 32856: 2, 32855: 2, 32854: 4, 32853: 2, 32852: 2, 32851: 1, 32850: 4, 32849: 2, 32848: 1, 32847: 1, 32846: 6, 32845: 4, 32844: 4, 32843: 0, 32842: 3, 32841: 2, 32840: 1, 32839: 4, 32838: 4, 32837: 2, 32836: 1, 32835: 1, 32834: 2, 32833: 3, 32832: 2, 32831: 2, 32830: 2, 32829: 4, 32828: 5, 32827: 1, 32826: 1, 32825: 3, 32824: 1, 32823: 5, 32822: 0, 32821: 0, 32820: 3, 32819: 1, 32818: 0, 32817: 2, 32816: 2, 32815: 3, 32814: 5, 32813: 3, 32812: 1, 32811: 0, 32810: 3, 32809: 4, 32808: 1, 32807: 2, 32806: 1, 32805: 1, 32804: 1, 32803: 9, 32802: 5, 32801: 3, 32800: 5, 32799: 6, 32798: 6, 32797: 2, 32796: 1, 32795: 2, 32794: 1, 32793: 2, 32792: 2, 32791: 0, 32790: 0, 32789: 1, 32788: 2, 32787: 1, 32786: 3, 32785: 2, 32784: 1, 32783: 2, 32782: 1, 32781: 4, 32780: 2, 32779: 1, 32778: 0, 32777: 2, 32776: 6, 32775: 2, 32774: 2, 32773: 3, 32772: 2, 32771: 1, 32770: 0, 32769: 0, 32768: 2, 32767: 4, 32766: 3, 32765: 2, 32764: 3, 32763: 2, 32762: 1, 32761: 5, 32760: 1, 32759: 0, 32758: 2, 32757: 2, 32756: 2, 32755: 1, 32754: 2, 32753: 2, 32752: 3, 32751: 3, 32750: 2, 32749: 5, 32748: 3, 32747: 0, 32746: 2, 32745: 2, 32744: 1, 32743: 1, 32742: 0, 32741: 4, 32740: 2, 32739: 3, 32738: 1, 32737: 0, 32736: 2, 32735: 5, 32734: 1, 32733: 3, 32732: 2, 32731: 2, 32730: 1, 32729: 4, 32728: 0, 32727: 6, 32726: 3, 32725: 2, 32724: 0, 32723: 1, 32722: 2, 32721: 1, 32720: 1, 32719: 5, 32718: 2, 32717: 3, 32716: 4, 32715: 1, 32714: 1, 32713: 4, 32712: 2, 32711: 1, 32710: 3, 32709: 2, 32708: 1, 32707: 4, 32706: 5, 32705: 0, 32704: 2, 32703: 2, 32702: 1, 32701: 4, 32700: 3, 32699: 3, 32698: 1, 32697: 1, 32696: 1, 32695: 2, 32694: 3, 32693: 4, 32692: 2, 32691: 3, 32690: 2, 32689: 3, 32688: 3, 32687: 2, 32686: 3, 32685: 2, 32684: 2, 32683: 4, 32682: 3, 32681: 1, 32680: 1, 32679: 3, 32678: 1, 32677: 2, 32676: 1, 32675: 1, 32674: 2, 32673: 2, 32672: 2, 32671: 0, 32670: 0, 32669: 1, 32668: 2, 32667: 1, 32666: 2, 32665: 4, 32664: 4, 32663: 3, 32662: 2, 32661: 1, 32660: 4, 32659: 1, 32658: 0, 32657: 1, 32656: 5, 32655: 3, 32654: 1, 32653: 2, 32652: 1, 32651: 3, 32650: 3, 32649: 3, 32648: 7, 32647: 2, 32646: 3, 32645: 5, 32644: 5, 32643: 5, 32642: 4, 32641: 3, 32640: 2, 32639: 1, 32638: 2, 32637: 1, 32636: 2, 32635: 4, 32634: 3, 32633: 3, 32632: 4, 32631: 2, 32630: 0, 32629: 1, 32628: 2, 32627: 3, 32626: 5, 32625: 3, 32624: 1, 32623: 2, 32622: 4, 32621: 0, 32620: 2, 32619: 0, 32618: 2, 32617: 3, 32616: 1, 32615: 1, 32614: 2, 32613: 1, 32612: 1, 32611: 1, 32610: 1, 32609: 0, 32608: 2, 32607: 3, 32606: 1, 32605: 1, 32604: 1, 32603: 2, 32602: 1, 32601: 4, 32600: 3, 32599: 4, 32598: 4, 32597: 1, 32596: 0, 32595: 2, 32594: 3, 32593: 1, 32592: 2, 32591: 1, 32590: 1, 32589: 4, 32588: 4, 32587: 2, 32586: 3, 32585: 1, 32584: 3, 32583: 4, 32582: 3, 32581: 1, 32580: 2, 32579: 2, 32578: 3, 32577: 2, 32576: 4, 32575: 6, 32574: 2, 32573: 3, 32572: 1, 32571: 2, 32570: 2, 32569: 2, 32568: 4, 32567: 2, 32566: 4, 32565: 4, 32564: 1, 32563: 1, 32562: 1, 32561: 2, 32560: 2, 32559: 3, 32558: 3, 32557: 2, 32556: 1, 32555: 4, 32554: 3, 32553: 3, 32552: 1, 32551: 1, 32550: 1, 32549: 1, 32548: 1, 32547: 1, 32546: 2, 32545: 1, 32544: 3, 32543: 4, 32542: 3, 32541: 4, 32540: 4, 32539: 2, 32538: 4, 32537: 1, 32536: 2, 32535: 2, 32534: 3, 32533: 5, 32532: 4, 32531: 8, 32530: 5, 32529: 8, 32528: 5, 32527: 1, 32526: 2, 32525: 8, 32524: 1, 32523: 3, 32522: 2, 32521: 3, 32520: 4, 32519: 4, 32518: 3, 32517: 4, 32516: 2, 32515: 1, 32514: 2, 32513: 3, 32512: 2, 32511: 1, 32510: 3, 32509: 3, 32508: 4, 32507: 2, 32506: 4, 32505: 2, 32504: 2, 32503: 3, 32502: 3, 32501: 2, 32500: 10, 32499: 1, 32498: 6, 32497: 1, 32496: 2, 32495: 1, 32494: 3, 32493: 2, 32492: 1, 32491: 0, 32490: 3, 32489: 5, 32488: 6, 32487: 6, 32486: 7, 32485: 6, 32484: 6, 32483: 4, 32482: 6, 32481: 6, 32480: 1, 32479: 1, 32478: 3, 32477: 1, 32476: 3, 32475: 1, 32474: 5, 32473: 1, 32472: 1, 32471: 11, 32470: 16, 32469: 11, 32468: 12, 32467: 14, 32466: 3, 32465: 2, 32464: 2, 32463: 5, 32462: 4, 32461: 5, 32460: 13, 32459: 9, 32458: 2, 32457: 1, 32456: 0, 32455: 1, 32454: 2, 32453: 0, 32452: 2, 32451: 0, 32450: 2, 32449: 2, 32448: 1, 32447: 2, 32446: 2, 32445: 0, 32444: 7, 32443: 5, 32442: 2, 32441: 10, 32440: 10, 32439: 14, 32438: 3, 32437: 0, 32436: 2, 32435: 1, 32434: 4, 32433: 2, 32432: 1, 32431: 1, 32430: 2, 32429: 1, 32428: 2, 32427: 1, 32426: 2, 32425: 1, 32424: 3, 32423: 4, 32422: 3, 32421: 3, 32420: 3, 32419: 2, 32418: 1, 32417: 2, 32416: 1, 32415: 4, 32414: 2, 32413: 1, 32412: 0, 32411: 0, 32410: 4, 32409: 3, 32408: 3, 32407: 1, 32406: 1, 32405: 2, 32404: 3, 32403: 2, 32402: 4, 32401: 2, 32400: 1, 32399: 0, 32398: 4, 32397: 2, 32396: 1, 32395: 5, 32394: 1, 32393: 0, 32392: 0, 32391: 2, 32390: 2, 32389: 0, 32388: 2, 32387: 3, 32386: 3, 32385: 2, 32384: 6, 32383: 5, 32382: 2, 32381: 0, 32380: 0, 32379: 0, 32378: 6, 32377: 6, 32376: 0, 32375: 3, 32374: 1, 32373: 2, 32372: 2, 32371: 4, 32370: 5, 32369: 1, 32368: 3, 32367: 5, 32366: 3, 32365: 3, 32364: 3, 32363: 8, 32362: 6, 32361: 6, 32360: 4, 32359: 0, 32358: 1, 32357: 0, 32356: 3, 32355: 1, 32354: 5, 32353: 1, 32352: 3, 32351: 1, 32350: 0, 32349: 0, 32348: 5, 32347: 5, 32346: 0, 32345: 5, 32344: 2, 32343: 2, 32342: 1, 32341: 1, 32340: 3, 32339: 2, 32338: 2, 32337: 2, 32336: 2, 32335: 3, 32334: 0, 32333: 0, 32332: 5, 32331: 2, 32330: 5, 32329: 8, 32328: 7, 32327: 2, 32326: 2, 32325: 2, 32324: 5, 32323: 1, 32322: 1, 32321: 2, 32320: 3, 32319: 0, 32318: 3, 32317: 4, 32316: 4, 32315: 4, 32314: 0, 32313: 0, 32312: 1, 32311: 4, 32310: 3, 32309: 6, 32308: 15, 32307: 15, 32306: 17, 32305: 0, 32304: 4, 32303: 2, 32302: 3, 32301: 4, 32300: 3, 32299: 4, 32298: 3, 32297: 3, 32296: 2, 32295: 1, 32294: 3, 32293: 2, 32292: 4, 32291: 0, 32290: 3, 32289: 2, 32288: 0, 32287: 1, 32286: 1, 32285: 4, 32284: 5, 32283: 4, 32282: 1, 32281: 1, 32280: 1, 32279: 0, 32278: 1, 32277: 2, 32276: 1, 32275: 3, 32274: 4, 32273: 2, 32272: 2, 32271: 1, 32270: 2, 32269: 2, 32268: 3, 32267: 2, 32266: 2, 32265: 1, 32264: 2, 32263: 1, 32262: 1, 32261: 2, 32260: 5, 32259: 2, 32258: 2, 32257: 2, 32256: 2, 32255: 0, 32254: 3, 32253: 1, 32252: 1, 32251: 3, 32250: 0, 32249: 3, 32248: 1, 32247: 2, 32246: 3, 32245: 3, 32244: 2, 32243: 2, 32242: 3, 32241: 2, 32240: 4, 32239: 4, 32238: 1, 32237: 1, 32236: 1, 32235: 1, 32234: 4, 32233: 1, 32232: 3, 32231: 0, 32230: 7, 32229: 8, 32228: 7, 32227: 7, 32226: 3, 32225: 1, 32224: 2, 32223: 3, 32222: 2, 32221: 2, 32220: 2, 32219: 3, 32218: 2, 32217: 2, 32216: 2, 32215: 0, 32214: 2, 32213: 4, 32212: 3, 32211: 2, 32210: 1, 32209: 2, 32208: 2, 32207: 1, 32206: 1, 32205: 1, 32204: 4, 32203: 6, 32202: 5, 32201: 0, 32200: 2, 32199: 6, 32198: 1, 32197: 2, 32196: 4, 32195: 2, 32194: 2, 32193: 3, 32192: 4, 32191: 3, 32190: 2, 32189: 3, 32188: 1, 32187: 4, 32186: 2, 32185: 2, 32184: 2, 32183: 1, 32182: 1, 32181: 2, 32180: 2, 32179: 0, 32178: 1, 32177: 0, 32176: 2, 32175: 0, 32174: 3, 32173: 1, 32172: 2, 32171: 2, 32170: 4, 32169: 1, 32168: 0, 32167: 1, 32166: 2, 32165: 2, 32164: 2, 32163: 2, 32162: 2, 32161: 1, 32160: 2, 32159: 1, 32158: 0, 32157: 3, 32156: 3, 32155: 4, 32154: 4, 32153: 3, 32152: 3, 32151: 2, 32150: 2, 32149: 2, 32148: 2, 32147: 2, 32146: 1, 32145: 4, 32144: 1, 32143: 2, 32142: 3, 32141: 3, 32140: 4, 32139: 2, 32138: 3, 32137: 3, 32136: 3, 32135: 3, 32134: 5, 32133: 3, 32132: 4, 32131: 2, 32130: 0, 32129: 1, 32128: 1, 32127: 4, 32126: 4, 32125: 7, 32124: 8, 32123: 2, 32122: 2, 32121: 0, 32120: 4, 32119: 2, 32118: 1, 32117: 2, 32116: 2, 32115: 3, 32114: 2, 32113: 1, 32112: 2, 32111: 2, 32110: 3, 32109: 2, 32108: 2, 32107: 3, 32106: 3, 32105: 0, 32104: 15, 32103: 12, 32102: 3, 32101: 4, 32100: 3, 32099: 5, 32098: 5, 32097: 5, 32096: 4, 32095: 3, 32094: 2, 32093: 2, 32092: 0, 32091: 4, 32090: 3, 32089: 3, 32088: 4, 32087: 3, 32086: 4, 32085: 4, 32084: 6, 32083: 6, 32082: 3, 32081: 3, 32080: 4, 32079: 2, 32078: 6, 32077: 11, 32076: 6, 32075: 5, 32074: 6, 32073: 1, 32072: 2, 32071: 8, 32070: 1, 32069: 1, 32068: 6, 32067: 3, 32066: 4, 32065: 5, 32064: 1, 32063: 2, 32062: 1, 32061: 2, 32060: 3, 32059: 2, 32058: 3, 32057: 4, 32056: 4, 32055: 4, 32054: 2, 32053: 0, 32052: 3, 32051: 0, 32050: 1, 32049: 0, 32048: 2, 32047: 3, 32046: 2, 32045: 2, 32044: 4, 32043: 3, 32042: 1, 32041: 16, 32040: 9, 32039: 12, 32038: 12, 32037: 10, 32036: 11, 32035: 15, 32034: 11, 32033: 11, 32032: 13, 32031: 12, 32030: 10, 32029: 2, 32028: 2, 32027: 4, 32026: 3, 32025: 2, 32024: 2, 32023: 1, 32022: 2, 32021: 4, 32020: 2, 32019: 3, 32018: 3, 32017: 2, 32016: 0, 32015: 2, 32014: 3, 32013: 1, 32012: 4, 32011: 1, 32010: 2, 32009: 0, 32008: 0, 32007: 1, 32006: 3, 32005: 1, 32004: 1, 32003: 1, 32002: 2, 32001: 1, 32000: 2, 31999: 6, 31998: 0, 31997: 2, 31996: 3, 31995: 4, 31994: 1, 31993: 2, 31992: 4, 31991: 5, 31990: 1, 31989: 0, 31988: 2, 31987: 1, 31986: 1, 31985: 2, 31984: 1, 31983: 0, 31982: 4, 31981: 0, 31980: 2, 31979: 3, 31978: 2, 31977: 2, 31976: 3, 31975: 3, 31974: 2, 31973: 3, 31972: 7, 31971: 1, 31970: 1, 31969: 3, 31968: 3, 31967: 6, 31966: 5, 31965: 2, 31964: 2, 31963: 2, 31962: 2, 31961: 3, 31960: 3, 31959: 3, 31958: 3, 31957: 0, 31956: 4, 31955: 1, 31954: 1, 31953: 0, 31952: 0, 31951: 4, 31950: 8, 31949: 5, 31948: 0, 31947: 4, 31946: 7, 31945: 4, 31944: 1, 31943: 3, 31942: 5, 31941: 2, 31940: 3, 31939: 0, 31938: 5, 31937: 0, 31936: 2, 31935: 3, 31934: 0, 31933: 3, 31932: 2, 31931: 2, 31930: 2, 31929: 2, 31928: 9, 31927: 1, 31926: 1, 31925: 0, 31924: 1, 31923: 0, 31922: 0, 31921: 0, 31920: 4, 31919: 4, 31918: 2, 31917: 1, 31916: 2, 31915: 5, 31914: 0, 31913: 1, 31912: 0, 31911: 1, 31910: 4, 31909: 2, 31908: 2, 31907: 1, 31906: 1, 31905: 1, 31904: 1, 31903: 1, 31902: 3, 31901: 4, 31900: 2, 31899: 1, 31898: 3, 31897: 1, 31896: 1, 31895: 3, 31894: 4, 31893: 5, 31892: 0, 31891: 4, 31890: 2, 31889: 1, 31888: 1, 31887: 2, 31886: 6, 31885: 1, 31884: 2, 31883: 3, 31882: 0, 31881: 0, 31880: 1, 31879: 1, 31878: 0, 31877: 0, 31876: 8, 31875: 0, 31874: 6, 31873: 6, 31872: 1, 31871: 2, 31870: 1, 31869: 1, 31868: 2, 31867: 3, 31866: 3, 31865: 2, 31864: 2, 31863: 0, 31862: 1, 31861: 2, 31860: 2, 31859: 3, 31858: 1, 31857: 3, 31856: 2, 31855: 4, 31854: 1, 31853: 2, 31852: 3, 31851: 4, 31850: 0, 31849: 0, 31848: 5, 31847: 3, 31846: 3, 31845: 5, 31844: 1, 31843: 0, 31842: 2, 31841: 2, 31840: 1, 31839: 2, 31838: 2, 31837: 1, 31836: 3, 31835: 2, 31834: 2, 31833: 0, 31832: 4, 31831: 4, 31830: 1, 31829: 0, 31828: 2, 31827: 2, 31826: 0, 31825: 2, 31824: 2, 31823: 4, 31822: 1, 31821: 1, 31820: 2, 31819: 0, 31818: 0, 31817: 0, 31816: 8, 31815: 5, 31814: 5, 31813: 1, 31812: 1, 31811: 2, 31810: 2, 31809: 1, 31808: 1, 31807: 1, 31806: 0, 31805: 1, 31804: 1, 31803: 4, 31802: 3, 31801: 2, 31800: 1, 31799: 2, 31798: 0, 31797: 0, 31796: 3, 31795: 1, 31794: 1, 31793: 1, 31792: 1, 31791: 0, 31790: 3, 31789: 0, 31788: 2, 31787: 1, 31786: 3, 31785: 3, 31784: 3, 31783: 3, 31782: 4, 31781: 2, 31780: 4, 31779: 3, 31778: 2, 31777: 2, 31776: 0, 31775: 3, 31774: 1, 31773: 7, 31772: 1, 31771: 2, 31770: 6, 31769: 2, 31768: 4, 31767: 0, 31766: 14, 31765: 14, 31764: 4, 31763: 2, 31762: 3, 31761: 0, 31760: 1, 31759: 0, 31758: 7, 31757: 6, 31756: 7, 31755: 0, 31754: 7, 31753: 1, 31752: 1, 31751: 1, 31750: 1, 31749: 6, 31748: 5, 31747: 5, 31746: 2, 31745: 3, 31744: 3, 31743: 1, 31742: 2, 31741: 3, 31740: 6, 31739: 2, 31738: 3, 31737: 2, 31736: 1, 31735: 1, 31734: 0, 31733: 0, 31732: 2, 31731: 3, 31730: 3, 31729: 1, 31728: 3, 31727: 1, 31726: 3, 31725: 2, 31724: 1, 31723: 2, 31722: 5, 31721: 4, 31720: 3, 31719: 1, 31718: 2, 31717: 0, 31716: 3, 31715: 4, 31714: 2, 31713: 9, 31712: 6, 31711: 3, 31710: 0, 31709: 3, 31708: 1, 31707: 1, 31706: 2, 31705: 1, 31704: 2, 31703: 4, 31702: 3, 31701: 1, 31700: 0, 31699: 4, 31698: 3, 31697: 2, 31696: 0, 31695: 2, 31694: 2, 31693: 1, 31692: 1, 31691: 0, 31690: 2, 31689: 1, 31688: 1, 31687: 2, 31686: 1, 31685: 1, 31684: 0, 31683: 2, 31682: 2, 31681: 8, 31680: 1, 31679: 4, 31678: 2, 31677: 0, 31676: 2, 31675: 1, 31674: 6, 31673: 2, 31672: 0, 31671: 1, 31670: 2, 31669: 1, 31668: 1, 31667: 2, 31666: 2, 31665: 2, 31664: 2, 31663: 2, 31662: 5, 31661: 6, 31660: 1, 31659: 1, 31658: 1, 31657: 2, 31656: 2, 31655: 1, 31654: 0, 31653: 7, 31652: 3, 31651: 0, 31650: 1, 31649: 0, 31648: 0, 31647: 1, 31646: 2, 31645: 1, 31644: 4, 31643: 1, 31642: 1, 31641: 0, 31640: 3, 31639: 4, 31638: 4, 31637: 0, 31636: 2, 31635: 3, 31634: 4, 31633: 4, 31632: 2, 31631: 11, 31630: 14, 31629: 0, 31628: 2, 31627: 1, 31626: 2, 31625: 4, 31624: 0, 31623: 2, 31622: 3, 31621: 4, 31620: 2, 31619: 3, 31618: 1, 31617: 3, 31616: 3, 31615: 2, 31614: 1, 31613: 5, 31612: 2, 31611: 0, 31610: 2, 31609: 3, 31608: 2, 31607: 1, 31606: 2, 31605: 0, 31604: 4, 31603: 2, 31602: 0, 31601: 2, 31600: 2, 31599: 1, 31598: 0, 31597: 1, 31596: 2, 31595: 2, 31594: 1, 31593: 0, 31592: 3, 31591: 0, 31590: 1, 31589: 3, 31588: 3, 31587: 4, 31586: 1, 31585: 1, 31584: 3, 31583: 1, 31582: 4, 31581: 1, 31580: 3, 31579: 5, 31578: 2, 31577: 4, 31576: 0, 31575: 2, 31574: 4, 31573: 4, 31572: 3, 31571: 6, 31570: 1, 31569: 1, 31568: 4, 31567: 0, 31566: 0, 31565: 3, 31564: 2, 31563: 5, 31562: 4, 31561: 3, 31560: 5, 31559: 1, 31558: 0, 31557: 2, 31556: 3, 31555: 11, 31554: 2, 31553: 0, 31552: 7, 31551: 6, 31550: 0, 31549: 4, 31548: 5, 31547: 5, 31546: 1, 31545: 1, 31544: 3, 31543: 1, 31542: 2, 31541: 2, 31540: 5, 31539: 4, 31538: 3, 31537: 1, 31536: 0, 31535: 6, 31534: 4, 31533: 5, 31532: 2, 31531: 1, 31530: 4, 31529: 5, 31528: 2, 31527: 1, 31526: 1, 31525: 0, 31524: 3, 31523: 0, 31522: 1, 31521: 0, 31520: 0, 31519: 3, 31518: 3, 31517: 1, 31516: 2, 31515: 7, 31514: 1, 31513: 3, 31512: 3, 31511: 3, 31510: 2, 31509: 4, 31508: 2, 31507: 0, 31506: 1, 31505: 3, 31504: 2, 31503: 1, 31502: 0, 31501: 2, 31500: 1, 31499: 3, 31498: 1, 31497: 2, 31496: 0, 31495: 1, 31494: 2, 31493: 5, 31492: 1, 31491: 1, 31490: 2, 31489: 1, 31488: 3, 31487: 4, 31486: 0, 31485: 1, 31484: 2, 31483: 1, 31482: 1, 31481: 1, 31480: 1, 31479: 2, 31478: 1, 31477: 2, 31476: 1, 31475: 1, 31474: 2, 31473: 4, 31472: 5, 31471: 2, 31470: 2, 31469: 2, 31468: 4, 31467: 3, 31466: 1, 31465: 3, 31464: 2, 31463: 0, 31462: 0, 31461: 0, 31460: 2, 31459: 2, 31458: 1, 31457: 1, 31456: 6, 31455: 3, 31454: 2, 31453: 2, 31452: 2, 31451: 2, 31450: 4, 31449: 5, 31448: 0, 31447: 2, 31446: 2, 31445: 1, 31444: 1, 31443: 6, 31442: 0, 31441: 4, 31440: 3, 31439: 3, 31438: 2, 31437: 7, 31436: 6, 31435: 6, 31434: 4, 31433: 2, 31432: 1, 31431: 3, 31430: 1, 31429: 0, 31428: 5, 31427: 4, 31426: 4, 31425: 4, 31424: 1, 31423: 1, 31422: 5, 31421: 5, 31420: 2, 31419: 4, 31418: 1, 31417: 1, 31416: 0, 31415: 0, 31414: 3, 31413: 2, 31412: 3, 31411: 0, 31410: 5, 31409: 2, 31408: 0, 31407: 2, 31406: 1, 31405: 2, 31404: 2, 31403: 1, 31402: 3, 31401: 3, 31400: 2, 31399: 3, 31398: 2, 31397: 5, 31396: 2, 31395: 2, 31394: 1, 31393: 2, 31392: 1, 31391: 2, 31390: 2, 31389: 0, 31388: 1, 31387: 2, 31386: 4, 31385: 3, 31384: 2, 31383: 2, 31382: 1, 31381: 2, 31380: 3, 31379: 3, 31378: 4, 31377: 0, 31376: 0, 31375: 2, 31374: 2, 31373: 0, 31372: 2, 31371: 1, 31370: 3, 31369: 3, 31368: 1, 31367: 0, 31366: 2, 31365: 1, 31364: 0, 31363: 3, 31362: 2, 31361: 2, 31360: 1, 31359: 1, 31358: 1, 31357: 3, 31356: 1, 31355: 0, 31354: 5, 31353: 1, 31352: 4, 31351: 1, 31350: 1, 31349: 2, 31348: 2, 31347: 0, 31346: 2, 31345: 2, 31344: 2, 31343: 0, 31342: 1, 31341: 2, 31340: 2, 31339: 0, 31338: 1, 31337: 2, 31336: 2, 31335: 4, 31334: 1, 31333: 1, 31332: 1, 31331: 1, 31330: 4, 31329: 1, 31328: 1, 31327: 2, 31326: 0, 31325: 5, 31324: 4, 31323: 2, 31322: 0, 31321: 10, 31320: 2, 31319: 0, 31318: 1, 31317: 2, 31316: 1, 31315: 7, 31314: 3, 31313: 3, 31312: 0, 31311: 0, 31310: 1, 31309: 1, 31308: 1, 31307: 2, 31306: 1, 31305: 4, 31304: 1, 31303: 4, 31302: 3, 31301: 1, 31300: 0, 31299: 2, 31298: 4, 31297: 1, 31296: 1, 31295: 2, 31294: 3, 31293: 2, 31292: 1, 31291: 7, 31290: 1, 31289: 3, 31288: 3, 31287: 4, 31286: 4, 31285: 0, 31284: 0, 31283: 3, 31282: 1, 31281: 1, 31280: 2, 31279: 3, 31278: 2, 31277: 3, 31276: 0, 31275: 5, 31274: 5, 31273: 5, 31272: 4, 31271: 1, 31270: 1, 31269: 2, 31268: 2, 31267: 2, 31266: 3, 31265: 3, 31264: 1, 31263: 5, 31262: 4, 31261: 3, 31260: 2, 31259: 4, 31258: 3, 31257: 4, 31256: 3, 31255: 2, 31254: 5, 31253: 1, 31252: 1, 31251: 0, 31250: 1, 31249: 0, 31248: 4, 31247: 2, 31246: 2, 31245: 2, 31244: 1, 31243: 2, 31242: 1, 31241: 2, 31240: 9, 31239: 3, 31238: 1, 31237: 1, 31236: 3, 31235: 0, 31234: 1, 31233: 2, 31232: 3, 31231: 4, 31230: 6, 31229: 2, 31228: 1, 31227: 4, 31226: 2, 31225: 4, 31224: 3, 31223: 0, 31222: 4, 31221: 4, 31220: 3, 31219: 3, 31218: 2, 31217: 3, 31216: 4, 31215: 1, 31214: 4, 31213: 3, 31212: 3, 31211: 2, 31210: 2, 31209: 2, 31208: 1, 31207: 3, 31206: 5, 31205: 6, 31204: 4, 31203: 5, 31202: 3, 31201: 1, 31200: 3, 31199: 2, 31198: 2, 31197: 1, 31196: 2, 31195: 4, 31194: 3, 31193: 2, 31192: 1, 31191: 0, 31190: 2, 31189: 2, 31188: 0, 31187: 2, 31186: 4, 31185: 2, 31184: 2, 31183: 2, 31182: 1, 31181: 2, 31180: 6, 31179: 2, 31178: 1, 31177: 0, 31176: 6, 31175: 2, 31174: 1, 31173: 2, 31172: 2, 31171: 7, 31170: 7, 31169: 6, 31168: 7, 31167: 0, 31166: 6, 31165: 2, 31164: 3, 31163: 1, 31162: 1, 31161: 2, 31160: 2, 31159: 3, 31158: 5, 31157: 3, 31156: 4, 31155: 0, 31154: 2, 31153: 0, 31152: 3, 31151: 0, 31150: 2, 31149: 3, 31148: 3, 31147: 1, 31146: 1, 31145: 3, 31144: 3, 31143: 3, 31142: 3, 31141: 3, 31140: 1, 31139: 0, 31138: 2, 31137: 0, 31136: 2, 31135: 1, 31134: 0, 31133: 2, 31132: 3, 31131: 1, 31130: 1, 31129: 3, 31128: 4, 31127: 2, 31126: 2, 31125: 1, 31124: 8, 31123: 0, 31122: 1, 31121: 4, 31120: 2, 31119: 0, 31118: 3, 31117: 3, 31116: 2, 31115: 2, 31114: 3, 31113: 7, 31112: 3, 31111: 5, 31110: 3, 31109: 4, 31108: 0, 31107: 2, 31106: 2, 31105: 5, 31104: 4, 31103: 8, 31102: 4, 31101: 4, 31100: 4, 31099: 3, 31098: 3, 31097: 2, 31096: 5, 31095: 4, 31094: 3, 31093: 4, 31092: 4, 31091: 7, 31090: 2, 31089: 3, 31088: 10, 31087: 9, 31086: 5, 31085: 8, 31084: 7, 31083: 10, 31082: 12, 31081: 5, 31080: 5, 31079: 7, 31078: 12, 31077: 7, 31076: 7, 31075: 7, 31074: 7, 31073: 6, 31072: 7, 31071: 1, 31070: 5, 31069: 3, 31068: 2, 31067: 0, 31066: 5, 31065: 1, 31064: 1, 31063: 1, 31062: 2, 31061: 1, 31060: 2, 31059: 2, 31058: 4, 31057: 1, 31056: 3, 31055: 0, 31054: 2, 31053: 3, 31052: 6, 31051: 4, 31050: 3, 31049: 1, 31048: 3, 31047: 3, 31046: 6, 31045: 6, 31044: 4, 31043: 4, 31042: 2, 31041: 3, 31040: 4, 31039: 3, 31038: 3, 31037: 1, 31036: 2, 31035: 4, 31034: 2, 31033: 3, 31032: 4, 31031: 1, 31030: 2, 31029: 2, 31028: 1, 31027: 2, 31026: 0, 31025: 3, 31024: 2, 31023: 0, 31022: 1, 31021: 1, 31020: 2, 31019: 1, 31018: 2, 31017: 1, 31016: 2, 31015: 5, 31014: 2, 31013: 2, 31012: 7, 31011: 4, 31010: 1, 31009: 3, 31008: 2, 31007: 3, 31006: 1, 31005: 2, 31004: 2, 31003: 2, 31002: 1, 31001: 3, 31000: 4, 30999: 4, 30998: 6, 30997: 3, 30996: 6, 30995: 6, 30994: 4, 30993: 6, 30992: 7, 30991: 2, 30990: 4, 30989: 3, 30988: 3, 30987: 3, 30986: 0, 30985: 3, 30984: 3, 30983: 1, 30982: 1, 30981: 5, 30980: 2, 30979: 1, 30978: 1, 30977: 3, 30976: 3, 30975: 1, 30974: 3, 30973: 1, 30972: 5, 30971: 3, 30970: 3, 30969: 3, 30968: 3, 30967: 5, 30966: 6, 30965: 1, 30964: 1, 30963: 2, 30962: 2, 30961: 0, 30960: 4, 30959: 2, 30958: 1, 30957: 6, 30956: 1, 30955: 0, 30954: 1, 30953: 1, 30952: 2, 30951: 1, 30950: 2, 30949: 2, 30948: 3, 30947: 1, 30946: 0, 30945: 4, 30944: 3, 30943: 1, 30942: 1, 30941: 2, 30940: 2, 30939: 5, 30938: 8, 30937: 3, 30936: 2, 30935: 2, 30934: 1, 30933: 1, 30932: 3, 30931: 1, 30930: 2, 30929: 3, 30928: 4, 30927: 0, 30926: 4, 30925: 6, 30924: 1, 30923: 3, 30922: 3, 30921: 1, 30920: 4, 30919: 4, 30918: 1, 30917: 0, 30916: 2, 30915: 3, 30914: 5, 30913: 5, 30912: 0, 30911: 3, 30910: 1, 30909: 2, 30908: 2, 30907: 2, 30906: 2, 30905: 3, 30904: 3, 30903: 3, 30902: 0, 30901: 3, 30900: 0, 30899: 1, 30898: 5, 30897: 1, 30896: 0, 30895: 1, 30894: 0, 30893: 2, 30892: 1, 30891: 2, 30890: 1, 30889: 2, 30888: 1, 30887: 1, 30886: 6, 30885: 4, 30884: 2, 30883: 3, 30882: 3, 30881: 2, 30880: 2, 30879: 3, 30878: 2, 30877: 4, 30876: 1, 30875: 2, 30874: 0, 30873: 3, 30872: 4, 30871: 0, 30870: 1, 30869: 6, 30868: 4, 30867: 2, 30866: 0, 30865: 2, 30864: 1, 30863: 4, 30862: 2, 30861: 2, 30860: 2, 30859: 3, 30858: 2, 30857: 2, 30856: 0, 30855: 4, 30854: 2, 30853: 3, 30852: 8, 30851: 4, 30850: 0, 30849: 3, 30848: 3, 30847: 3, 30846: 4, 30845: 4, 30844: 1, 30843: 2, 30842: 1, 30841: 2, 30840: 1, 30839: 3, 30838: 1, 30837: 3, 30836: 1, 30835: 1, 30834: 2, 30833: 0, 30832: 0, 30831: 0, 30830: 1, 30829: 1, 30828: 6, 30827: 4, 30826: 1, 30825: 2, 30824: 2, 30823: 8, 30822: 10, 30821: 4, 30820: 5, 30819: 2, 30818: 4, 30817: 5, 30816: 3, 30815: 5, 30814: 2, 30813: 3, 30812: 2, 30811: 4, 30810: 3, 30809: 3, 30808: 1, 30807: 1, 30806: 1, 30805: 1, 30804: 2, 30803: 2, 30802: 3, 30801: 2, 30800: 3, 30799: 5, 30798: 0, 30797: 3, 30796: 3, 30795: 3, 30794: 1, 30793: 5, 30792: 3, 30791: 1, 30790: 3, 30789: 2, 30788: 1, 30787: 1, 30786: 2, 30785: 0, 30784: 2, 30783: 0, 30782: 5, 30781: 0, 30780: 2, 30779: 2, 30778: 1, 30777: 1, 30776: 2, 30775: 3, 30774: 3, 30773: 2, 30772: 1, 30771: 0, 30770: 3, 30769: 2, 30768: 2, 30767: 0, 30766: 4, 30765: 5, 30764: 4, 30763: 4, 30762: 6, 30761: 7, 30760: 3, 30759: 8, 30758: 2, 30757: 3, 30756: 1, 30755: 0, 30754: 2, 30753: 2, 30752: 1, 30751: 5, 30750: 1, 30749: 8, 30748: 1, 30747: 1, 30746: 2, 30745: 0, 30744: 3, 30743: 2, 30742: 2, 30741: 3, 30740: 3, 30739: 2, 30738: 1, 30737: 1, 30736: 5, 30735: 1, 30734: 4, 30733: 5, 30732: 3, 30731: 2, 30730: 4, 30729: 4, 30728: 2, 30727: 3, 30726: 4, 30725: 1, 30724: 3, 30723: 4, 30722: 3, 30721: 3, 30720: 5, 30719: 4, 30718: 4, 30717: 3, 30716: 4, 30715: 3, 30714: 1, 30713: 1, 30712: 2, 30711: 3, 30710: 4, 30709: 2, 30708: 4, 30707: 2, 30706: 0, 30705: 4, 30704: 2, 30703: 2, 30702: 5, 30701: 3, 30700: 2, 30699: 2, 30698: 6, 30697: 3, 30696: 5, 30695: 4, 30694: 4, 30693: 5, 30692: 2, 30691: 5, 30690: 2, 30689: 1, 30688: 4, 30687: 3, 30686: 1, 30685: 3, 30684: 2, 30683: 4, 30682: 2, 30681: 2, 30680: 1, 30679: 2, 30678: 1, 30677: 3, 30676: 2, 30675: 4, 30674: 3, 30673: 0, 30672: 1, 30671: 2, 30670: 1, 30669: 2, 30668: 2, 30667: 0, 30666: 0, 30665: 2, 30664: 2, 30663: 1, 30662: 1, 30661: 4, 30660: 2, 30659: 2, 30658: 0, 30657: 2, 30656: 2, 30655: 1, 30654: 0, 30653: 5, 30652: 4, 30651: 2, 30650: 3, 30649: 5, 30648: 3, 30647: 3, 30646: 4, 30645: 1, 30644: 0, 30643: 4, 30642: 1, 30641: 4, 30640: 4, 30639: 2, 30638: 1, 30637: 3, 30636: 3, 30635: 5, 30634: 5, 30633: 1, 30632: 3, 30631: 2, 30630: 2, 30629: 2, 30628: 4, 30627: 2, 30626: 2, 30625: 3, 30624: 6, 30623: 5, 30622: 1, 30621: 1, 30620: 1, 30619: 5, 30618: 2, 30617: 3, 30616: 4, 30615: 1, 30614: 2, 30613: 7, 30612: 2, 30611: 3, 30610: 3, 30609: 3, 30608: 2, 30607: 3, 30606: 1, 30605: 1, 30604: 2, 30603: 4, 30602: 0, 30601: 1, 30600: 6, 30599: 2, 30598: 3, 30597: 2, 30596: 2, 30595: 3, 30594: 1, 30593: 2, 30592: 4, 30591: 2, 30590: 2, 30589: 1, 30588: 1, 30587: 3, 30586: 2, 30585: 1, 30584: 1, 30583: 3, 30582: 3, 30581: 3, 30580: 3, 30579: 7, 30578: 1, 30577: 7, 30576: 4, 30575: 6, 30574: 0, 30573: 1, 30572: 1, 30571: 2, 30570: 1, 30569: 0, 30568: 7, 30567: 1, 30566: 4, 30565: 0, 30564: 3, 30563: 1, 30562: 4, 30561: 2, 30560: 0, 30559: 3, 30558: 4, 30557: 2, 30556: 1, 30555: 4, 30554: 1, 30553: 1, 30552: 2, 30551: 4, 30550: 1, 30549: 2, 30548: 4, 30547: 1, 30546: 6, 30545: 4, 30544: 3, 30543: 3, 30542: 2, 30541: 3, 30540: 2, 30539: 2, 30538: 0, 30537: 2, 30536: 2, 30535: 2, 30534: 0, 30533: 4, 30532: 2, 30531: 3, 30530: 2, 30529: 2, 30528: 3, 30527: 4, 30526: 2, 30525: 2, 30524: 2, 30523: 2, 30522: 0, 30521: 1, 30520: 1, 30519: 2, 30518: 3, 30517: 3, 30516: 0, 30515: 4, 30514: 5, 30513: 4, 30512: 2, 30511: 1, 30510: 1, 30509: 1, 30508: 0, 30507: 3, 30506: 2, 30505: 3, 30504: 2, 30503: 3, 30502: 9, 30501: 7, 30500: 5, 30499: 6, 30498: 2, 30497: 1, 30496: 1, 30495: 1, 30494: 2, 30493: 4, 30492: 2, 30491: 1, 30490: 3, 30489: 3, 30488: 2, 30487: 5, 30486: 2, 30485: 2, 30484: 1, 30483: 1, 30482: 0, 30481: 1, 30480: 2, 30479: 1, 30478: 2, 30477: 4, 30476: 0, 30475: 4, 30474: 2, 30473: 4, 30472: 3, 30471: 3, 30470: 5, 30469: 4, 30468: 3, 30467: 4, 30466: 1, 30465: 1, 30464: 2, 30463: 0, 30462: 2, 30461: 3, 30460: 1, 30459: 3, 30458: 1, 30457: 1, 30456: 0, 30455: 9, 30454: 3, 30453: 3, 30452: 3, 30451: 3, 30450: 2, 30449: 2, 30448: 0, 30447: 2, 30446: 1, 30445: 2, 30444: 1, 30443: 1, 30442: 2, 30441: 2, 30440: 2, 30439: 2, 30438: 0, 30437: 3, 30436: 0, 30435: 3, 30434: 4, 30433: 2, 30432: 0, 30431: 1, 30430: 1, 30429: 3, 30428: 5, 30427: 1, 30426: 1, 30425: 1, 30424: 2, 30423: 2, 30422: 4, 30421: 1, 30420: 3, 30419: 5, 30418: 2, 30417: 0, 30416: 1, 30415: 2, 30414: 2, 30413: 6, 30412: 1, 30411: 6, 30410: 5, 30409: 2, 30408: 3, 30407: 0, 30406: 1, 30405: 4, 30404: 1, 30403: 3, 30402: 6, 30401: 4, 30400: 2, 30399: 2, 30398: 2, 30397: 4, 30396: 1, 30395: 0, 30394: 9, 30393: 7, 30392: 6, 30391: 3, 30390: 1, 30389: 3, 30388: 3, 30387: 8, 30386: 3, 30385: 3, 30384: 1, 30383: 1, 30382: 5, 30381: 1, 30380: 6, 30379: 0, 30378: 3, 30377: 4, 30376: 2, 30375: 2, 30374: 3, 30373: 1, 30372: 3, 30371: 1, 30370: 1, 30369: 0, 30368: 1, 30367: 3, 30366: 3, 30365: 3, 30364: 1, 30363: 6, 30362: 7, 30361: 5, 30360: 5, 30359: 5, 30358: 6, 30357: 6, 30356: 7, 30355: 7, 30354: 6, 30353: 4, 30352: 1, 30351: 3, 30350: 2, 30349: 2, 30348: 2, 30347: 3, 30346: 3, 30345: 3, 30344: 2, 30343: 2, 30342: 2, 30341: 2, 30340: 4, 30339: 3, 30338: 2, 30337: 1, 30336: 4, 30335: 4, 30334: 2, 30333: 2, 30332: 3, 30331: 0, 30330: 2, 30329: 2, 30328: 3, 30327: 2, 30326: 3, 30325: 2, 30324: 5, 30323: 3, 30322: 2, 30321: 4, 30320: 2, 30319: 3, 30318: 1, 30317: 1, 30316: 6, 30315: 5, 30314: 7, 30313: 4, 30312: 2, 30311: 2, 30310: 2, 30309: 4, 30308: 1, 30307: 2, 30306: 2, 30305: 6, 30304: 2, 30303: 1, 30302: 3, 30301: 2, 30300: 0, 30299: 5, 30298: 5, 30297: 2, 30296: 1, 30295: 3, 30294: 1, 30293: 2, 30292: 1, 30291: 2, 30290: 0, 30289: 1, 30288: 5, 30287: 3, 30286: 3, 30285: 6, 30284: 5, 30283: 3, 30282: 5, 30281: 4, 30280: 2, 30279: 8, 30278: 5, 30277: 3, 30276: 5, 30275: 3, 30274: 4, 30273: 3, 30272: 5, 30271: 1, 30270: 7, 30269: 1, 30268: 3, 30267: 3, 30266: 2, 30265: 2, 30264: 2, 30263: 4, 30262: 4, 30261: 3, 30260: 3, 30259: 3, 30258: 4, 30257: 4, 30256: 4, 30255: 5, 30254: 5, 30253: 1, 30252: 4, 30251: 6, 30250: 4, 30249: 5, 30248: 2, 30247: 1, 30246: 3, 30245: 1, 30244: 1, 30243: 4, 30242: 2, 30241: 1, 30240: 1, 30239: 6, 30238: 5, 30237: 1, 30236: 2, 30235: 1, 30234: 4, 30233: 5, 30232: 1, 30231: 2, 30230: 2, 30229: 3, 30228: 1, 30227: 4, 30226: 3, 30225: 3, 30224: 4, 30223: 3, 30222: 2, 30221: 4, 30220: 2, 30219: 1, 30218: 4, 30217: 3, 30216: 3, 30215: 3, 30214: 1, 30213: 1, 30212: 1, 30211: 2, 30210: 2, 30209: 2, 30208: 3, 30207: 4, 30206: 4, 30205: 16, 30204: 1, 30203: 1, 30202: 5, 30201: 4, 30200: 1, 30199: 2, 30198: 3, 30197: 2, 30196: 4, 30195: 5, 30194: 5, 30193: 5, 30192: 2, 30191: 3, 30190: 3, 30189: 1, 30188: 1, 30187: 1, 30186: 1, 30185: 4, 30184: 4, 30183: 8, 30182: 2, 30181: 1, 30180: 1, 30179: 2, 30178: 4, 30177: 3, 30176: 4, 30175: 1, 30174: 5, 30173: 2, 30172: 1, 30171: 1, 30170: 1, 30169: 3, 30168: 1, 30167: 2, 30166: 1, 30165: 7, 30164: 1, 30163: 1, 30162: 1, 30161: 4, 30160: 1, 30159: 2, 30158: 2, 30157: 0, 30156: 2, 30155: 0, 30154: 3, 30153: 3, 30152: 1, 30151: 1, 30150: 3, 30149: 4, 30148: 2, 30147: 5, 30146: 6, 30145: 3, 30144: 2, 30143: 4, 30142: 2, 30141: 1, 30140: 0, 30139: 3, 30138: 8, 30137: 1, 30136: 4, 30135: 1, 30134: 1, 30133: 3, 30132: 2, 30131: 7, 30130: 6, 30129: 6, 30128: 6, 30127: 5, 30126: 6, 30125: 8, 30124: 2, 30123: 1, 30122: 4, 30121: 8, 30120: 4, 30119: 3, 30118: 3, 30117: 3, 30116: 3, 30115: 3, 30114: 1, 30113: 1, 30112: 2, 30111: 5, 30110: 2, 30109: 7, 30108: 11, 30107: 8, 30106: 12, 30105: 9, 30104: 4, 30103: 3, 30102: 3, 30101: 1, 30100: 3, 30099: 1, 30098: 4, 30097: 5, 30096: 5, 30095: 6, 30094: 6, 30093: 5, 30092: 1, 30091: 0, 30090: 3, 30089: 4, 30088: 2, 30087: 4, 30086: 3, 30085: 1, 30084: 7, 30083: 3, 30082: 4, 30081: 4, 30080: 1, 30079: 1, 30078: 1, 30077: 2, 30076: 2, 30075: 3, 30074: 3, 30073: 3, 30072: 0, 30071: 3, 30070: 6, 30069: 10, 30068: 0, 30067: 1, 30066: 3, 30065: 1, 30064: 1, 30063: 1, 30062: 1, 30061: 3, 30060: 2, 30059: 4, 30058: 1, 30057: 3, 30056: 1, 30055: 5, 30054: 7, 30053: 1, 30052: 4, 30051: 7, 30050: 2, 30049: 3, 30048: 3, 30047: 2, 30046: 3, 30045: 2, 30044: 2, 30043: 1, 30042: 1, 30041: 3, 30040: 2, 30039: 3, 30038: 3, 30037: 0, 30036: 6, 30035: 4, 30034: 5, 30033: 5, 30032: 1, 30031: 1, 30030: 1, 30029: 0, 30028: 5, 30027: 3, 30026: 0, 30025: 0, 30024: 2, 30023: 3, 30022: 5, 30021: 3, 30020: 1, 30019: 7, 30018: 1, 30017: 0, 30016: 5, 30015: 4, 30014: 1, 30013: 1, 30012: 1, 30011: 2, 30010: 1, 30009: 1, 30008: 4, 30007: 4, 30006: 2, 30005: 1, 30004: 2, 30003: 1, 30002: 0, 30001: 1, 30000: 2, 29999: 3, 29998: 6, 29997: 5, 29996: 3, 29995: 0, 29994: 1, 29993: 2, 29992: 3, 29991: 1, 29990: 2, 29989: 3, 29988: 1, 29987: 1, 29986: 2, 29985: 1, 29984: 2, 29983: 8, 29982: 4, 29981: 1, 29980: 4, 29979: 5, 29978: 2, 29977: 2, 29976: 9, 29975: 3, 29974: 3, 29973: 4, 29972: 5, 29971: 6, 29970: 4, 29969: 4, 29968: 2, 29967: 3, 29966: 4, 29965: 3, 29964: 3, 29963: 1, 29962: 3, 29961: 4, 29960: 1, 29959: 1, 29958: 1, 29957: 2, 29956: 2, 29955: 2, 29954: 2, 29953: 4, 29952: 0, 29951: 8, 29950: 1, 29949: 1, 29948: 4, 29947: 5, 29946: 6, 29945: 1, 29944: 3, 29943: 5, 29942: 5, 29941: 2, 29940: 13, 29939: 14, 29938: 2, 29937: 4, 29936: 2, 29935: 1, 29934: 1, 29933: 1, 29932: 0, 29931: 1, 29930: 3, 29929: 3, 29928: 0, 29927: 2, 29926: 1, 29925: 1, 29924: 1, 29923: 2, 29922: 3, 29921: 1, 29920: 1, 29919: 3, 29918: 2, 29917: 1, 29916: 2, 29915: 4, 29914: 0, 29913: 6, 29912: 2, 29911: 3, 29910: 2, 29909: 0, 29908: 7, 29907: 5, 29906: 2, 29905: 1, 29904: 4, 29903: 3, 29902: 4, 29901: 2, 29900: 1, 29899: 2, 29898: 3, 29897: 2, 29896: 2, 29895: 2, 29894: 1, 29893: 3, 29892: 3, 29891: 9, 29890: 6, 29889: 4, 29888: 5, 29887: 6, 29886: 4, 29885: 6, 29884: 3, 29883: 3, 29882: 3, 29881: 0, 29880: 2, 29879: 4, 29878: 17, 29877: 13, 29876: 13, 29875: 2, 29874: 0, 29873: 0, 29872: 5, 29871: 5, 29870: 6, 29869: 3, 29868: 1, 29867: 3, 29866: 4, 29865: 4, 29864: 4, 29863: 2, 29862: 1, 29861: 1, 29860: 16, 29859: 12, 29858: 13, 29857: 10, 29856: 13, 29855: 13, 29854: 4, 29853: 2, 29852: 3, 29851: 2, 29850: 2, 29849: 3, 29848: 3, 29847: 7, 29846: 2, 29845: 2, 29844: 0, 29843: 3, 29842: 3, 29841: 2, 29840: 3, 29839: 1, 29838: 2, 29837: 2, 29836: 1, 29835: 2, 29834: 2, 29833: 4, 29832: 2, 29831: 2, 29830: 4, 29829: 2, 29828: 2, 29827: 1, 29826: 2, 29825: 0, 29824: 2, 29823: 4, 29822: 2, 29821: 0, 29820: 1, 29819: 3, 29818: 1, 29817: 3, 29816: 3, 29815: 4, 29814: 4, 29813: 3, 29812: 4, 29811: 4, 29810: 2, 29809: 1, 29808: 0, 29807: 1, 29806: 2, 29805: 3, 29804: 2, 29803: 5, 29802: 1, 29801: 3, 29800: 1, 29799: 3, 29798: 3, 29797: 8, 29796: 7, 29795: 1, 29794: 6, 29793: 8, 29792: 7, 29791: 9, 29790: 1, 29789: 2, 29788: 0, 29787: 2, 29786: 2, 29785: 3, 29784: 2, 29783: 3, 29782: 2, 29781: 1, 29780: 2, 29779: 1, 29778: 0, 29777: 2, 29776: 0, 29775: 1, 29774: 5, 29773: 1, 29772: 2, 29771: 2, 29770: 2, 29769: 1, 29768: 2, 29767: 4, 29766: 1, 29765: 2, 29764: 3, 29763: 2, 29762: 2, 29761: 2, 29760: 2, 29759: 1, 29758: 7, 29757: 2, 29756: 0, 29755: 1, 29754: 3, 29753: 1, 29752: 1, 29751: 2, 29750: 3, 29749: 3, 29748: 3, 29747: 3, 29746: 5, 29745: 2, 29744: 1, 29743: 2, 29742: 3, 29741: 4, 29740: 2, 29739: 3, 29738: 3, 29737: 4, 29736: 3, 29735: 3, 29734: 2, 29733: 4, 29732: 1, 29731: 1, 29730: 1, 29729: 3, 29728: 4, 29727: 2, 29726: 3, 29725: 4, 29724: 3, 29723: 2, 29722: 2, 29721: 2, 29720: 6, 29719: 1, 29718: 1, 29717: 2, 29716: 2, 29715: 5, 29714: 3, 29713: 2, 29712: 1, 29711: 5, 29710: 6, 29709: 4, 29708: 6, 29707: 2, 29706: 2, 29705: 7, 29704: 2, 29703: 1, 29702: 2, 29701: 2, 29700: 3, 29699: 2, 29698: 1, 29697: 0, 29696: 6, 29695: 2, 29694: 0, 29693: 1, 29692: 3, 29691: 3, 29690: 3, 29689: 4, 29688: 1, 29687: 1, 29686: 2, 29685: 0, 29684: 1, 29683: 1, 29682: 7, 29681: 6, 29680: 6, 29679: 5, 29678: 3, 29677: 6, 29676: 2, 29675: 1, 29674: 3, 29673: 17, 29672: 2, 29671: 4, 29670: 3, 29669: 2, 29668: 1, 29667: 0, 29666: 1, 29665: 6, 29664: 2, 29663: 5, 29662: 3, 29661: 3, 29660: 3, 29659: 2, 29658: 1, 29657: 1, 29656: 2, 29655: 2, 29654: 4, 29653: 3, 29652: 1, 29651: 2, 29650: 1, 29649: 0, 29648: 1, 29647: 1, 29646: 2, 29645: 6, 29644: 2, 29643: 1, 29642: 2, 29641: 2, 29640: 1, 29639: 4, 29638: 5, 29637: 1, 29636: 1, 29635: 2, 29634: 4, 29633: 8, 29632: 3, 29631: 3, 29630: 0, 29629: 2, 29628: 3, 29627: 2, 29626: 2, 29625: 3, 29624: 4, 29623: 4, 29622: 2, 29621: 2, 29620: 1, 29619: 2, 29618: 1, 29617: 0, 29616: 5, 29615: 6, 29614: 4, 29613: 2, 29612: 0, 29611: 6, 29610: 2, 29609: 2, 29608: 3, 29607: 3, 29606: 4, 29605: 1, 29604: 3, 29603: 1, 29602: 0, 29601: 12, 29600: 2, 29599: 8, 29598: 0, 29597: 1, 29596: 1, 29595: 2, 29594: 1, 29593: 3, 29592: 2, 29591: 5, 29590: 5, 29589: 2, 29588: 3, 29587: 4, 29586: 2, 29585: 0, 29584: 2, 29583: 3, 29582: 6, 29581: 3, 29580: 5, 29579: 5, 29578: 0, 29577: 4, 29576: 16, 29575: 9, 29574: 16, 29573: 6, 29572: 7, 29571: 5, 29570: 4, 29569: 8, 29568: 4, 29567: 9, 29566: 3, 29565: 4, 29564: 3, 29563: 2, 29562: 2, 29561: 1, 29560: 2, 29559: 8, 29558: 5, 29557: 11, 29556: 9, 29555: 14, 29554: 3, 29553: 1, 29552: 4, 29551: 1, 29550: 4, 29549: 4, 29548: 1, 29547: 1, 29546: 2, 29545: 1, 29544: 1, 29543: 3, 29542: 5, 29541: 4, 29540: 4, 29539: 4, 29538: 3, 29537: 3, 29536: 6, 29535: 10, 29534: 9, 29533: 3, 29532: 0, 29531: 1, 29530: 1, 29529: 2, 29528: 2, 29527: 3, 29526: 2, 29525: 0, 29524: 9, 29523: 3, 29522: 5, 29521: 4, 29520: 4, 29519: 3, 29518: 5, 29517: 0, 29516: 2, 29515: 5, 29514: 2, 29513: 2, 29512: 2, 29511: 1, 29510: 2, 29509: 4, 29508: 0, 29507: 3, 29506: 0, 29505: 3, 29504: 2, 29503: 3, 29502: 4, 29501: 2, 29500: 2, 29499: 4, 29498: 2, 29497: 0, 29496: 3, 29495: 1, 29494: 2, 29493: 2, 29492: 2, 29491: 0, 29490: 2, 29489: 3, 29488: 0, 29487: 2, 29486: 1, 29485: 1, 29484: 4, 29483: 3, 29482: 1, 29481: 2, 29480: 4, 29479: 4, 29478: 3, 29477: 1, 29476: 3, 29475: 2, 29474: 4, 29473: 0, 29472: 3, 29471: 4, 29470: 4, 29469: 2, 29468: 10, 29467: 1, 29466: 5, 29465: 4, 29464: 0, 29463: 4, 29462: 1, 29461: 3, 29460: 3, 29459: 4, 29458: 0, 29457: 2, 29456: 1, 29455: 4, 29454: 3, 29453: 0, 29452: 1, 29451: 3, 29450: 2, 29449: 1, 29448: 0, 29447: 3, 29446: 2, 29445: 4, 29444: 7, 29443: 0, 29442: 1, 29441: 0, 29440: 4, 29439: 3, 29438: 3, 29437: 3, 29436: 2, 29435: 6, 29434: 6, 29433: 7, 29432: 1, 29431: 4, 29430: 5, 29429: 4, 29428: 3, 29427: 2, 29426: 1, 29425: 2, 29424: 1, 29423: 6, 29422: 7, 29421: 3, 29420: 1, 29419: 2, 29418: 3, 29417: 5, 29416: 0, 29415: 1, 29414: 3, 29413: 2, 29412: 3, 29411: 2, 29410: 5, 29409: 0, 29408: 0, 29407: 2, 29406: 3, 29405: 3, 29404: 3, 29403: 5, 29402: 2, 29401: 4, 29400: 4, 29399: 3, 29398: 4, 29397: 1, 29396: 2, 29395: 4, 29394: 8, 29393: 9, 29392: 2, 29391: 1, 29390: 1, 29389: 4, 29388: 0, 29387: 3, 29386: 4, 29385: 5, 29384: 2, 29383: 1, 29382: 2, 29381: 4, 29380: 4, 29379: 2, 29378: 0, 29377: 6, 29376: 8, 29375: 6, 29374: 5, 29373: 2, 29372: 2, 29371: 2, 29370: 4, 29369: 2, 29368: 4, 29367: 3, 29366: 2, 29365: 2, 29364: 6, 29363: 1, 29362: 0, 29361: 4, 29360: 2, 29359: 1, 29358: 3, 29357: 1, 29356: 3, 29355: 2, 29354: 2, 29353: 2, 29352: 5, 29351: 2, 29350: 2, 29349: 3, 29348: 1, 29347: 5, 29346: 3, 29345: 4, 29344: 4, 29343: 2, 29342: 6, 29341: 4, 29340: 4, 29339: 2, 29338: 4, 29337: 3, 29336: 5, 29335: 1, 29334: 4, 29333: 2, 29332: 2, 29331: 2, 29330: 2, 29329: 4, 29328: 4, 29327: 4, 29326: 7, 29325: 3, 29324: 2, 29323: 5, 29322: 7, 29321: 1, 29320: 5, 29319: 4, 29318: 0, 29317: 0, 29316: 0, 29315: 0, 29314: 4, 29313: 1, 29312: 3, 29311: 1, 29310: 3, 29309: 5, 29308: 3, 29307: 6, 29306: 3, 29305: 3, 29304: 0, 29303: 4, 29302: 2, 29301: 4, 29300: 1, 29299: 2, 29298: 2, 29297: 3, 29296: 4, 29295: 1, 29294: 4, 29293: 6, 29292: 2, 29291: 3, 29290: 2, 29289: 4, 29288: 7, 29287: 3, 29286: 4, 29285: 2, 29284: 0, 29283: 1, 29282: 4, 29281: 2, 29280: 2, 29279: 2, 29278: 4, 29277: 9, 29276: 12, 29275: 8, 29274: 14, 29273: 11, 29272: 7, 29271: 13, 29270: 0, 29269: 4, 29268: 2, 29267: 5, 29266: 6, 29265: 3, 29264: 6, 29263: 2, 29262: 8, 29261: 17, 29260: 12, 29259: 13, 29258: 15, 29257: 1, 29256: 2, 29255: 1, 29254: 5, 29253: 6, 29252: 5, 29251: 7, 29250: 7, 29249: 2, 29248: 4, 29247: 4, 29246: 2, 29245: 1, 29244: 1, 29243: 6, 29242: 9, 29241: 12, 29240: 7, 29239: 7, 29238: 8, 29237: 1, 29236: 1, 29235: 1, 29234: 0, 29233: 1, 29232: 3, 29231: 1, 29230: 1, 29229: 2, 29228: 1, 29227: 4, 29226: 8, 29225: 6, 29224: 2, 29223: 4, 29222: 0, 29221: 2, 29220: 6, 29219: 2, 29218: 0, 29217: 1, 29216: 2, 29215: 2, 29214: 3, 29213: 2, 29212: 1, 29211: 3, 29210: 1, 29209: 3, 29208: 1, 29207: 2, 29206: 1, 29205: 3, 29204: 3, 29203: 2, 29202: 0, 29201: 1, 29200: 1, 29199: 0, 29198: 4, 29197: 5, 29196: 2, 29195: 0, 29194: 4, 29193: 1, 29192: 1, 29191: 3, 29190: 3, 29189: 2, 29188: 1, 29187: 1, 29186: 0, 29185: 12, 29184: 3, 29183: 4, 29182: 2, 29181: 1, 29180: 2, 29179: 2, 29178: 2, 29177: 3, 29176: 3, 29175: 2, 29174: 1, 29173: 1, 29172: 4, 29171: 2, 29170: 1, 29169: 4, 29168: 3, 29167: 1, 29166: 2, 29165: 1, 29164: 1, 29163: 3, 29162: 5, 29161: 2, 29160: 4, 29159: 2, 29158: 3, 29157: 2, 29156: 1, 29155: 3, 29154: 1, 29153: 0, 29152: 2, 29151: 5, 29150: 4, 29149: 4, 29148: 2, 29147: 3, 29146: 1, 29145: 3, 29144: 1, 29143: 2, 29142: 4, 29141: 0, 29140: 3, 29139: 2, 29138: 2, 29137: 2, 29136: 3, 29135: 5, 29134: 0, 29133: 4, 29132: 1, 29131: 2, 29130: 3, 29129: 2, 29128: 1, 29127: 2, 29126: 2, 29125: 1, 29124: 2, 29123: 0, 29122: 1, 29121: 9, 29120: 3, 29119: 5, 29118: 2, 29117: 0, 29116: 3, 29115: 1, 29114: 2, 29113: 2, 29112: 6, 29111: 2, 29110: 1, 29109: 2, 29108: 2, 29107: 1, 29106: 2, 29105: 0, 29104: 2, 29103: 2, 29102: 4, 29101: 2, 29100: 3, 29099: 0, 29098: 3, 29097: 0, 29096: 3, 29095: 3, 29094: 0, 29093: 3, 29092: 1, 29091: 0, 29090: 2, 29089: 1, 29088: 1, 29087: 0, 29086: 1, 29085: 5, 29084: 1, 29083: 1, 29082: 2, 29081: 1, 29080: 1, 29079: 0, 29078: 2, 29077: 2, 29076: 1, 29075: 2, 29074: 1, 29073: 2, 29072: 1, 29071: 3, 29070: 3, 29069: 0, 29068: 1, 29067: 1, 29066: 3, 29065: 1, 29064: 2, 29063: 1, 29062: 2, 29061: 3, 29060: 1, 29059: 3, 29058: 5, 29057: 3, 29056: 3, 29055: 2, 29054: 2, 29053: 2, 29052: 4, 29051: 4, 29050: 2, 29049: 2, 29048: 1, 29047: 0, 29046: 1, 29045: 2, 29044: 1, 29043: 1, 29042: 1, 29041: 2, 29040: 1, 29039: 2, 29038: 2, 29037: 1, 29036: 0, 29035: 4, 29034: 1, 29033: 1, 29032: 0, 29031: 4, 29030: 3, 29029: 5, 29028: 3, 29027: 1, 29026: 0, 29025: 1, 29024: 2, 29023: 2, 29022: 0, 29021: 2, 29020: 1, 29019: 3, 29018: 0, 29017: 4, 29016: 1, 29015: 3, 29014: 3, 29013: 5, 29012: 3, 29011: 1, 29010: 0, 29009: 2, 29008: 0, 29007: 4, 29006: 2, 29005: 3, 29004: 4, 29003: 1, 29002: 4, 29001: 1, 29000: 1, 28999: 2, 28998: 2, 28997: 4, 28996: 1, 28995: 2, 28994: 1, 28993: 2, 28992: 2, 28991: 1, 28990: 1, 28989: 1, 28988: 3, 28987: 1, 28986: 4, 28985: 4, 28984: 2, 28983: 3, 28982: 3, 28981: 3, 28980: 0, 28979: 2, 28978: 0, 28977: 1, 28976: 1, 28975: 4, 28974: 1, 28973: 1, 28972: 4, 28971: 2, 28970: 0, 28969: 1, 28968: 2, 28967: 2, 28966: 7, 28965: 2, 28964: 1, 28963: 1, 28962: 2, 28961: 2, 28960: 3, 28959: 0, 28958: 3, 28957: 1, 28956: 1, 28955: 0, 28954: 8, 28953: 2, 28952: 4, 28951: 3, 28950: 3, 28949: 3, 28948: 2, 28947: 5, 28946: 0, 28945: 1, 28944: 5, 28943: 3, 28942: 0, 28941: 2, 28940: 2, 28939: 1, 28938: 3, 28937: 3, 28936: 1, 28935: 1, 28934: 3, 28933: 2, 28932: 2, 28931: 5, 28930: 2, 28929: 2, 28928: 5, 28927: 4, 28926: 1, 28925: 1, 28924: 4, 28923: 0, 28922: 3, 28921: 3, 28920: 0, 28919: 0, 28918: 1, 28917: 1, 28916: 2, 28915: 3, 28914: 2, 28913: 1, 28912: 2, 28911: 3, 28910: 3, 28909: 2, 28908: 1, 28907: 0, 28906: 3, 28905: 2, 28904: 1, 28903: 2, 28902: 3, 28901: 1, 28900: 2, 28899: 3, 28898: 1, 28897: 2, 28896: 4, 28895: 7, 28894: 1, 28893: 2, 28892: 1, 28891: 5, 28890: 1, 28889: 2, 28888: 1, 28887: 2, 28886: 2, 28885: 2, 28884: 3, 28883: 0, 28882: 2, 28881: 1, 28880: 3, 28879: 1, 28878: 1, 28877: 3, 28876: 3, 28875: 3, 28874: 2, 28873: 1, 28872: 1, 28871: 0, 28870: 2, 28869: 3, 28868: 0, 28867: 0, 28866: 1, 28865: 1, 28864: 1, 28863: 3, 28862: 4, 28861: 4, 28860: 1, 28859: 2, 28858: 3, 28857: 4, 28856: 1, 28855: 2, 28854: 3, 28853: 1, 28852: 2, 28851: 2, 28850: 1, 28849: 3, 28848: 3, 28847: 2, 28846: 3, 28845: 2, 28844: 4, 28843: 4, 28842: 1, 28841: 1, 28840: 1, 28839: 0, 28838: 1, 28837: 3, 28836: 9, 28835: 6, 28834: 7, 28833: 1, 28832: 1, 28831: 4, 28830: 1, 28829: 4, 28828: 6, 28827: 1, 28826: 2, 28825: 3, 28824: 1, 28823: 7, 28822: 1, 28821: 3, 28820: 0, 28819: 4, 28818: 2, 28817: 3, 28816: 1, 28815: 1, 28814: 2, 28813: 2, 28812: 3, 28811: 3, 28810: 1, 28809: 4, 28808: 3, 28807: 4, 28806: 2, 28805: 1, 28804: 4, 28803: 3, 28802: 1, 28801: 2, 28800: 3, 28799: 3, 28798: 2, 28797: 2, 28796: 3, 28795: 5, 28794: 2, 28793: 2, 28792: 3, 28791: 4, 28790: 3, 28789: 1, 28788: 1, 28787: 0, 28786: 0, 28785: 1, 28784: 0, 28783: 1, 28782: 4, 28781: 2, 28780: 3, 28779: 4, 28778: 3, 28777: 9, 28776: 7, 28775: 4, 28774: 5, 28773: 3, 28772: 2, 28771: 2, 28770: 1, 28769: 2, 28768: 2, 28767: 9, 28766: 5, 28765: 1, 28764: 3, 28763: 5, 28762: 2, 28761: 3, 28760: 2, 28759: 4, 28758: 1, 28757: 3, 28756: 4, 28755: 2, 28754: 1, 28753: 0, 28752: 1, 28751: 0, 28750: 5, 28749: 3, 28748: 3, 28747: 2, 28746: 1, 28745: 1, 28744: 4, 28743: 3, 28742: 4, 28741: 0, 28740: 0, 28739: 4, 28738: 2, 28737: 3, 28736: 2, 28735: 3, 28734: 0, 28733: 4, 28732: 3, 28731: 0, 28730: 2, 28729: 2, 28728: 0, 28727: 3, 28726: 0, 28725: 1, 28724: 1, 28723: 2, 28722: 0, 28721: 3, 28720: 2, 28719: 2, 28718: 2, 28717: 3, 28716: 2, 28715: 2, 28714: 0, 28713: 1, 28712: 3, 28711: 4, 28710: 4, 28709: 2, 28708: 2, 28707: 3, 28706: 3, 28705: 5, 28704: 2, 28703: 2, 28702: 1, 28701: 3, 28700: 3, 28699: 3, 28698: 4, 28697: 2, 28696: 4, 28695: 1, 28694: 3, 28693: 0, 28692: 2, 28691: 4, 28690: 1, 28689: 1, 28688: 1, 28687: 2, 28686: 3, 28685: 1, 28684: 2, 28683: 2, 28682: 2, 28681: 1, 28680: 0, 28679: 3, 28678: 2, 28677: 0, 28676: 3, 28675: 2, 28674: 1, 28673: 1, 28672: 1, 28671: 1, 28670: 2, 28669: 3, 28668: 1, 28667: 3, 28666: 1, 28665: 1, 28664: 1, 28663: 1, 28662: 0, 28661: 3, 28660: 2, 28659: 2, 28658: 5, 28657: 1, 28656: 1, 28655: 1, 28654: 1, 28653: 2, 28652: 0, 28651: 1, 28650: 2, 28649: 4, 28648: 1, 28647: 7, 28646: 4, 28645: 4, 28644: 4, 28643: 1, 28642: 2, 28641: 2, 28640: 6, 28639: 1, 28638: 1, 28637: 2, 28636: 5, 28635: 1, 28634: 2, 28633: 12, 28632: 4, 28631: 6, 28630: 3, 28629: 3, 28628: 6, 28627: 1, 28626: 5, 28625: 4, 28624: 2, 28623: 4, 28622: 0, 28621: 4, 28620: 0, 28619: 1, 28618: 2, 28617: 0, 28616: 3, 28615: 3, 28614: 3, 28613: 0, 28612: 2, 28611: 1, 28610: 2, 28609: 2, 28608: 0, 28607: 1, 28606: 1, 28605: 0, 28604: 0, 28603: 1, 28602: 4, 28601: 2, 28600: 0, 28599: 1, 28598: 2, 28597: 2, 28596: 2, 28595: 4, 28594: 1, 28593: 5, 28592: 2, 28591: 0, 28590: 2, 28589: 3, 28588: 5, 28587: 6, 28586: 3, 28585: 3, 28584: 4, 28583: 1, 28582: 7, 28581: 1, 28580: 1, 28579: 2, 28578: 2, 28577: 1, 28576: 0, 28575: 5, 28574: 0, 28573: 1, 28572: 1, 28571: 0, 28570: 3, 28569: 4, 28568: 3, 28567: 2, 28566: 5, 28565: 1, 28564: 1, 28563: 2, 28562: 1, 28561: 2, 28560: 0, 28559: 4, 28558: 5, 28557: 3, 28556: 1, 28555: 3, 28554: 0, 28553: 4, 28552: 2, 28551: 1, 28550: 5, 28549: 2, 28548: 2, 28547: 1, 28546: 1, 28545: 4, 28544: 10, 28543: 6, 28542: 7, 28541: 4, 28540: 7, 28539: 6, 28538: 2, 28537: 2, 28536: 6, 28535: 1, 28534: 3, 28533: 1, 28532: 1, 28531: 1, 28530: 1, 28529: 1, 28528: 2, 28527: 3, 28526: 3, 28525: 2, 28524: 1, 28523: 1, 28522: 5, 28521: 4, 28520: 0, 28519: 1, 28518: 3, 28517: 3, 28516: 2, 28515: 0, 28514: 2, 28513: 3, 28512: 3, 28511: 2, 28510: 2, 28509: 1, 28508: 2, 28507: 3, 28506: 1, 28505: 2, 28504: 1, 28503: 3, 28502: 1, 28501: 4, 28500: 1, 28499: 2, 28498: 1, 28497: 6, 28496: 3, 28495: 4, 28494: 0, 28493: 2, 28492: 3, 28491: 4, 28490: 2, 28489: 3, 28488: 2, 28487: 4, 28486: 1, 28485: 0, 28484: 1, 28483: 4, 28482: 4, 28481: 8, 28480: 2, 28479: 2, 28478: 1, 28477: 3, 28476: 1, 28475: 2, 28474: 2, 28473: 2, 28472: 1, 28471: 1, 28470: 5, 28469: 4, 28468: 1, 28467: 1, 28466: 4, 28465: 0, 28464: 3, 28463: 4, 28462: 3, 28461: 1, 28460: 0, 28459: 3, 28458: 3, 28457: 3, 28456: 3, 28455: 0, 28454: 3, 28453: 3, 28452: 3, 28451: 1, 28450: 1, 28449: 1, 28448: 2, 28447: 2, 28446: 5, 28445: 6, 28444: 9, 28443: 12, 28442: 4, 28441: 5, 28440: 15, 28439: 2, 28438: 1, 28437: 1, 28436: 1, 28435: 3, 28434: 1, 28433: 2, 28432: 2, 28431: 3, 28430: 3, 28429: 1, 28428: 2, 28427: 1, 28426: 1, 28425: 4, 28424: 1, 28423: 1, 28422: 1, 28421: 0, 28420: 3, 28419: 3, 28418: 3, 28417: 3, 28416: 3, 28415: 13, 28414: 1, 28413: 1, 28412: 3, 28411: 0, 28410: 1, 28409: 1, 28408: 0, 28407: 2, 28406: 1, 28405: 1, 28404: 2, 28403: 4, 28402: 3, 28401: 6, 28400: 4, 28399: 3, 28398: 6, 28397: 1, 28396: 3, 28395: 0, 28394: 1, 28393: 2, 28392: 1, 28391: 1, 28390: 3, 28389: 0, 28388: 4, 28387: 1, 28386: 3, 28385: 3, 28384: 4, 28383: 1, 28382: 1, 28381: 4, 28380: 2, 28379: 3, 28378: 3, 28377: 1, 28376: 3, 28375: 0, 28374: 2, 28373: 7, 28372: 1, 28371: 1, 28370: 1, 28369: 4, 28368: 2, 28367: 2, 28366: 0, 28365: 0, 28364: 7, 28363: 7, 28362: 1, 28361: 1, 28360: 4, 28359: 2, 28358: 1, 28357: 5, 28356: 4, 28355: 4, 28354: 2, 28353: 11, 28352: 2, 28351: 1, 28350: 2, 28349: 2, 28348: 5, 28347: 0, 28346: 2, 28345: 3, 28344: 2, 28343: 6, 28342: 3, 28341: 4, 28340: 1, 28339: 2, 28338: 3, 28337: 4, 28336: 0, 28335: 0, 28334: 0, 28333: 2, 28332: 3, 28331: 2, 28330: 1, 28329: 1, 28328: 2, 28327: 3, 28326: 4, 28325: 6, 28324: 4, 28323: 3, 28322: 3, 28321: 2, 28320: 3, 28319: 3, 28318: 2, 28317: 3, 28316: 2, 28315: 2, 28314: 5, 28313: 4, 28312: 3, 28311: 2, 28310: 2, 28309: 1, 28308: 3, 28307: 3, 28306: 2, 28305: 2, 28304: 2, 28303: 2, 28302: 3, 28301: 3, 28300: 1, 28299: 3, 28298: 2, 28297: 0, 28296: 3, 28295: 3, 28294: 0, 28293: 1, 28292: 2, 28291: 3, 28290: 2, 28289: 1, 28288: 2, 28287: 4, 28286: 7, 28285: 3, 28284: 15, 28283: 1, 28282: 1, 28281: 3, 28280: 2, 28279: 2, 28278: 1, 28277: 4, 28276: 2, 28275: 1, 28274: 2, 28273: 1, 28272: 0, 28271: 3, 28270: 1, 28269: 4, 28268: 5, 28267: 1, 28266: 3, 28265: 2, 28264: 3, 28263: 0, 28262: 0, 28261: 3, 28260: 4, 28259: 3, 28258: 8, 28257: 10, 28256: 0, 28255: 2, 28254: 3, 28253: 0, 28252: 1, 28251: 2, 28250: 2, 28249: 4, 28248: 3, 28247: 5, 28246: 6, 28245: 0, 28244: 0, 28243: 1, 28242: 8, 28241: 10, 28240: 6, 28239: 10, 28238: 10, 28237: 1, 28236: 1, 28235: 2, 28234: 2, 28233: 1, 28232: 1, 28231: 1, 28230: 4, 28229: 2, 28228: 3, 28227: 2, 28226: 2, 28225: 1, 28224: 3, 28223: 1, 28222: 3, 28221: 1, 28220: 3, 28219: 2, 28218: 6, 28217: 1, 28216: 2, 28215: 0, 28214: 3, 28213: 2, 28212: 1, 28211: 3, 28210: 2, 28209: 2, 28208: 5, 28207: 7, 28206: 4, 28205: 4, 28204: 4, 28203: 2, 28202: 1, 28201: 2, 28200: 2, 28199: 1, 28198: 0, 28197: 3, 28196: 12, 28195: 10, 28194: 1, 28193: 3, 28192: 1, 28191: 1, 28190: 6, 28189: 1, 28188: 0, 28187: 4, 28186: 5, 28185: 0, 28184: 5, 28183: 8, 28182: 9, 28181: 12, 28180: 6, 28179: 9, 28178: 11, 28177: 10, 28176: 11, 28175: 8, 28174: 4, 28173: 6, 28172: 3, 28171: 11, 28170: 7, 28169: 1, 28168: 3, 28167: 7, 28166: 4, 28165: 3, 28164: 2, 28163: 5, 28162: 3, 28161: 3, 28160: 4, 28159: 5, 28158: 3, 28157: 3, 28156: 4, 28155: 4, 28154: 5, 28153: 4, 28152: 0, 28151: 12, 28150: 4, 28149: 1, 28148: 1, 28147: 5, 28146: 4, 28145: 2, 28144: 8, 28143: 0, 28142: 3, 28141: 6, 28140: 1, 28139: 4, 28138: 3, 28137: 4, 28136: 7, 28135: 4, 28134: 5, 28133: 5, 28132: 7, 28131: 5, 28130: 5, 28129: 10, 28128: 1, 28127: 5, 28126: 3, 28125: 2, 28124: 3, 28123: 0, 28122: 4, 28121: 2, 28120: 3, 28119: 2, 28118: 5, 28117: 3, 28116: 5, 28115: 5, 28114: 4, 28113: 4, 28112: 4, 28111: 4, 28110: 4, 28109: 13, 28108: 9, 28107: 2, 28106: 2, 28105: 2, 28104: 2, 28103: 2, 28102: 2, 28101: 5, 28100: 3, 28099: 2, 28098: 2, 28097: 4, 28096: 3, 28095: 1, 28094: 3, 28093: 2, 28092: 5, 28091: 2, 28090: 3, 28089: 4, 28088: 4, 28087: 4, 28086: 3, 28085: 3, 28084: 1, 28083: 2, 28082: 1, 28081: 1, 28080: 0, 28079: 4, 28078: 4, 28077: 1, 28076: 1, 28075: 3, 28074: 2, 28073: 1, 28072: 3, 28071: 3, 28070: 2, 28069: 3, 28068: 2, 28067: 2, 28066: 1, 28065: 4, 28064: 2, 28063: 3, 28062: 4, 28061: 3, 28060: 1, 28059: 2, 28058: 4, 28057: 1, 28056: 1, 28055: 3, 28054: 1, 28053: 6, 28052: 6, 28051: 4, 28050: 5, 28049: 2, 28048: 7, 28047: 1, 28046: 4, 28045: 3, 28044: 2, 28043: 2, 28042: 1, 28041: 1, 28040: 0, 28039: 3, 28038: 2, 28037: 5, 28036: 3, 28035: 2, 28034: 2, 28033: 1, 28032: 1, 28031: 2, 28030: 5, 28029: 3, 28028: 3, 28027: 3, 28026: 3, 28025: 3, 28024: 8, 28023: 1, 28022: 6, 28021: 1, 28020: 1, 28019: 10, 28018: 2, 28017: 0, 28016: 2, 28015: 1, 28014: 1, 28013: 2, 28012: 1, 28011: 4, 28010: 15, 28009: 3, 28008: 2, 28007: 12, 28006: 11, 28005: 1, 28004: 3, 28003: 3, 28002: 1, 28001: 2, 28000: 4, 27999: 2, 27998: 1, 27997: 4, 27996: 2, 27995: 2, 27994: 2, 27993: 2, 27992: 6, 27991: 0, 27990: 0, 27989: 3, 27988: 2, 27987: 0, 27986: 2, 27985: 3, 27984: 1, 27983: 2, 27982: 3, 27981: 6, 27980: 1, 27979: 2, 27978: 3, 27977: 3, 27976: 4, 27975: 2, 27974: 5, 27973: 7, 27972: 9, 27971: 5, 27970: 4, 27969: 4, 27968: 2, 27967: 4, 27966: 7, 27965: 2, 27964: 3, 27963: 2, 27962: 1, 27961: 7, 27960: 5, 27959: 7, 27958: 1, 27957: 4, 27956: 1, 27955: 1, 27954: 1, 27953: 2, 27952: 9, 27951: 5, 27950: 1, 27949: 4, 27948: 5, 27947: 4, 27946: 6, 27945: 4, 27944: 2, 27943: 3, 27942: 1, 27941: 4, 27940: 2, 27939: 2, 27938: 3, 27937: 2, 27936: 2, 27935: 1, 27934: 2, 27933: 3, 27932: 2, 27931: 3, 27930: 3, 27929: 3, 27928: 1, 27927: 2, 27926: 2, 27925: 2, 27924: 0, 27923: 3, 27922: 3, 27921: 6, 27920: 8, 27919: 2, 27918: 1, 27917: 1, 27916: 2, 27915: 3, 27914: 1, 27913: 2, 27912: 2, 27911: 2, 27910: 2, 27909: 3, 27908: 3, 27907: 6, 27906: 4, 27905: 1, 27904: 4, 27903: 1, 27902: 2, 27901: 0, 27900: 1, 27899: 3, 27898: 3, 27897: 4, 27896: 0, 27895: 3, 27894: 1, 27893: 2, 27892: 2, 27891: 2, 27890: 3, 27889: 4, 27888: 3, 27887: 2, 27886: 7, 27885: 13, 27884: 2, 27883: 2, 27882: 4, 27881: 2, 27880: 1, 27879: 4, 27878: 2, 27877: 2, 27876: 5, 27875: 6, 27874: 4, 27873: 3, 27872: 2, 27871: 2, 27870: 10, 27869: 3, 27868: 3, 27867: 3, 27866: 3, 27865: 5, 27864: 18, 27863: 1, 27862: 4, 27861: 3, 27860: 5, 27859: 4, 27858: 5, 27857: 2, 27856: 2, 27855: 3, 27854: 2, 27853: 0, 27852: 0, 27851: 1, 27850: 2, 27849: 0, 27848: 4, 27847: 1, 27846: 2, 27845: 2, 27844: 3, 27843: 5, 27842: 5, 27841: 3, 27840: 3, 27839: 2, 27838: 1, 27837: 2, 27836: 2, 27835: 1, 27834: 1, 27833: 5, 27832: 0, 27831: 8, 27830: 1, 27829: 1, 27828: 3, 27827: 6, 27826: 4, 27825: 4, 27824: 1, 27823: 2, 27822: 2, 27821: 6, 27820: 3, 27819: 3, 27818: 2, 27817: 4, 27816: 2, 27815: 3, 27814: 2, 27813: 6, 27812: 3, 27811: 3, 27810: 3, 27809: 2, 27808: 5, 27807: 5, 27806: 1, 27805: 3, 27804: 2, 27803: 1, 27802: 1, 27801: 1, 27800: 1, 27799: 1, 27798: 5, 27797: 2, 27796: 4, 27795: 2, 27794: 1, 27793: 0, 27792: 0, 27791: 2, 27790: 4, 27789: 1, 27788: 2, 27787: 3, 27786: 1, 27785: 1, 27784: 2, 27783: 1, 27782: 1, 27781: 2, 27780: 3, 27779: 4, 27778: 1, 27777: 2, 27776: 2, 27775: 1, 27774: 3, 27773: 2, 27772: 2, 27771: 1, 27770: 2, 27769: 3, 27768: 3, 27767: 7, 27766: 0, 27765: 0, 27764: 4, 27763: 1, 27762: 1, 27761: 1, 27760: 4, 27759: 5, 27758: 4, 27757: 1, 27756: 1, 27755: 4, 27754: 6, 27753: 4, 27752: 7, 27751: 6, 27750: 8, 27749: 1, 27748: 2, 27747: 4, 27746: 1, 27745: 1, 27744: 1, 27743: 2, 27742: 1, 27741: 1, 27740: 1, 27739: 1, 27738: 1, 27737: 0, 27736: 13, 27735: 3, 27734: 6, 27733: 3, 27732: 3, 27731: 3, 27730: 1, 27729: 2, 27728: 1, 27727: 2, 27726: 5, 27725: 4, 27724: 1, 27723: 0, 27722: 4, 27721: 3, 27720: 5, 27719: 4, 27718: 2, 27717: 1, 27716: 1, 27715: 1, 27714: 5, 27713: 7, 27712: 6, 27711: 1, 27710: 2, 27709: 5, 27708: 1, 27707: 7, 27706: 1, 27705: 5, 27704: 4, 27703: 1, 27702: 4, 27701: 4, 27700: 3, 27699: 1, 27698: 2, 27697: 2, 27696: 2, 27695: 2, 27694: 0, 27693: 0, 27692: 2, 27691: 0, 27690: 2, 27689: 3, 27688: 2, 27687: 7, 27686: 8, 27685: 5, 27684: 4, 27683: 4, 27682: 2, 27681: 2, 27680: 3, 27679: 1, 27678: 5, 27677: 11, 27676: 7, 27675: 0, 27674: 1, 27673: 1, 27672: 2, 27671: 1, 27670: 3, 27669: 9, 27668: 1, 27667: 3, 27666: 3, 27665: 1, 27664: 1, 27663: 1, 27662: 5, 27661: 2, 27660: 5, 27659: 2, 27658: 0, 27657: 3, 27656: 3, 27655: 4, 27654: 4, 27653: 1, 27652: 0, 27651: 1, 27650: 1, 27649: 2, 27648: 4, 27647: 2, 27646: 2, 27645: 2, 27644: 1, 27643: 0, 27642: 0, 27641: 2, 27640: 2, 27639: 1, 27638: 3, 27637: 1, 27636: 2, 27635: 5, 27634: 1, 27633: 1, 27632: 0, 27631: 2, 27630: 1, 27629: 3, 27628: 1, 27627: 4, 27626: 1, 27625: 1, 27624: 1, 27623: 1, 27622: 3, 27621: 5, 27620: 9, 27619: 7, 27618: 6, 27617: 6, 27616: 1, 27615: 3, 27614: 2, 27613: 2, 27612: 4, 27611: 2, 27610: 2, 27609: 3, 27608: 1, 27607: 0, 27606: 1, 27605: 0, 27604: 2, 27603: 2, 27602: 3, 27601: 1, 27600: 4, 27599: 2, 27598: 4, 27597: 4, 27596: 3, 27595: 4, 27594: 3, 27593: 11, 27592: 3, 27591: 4, 27590: 2, 27589: 3, 27588: 6, 27587: 5, 27586: 2, 27585: 5, 27584: 1, 27583: 2, 27582: 7, 27581: 3, 27580: 3, 27579: 3, 27578: 2, 27577: 0, 27576: 0, 27575: 0, 27574: 1, 27573: 2, 27572: 4, 27571: 5, 27570: 4, 27569: 3, 27568: 2, 27567: 3, 27566: 4, 27565: 3, 27564: 2, 27563: 5, 27562: 4, 27561: 6, 27560: 2, 27559: 2, 27558: 1, 27557: 3, 27556: 1, 27555: 1, 27554: 3, 27553: 2, 27552: 2, 27551: 2, 27550: 4, 27549: 1, 27548: 3, 27547: 4, 27546: 3, 27545: 1, 27544: 2, 27543: 2, 27542: 2, 27541: 2, 27540: 0, 27539: 2, 27538: 3, 27537: 1, 27536: 4, 27535: 0, 27534: 0, 27533: 1, 27532: 0, 27531: 1, 27530: 0, 27529: 2, 27528: 2, 27527: 0, 27526: 7, 27525: 1, 27524: 0, 27523: 1, 27522: 3, 27521: 2, 27520: 2, 27519: 4, 27518: 1, 27517: 6, 27516: 2, 27515: 3, 27514: 0, 27513: 4, 27512: 4, 27511: 8, 27510: 8, 27509: 5, 27508: 4, 27507: 4, 27506: 1, 27505: 3, 27504: 1, 27503: 7, 27502: 4, 27501: 10, 27500: 7, 27499: 2, 27498: 2, 27497: 5, 27496: 5, 27495: 5, 27494: 5, 27493: 2, 27492: 1, 27491: 4, 27490: 2, 27489: 6, 27488: 5, 27487: 5, 27486: 5, 27485: 1, 27484: 3, 27483: 1, 27482: 1, 27481: 2, 27480: 6, 27479: 7, 27478: 0, 27477: 0, 27476: 2, 27475: 8, 27474: 1, 27473: 5, 27472: 4, 27471: 6, 27470: 4, 27469: 0, 27468: 2, 27467: 5, 27466: 0, 27465: 0, 27464: 2, 27463: 1, 27462: 2, 27461: 3, 27460: 0, 27459: 5, 27458: 4, 27457: 5, 27456: 1, 27455: 3, 27454: 5, 27453: 2, 27452: 3, 27451: 1, 27450: 1, 27449: 3, 27448: 3, 27447: 8, 27446: 9, 27445: 4, 27444: 2, 27443: 6, 27442: 2, 27441: 2, 27440: 3, 27439: 1, 27438: 2, 27437: 3, 27436: 3, 27435: 1, 27434: 3, 27433: 1, 27432: 2, 27431: 3, 27430: 2, 27429: 1, 27428: 2, 27427: 2, 27426: 3, 27425: 0, 27424: 5, 27423: 1, 27422: 4, 27421: 4, 27420: 1, 27419: 3, 27418: 4, 27417: 2, 27416: 7, 27415: 2, 27414: 6, 27413: 2, 27412: 2, 27411: 2, 27410: 5, 27409: 5, 27408: 3, 27407: 3, 27406: 1, 27405: 2, 27404: 6, 27403: 3, 27402: 1, 27401: 2, 27400: 1, 27399: 2, 27398: 0, 27397: 7, 27396: 2, 27395: 1, 27394: 1, 27393: 2, 27392: 1, 27391: 2, 27390: 0, 27389: 3, 27388: 1, 27387: 2, 27386: 4, 27385: 0, 27384: 1, 27383: 3, 27382: 0, 27381: 3, 27380: 3, 27379: 1, 27378: 8, 27377: 1, 27376: 1, 27375: 1, 27374: 3, 27373: 2, 27372: 2, 27371: 1, 27370: 2, 27369: 2, 27368: 2, 27367: 3, 27366: 2, 27365: 5, 27364: 4, 27363: 0, 27362: 4, 27361: 2, 27360: 12, 27359: 4, 27358: 6, 27357: 1, 27356: 4, 27355: 16, 27354: 4, 27353: 3, 27352: 2, 27351: 2, 27350: 2, 27349: 0, 27348: 3, 27347: 1, 27346: 4, 27345: 5, 27344: 3, 27343: 0, 27342: 1, 27341: 2, 27340: 3, 27339: 4, 27338: 4, 27337: 2, 27336: 1, 27335: 7, 27334: 4, 27333: 9, 27332: 11, 27331: 2, 27330: 1, 27329: 1, 27328: 2, 27327: 2, 27326: 4, 27325: 3, 27324: 2, 27323: 2, 27322: 2, 27321: 3, 27320: 6, 27319: 4, 27318: 2, 27317: 2, 27316: 1, 27315: 0, 27314: 10, 27313: 2, 27312: 2, 27311: 2, 27310: 3, 27309: 3, 27308: 5, 27307: 2, 27306: 4, 27305: 2, 27304: 1, 27303: 2, 27302: 2, 27301: 4, 27300: 4, 27299: 3, 27298: 2, 27297: 3, 27296: 1, 27295: 1, 27294: 2, 27293: 3, 27292: 2, 27291: 1, 27290: 2, 27289: 4, 27288: 3, 27287: 3, 27286: 0, 27285: 1, 27284: 4, 27283: 6, 27282: 5, 27281: 1, 27280: 0, 27279: 1, 27278: 0, 27277: 2, 27276: 1, 27275: 0, 27274: 1, 27273: 1, 27272: 2, 27271: 1, 27270: 3, 27269: 4, 27268: 2, 27267: 2, 27266: 1, 27265: 3, 27264: 5, 27263: 1, 27262: 1, 27261: 2, 27260: 4, 27259: 6, 27258: 5, 27257: 2, 27256: 2, 27255: 5, 27254: 10, 27253: 1, 27252: 6, 27251: 6, 27250: 4, 27249: 5, 27248: 3, 27247: 2, 27246: 2, 27245: 3, 27244: 2, 27243: 4, 27242: 3, 27241: 2, 27240: 0, 27239: 4, 27238: 2, 27237: 1, 27236: 5, 27235: 10, 27234: 2, 27233: 1, 27232: 1, 27231: 2, 27230: 4, 27229: 3, 27228: 5, 27227: 7, 27226: 5, 27225: 4, 27224: 0, 27223: 1, 27222: 10, 27221: 5, 27220: 4, 27219: 3, 27218: 2, 27217: 3, 27216: 6, 27215: 7, 27214: 3, 27213: 2, 27212: 1, 27211: 5, 27210: 1, 27209: 4, 27208: 2, 27207: 2, 27206: 1, 27205: 2, 27204: 2, 27203: 2, 27202: 3, 27201: 2, 27200: 2, 27199: 3, 27198: 4, 27197: 2, 27196: 1, 27195: 2, 27194: 2, 27193: 0, 27192: 4, 27191: 4, 27190: 2, 27189: 4, 27188: 2, 27187: 0, 27186: 3, 27185: 5, 27184: 1, 27183: 2, 27182: 3, 27181: 1, 27180: 0, 27179: 4, 27178: 1, 27177: 4, 27176: 6, 27175: 4, 27174: 3, 27173: 2, 27172: 1, 27171: 6, 27170: 5, 27169: 7, 27168: 3, 27167: 4, 27166: 4, 27165: 2, 27164: 3, 27163: 6, 27162: 3, 27161: 2, 27160: 0, 27159: 3, 27158: 2, 27157: 2, 27156: 5, 27155: 3, 27154: 2, 27153: 2, 27152: 2, 27151: 2, 27150: 3, 27149: 4, 27148: 3, 27147: 4, 27146: 3, 27145: 6, 27144: 5, 27143: 2, 27142: 0, 27141: 2, 27140: 1, 27139: 2, 27138: 3, 27137: 2, 27136: 8, 27135: 10, 27134: 7, 27133: 6, 27132: 8, 27131: 2, 27130: 3, 27129: 6, 27128: 2, 27127: 1, 27126: 2, 27125: 4, 27124: 4, 27123: 3, 27122: 3, 27121: 1, 27120: 3, 27119: 1, 27118: 4, 27117: 2, 27116: 3, 27115: 0, 27114: 4, 27113: 1, 27112: 1, 27111: 1, 27110: 1, 27109: 3, 27108: 4, 27107: 1, 27106: 1, 27105: 4, 27104: 2, 27103: 4, 27102: 1, 27101: 4, 27100: 7, 27099: 6, 27098: 5, 27097: 6, 27096: 2, 27095: 1, 27094: 2, 27093: 4, 27092: 1, 27091: 0, 27090: 1, 27089: 2, 27088: 1, 27087: 1, 27086: 1, 27085: 1, 27084: 1, 27083: 3, 27082: 3, 27081: 3, 27080: 2, 27079: 7, 27078: 5, 27077: 7, 27076: 5, 27075: 4, 27074: 9, 27073: 4, 27072: 6, 27071: 0, 27070: 3, 27069: 2, 27068: 3, 27067: 5, 27066: 1, 27065: 4, 27064: 5, 27063: 1, 27062: 4, 27061: 3, 27060: 5, 27059: 2, 27058: 1, 27057: 12, 27056: 2, 27055: 5, 27054: 3, 27053: 2, 27052: 3, 27051: 2, 27050: 2, 27049: 4, 27048: 5, 27047: 3, 27046: 5, 27045: 3, 27044: 4, 27043: 4, 27042: 1, 27041: 3, 27040: 5, 27039: 4, 27038: 1, 27037: 2, 27036: 2, 27035: 1, 27034: 2, 27033: 1, 27032: 2, 27031: 2, 27030: 2, 27029: 5, 27028: 3, 27027: 5, 27026: 3, 27025: 1, 27024: 3, 27023: 4, 27022: 6, 27021: 1, 27020: 2, 27019: 1, 27018: 5, 27017: 5, 27016: 3, 27015: 1, 27014: 4, 27013: 3, 27012: 2, 27011: 1, 27010: 2, 27009: 6, 27008: 3, 27007: 4, 27006: 10, 27005: 2, 27004: 1, 27003: 1, 27002: 1, 27001: 9, 27000: 2, 26999: 3, 26998: 4, 26997: 1, 26996: 3, 26995: 2, 26994: 1, 26993: 3, 26992: 2, 26991: 5, 26990: 3, 26989: 3, 26988: 5, 26987: 2, 26986: 9, 26985: 3, 26984: 5, 26983: 2, 26982: 3, 26981: 2, 26980: 4, 26979: 3, 26978: 2, 26977: 5, 26976: 5, 26975: 3, 26974: 6, 26973: 5, 26972: 3, 26971: 2, 26970: 1, 26969: 5, 26968: 5, 26967: 3, 26966: 2, 26965: 0, 26964: 6, 26963: 3, 26962: 6, 26961: 1, 26960: 1, 26959: 2, 26958: 3, 26957: 2, 26956: 4, 26955: 2, 26954: 1, 26953: 1, 26952: 3, 26951: 0, 26950: 1, 26949: 5, 26948: 5, 26947: 5, 26946: 4, 26945: 6, 26944: 4, 26943: 3, 26942: 0, 26941: 4, 26940: 3, 26939: 5, 26938: 1, 26937: 1, 26936: 0, 26935: 3, 26934: 2, 26933: 7, 26932: 1, 26931: 3, 26930: 1, 26929: 4, 26928: 2, 26927: 3, 26926: 6, 26925: 4, 26924: 5, 26923: 6, 26922: 5, 26921: 1, 26920: 0, 26919: 2, 26918: 2, 26917: 0, 26916: 1, 26915: 2, 26914: 0, 26913: 1, 26912: 3, 26911: 3, 26910: 1, 26909: 1, 26908: 1, 26907: 2, 26906: 0, 26905: 4, 26904: 6, 26903: 5, 26902: 1, 26901: 5, 26900: 4, 26899: 4, 26898: 2, 26897: 3, 26896: 0, 26895: 5, 26894: 5, 26893: 4, 26892: 7, 26891: 7, 26890: 1, 26889: 5, 26888: 1, 26887: 2, 26886: 9, 26885: 7, 26884: 6, 26883: 4, 26882: 4, 26881: 1, 26880: 2, 26879: 6, 26878: 5, 26877: 5, 26876: 5, 26875: 5, 26874: 1, 26873: 1, 26872: 2, 26871: 1, 26870: 0, 26869: 4, 26868: 4, 26867: 4, 26866: 3, 26865: 2, 26864: 2, 26863: 5, 26862: 0, 26861: 3, 26860: 3, 26859: 1, 26858: 7, 26857: 6, 26856: 6, 26855: 9, 26854: 0, 26853: 3, 26852: 4, 26851: 2, 26850: 1, 26849: 1, 26848: 1, 26847: 2, 26846: 1, 26845: 15, 26844: 4, 26843: 3, 26842: 1, 26841: 4, 26840: 4, 26839: 5, 26838: 1, 26837: 2, 26836: 2, 26835: 1, 26834: 3, 26833: 4, 26832: 5, 26831: 2, 26830: 2, 26829: 2, 26828: 2, 26827: 1, 26826: 1, 26825: 2, 26824: 1, 26823: 2, 26822: 2, 26821: 8, 26820: 2, 26819: 1, 26818: 5, 26817: 9, 26816: 4, 26815: 2, 26814: 3, 26813: 3, 26812: 2, 26811: 2, 26810: 4, 26809: 3, 26808: 4, 26807: 2, 26806: 3, 26805: 4, 26804: 4, 26803: 6, 26802: 3, 26801: 1, 26800: 0, 26799: 3, 26798: 1, 26797: 2, 26796: 3, 26795: 4, 26794: 0, 26793: 2, 26792: 2, 26791: 4, 26790: 5, 26789: 4, 26788: 1, 26787: 0, 26786: 4, 26785: 1, 26784: 1, 26783: 1, 26782: 1, 26781: 0, 26780: 1, 26779: 4, 26778: 2, 26777: 2, 26776: 3, 26775: 4, 26774: 3, 26773: 1, 26772: 3, 26771: 6, 26770: 0, 26769: 1, 26768: 13, 26767: 4, 26766: 2, 26765: 1, 26764: 0, 26763: 3, 26762: 4, 26761: 4, 26760: 7, 26759: 5, 26758: 1, 26757: 2, 26756: 3, 26755: 3, 26754: 1, 26753: 1, 26752: 3, 26751: 0, 26750: 3, 26749: 1, 26748: 2, 26747: 2, 26746: 3, 26745: 2, 26744: 1, 26743: 2, 26742: 4, 26741: 2, 26740: 4, 26739: 1, 26738: 2, 26737: 4, 26736: 1, 26735: 4, 26734: 5, 26733: 3, 26732: 5, 26731: 2, 26730: 5, 26729: 5, 26728: 5, 26727: 6, 26726: 1, 26725: 5, 26724: 6, 26723: 5, 26722: 6, 26721: 5, 26720: 1, 26719: 3, 26718: 7, 26717: 7, 26716: 4, 26715: 3, 26714: 3, 26713: 3, 26712: 13, 26711: 11, 26710: 9, 26709: 5, 26708: 3, 26707: 8, 26706: 3, 26705: 10, 26704: 14, 26703: 15, 26702: 10, 26701: 17, 26700: 12, 26699: 11, 26698: 10, 26697: 2, 26696: 3, 26695: 4, 26694: 5, 26693: 12, 26692: 4, 26691: 2, 26690: 3, 26689: 2, 26688: 3, 26687: 4, 26686: 6, 26685: 3, 26684: 3, 26683: 4, 26682: 2, 26681: 3, 26680: 2, 26679: 2, 26678: 2, 26677: 1, 26676: 2, 26675: 2, 26674: 12, 26673: 2, 26672: 5, 26671: 1, 26670: 2, 26669: 5, 26668: 4, 26667: 6, 26666: 1, 26665: 8, 26664: 2, 26663: 3, 26662: 3, 26661: 1, 26660: 1, 26659: 3, 26658: 17, 26657: 3, 26656: 0, 26655: 5, 26654: 2, 26653: 1, 26652: 1, 26651: 1, 26650: 1, 26649: 2, 26648: 2, 26647: 2, 26646: 3, 26645: 3, 26644: 3, 26643: 2, 26642: 2, 26641: 1, 26640: 0, 26639: 1, 26638: 2, 26637: 3, 26636: 1, 26635: 2, 26634: 2, 26633: 2, 26632: 0, 26631: 6, 26630: 1, 26629: 3, 26628: 5, 26627: 1, 26626: 3, 26625: 4, 26624: 1, 26623: 1, 26622: 1, 26621: 5, 26620: 0, 26619: 1, 26618: 4, 26617: 4, 26616: 2, 26615: 4, 26614: 3, 26613: 1, 26612: 1, 26611: 4, 26610: 2, 26609: 2, 26608: 2, 26607: 1, 26606: 2, 26605: 3, 26604: 3, 26603: 5, 26602: 5, 26601: 8, 26600: 12, 26599: 4, 26598: 4, 26597: 4, 26596: 4, 26595: 2, 26594: 4, 26593: 2, 26592: 2, 26591: 2, 26590: 6, 26589: 1, 26588: 2, 26587: 5, 26586: 3, 26585: 2, 26584: 6, 26583: 3, 26582: 3, 26581: 1, 26580: 3, 26579: 2, 26578: 8, 26577: 8, 26576: 3, 26575: 6, 26574: 7, 26573: 6, 26572: 4, 26571: 0, 26570: 14, 26569: 1, 26568: 1, 26567: 5, 26566: 2, 26565: 3, 26564: 0, 26563: 2, 26562: 2, 26561: 4, 26560: 3, 26559: 2, 26558: 3, 26557: 0, 26556: 2, 26555: 2, 26554: 2, 26553: 2, 26552: 1, 26551: 6, 26550: 2, 26549: 1, 26548: 2, 26547: 0, 26546: 0, 26545: 1, 26544: 3, 26543: 3, 26542: 3, 26541: 3, 26540: 0, 26539: 2, 26538: 3, 26537: 1, 26536: 0, 26535: 1, 26534: 4, 26533: 3, 26532: 0, 26531: 2, 26530: 3, 26529: 3, 26528: 1, 26527: 2, 26526: 1, 26525: 2, 26524: 4, 26523: 3, 26522: 2, 26521: 4, 26520: 3, 26519: 0, 26518: 2, 26517: 1, 26516: 4, 26515: 3, 26514: 2, 26513: 0, 26512: 5, 26511: 4, 26510: 2, 26509: 3, 26508: 4, 26507: 2, 26506: 2, 26505: 4, 26504: 3, 26503: 5, 26502: 2, 26501: 5, 26500: 1, 26499: 2, 26498: 1, 26497: 4, 26496: 3, 26495: 4, 26494: 3, 26493: 4, 26492: 1, 26491: 2, 26490: 1, 26489: 8, 26488: 1, 26487: 2, 26486: 5, 26485: 5, 26484: 6, 26483: 8, 26482: 3, 26481: 0, 26480: 2, 26479: 2, 26478: 4, 26477: 1, 26476: 1, 26475: 1, 26474: 0, 26473: 1, 26472: 1, 26471: 3, 26470: 3, 26469: 4, 26468: 1, 26467: 4, 26466: 2, 26465: 3, 26464: 2, 26463: 4, 26462: 3, 26461: 5, 26460: 3, 26459: 1, 26458: 5, 26457: 0, 26456: 0, 26455: 5, 26454: 4, 26453: 1, 26452: 2, 26451: 5, 26450: 4, 26449: 7, 26448: 6, 26447: 2, 26446: 3, 26445: 2, 26444: 1, 26443: 2, 26442: 3, 26441: 0, 26440: 1, 26439: 1, 26438: 2, 26437: 1, 26436: 0, 26435: 1, 26434: 3, 26433: 1, 26432: 0, 26431: 2, 26430: 8, 26429: 5, 26428: 1, 26427: 1, 26426: 1, 26425: 1, 26424: 4, 26423: 2, 26422: 1, 26421: 3, 26420: 2, 26419: 4, 26418: 0, 26417: 3, 26416: 4, 26415: 3, 26414: 2, 26413: 1, 26412: 1, 26411: 3, 26410: 3, 26409: 2, 26408: 3, 26407: 3, 26406: 3, 26405: 1, 26404: 5, 26403: 3, 26402: 1, 26401: 2, 26400: 2, 26399: 3, 26398: 1, 26397: 3, 26396: 1, 26395: 2, 26394: 2, 26393: 1, 26392: 3, 26391: 3, 26390: 6, 26389: 4, 26388: 4, 26387: 5, 26386: 5, 26385: 1, 26384: 0, 26383: 1, 26382: 9, 26381: 2, 26380: 5, 26379: 2, 26378: 1, 26377: 2, 26376: 8, 26375: 4, 26374: 7, 26373: 9, 26372: 7, 26371: 2, 26370: 1, 26369: 1, 26368: 3, 26367: 2, 26366: 4, 26365: 1, 26364: 2, 26363: 2, 26362: 3, 26361: 3, 26360: 3, 26359: 2, 26358: 5, 26357: 4, 26356: 4, 26355: 5, 26354: 1, 26353: 6, 26352: 2, 26351: 2, 26350: 2, 26349: 3, 26348: 2, 26347: 7, 26346: 12, 26345: 7, 26344: 5, 26343: 6, 26342: 3, 26341: 4, 26340: 5, 26339: 3, 26338: 2, 26337: 1, 26336: 2, 26335: 3, 26334: 2, 26333: 1, 26332: 1, 26331: 2, 26330: 4, 26329: 4, 26328: 5, 26327: 1, 26326: 2, 26325: 3, 26324: 2, 26323: 5, 26322: 4, 26321: 0, 26320: 1, 26319: 2, 26318: 3, 26317: 1, 26316: 3, 26315: 3, 26314: 1, 26313: 3, 26312: 5, 26311: 2, 26310: 4, 26309: 3, 26308: 1, 26307: 1, 26306: 2, 26305: 5, 26304: 1, 26303: 0, 26302: 7, 26301: 3, 26300: 3, 26299: 2, 26298: 5, 26297: 3, 26296: 2, 26295: 2, 26294: 3, 26293: 1, 26292: 3, 26291: 7, 26290: 7, 26289: 1, 26288: 4, 26287: 2, 26286: 7, 26285: 2, 26284: 2, 26283: 1, 26282: 2, 26281: 16, 26280: 5, 26279: 1, 26278: 5, 26277: 2, 26276: 2, 26275: 3, 26274: 3, 26273: 1, 26272: 4, 26271: 2, 26270: 2, 26269: 1, 26268: 2, 26267: 0, 26266: 3, 26265: 1, 26264: 1, 26263: 5, 26262: 5, 26261: 2, 26260: 9, 26259: 7, 26258: 3, 26257: 2, 26256: 4, 26255: 4, 26254: 4, 26253: 7, 26252: 9, 26251: 2, 26250: 5, 26249: 3, 26248: 0, 26247: 4, 26246: 3, 26245: 5, 26244: 6, 26243: 4, 26242: 2, 26241: 0, 26240: 2, 26239: 12, 26238: 8, 26237: 4, 26236: 3, 26235: 6, 26234: 6, 26233: 5, 26232: 6, 26231: 7, 26230: 4, 26229: 16, 26228: 8, 26227: 5, 26226: 7, 26225: 7, 26224: 1, 26223: 9, 26222: 5, 26221: 2, 26220: 0, 26219: 2, 26218: 1, 26217: 9, 26216: 3, 26215: 1, 26214: 1, 26213: 10, 26212: 9, 26211: 8, 26210: 4, 26209: 2, 26208: 1, 26207: 0, 26206: 4, 26205: 4, 26204: 7, 26203: 11, 26202: 9, 26201: 6, 26200: 6, 26199: 9, 26198: 9, 26197: 4, 26196: 3, 26195: 2, 26194: 2, 26193: 4, 26192: 6, 26191: 6, 26190: 3, 26189: 1, 26188: 15, 26187: 13, 26186: 11, 26185: 9, 26184: 10, 26183: 9, 26182: 14, 26181: 11, 26180: 0, 26179: 3, 26178: 1, 26177: 0, 26176: 3, 26175: 2, 26174: 3, 26173: 6, 26172: 5, 26171: 3, 26170: 8, 26169: 5, 26168: 1, 26167: 3, 26166: 2, 26165: 3, 26164: 1, 26163: 7, 26162: 2, 26161: 5, 26160: 1, 26159: 6, 26158: 4, 26157: 4, 26156: 6, 26155: 8, 26154: 2, 26153: 1, 26152: 0, 26151: 0, 26150: 2, 26149: 0, 26148: 2, 26147: 2, 26146: 1, 26145: 2, 26144: 0, 26143: 1, 26142: 9, 26141: 3, 26140: 6, 26139: 2, 26138: 1, 26137: 1, 26136: 7, 26135: 1, 26134: 7, 26133: 1, 26132: 1, 26131: 7, 26130: 2, 26129: 4, 26128: 3, 26127: 6, 26126: 3, 26125: 3, 26124: 2, 26123: 1, 26122: 3, 26121: 4, 26120: 1, 26119: 2, 26118: 1, 26117: 1, 26116: 3, 26115: 3, 26114: 2, 26113: 4, 26112: 6, 26111: 9, 26110: 4, 26109: 7, 26108: 5, 26107: 1, 26106: 4, 26105: 2, 26104: 1, 26103: 4, 26102: 1, 26101: 1, 26100: 3, 26099: 3, 26098: 3, 26097: 2, 26096: 2, 26095: 2, 26094: 4, 26093: 1, 26092: 3, 26091: 1, 26090: 1, 26089: 2, 26088: 0, 26087: 3, 26086: 1, 26085: 4, 26084: 1, 26083: 1, 26082: 4, 26081: 8, 26080: 9, 26079: 5, 26078: 5, 26077: 6, 26076: 5, 26075: 7, 26074: 5, 26073: 6, 26072: 4, 26071: 9, 26070: 2, 26069: 3, 26068: 6, 26067: 1, 26066: 0, 26065: 1, 26064: 4, 26063: 1, 26062: 4, 26061: 2, 26060: 9, 26059: 2, 26058: 2, 26057: 5, 26056: 1, 26055: 6, 26054: 2, 26053: 3, 26052: 2, 26051: 1, 26050: 0, 26049: 2, 26048: 1, 26047: 7, 26046: 6, 26045: 9, 26044: 8, 26043: 9, 26042: 4, 26041: 7, 26040: 5, 26039: 6, 26038: 7, 26037: 3, 26036: 3, 26035: 5, 26034: 0, 26033: 5, 26032: 1, 26031: 2, 26030: 1, 26029: 3, 26028: 12, 26027: 2, 26026: 2, 26025: 6, 26024: 4, 26023: 2, 26022: 6, 26021: 5, 26020: 3, 26019: 4, 26018: 3, 26017: 5, 26016: 9, 26015: 2, 26014: 4, 26013: 2, 26012: 1, 26011: 5, 26010: 4, 26009: 2, 26008: 1, 26007: 1, 26006: 1, 26005: 0, 26004: 1, 26003: 7, 26002: 7, 26001: 1, 26000: 0, 25999: 1, 25998: 3, 25997: 2, 25996: 7, 25995: 1, 25994: 0, 25993: 4, 25992: 1, 25991: 2, 25990: 3, 25989: 3, 25988: 0, 25987: 2, 25986: 4, 25985: 0, 25984: 4, 25983: 1, 25982: 2, 25981: 4, 25980: 0, 25979: 0, 25978: 3, 25977: 3, 25976: 0, 25975: 0, 25974: 2, 25973: 2, 25972: 1, 25971: 1, 25970: 4, 25969: 2, 25968: 0, 25967: 3, 25966: 1, 25965: 2, 25964: 1, 25963: 3, 25962: 2, 25961: 1, 25960: 2, 25959: 2, 25958: 2, 25957: 3, 25956: 1, 25955: 2, 25954: 3, 25953: 6, 25952: 0, 25951: 1, 25950: 4, 25949: 8, 25948: 2, 25947: 2, 25946: 2, 25945: 2, 25944: 1, 25943: 5, 25942: 4, 25941: 7, 25940: 2, 25939: 1, 25938: 3, 25937: 5, 25936: 1, 25935: 1, 25934: 22, 25933: 4, 25932: 0, 25931: 1, 25930: 9, 25929: 0, 25928: 1, 25927: 2, 25926: 3, 25925: 4, 25924: 2, 25923: 4, 25922: 2, 25921: 1, 25920: 5, 25919: 0, 25918: 0, 25917: 2, 25916: 5, 25915: 0, 25914: 2, 25913: 1, 25912: 2, 25911: 2, 25910: 0, 25909: 1, 25908: 4, 25907: 3, 25906: 2, 25905: 1, 25904: 0, 25903: 2, 25902: 2, 25901: 1, 25900: 1, 25899: 1, 25898: 3, 25897: 2, 25896: 6, 25895: 2, 25894: 2, 25893: 1, 25892: 1, 25891: 3, 25890: 1, 25889: 0, 25888: 0, 25887: 2, 25886: 6, 25885: 8, 25884: 2, 25883: 1, 25882: 2, 25881: 5, 25880: 3, 25879: 2, 25878: 0, 25877: 2, 25876: 1, 25875: 1, 25874: 2, 25873: 1, 25872: 3, 25871: 2, 25870: 0, 25869: 1, 25868: 3, 25867: 2, 25866: 2, 25865: 3, 25864: 2, 25863: 0, 25862: 2, 25861: 2, 25860: 2, 25859: 2, 25858: 1, 25857: 0, 25856: 1, 25855: 4, 25854: 2, 25853: 2, 25852: 1, 25851: 1, 25850: 1, 25849: 1, 25848: 5, 25847: 3, 25846: 1, 25845: 3, 25844: 4, 25843: 2, 25842: 2, 25841: 2, 25840: 5, 25839: 2, 25838: 2, 25837: 1, 25836: 0, 25835: 1, 25834: 10, 25833: 2, 25832: 1, 25831: 1, 25830: 2, 25829: 0, 25828: 1, 25827: 2, 25826: 2, 25825: 2, 25824: 1, 25823: 2, 25822: 3, 25821: 2, 25820: 2, 25819: 5, 25818: 4, 25817: 1, 25816: 2, 25815: 6, 25814: 1, 25813: 2, 25812: 1, 25811: 1, 25810: 2, 25809: 2, 25808: 1, 25807: 3, 25806: 0, 25805: 0, 25804: 0, 25803: 1, 25802: 2, 25801: 3, 25800: 8, 25799: 3, 25798: 1, 25797: 1, 25796: 1, 25795: 2, 25794: 2, 25793: 1, 25792: 4, 25791: 3, 25790: 1, 25789: 2, 25788: 1, 25787: 1, 25786: 0, 25785: 0, 25784: 0, 25783: 1, 25782: 2, 25781: 0, 25780: 1, 25779: 1, 25778: 2, 25777: 1, 25776: 2, 25775: 2, 25774: 1, 25773: 1, 25772: 1, 25771: 0, 25770: 4, 25769: 4, 25768: 0, 25767: 0, 25766: 0, 25765: 3, 25764: 7, 25763: 3, 25762: 2, 25761: 4, 25760: 1, 25759: 7, 25758: 6, 25757: 4, 25756: 1, 25755: 2, 25754: 0, 25753: 3, 25752: 5, 25751: 2, 25750: 6, 25749: 2, 25748: 3, 25747: 3, 25746: 3, 25745: 1, 25744: 1, 25743: 2, 25742: 0, 25741: 1, 25740: 2, 25739: 1, 25738: 1, 25737: 2, 25736: 4, 25735: 4, 25734: 1, 25733: 2, 25732: 9, 25731: 5, 25730: 0, 25729: 2, 25728: 2, 25727: 5, 25726: 4, 25725: 1, 25724: 8, 25723: 1, 25722: 0, 25721: 1, 25720: 0, 25719: 4, 25718: 3, 25717: 5, 25716: 4, 25715: 1, 25714: 3, 25713: 2, 25712: 3, 25711: 3, 25710: 6, 25709: 0, 25708: 1, 25707: 2, 25706: 3, 25705: 3, 25704: 2, 25703: 1, 25702: 3, 25701: 2, 25700: 3, 25699: 1, 25698: 4, 25697: 4, 25696: 0, 25695: 0, 25694: 5, 25693: 0, 25692: 4, 25691: 3, 25690: 4, 25689: 3, 25688: 3, 25687: 3, 25686: 4, 25685: 2, 25684: 2, 25683: 6, 25682: 5, 25681: 0, 25680: 0, 25679: 9, 25678: 2, 25677: 1, 25676: 7, 25675: 1, 25674: 5, 25673: 3, 25672: 3, 25671: 1, 25670: 1, 25669: 0, 25668: 7, 25667: 1, 25666: 1, 25665: 2, 25664: 2, 25663: 0, 25662: 1, 25661: 3, 25660: 5, 25659: 1, 25658: 2, 25657: 4, 25656: 3, 25655: 6, 25654: 0, 25653: 1, 25652: 1, 25651: 1, 25650: 2, 25649: 1, 25648: 1, 25647: 1, 25646: 1, 25645: 2, 25644: 1, 25643: 1, 25642: 1, 25641: 0, 25640: 4, 25639: 1, 25638: 3, 25637: 1, 25636: 0, 25635: 3, 25634: 2, 25633: 5, 25632: 1, 25631: 1, 25630: 2, 25629: 2, 25628: 1, 25627: 1, 25626: 1, 25625: 2, 25624: 3, 25623: 3, 25622: 2, 25621: 0, 25620: 2, 25619: 1, 25618: 2, 25617: 4, 25616: 2, 25615: 0, 25614: 1, 25613: 0, 25612: 1, 25611: 7, 25610: 2, 25609: 4, 25608: 4, 25607: 3, 25606: 2, 25605: 2, 25604: 5, 25603: 7, 25602: 1, 25601: 3, 25600: 4, 25599: 1, 25598: 4, 25597: 4, 25596: 4, 25595: 4, 25594: 8, 25593: 1, 25592: 2, 25591: 6, 25590: 2, 25589: 2, 25588: 1, 25587: 1, 25586: 1, 25585: 1, 25584: 2, 25583: 2, 25582: 1, 25581: 0, 25580: 2, 25579: 1, 25578: 4, 25577: 1, 25576: 1, 25575: 1, 25574: 3, 25573: 5, 25572: 4, 25571: 2, 25570: 0, 25569: 2, 25568: 5, 25567: 0, 25566: 4, 25565: 3, 25564: 1, 25563: 1, 25562: 4, 25561: 1, 25560: 4, 25559: 3, 25558: 6, 25557: 6, 25556: 2, 25555: 2, 25554: 3, 25553: 3, 25552: 0, 25551: 2, 25550: 0, 25549: 6, 25548: 7, 25547: 5, 25546: 2, 25545: 2, 25544: 2, 25543: 2, 25542: 2, 25541: 2, 25540: 2, 25539: 2, 25538: 7, 25537: 1, 25536: 0, 25535: 1, 25534: 1, 25533: 4, 25532: 2, 25531: 1, 25530: 4, 25529: 2, 25528: 4, 25527: 4, 25526: 2, 25525: 2, 25524: 1, 25523: 1, 25522: 1, 25521: 3, 25520: 2, 25519: 7, 25518: 5, 25517: 5, 25516: 1, 25515: 0, 25514: 6, 25513: 4, 25512: 1, 25511: 2, 25510: 0, 25509: 4, 25508: 4, 25507: 6, 25506: 5, 25505: 1, 25504: 2, 25503: 2, 25502: 1, 25501: 10, 25500: 3, 25499: 1, 25498: 14, 25497: 3, 25496: 1, 25495: 3, 25494: 1, 25493: 3, 25492: 7, 25491: 2, 25490: 3, 25489: 2, 25488: 1, 25487: 2, 25486: 1, 25485: 1, 25484: 1, 25483: 0, 25482: 2, 25481: 1, 25480: 5, 25479: 2, 25478: 4, 25477: 2, 25476: 0, 25475: 3, 25474: 4, 25473: 1, 25472: 2, 25471: 2, 25470: 4, 25469: 5, 25468: 2, 25467: 1, 25466: 2, 25465: 0, 25464: 4, 25463: 2, 25462: 0, 25461: 1, 25460: 6, 25459: 1, 25458: 2, 25457: 6, 25456: 0, 25455: 1, 25454: 1, 25453: 1, 25452: 0, 25451: 2, 25450: 3, 25449: 2, 25448: 1, 25447: 1, 25446: 0, 25445: 7, 25444: 4, 25443: 4, 25442: 3, 25441: 4, 25440: 2, 25439: 6, 25438: 0, 25437: 4, 25436: 2, 25435: 3, 25434: 4, 25433: 1, 25432: 5, 25431: 1, 25430: 2, 25429: 4, 25428: 1, 25427: 2, 25426: 0, 25425: 7, 25424: 6, 25423: 4, 25422: 3, 25421: 4, 25420: 2, 25419: 1, 25418: 12, 25417: 1, 25416: 2, 25415: 1, 25414: 2, 25413: 1, 25412: 1, 25411: 3, 25410: 2, 25409: 0, 25408: 2, 25407: 4, 25406: 1, 25405: 2, 25404: 2, 25403: 0, 25402: 1, 25401: 2, 25400: 3, 25399: 0, 25398: 3, 25397: 2, 25396: 3, 25395: 1, 25394: 3, 25393: 3, 25392: 2, 25391: 2, 25390: 2, 25389: 4, 25388: 1, 25387: 12, 25386: 1, 25385: 2, 25384: 2, 25383: 3, 25382: 3, 25381: 3, 25380: 5, 25379: 3, 25378: 5, 25377: 3, 25376: 2, 25375: 4, 25374: 5, 25373: 1, 25372: 4, 25371: 1, 25370: 4, 25369: 2, 25368: 1, 25367: 1, 25366: 5, 25365: 2, 25364: 2, 25363: 0, 25362: 5, 25361: 1, 25360: 3, 25359: 0, 25358: 2, 25357: 1, 25356: 2, 25355: 2, 25354: 5, 25353: 1, 25352: 1, 25351: 2, 25350: 1, 25349: 4, 25348: 2, 25347: 5, 25346: 1, 25345: 1, 25344: 1, 25343: 3, 25342: 2, 25341: 5, 25340: 5, 25339: 3, 25338: 2, 25337: 0, 25336: 1, 25335: 8, 25334: 4, 25333: 5, 25332: 3, 25331: 0, 25330: 3, 25329: 1, 25328: 2, 25327: 3, 25326: 1, 25325: 1, 25324: 1, 25323: 1, 25322: 0, 25321: 1, 25320: 3, 25319: 1, 25318: 5, 25317: 2, 25316: 3, 25315: 1, 25314: 1, 25313: 3, 25312: 2, 25311: 3, 25310: 2, 25309: 1, 25308: 0, 25307: 1, 25306: 1, 25305: 5, 25304: 2, 25303: 0, 25302: 9, 25301: 4, 25300: 0, 25299: 1, 25298: 1, 25297: 2, 25296: 4, 25295: 2, 25294: 1, 25293: 0, 25292: 1, 25291: 2, 25290: 1, 25289: 5, 25288: 3, 25287: 4, 25286: 2, 25285: 2, 25284: 1, 25283: 3, 25282: 2, 25281: 2, 25280: 0, 25279: 2, 25278: 1, 25277: 1, 25276: 2, 25275: 2, 25274: 0, 25273: 2, 25272: 1, 25271: 3, 25270: 1, 25269: 2, 25268: 6, 25267: 2, 25266: 3, 25265: 1, 25264: 1, 25263: 1, 25262: 2, 25261: 1, 25260: 2, 25259: 2, 25258: 2, 25257: 2, 25256: 1, 25255: 1, 25254: 2, 25253: 0, 25252: 1, 25251: 0, 25250: 0, 25249: 6, 25248: 1, 25247: 0, 25246: 0, 25245: 1, 25244: 1, 25243: 2, 25242: 1, 25241: 1, 25240: 1, 25239: 2, 25238: 2, 25237: 1, 25236: 3, 25235: 2, 25234: 2, 25233: 1, 25232: 3, 25231: 5, 25230: 7, 25229: 5, 25228: 1, 25227: 2, 25226: 1, 25225: 2, 25224: 3, 25223: 3, 25222: 0, 25221: 0, 25220: 1, 25219: 0, 25218: 2, 25217: 3, 25216: 2, 25215: 1, 25214: 2, 25213: 3, 25212: 3, 25211: 2, 25210: 3, 25209: 0, 25208: 1, 25207: 9, 25206: 14, 25205: 1, 25204: 3, 25203: 2, 25202: 1, 25201: 4, 25200: 4, 25199: 3, 25198: 4, 25197: 1, 25196: 2, 25195: 2, 25194: 2, 25193: 2, 25192: 0, 25191: 1, 25190: 1, 25189: 1, 25188: 2, 25187: 1, 25186: 7, 25185: 1, 25184: 2, 25183: 4, 25182: 3, 25181: 3, 25180: 4, 25179: 2, 25178: 24, 25177: 10, 25176: 1, 25175: 2, 25174: 0, 25173: 3, 25172: 1, 25171: 3, 25170: 1, 25169: 6, 25168: 2, 25167: 2, 25166: 5, 25165: 1, 25164: 1, 25163: 0, 25162: 1, 25161: 5, 25160: 3, 25159: 4, 25158: 11, 25157: 2, 25156: 4, 25155: 4, 25154: 2, 25153: 2, 25152: 1, 25151: 4, 25150: 0, 25149: 3, 25148: 2, 25147: 2, 25146: 1, 25145: 4, 25144: 4, 25143: 13, 25142: 2, 25141: 3, 25140: 5, 25139: 3, 25138: 3, 25137: 12, 25136: 7, 25135: 2, 25134: 3, 25133: 4, 25132: 0, 25131: 5, 25130: 0, 25129: 4, 25128: 1, 25127: 1, 25126: 4, 25125: 2, 25124: 2, 25123: 6, 25122: 6, 25121: 3, 25120: 4, 25119: 3, 25118: 5, 25117: 2, 25116: 5, 25115: 2, 25114: 1, 25113: 1, 25112: 1, 25111: 3, 25110: 2, 25109: 3, 25108: 2, 25107: 0, 25106: 0, 25105: 1, 25104: 5, 25103: 2, 25102: 1, 25101: 4, 25100: 3, 25099: 3, 25098: 2, 25097: 4, 25096: 2, 25095: 1, 25094: 8, 25093: 4, 25092: 2, 25091: 3, 25090: 2, 25089: 3, 25088: 1, 25087: 3, 25086: 6, 25085: 2, 25084: 1, 25083: 4, 25082: 1, 25081: 4, 25080: 2, 25079: 2, 25078: 4, 25077: 5, 25076: 5, 25075: 5, 25074: 6, 25073: 7, 25072: 5, 25071: 9, 25070: 4, 25069: 5, 25068: 3, 25067: 2, 25066: 0, 25065: 15, 25064: 3, 25063: 3, 25062: 2, 25061: 1, 25060: 3, 25059: 6, 25058: 2, 25057: 1, 25056: 3, 25055: 4, 25054: 4, 25053: 4, 25052: 9, 25051: 3, 25050: 3, 25049: 0, 25048: 1, 25047: 1, 25046: 7, 25045: 4, 25044: 1, 25043: 1, 25042: 5, 25041: 5, 25040: 2, 25039: 6, 25038: 5, 25037: 6, 25036: 5, 25035: 1, 25034: 1, 25033: 2, 25032: 4, 25031: 1, 25030: 2, 25029: 12, 25028: 7, 25027: 13, 25026: 13, 25025: 0, 25024: 0, 25023: 3, 25022: 1, 25021: 2, 25020: 2, 25019: 5, 25018: 4, 25017: 5, 25016: 2, 25015: 1, 25014: 0, 25013: 3, 25012: 2, 25011: 4, 25010: 1, 25009: 2, 25008: 2, 25007: 2, 25006: 4, 25005: 0, 25004: 5, 25003: 1, 25002: 0, 25001: 2, 25000: 2, 24999: 3, 24998: 1, 24997: 1, 24996: 0, 24995: 5, 24994: 4, 24993: 2, 24992: 2, 24991: 0, 24990: 4, 24989: 2, 24988: 2, 24987: 7, 24986: 4, 24985: 5, 24984: 1, 24983: 1, 24982: 3, 24981: 4, 24980: 4, 24979: 3, 24978: 2, 24977: 3, 24976: 3, 24975: 3, 24974: 4, 24973: 2, 24972: 5, 24971: 1, 24970: 1, 24969: 3, 24968: 3, 24967: 5, 24966: 5, 24965: 5, 24964: 1, 24963: 3, 24962: 2, 24961: 1, 24960: 1, 24959: 2, 24958: 3, 24957: 1, 24956: 3, 24955: 0, 24954: 1, 24953: 2, 24952: 2, 24951: 1, 24950: 6, 24949: 0, 24948: 6, 24947: 3, 24946: 6, 24945: 3, 24944: 1, 24943: 5, 24942: 1, 24941: 1, 24940: 3, 24939: 2, 24938: 0, 24937: 5, 24936: 0, 24935: 2, 24934: 0, 24933: 1, 24932: 1, 24931: 6, 24930: 3, 24929: 1, 24928: 4, 24927: 6, 24926: 4, 24925: 2, 24924: 2, 24923: 3, 24922: 2, 24921: 6, 24920: 1, 24919: 2, 24918: 1, 24917: 3, 24916: 3, 24915: 4, 24914: 2, 24913: 1, 24912: 3, 24911: 2, 24910: 4, 24909: 3, 24908: 5, 24907: 4, 24906: 3, 24905: 2, 24904: 1, 24903: 2, 24902: 4, 24901: 2, 24900: 2, 24899: 2, 24898: 4, 24897: 1, 24896: 2, 24895: 1, 24894: 3, 24893: 5, 24892: 4, 24891: 2, 24890: 3, 24889: 2, 24888: 2, 24887: 0, 24886: 0, 24885: 5, 24884: 2, 24883: 2, 24882: 1, 24881: 4, 24880: 7, 24879: 9, 24878: 4, 24877: 1, 24876: 13, 24875: 4, 24874: 3, 24873: 0, 24872: 1, 24871: 9, 24870: 1, 24869: 4, 24868: 3, 24867: 2, 24866: 1, 24865: 1, 24864: 2, 24863: 2, 24862: 2, 24861: 2, 24860: 0, 24859: 1, 24858: 3, 24857: 2, 24856: 3, 24855: 2, 24854: 1, 24853: 3, 24852: 9, 24851: 4, 24850: 2, 24849: 2, 24848: 3, 24847: 2, 24846: 0, 24845: 4, 24844: 3, 24843: 0, 24842: 2, 24841: 2, 24840: 2, 24839: 2, 24838: 4, 24837: 1, 24836: 1, 24835: 2, 24834: 2, 24833: 0, 24832: 4, 24831: 5, 24830: 2, 24829: 7, 24828: 8, 24827: 2, 24826: 7, 24825: 1, 24824: 1, 24823: 1, 24822: 3, 24821: 1, 24820: 2, 24819: 1, 24818: 2, 24817: 2, 24816: 2, 24815: 0, 24814: 2, 24813: 3, 24812: 2, 24811: 6, 24810: 4, 24809: 4, 24808: 4, 24807: 1, 24806: 4, 24805: 2, 24804: 6, 24803: 4, 24802: 5, 24801: 7, 24800: 0, 24799: 5, 24798: 3, 24797: 2, 24796: 2, 24795: 3, 24794: 2, 24793: 0, 24792: 1, 24791: 4, 24790: 4, 24789: 6, 24788: 1, 24787: 8, 24786: 4, 24785: 1, 24784: 1, 24783: 0, 24782: 4, 24781: 3, 24780: 2, 24779: 1, 24778: 3, 24777: 3, 24776: 2, 24775: 3, 24774: 4, 24773: 1, 24772: 1, 24771: 0, 24770: 3, 24769: 6, 24768: 5, 24767: 1, 24766: 8, 24765: 6, 24764: 1, 24763: 4, 24762: 0, 24761: 17, 24760: 5, 24759: 7, 24758: 12, 24757: 1, 24756: 2, 24755: 3, 24754: 0, 24753: 1, 24752: 4, 24751: 2, 24750: 1, 24749: 2, 24748: 2, 24747: 4, 24746: 4, 24745: 3, 24744: 2, 24743: 4, 24742: 1, 24741: 1, 24740: 4, 24739: 2, 24738: 1, 24737: 4, 24736: 1, 24735: 3, 24734: 0, 24733: 3, 24732: 4, 24731: 6, 24730: 1, 24729: 4, 24728: 2, 24727: 0, 24726: 2, 24725: 2, 24724: 0, 24723: 10, 24722: 10, 24721: 1, 24720: 3, 24719: 3, 24718: 5, 24717: 1, 24716: 1, 24715: 1, 24714: 2, 24713: 5, 24712: 4, 24711: 1, 24710: 1, 24709: 2, 24708: 1, 24707: 3, 24706: 1, 24705: 0, 24704: 0, 24703: 1, 24702: 2, 24701: 1, 24700: 3, 24699: 2, 24698: 4, 24697: 0, 24696: 3, 24695: 0, 24694: 2, 24693: 1, 24692: 5, 24691: 1, 24690: 1, 24689: 2, 24688: 1, 24687: 3, 24686: 1, 24685: 3, 24684: 1, 24683: 4, 24682: 2, 24681: 2, 24680: 4, 24679: 2, 24678: 0, 24677: 1, 24676: 2, 24675: 2, 24674: 6, 24673: 1, 24672: 2, 24671: 2, 24670: 6, 24669: 0, 24668: 3, 24667: 5, 24666: 2, 24665: 3, 24664: 1, 24663: 1, 24662: 2, 24661: 1, 24660: 1, 24659: 1, 24658: 3, 24657: 1, 24656: 1, 24655: 3, 24654: 6, 24653: 4, 24652: 2, 24651: 4, 24650: 5, 24649: 3, 24648: 1, 24647: 0, 24646: 5, 24645: 10, 24644: 4, 24643: 5, 24642: 2, 24641: 1, 24640: 0, 24639: 11, 24638: 8, 24637: 8, 24636: 6, 24635: 11, 24634: 8, 24633: 2, 24632: 2, 24631: 2, 24630: 1, 24629: 1, 24628: 7, 24627: 2, 24626: 5, 24625: 0, 24624: 9, 24623: 5, 24622: 4, 24621: 4, 24620: 1, 24619: 7, 24618: 4, 24617: 9, 24616: 4, 24615: 3, 24614: 6, 24613: 3, 24612: 2, 24611: 3, 24610: 4, 24609: 3, 24608: 2, 24607: 2, 24606: 6, 24605: 3, 24604: 0, 24603: 2, 24602: 1, 24601: 3, 24600: 1, 24599: 7, 24598: 2, 24597: 4, 24596: 7, 24595: 5, 24594: 1, 24593: 5, 24592: 7, 24591: 0, 24590: 4, 24589: 2, 24588: 1, 24587: 1, 24586: 0, 24585: 2, 24584: 1, 24583: 4, 24582: 0, 24581: 2, 24580: 2, 24579: 3, 24578: 1, 24577: 2, 24576: 1, 24575: 3, 24574: 7, 24573: 6, 24572: 4, 24571: 1, 24570: 4, 24569: 2, 24568: 3, 24567: 0, 24566: 2, 24565: 1, 24564: 2, 24563: 0, 24562: 5, 24561: 3, 24560: 1, 24559: 3, 24558: 1, 24557: 3, 24556: 3, 24555: 1, 24554: 1, 24553: 3, 24552: 3, 24551: 1, 24550: 0, 24549: 5, 24548: 1, 24547: 2, 24546: 0, 24545: 1, 24544: 0, 24543: 3, 24542: 1, 24541: 2, 24540: 1, 24539: 3, 24538: 7, 24537: 1, 24536: 4, 24535: 11, 24534: 16, 24533: 10, 24532: 1, 24531: 2, 24530: 4, 24529: 3, 24528: 1, 24527: 3, 24526: 3, 24525: 5, 24524: 4, 24523: 4, 24522: 5, 24521: 1, 24520: 4, 24519: 7, 24518: 1, 24517: 2, 24516: 3, 24515: 0, 24514: 5, 24513: 3, 24512: 3, 24511: 3, 24510: 2, 24509: 5, 24508: 3, 24507: 1, 24506: 2, 24505: 3, 24504: 2, 24503: 2, 24502: 6, 24501: 4, 24500: 2, 24499: 5, 24498: 2, 24497: 1, 24496: 1, 24495: 1, 24494: 3, 24493: 5, 24492: 1, 24491: 1, 24490: 2, 24489: 3, 24488: 3, 24487: 2, 24486: 2, 24485: 5, 24484: 9, 24483: 8, 24482: 2, 24481: 3, 24480: 6, 24479: 1, 24478: 8, 24477: 4, 24476: 4, 24475: 4, 24474: 1, 24473: 2, 24472: 0, 24471: 1, 24470: 2, 24469: 0, 24468: 1, 24467: 1, 24466: 9, 24465: 1, 24464: 2, 24463: 2, 24462: 4, 24461: 2, 24460: 2, 24459: 9, 24458: 3, 24457: 2, 24456: 4, 24455: 4, 24454: 3, 24453: 0, 24452: 2, 24451: 2, 24450: 4, 24449: 2, 24448: 3, 24447: 3, 24446: 0, 24445: 2, 24444: 4, 24443: 2, 24442: 4, 24441: 3, 24440: 6, 24439: 6, 24438: 4, 24437: 1, 24436: 2, 24435: 4, 24434: 2, 24433: 5, 24432: 4, 24431: 1, 24430: 1, 24429: 0, 24428: 1, 24427: 1, 24426: 1, 24425: 4, 24424: 1, 24423: 4, 24422: 1, 24421: 1, 24420: 2, 24419: 1, 24418: 5, 24417: 2, 24416: 4, 24415: 0, 24414: 3, 24413: 7, 24412: 0, 24411: 4, 24410: 8, 24409: 7, 24408: 7, 24407: 0, 24406: 0, 24405: 7, 24404: 5, 24403: 6, 24402: 6, 24401: 4, 24400: 3, 24399: 5, 24398: 3, 24397: 5, 24396: 1, 24395: 1, 24394: 2, 24393: 4, 24392: 8, 24391: 9, 24390: 2, 24389: 4, 24388: 1, 24387: 3, 24386: 3, 24385: 4, 24384: 2, 24383: 2, 24382: 3, 24381: 1, 24380: 1, 24379: 2, 24378: 0, 24377: 2, 24376: 4, 24375: 4, 24374: 1, 24373: 1, 24372: 2, 24371: 3, 24370: 3, 24369: 3, 24368: 3, 24367: 3, 24366: 1, 24365: 3, 24364: 4, 24363: 1, 24362: 3, 24361: 2, 24360: 5, 24359: 0, 24358: 1, 24357: 10, 24356: 2, 24355: 4, 24354: 3, 24353: 4, 24352: 0, 24351: 1, 24350: 1, 24349: 1, 24348: 3, 24347: 2, 24346: 2, 24345: 0, 24344: 4, 24343: 6, 24342: 2, 24341: 0, 24340: 3, 24339: 2, 24338: 9, 24337: 7, 24336: 15, 24335: 6, 24334: 7, 24333: 0, 24332: 2, 24331: 2, 24330: 1, 24329: 2, 24328: 6, 24327: 2, 24326: 3, 24325: 3, 24324: 1, 24323: 7, 24322: 14, 24321: 4, 24320: 0, 24319: 1, 24318: 14, 24317: 1, 24316: 6, 24315: 3, 24314: 0, 24313: 1, 24312: 3, 24311: 2, 24310: 2, 24309: 3, 24308: 3, 24307: 3, 24306: 2, 24305: 2, 24304: 1, 24303: 1, 24302: 6, 24301: 3, 24300: 3, 24299: 2, 24298: 1, 24297: 1, 24296: 3, 24295: 2, 24294: 3, 24293: 3, 24292: 7, 24291: 4, 24290: 5, 24289: 5, 24288: 1, 24287: 3, 24286: 3, 24285: 3, 24284: 3, 24283: 2, 24282: 0, 24281: 2, 24280: 1, 24279: 1, 24278: 0, 24277: 1, 24276: 3, 24275: 1, 24274: 0, 24273: 5, 24272: 2, 24271: 2, 24270: 1, 24269: 0, 24268: 5, 24267: 8, 24266: 11, 24265: 2, 24264: 3, 24263: 5, 24262: 5, 24261: 4, 24260: 1, 24259: 3, 24258: 0, 24257: 2, 24256: 2, 24255: 2, 24254: 1, 24253: 2, 24252: 1, 24251: 1, 24250: 1, 24249: 1, 24248: 1, 24247: 4, 24246: 4, 24245: 1, 24244: 1, 24243: 5, 24242: 2, 24241: 3, 24240: 3, 24239: 3, 24238: 5, 24237: 2, 24236: 2, 24235: 2, 24234: 4, 24233: 2, 24232: 3, 24231: 1, 24230: 4, 24229: 2, 24228: 3, 24227: 2, 24226: 3, 24225: 2, 24224: 4, 24223: 4, 24222: 0, 24221: 6, 24220: 2, 24219: 1, 24218: 1, 24217: 0, 24216: 4, 24215: 1, 24214: 9, 24213: 3, 24212: 1, 24211: 7, 24210: 1, 24209: 3, 24208: 1, 24207: 3, 24206: 3, 24205: 4, 24204: 2, 24203: 2, 24202: 3, 24201: 9, 24200: 5, 24199: 12, 24198: 10, 24197: 1, 24196: 2, 24195: 1, 24194: 9, 24193: 2, 24192: 9, 24191: 1, 24190: 4, 24189: 2, 24188: 2, 24187: 1, 24186: 2, 24185: 5, 24184: 1, 24183: 2, 24182: 2, 24181: 2, 24180: 4, 24179: 1, 24178: 1, 24177: 4, 24176: 8, 24175: 3, 24174: 3, 24173: 3, 24172: 2, 24171: 3, 24170: 1, 24169: 1, 24168: 1, 24167: 8, 24166: 7, 24165: 6, 24164: 0, 24163: 3, 24162: 4, 24161: 2, 24160: 1, 24159: 1, 24158: 4, 24157: 1, 24156: 1, 24155: 5, 24154: 2, 24153: 2, 24152: 1, 24151: 2, 24150: 2, 24149: 5, 24148: 1, 24147: 3, 24146: 3, 24145: 2, 24144: 1, 24143: 4, 24142: 1, 24141: 2, 24140: 5, 24139: 6, 24138: 1, 24137: 3, 24136: 0, 24135: 1, 24134: 3, 24133: 3, 24132: 1, 24131: 2, 24130: 2, 24129: 5, 24128: 5, 24127: 5, 24126: 0, 24125: 2, 24124: 2, 24123: 2, 24122: 4, 24121: 3, 24120: 4, 24119: 1, 24118: 2, 24117: 5, 24116: 0, 24115: 8, 24114: 1, 24113: 5, 24112: 9, 24111: 0, 24110: 1, 24109: 2, 24108: 4, 24107: 3, 24106: 1, 24105: 2, 24104: 3, 24103: 7, 24102: 4, 24101: 4, 24100: 2, 24099: 1, 24098: 0, 24097: 2, 24096: 2, 24095: 10, 24094: 4, 24093: 7, 24092: 4, 24091: 3, 24090: 3, 24089: 9, 24088: 1, 24087: 3, 24086: 1, 24085: 2, 24084: 2, 24083: 2, 24082: 0, 24081: 2, 24080: 3, 24079: 4, 24078: 7, 24077: 4, 24076: 7, 24075: 11, 24074: 2, 24073: 3, 24072: 0, 24071: 2, 24070: 2, 24069: 3, 24068: 2, 24067: 0, 24066: 3, 24065: 1, 24064: 5, 24063: 3, 24062: 1, 24061: 1, 24060: 2, 24059: 3, 24058: 4, 24057: 0, 24056: 0, 24055: 3, 24054: 4, 24053: 3, 24052: 2, 24051: 1, 24050: 1, 24049: 4, 24048: 1, 24047: 3, 24046: 6, 24045: 6, 24044: 7, 24043: 1, 24042: 1, 24041: 1, 24040: 3, 24039: 3, 24038: 1, 24037: 1, 24036: 1, 24035: 3, 24034: 1, 24033: 7, 24032: 5, 24031: 4, 24030: 3, 24029: 2, 24028: 4, 24027: 9, 24026: 8, 24025: 1, 24024: 0, 24023: 2, 24022: 2, 24021: 4, 24020: 4, 24019: 4, 24018: 2, 24017: 1, 24016: 1, 24015: 2, 24014: 2, 24013: 1, 24012: 2, 24011: 3, 24010: 5, 24009: 6, 24008: 1, 24007: 1, 24006: 3, 24005: 5, 24004: 3, 24003: 5, 24002: 6, 24001: 6, 24000: 4, 23999: 2, 23998: 4, 23997: 0, 23996: 3, 23995: 0, 23994: 1, 23993: 5, 23992: 12, 23991: 9, 23990: 3, 23989: 13, 23988: 10, 23987: 0, 23986: 0, 23985: 4, 23984: 1, 23983: 1, 23982: 7, 23981: 4, 23980: 5, 23979: 6, 23978: 1, 23977: 3, 23976: 3, 23975: 4, 23974: 7, 23973: 3, 23972: 3, 23971: 2, 23970: 5, 23969: 3, 23968: 9, 23967: 3, 23966: 6, 23965: 6, 23964: 0, 23963: 1, 23962: 1, 23961: 0, 23960: 3, 23959: 3, 23958: 8, 23957: 3, 23956: 6, 23955: 2, 23954: 3, 23953: 4, 23952: 5, 23951: 2, 23950: 5, 23949: 3, 23948: 1, 23947: 3, 23946: 3, 23945: 4, 23944: 5, 23943: 4, 23942: 4, 23941: 4, 23940: 5, 23939: 1, 23938: 2, 23937: 8, 23936: 2, 23935: 12, 23934: 9, 23933: 9, 23932: 7, 23931: 10, 23930: 3, 23929: 2, 23928: 0, 23927: 3, 23926: 2, 23925: 4, 23924: 4, 23923: 1, 23922: 3, 23921: 1, 23920: 1, 23919: 3, 23918: 4, 23917: 5, 23916: 1, 23915: 3, 23914: 3, 23913: 1, 23912: 3, 23911: 4, 23910: 3, 23909: 2, 23908: 4, 23907: 3, 23906: 2, 23905: 5, 23904: 4, 23903: 1, 23902: 4, 23901: 2, 23900: 7, 23899: 4, 23898: 3, 23897: 3, 23896: 4, 23895: 11, 23894: 6, 23893: 5, 23892: 4, 23891: 3, 23890: 5, 23889: 4, 23888: 5, 23887: 3, 23886: 3, 23885: 0, 23884: 3, 23883: 3, 23882: 6, 23881: 3, 23880: 4, 23879: 4, 23878: 7, 23877: 3, 23876: 4, 23875: 3, 23874: 3, 23873: 8, 23872: 0, 23871: 4, 23870: 2, 23869: 2, 23868: 1, 23867: 3, 23866: 5, 23865: 1, 23864: 3, 23863: 1, 23862: 2, 23861: 7, 23860: 5, 23859: 1, 23858: 3, 23857: 2, 23856: 7, 23855: 5, 23854: 2, 23853: 2, 23852: 1, 23851: 3, 23850: 4, 23849: 1, 23848: 4, 23847: 3, 23846: 1, 23845: 1, 23844: 2, 23843: 1, 23842: 2, 23841: 4, 23840: 2, 23839: 2, 23838: 3, 23837: 4, 23836: 2, 23835: 3, 23834: 8, 23833: 5, 23832: 3, 23831: 6, 23830: 6, 23829: 3, 23828: 3, 23827: 5, 23826: 1, 23825: 10, 23824: 3, 23823: 1, 23822: 1, 23821: 4, 23820: 4, 23819: 2, 23818: 3, 23817: 1, 23816: 2, 23815: 0, 23814: 2, 23813: 2, 23812: 3, 23811: 13, 23810: 4, 23809: 6, 23808: 7, 23807: 11, 23806: 6, 23805: 5, 23804: 5, 23803: 3, 23802: 5, 23801: 4, 23800: 3, 23799: 4, 23798: 0, 23797: 2, 23796: 1, 23795: 6, 23794: 3, 23793: 3, 23792: 2, 23791: 3, 23790: 0, 23789: 0, 23788: 1, 23787: 3, 23786: 2, 23785: 2, 23784: 2, 23783: 1, 23782: 3, 23781: 1, 23780: 2, 23779: 3, 23778: 1, 23777: 2, 23776: 0, 23775: 2, 23774: 3, 23773: 6, 23772: 2, 23771: 0, 23770: 0, 23769: 1, 23768: 1, 23767: 3, 23766: 5, 23765: 3, 23764: 3, 23763: 4, 23762: 7, 23761: 5, 23760: 0, 23759: 1, 23758: 2, 23757: 3, 23756: 2, 23755: 2, 23754: 4, 23753: 4, 23752: 6, 23751: 5, 23750: 4, 23749: 7, 23748: 3, 23747: 4, 23746: 8, 23745: 1, 23744: 5, 23743: 1, 23742: 3, 23741: 5, 23740: 2, 23739: 2, 23738: 4, 23737: 10, 23736: 10, 23735: 1, 23734: 1, 23733: 2, 23732: 9, 23731: 3, 23730: 4, 23729: 1, 23728: 0, 23727: 3, 23726: 5, 23725: 5, 23724: 5, 23723: 6, 23722: 3, 23721: 3, 23720: 1, 23719: 5, 23718: 5, 23717: 3, 23716: 2, 23715: 1, 23714: 2, 23713: 10, 23712: 9, 23711: 3, 23710: 4, 23709: 4, 23708: 6, 23707: 5, 23706: 4, 23705: 0, 23704: 6, 23703: 9, 23702: 7, 23701: 7, 23700: 4, 23699: 6, 23698: 6, 23697: 4, 23696: 5, 23695: 5, 23694: 1, 23693: 1, 23692: 1, 23691: 1, 23690: 0, 23689: 3, 23688: 0, 23687: 1, 23686: 2, 23685: 3, 23684: 4, 23683: 2, 23682: 3, 23681: 6, 23680: 2, 23679: 2, 23678: 3, 23677: 3, 23676: 3, 23675: 2, 23674: 2, 23673: 6, 23672: 8, 23671: 3, 23670: 2, 23669: 4, 23668: 1, 23667: 2, 23666: 1, 23665: 3, 23664: 1, 23663: 4, 23662: 4, 23661: 4, 23660: 2, 23659: 5, 23658: 3, 23657: 1, 23656: 1, 23655: 2, 23654: 6, 23653: 4, 23652: 0, 23651: 2, 23650: 4, 23649: 3, 23648: 1, 23647: 1, 23646: 3, 23645: 3, 23644: 3, 23643: 3, 23642: 0, 23641: 2, 23640: 0, 23639: 2, 23638: 2, 23637: 4, 23636: 4, 23635: 2, 23634: 1, 23633: 1, 23632: 3, 23631: 5, 23630: 1, 23629: 4, 23628: 2, 23627: 3, 23626: 7, 23625: 4, 23624: 5, 23623: 3, 23622: 6, 23621: 1, 23620: 2, 23619: 2, 23618: 3, 23617: 1, 23616: 2, 23615: 4, 23614: 1, 23613: 2, 23612: 13, 23611: 12, 23610: 14, 23609: 17, 23608: 16, 23607: 12, 23606: 15, 23605: 15, 23604: 15, 23603: 15, 23602: 10, 23601: 18, 23600: 4, 23599: 3, 23598: 2, 23597: 3, 23596: 3, 23595: 8, 23594: 5, 23593: 8, 23592: 4, 23591: 3, 23590: 2, 23589: 4, 23588: 14, 23587: 12, 23586: 14, 23585: 19, 23584: 14, 23583: 16, 23582: 14, 23581: 2, 23580: 2, 23579: 1, 23578: 2, 23577: 4, 23576: 3, 23575: 0, 23574: 5, 23573: 6, 23572: 4, 23571: 2, 23570: 1, 23569: 2, 23568: 3, 23567: 4, 23566: 6, 23565: 5, 23564: 3, 23563: 5, 23562: 3, 23561: 5, 23560: 4, 23559: 3, 23558: 5, 23557: 4, 23556: 2, 23555: 1, 23554: 3, 23553: 0, 23552: 10, 23551: 16, 23550: 9, 23549: 1, 23548: 7, 23547: 2, 23546: 2, 23545: 5, 23544: 1, 23543: 2, 23542: 6, 23541: 4, 23540: 6, 23539: 4, 23538: 2, 23537: 1, 23536: 2, 23535: 6, 23534: 4, 23533: 2, 23532: 3, 23531: 2, 23530: 0, 23529: 2, 23528: 1, 23527: 2, 23526: 2, 23525: 1, 23524: 5, 23523: 1, 23522: 3, 23521: 0, 23520: 10, 23519: 2, 23518: 5, 23517: 5, 23516: 2, 23515: 2, 23514: 4, 23513: 3, 23512: 1, 23511: 1, 23510: 4, 23509: 4, 23508: 3, 23507: 6, 23506: 1, 23505: 10, 23504: 1, 23503: 1, 23502: 1, 23501: 3, 23500: 0, 23499: 2, 23498: 3, 23497: 3, 23496: 5, 23495: 1, 23494: 0, 23493: 5, 23492: 18, 23491: 5, 23490: 0, 23489: 4, 23488: 8, 23487: 3, 23486: 3, 23485: 1, 23484: 1, 23483: 1, 23482: 4, 23481: 8, 23480: 1, 23479: 0, 23478: 3, 23477: 2, 23476: 2, 23475: 9, 23474: 4, 23473: 1, 23472: 1, 23471: 5, 23470: 2, 23469: 1, 23468: 0, 23467: 1, 23466: 1, 23465: 3, 23464: 2, 23463: 3, 23462: 0, 23461: 1, 23460: 1, 23459: 1, 23458: 2, 23457: 4, 23456: 2, 23455: 1, 23454: 1, 23453: 4, 23452: 2, 23451: 2, 23450: 3, 23449: 3, 23448: 2, 23447: 5, 23446: 3, 23445: 2, 23444: 1, 23443: 11, 23442: 0, 23441: 2, 23440: 2, 23439: 1, 23438: 0, 23437: 11, 23436: 8, 23435: 1, 23434: 4, 23433: 5, 23432: 3, 23431: 1, 23430: 4, 23429: 3, 23428: 1, 23427: 1, 23426: 0, 23425: 0, 23424: 1, 23423: 2, 23422: 6, 23421: 1, 23420: 1, 23419: 4, 23418: 3, 23417: 1, 23416: 3, 23415: 1, 23414: 6, 23413: 2, 23412: 0, 23411: 8, 23410: 0, 23409: 1, 23408: 3, 23407: 2, 23406: 1, 23405: 2, 23404: 4, 23403: 4, 23402: 2, 23401: 3, 23400: 11, 23399: 15, 23398: 1, 23397: 2, 23396: 2, 23395: 1, 23394: 1, 23393: 1, 23392: 6, 23391: 1, 23390: 3, 23389: 1, 23388: 9, 23387: 9, 23386: 7, 23385: 5, 23384: 5, 23383: 3, 23382: 1, 23381: 1, 23380: 6, 23379: 3, 23378: 1, 23377: 2, 23376: 2, 23375: 1, 23374: 2, 23373: 2, 23372: 7, 23371: 3, 23370: 2, 23369: 5, 23368: 2, 23367: 4, 23366: 4, 23365: 1, 23364: 3, 23363: 3, 23362: 7, 23361: 2, 23360: 5, 23359: 3, 23358: 2, 23357: 0, 23356: 1, 23355: 2, 23354: 3, 23353: 2, 23352: 5, 23351: 2, 23350: 3, 23349: 2, 23348: 2, 23347: 1, 23346: 1, 23345: 1, 23344: 2, 23343: 3, 23342: 3, 23341: 2, 23340: 1, 23339: 2, 23338: 6, 23337: 1, 23336: 0, 23335: 1, 23334: 4, 23333: 1, 23332: 1, 23331: 1, 23330: 7, 23329: 2, 23328: 1, 23327: 1, 23326: 1, 23325: 1, 23324: 2, 23323: 1, 23322: 1, 23321: 0, 23320: 3, 23319: 3, 23318: 1, 23317: 4, 23316: 6, 23315: 1, 23314: 2, 23313: 1, 23312: 2, 23311: 0, 23310: 2, 23309: 4, 23308: 2, 23307: 3, 23306: 3, 23305: 1, 23304: 2, 23303: 6, 23302: 5, 23301: 2, 23300: 2, 23299: 0, 23298: 2, 23297: 6, 23296: 7, 23295: 1, 23294: 5, 23293: 0, 23292: 1, 23291: 2, 23290: 6, 23289: 1, 23288: 2, 23287: 2, 23286: 5, 23285: 2, 23284: 2, 23283: 3, 23282: 2, 23281: 7, 23280: 1, 23279: 9, 23278: 6, 23277: 1, 23276: 2, 23275: 2, 23274: 2, 23273: 5, 23272: 1, 23271: 2, 23270: 5, 23269: 4, 23268: 2, 23267: 1, 23266: 4, 23265: 3, 23264: 3, 23263: 0, 23262: 2, 23261: 3, 23260: 1, 23259: 6, 23258: 2, 23257: 2, 23256: 1, 23255: 9, 23254: 2, 23253: 10, 23252: 1, 23251: 4, 23250: 1, 23249: 2, 23248: 1, 23247: 1, 23246: 1, 23245: 6, 23244: 22, 23243: 4, 23242: 5, 23241: 4, 23240: 4, 23239: 2, 23238: 0, 23237: 2, 23236: 2, 23235: 7, 23234: 10, 23233: 2, 23232: 1, 23231: 2, 23230: 6, 23229: 5, 23228: 4, 23227: 5, 23226: 6, 23225: 3, 23224: 4, 23223: 0, 23222: 9, 23221: 1, 23220: 1, 23219: 1, 23218: 4, 23217: 2, 23216: 0, 23215: 8, 23214: 2, 23213: 2, 23212: 7, 23211: 1, 23210: 0, 23209: 3, 23208: 5, 23207: 2, 23206: 4, 23205: 3, 23204: 2, 23203: 6, 23202: 5, 23201: 3, 23200: 9, 23199: 1, 23198: 3, 23197: 5, 23196: 4, 23195: 0, 23194: 5, 23193: 1, 23192: 11, 23191: 5, 23190: 4, 23189: 2, 23188: 0, 23187: 5, 23186: 2, 23185: 2, 23184: 1, 23183: 0, 23182: 5, 23181: 1, 23180: 3, 23179: 4, 23178: 0, 23177: 0, 23176: 3, 23175: 2, 23174: 2, 23173: 2, 23172: 5, 23171: 0, 23170: 13, 23169: 4, 23168: 1, 23167: 4, 23166: 9, 23165: 9, 23164: 8, 23163: 2, 23162: 4, 23161: 3, 23160: 2, 23159: 2, 23158: 0, 23157: 3, 23156: 0, 23155: 4, 23154: 4, 23153: 1, 23152: 2, 23151: 1, 23150: 1, 23149: 0, 23148: 0, 23147: 1, 23146: 0, 23145: 2, 23144: 2, 23143: 0, 23142: 4, 23141: 2, 23140: 0, 23139: 5, 23138: 1, 23137: 0, 23136: 3, 23135: 0, 23134: 3, 23133: 1, 23132: 2, 23131: 6, 23130: 0, 23129: 1, 23128: 1, 23127: 1, 23126: 1, 23125: 10, 23124: 4, 23123: 2, 23122: 1, 23121: 3, 23120: 2, 23119: 1, 23118: 0, 23117: 4, 23116: 2, 23115: 1, 23114: 4, 23113: 1, 23112: 4, 23111: 4, 23110: 2, 23109: 1, 23108: 4, 23107: 2, 23106: 1, 23105: 1, 23104: 4, 23103: 5, 23102: 2, 23101: 4, 23100: 2, 23099: 1, 23098: 2, 23097: 6, 23096: 2, 23095: 0, 23094: 2, 23093: 6, 23092: 5, 23091: 0, 23090: 0, 23089: 1, 23088: 3, 23087: 0, 23086: 0, 23085: 3, 23084: 2, 23083: 1, 23082: 2, 23081: 1, 23080: 1, 23079: 2, 23078: 4, 23077: 1, 23076: 0, 23075: 2, 23074: 6, 23073: 0, 23072: 2, 23071: 1, 23070: 0, 23069: 2, 23068: 2, 23067: 2, 23066: 3, 23065: 5, 23064: 0, 23063: 0, 23062: 3, 23061: 3, 23060: 1, 23059: 1, 23058: 2, 23057: 1, 23056: 3, 23055: 4, 23054: 4, 23053: 3, 23052: 1, 23051: 2, 23050: 2, 23049: 4, 23048: 0, 23047: 1, 23046: 2, 23045: 3, 23044: 4, 23043: 5, 23042: 0, 23041: 8, 23040: 0, 23039: 0, 23038: 2, 23037: 1, 23036: 7, 23035: 0, 23034: 1, 23033: 2, 23032: 4, 23031: 1, 23030: 2, 23029: 2, 23028: 2, 23027: 1, 23026: 1, 23025: 2, 23024: 1, 23023: 0, 23022: 0, 23021: 4, 23020: 12, 23019: 3, 23018: 5, 23017: 3, 23016: 13, 23015: 3, 23014: 5, 23013: 8, 23012: 5, 23011: 15, 23010: 13, 23009: 17, 23008: 3, 23007: 1, 23006: 1, 23005: 1, 23004: 1, 23003: 14, 23002: 6, 23001: 2, 23000: 3, 22999: 0, 22998: 4, 22997: 6, 22996: 4, 22995: 2, 22994: 0, 22993: 2, 22992: 1, 22991: 2, 22990: 2, 22989: 2, 22988: 2, 22987: 3, 22986: 2, 22985: 5, 22984: 8, 22983: 1, 22982: 4, 22981: 1, 22980: 2, 22979: 5, 22978: 23, 22977: 1, 22976: 4, 22975: 4, 22974: 4, 22973: 3, 22972: 4, 22971: 2, 22970: 2, 22969: 4, 22968: 3, 22967: 4, 22966: 3, 22965: 2, 22964: 1, 22963: 0, 22962: 4, 22961: 2, 22960: 4, 22959: 5, 22958: 6, 22957: 8, 22956: 5, 22955: 1, 22954: 2, 22953: 2, 22952: 1, 22951: 2, 22950: 2, 22949: 0, 22948: 3, 22947: 1, 22946: 3, 22945: 3, 22944: 1, 22943: 1, 22942: 3, 22941: 3, 22940: 7, 22939: 4, 22938: 3, 22937: 3, 22936: 3, 22935: 7, 22934: 4, 22933: 0, 22932: 1, 22931: 1, 22930: 1, 22929: 8, 22928: 6, 22927: 3, 22926: 2, 22925: 3, 22924: 4, 22923: 1, 22922: 2, 22921: 3, 22920: 0, 22919: 3, 22918: 8, 22917: 0, 22916: 3, 22915: 1, 22914: 8, 22913: 2, 22912: 4, 22911: 19, 22910: 3, 22909: 0, 22908: 1, 22907: 4, 22906: 2, 22905: 2, 22904: 1, 22903: 4, 22902: 6, 22901: 7, 22900: 6, 22899: 0, 22898: 2, 22897: 1, 22896: 2, 22895: 1, 22894: 0, 22893: 0, 22892: 11, 22891: 3, 22890: 2, 22889: 2, 22888: 3, 22887: 4, 22886: 5, 22885: 9, 22884: 2, 22883: 2, 22882: 2, 22881: 5, 22880: 3, 22879: 1, 22878: 5, 22877: 3, 22876: 3, 22875: 0, 22874: 3, 22873: 5, 22872: 3, 22871: 1, 22870: 3, 22869: 1, 22868: 0, 22867: 1, 22866: 3, 22865: 6, 22864: 6, 22863: 2, 22862: 1, 22861: 1, 22860: 0, 22859: 0, 22858: 3, 22857: 1, 22856: 0, 22855: 3, 22854: 2, 22853: 5, 22852: 4, 22851: 2, 22850: 0, 22849: 4, 22848: 1, 22847: 3, 22846: 2, 22845: 4, 22844: 2, 22843: 2, 22842: 5, 22841: 2, 22840: 10, 22839: 7, 22838: 2, 22837: 4, 22836: 2, 22835: 1, 22834: 2, 22833: 5, 22832: 4, 22831: 0, 22830: 3, 22829: 2, 22828: 2, 22827: 3, 22826: 3, 22825: 2, 22824: 5, 22823: 2, 22822: 1, 22821: 3, 22820: 1, 22819: 2, 22818: 1, 22817: 3, 22816: 2, 22815: 7, 22814: 1, 22813: 2, 22812: 2, 22811: 1, 22810: 1, 22809: 5, 22808: 3, 22807: 5, 22806: 2, 22805: 6, 22804: 4, 22803: 2, 22802: 4, 22801: 2, 22800: 0, 22799: 2, 22798: 3, 22797: 2, 22796: 4, 22795: 4, 22794: 1, 22793: 2, 22792: 1, 22791: 6, 22790: 3, 22789: 3, 22788: 2, 22787: 7, 22786: 2, 22785: 5, 22784: 3, 22783: 1, 22782: 3, 22781: 3, 22780: 5, 22779: 0, 22778: 1, 22777: 5, 22776: 1, 22775: 10, 22774: 6, 22773: 11, 22772: 4, 22771: 1, 22770: 1, 22769: 7, 22768: 2, 22767: 1, 22766: 5, 22765: 2, 22764: 4, 22763: 0, 22762: 2, 22761: 3, 22760: 3, 22759: 3, 22758: 2, 22757: 0, 22756: 1, 22755: 1, 22754: 1, 22753: 5, 22752: 3, 22751: 3, 22750: 0, 22749: 1, 22748: 2, 22747: 1, 22746: 0, 22745: 4, 22744: 0, 22743: 3, 22742: 0, 22741: 1, 22740: 9, 22739: 6, 22738: 2, 22737: 8, 22736: 0, 22735: 4, 22734: 3, 22733: 3, 22732: 3, 22731: 1, 22730: 2, 22729: 5, 22728: 0, 22727: 4, 22726: 9, 22725: 5, 22724: 1, 22723: 3, 22722: 3, 22721: 6, 22720: 1, 22719: 8, 22718: 7, 22717: 4, 22716: 3, 22715: 4, 22714: 2, 22713: 1, 22712: 0, 22711: 4, 22710: 11, 22709: 7, 22708: 1, 22707: 1, 22706: 5, 22705: 2, 22704: 5, 22703: 3, 22702: 3, 22701: 2, 22700: 4, 22699: 7, 22698: 2, 22697: 5, 22696: 3, 22695: 2, 22694: 0, 22693: 0, 22692: 4, 22691: 4, 22690: 5, 22689: 2, 22688: 3, 22687: 1, 22686: 4, 22685: 5, 22684: 1, 22683: 8, 22682: 4, 22681: 5, 22680: 3, 22679: 7, 22678: 1, 22677: 2, 22676: 6, 22675: 1, 22674: 2, 22673: 1, 22672: 3, 22671: 1, 22670: 4, 22669: 3, 22668: 1, 22667: 2, 22666: 0, 22665: 3, 22664: 8, 22663: 2, 22662: 3, 22661: 4, 22660: 1, 22659: 2, 22658: 2, 22657: 2, 22656: 1, 22655: 2, 22654: 1, 22653: 2, 22652: 0, 22651: 3, 22650: 2, 22649: 2, 22648: 0, 22647: 1, 22646: 4, 22645: 4, 22644: 1, 22643: 3, 22642: 3, 22641: 1, 22640: 3, 22639: 0, 22638: 2, 22637: 5, 22636: 5, 22635: 3, 22634: 1, 22633: 4, 22632: 5, 22631: 3, 22630: 0, 22629: 1, 22628: 2, 22627: 3, 22626: 2, 22625: 1, 22624: 3, 22623: 3, 22622: 0, 22621: 3, 22620: 3, 22619: 4, 22618: 2, 22617: 5, 22616: 2, 22615: 2, 22614: 2, 22613: 1, 22612: 1, 22611: 3, 22610: 5, 22609: 5, 22608: 6, 22607: 1, 22606: 4, 22605: 2, 22604: 2, 22603: 2, 22602: 2, 22601: 4, 22600: 1, 22599: 1, 22598: 3, 22597: 3, 22596: 1, 22595: 2, 22594: 0, 22593: 0, 22592: 3, 22591: 3, 22590: 5, 22589: 3, 22588: 0, 22587: 7, 22586: 0, 22585: 6, 22584: 2, 22583: 3, 22582: 6, 22581: 4, 22580: 1, 22579: 7, 22578: 4, 22577: 6, 22576: 3, 22575: 3, 22574: 1, 22573: 3, 22572: 5, 22571: 1, 22570: 1, 22569: 5, 22568: 3, 22567: 3, 22566: 2, 22565: 4, 22564: 10, 22563: 7, 22562: 6, 22561: 5, 22560: 5, 22559: 6, 22558: 7, 22557: 7, 22556: 9, 22555: 1, 22554: 35, 22553: 12, 22552: 10, 22551: 6, 22550: 6, 22549: 6, 22548: 2, 22547: 4, 22546: 1, 22545: 2, 22544: 0, 22543: 2, 22542: 1, 22541: 2, 22540: 7, 22539: 6, 22538: 4, 22537: 9, 22536: 5, 22535: 5, 22534: 6, 22533: 2, 22532: 4, 22531: 1, 22530: 4, 22529: 4, 22528: 4, 22527: 3, 22526: 2, 22525: 3, 22524: 2, 22523: 4, 22522: 0, 22521: 4, 22520: 3, 22519: 2, 22518: 3, 22517: 0, 22516: 5, 22515: 0, 22514: 2, 22513: 18, 22512: 3, 22511: 2, 22510: 2, 22509: 2, 22508: 1, 22507: 1, 22506: 8, 22505: 2, 22504: 5, 22503: 5, 22502: 3, 22501: 3, 22500: 1, 22499: 0, 22498: 3, 22497: 1, 22496: 0, 22495: 0, 22494: 3, 22493: 2, 22492: 8, 22491: 4, 22490: 0, 22489: 5, 22488: 5, 22487: 3, 22486: 1, 22485: 1, 22484: 1, 22483: 3, 22482: 3, 22481: 3, 22480: 1, 22479: 5, 22478: 4, 22477: 8, 22476: 5, 22475: 2, 22474: 3, 22473: 0, 22472: 3, 22471: 3, 22470: 9, 22469: 8, 22468: 1, 22467: 7, 22466: 10, 22465: 3, 22464: 1, 22463: 0, 22462: 5, 22461: 1, 22460: 3, 22459: 5, 22458: 4, 22457: 1, 22456: 2, 22455: 2, 22454: 2, 22453: 8, 22452: 5, 22451: 6, 22450: 17, 22449: 12, 22448: 3, 22447: 3, 22446: 3, 22445: 2, 22444: 4, 22443: 4, 22442: 4, 22441: 4, 22440: 3, 22439: 3, 22438: 1, 22437: 7, 22436: 2, 22435: 4, 22434: 3, 22433: 3, 22432: 0, 22431: 8, 22430: 0, 22429: 2, 22428: 1, 22427: 3, 22426: 3, 22425: 6, 22424: 2, 22423: 6, 22422: 1, 22421: 1, 22420: 2, 22419: 3, 22418: 1, 22417: 4, 22416: 0, 22415: 2, 22414: 4, 22413: 4, 22412: 5, 22411: 4, 22410: 1, 22409: 2, 22408: 10, 22407: 16, 22406: 5, 22405: 7, 22404: 12, 22403: 6, 22402: 6, 22401: 9, 22400: 6, 22399: 8, 22398: 10, 22397: 4, 22396: 6, 22395: 5, 22394: 4, 22393: 4, 22392: 15, 22391: 2, 22390: 5, 22389: 16, 22388: 5, 22387: 7, 22386: 4, 22385: 4, 22384: 4, 22383: 1, 22382: 3, 22381: 2, 22380: 2, 22379: 1, 22378: 1, 22377: 4, 22376: 3, 22375: 1, 22374: 3, 22373: 5, 22372: 4, 22371: 0, 22370: 2, 22369: 0, 22368: 1, 22367: 2, 22366: 13, 22365: 5, 22364: 3, 22363: 1, 22362: 5, 22361: 6, 22360: 3, 22359: 1, 22358: 3, 22357: 2, 22356: 19, 22355: 2, 22354: 0, 22353: 3, 22352: 3, 22351: 7, 22350: 3, 22349: 2, 22348: 3, 22347: 2, 22346: 0, 22345: 8, 22344: 6, 22343: 7, 22342: 4, 22341: 2, 22340: 2, 22339: 0, 22338: 2, 22337: 3, 22336: 3, 22335: 3, 22334: 2, 22333: 1, 22332: 2, 22331: 8, 22330: 7, 22329: 1, 22328: 2, 22327: 1, 22326: 2, 22325: 2, 22324: 3, 22323: 3, 22322: 3, 22321: 7, 22320: 2, 22319: 3, 22318: 3, 22317: 0, 22316: 0, 22315: 4, 22314: 14, 22313: 0, 22312: 11, 22311: 2, 22310: 3, 22309: 3, 22308: 3, 22307: 0, 22306: 1, 22305: 2, 22304: 1, 22303: 5, 22302: 9, 22301: 16, 22300: 1, 22299: 3, 22298: 7, 22297: 13, 22296: 4, 22295: 2, 22294: 11, 22293: 3, 22292: 2, 22291: 8, 22290: 7, 22289: 6, 22288: 4, 22287: 2, 22286: 2, 22285: 2, 22284: 3, 22283: 3, 22282: 2, 22281: 1, 22280: 8, 22279: 3, 22278: 2, 22277: 2, 22276: 2, 22275: 3, 22274: 0, 22273: 6, 22272: 4, 22271: 2, 22270: 4, 22269: 2, 22268: 6, 22267: 7, 22266: 2, 22265: 6, 22264: 2, 22263: 2, 22262: 3, 22261: 5, 22260: 2, 22259: 2, 22258: 4, 22257: 1, 22256: 2, 22255: 2, 22254: 4, 22253: 2, 22252: 2, 22251: 1, 22250: 3, 22249: 4, 22248: 3, 22247: 2, 22246: 5, 22245: 0, 22244: 3, 22243: 1, 22242: 1, 22241: 5, 22240: 5, 22239: 1, 22238: 2, 22237: 11, 22236: 13, 22235: 0, 22234: 3, 22233: 5, 22232: 1, 22231: 3, 22230: 0, 22229: 3, 22228: 5, 22227: 8, 22226: 5, 22225: 8, 22224: 1, 22223: 7, 22222: 7, 22221: 5, 22220: 5, 22219: 5, 22218: 9, 22217: 5, 22216: 2, 22215: 5, 22214: 3, 22213: 3, 22212: 2, 22211: 6, 22210: 5, 22209: 6, 22208: 11, 22207: 1, 22206: 2, 22205: 2, 22204: 4, 22203: 1, 22202: 3, 22201: 0, 22200: 3, 22199: 2, 22198: 10, 22197: 7, 22196: 5, 22195: 4, 22194: 3, 22193: 5, 22192: 2, 22191: 2, 22190: 3, 22189: 4, 22188: 4, 22187: 4, 22186: 4, 22185: 2, 22184: 3, 22183: 6, 22182: 5, 22181: 7, 22180: 5, 22179: 4, 22178: 3, 22177: 7, 22176: 3, 22175: 5, 22174: 2, 22173: 1, 22172: 2, 22171: 1, 22170: 8, 22169: 3, 22168: 4, 22167: 4, 22166: 2, 22165: 2, 22164: 4, 22163: 0, 22162: 5, 22161: 2, 22160: 1, 22159: 0, 22158: 4, 22157: 2, 22156: 1, 22155: 5, 22154: 0, 22153: 8, 22152: 6, 22151: 8, 22150: 1, 22149: 3, 22148: 2, 22147: 1, 22146: 9, 22145: 3, 22144: 1, 22143: 2, 22142: 2, 22141: 1, 22140: 10, 22139: 2, 22138: 5, 22137: 3, 22136: 1, 22135: 0, 22134: 15, 22133: 1, 22132: 3, 22131: 2, 22130: 3, 22129: 3, 22128: 5, 22127: 2, 22126: 1, 22125: 2, 22124: 4, 22123: 2, 22122: 2, 22121: 3, 22120: 1, 22119: 6, 22118: 4, 22117: 2, 22116: 3, 22115: 2, 22114: 6, 22113: 2, 22112: 3, 22111: 3, 22110: 4, 22109: 4, 22108: 5, 22107: 1, 22106: 4, 22105: 2, 22104: 4, 22103: 5, 22102: 7, 22101: 6, 22100: 0, 22099: 2, 22098: 1, 22097: 0, 22096: 1, 22095: 6, 22094: 4, 22093: 8, 22092: 2, 22091: 4, 22090: 3, 22089: 7, 22088: 2, 22087: 4, 22086: 3, 22085: 4, 22084: 2, 22083: 2, 22082: 0, 22081: 0, 22080: 0, 22079: 1, 22078: 4, 22077: 2, 22076: 5, 22075: 1, 22074: 0, 22073: 5, 22072: 6, 22071: 7, 22070: 6, 22069: 6, 22068: 11, 22067: 4, 22066: 5, 22065: 2, 22064: 3, 22063: 3, 22062: 1, 22061: 1, 22060: 10, 22059: 13, 22058: 13, 22057: 5, 22056: 5, 22055: 12, 22054: 3, 22053: 12, 22052: 2, 22051: 7, 22050: 3, 22049: 1, 22048: 3, 22047: 1, 22046: 3, 22045: 2, 22044: 2, 22043: 1, 22042: 7, 22041: 4, 22040: 5, 22039: 5, 22038: 5, 22037: 9, 22036: 6, 22035: 7, 22034: 2, 22033: 0, 22032: 0, 22031: 0, 22030: 0, 22029: 7, 22028: 9, 22027: 6, 22026: 7, 22025: 3, 22024: 2, 22023: 1, 22022: 5, 22021: 4, 22020: 4, 22019: 5, 22018: 1, 22017: 7, 22016: 2, 22015: 2, 22014: 6, 22013: 2, 22012: 2, 22011: 3, 22010: 3, 22009: 5, 22008: 2, 22007: 3, 22006: 4, 22005: 2, 22004: 2, 22003: 5, 22002: 2, 22001: 1, 22000: 3, 21999: 2, 21998: 6, 21997: 4, 21996: 2, 21995: 4, 21994: 3, 21993: 4, 21992: 3, 21991: 1, 21990: 2, 21989: 3, 21988: 2, 21987: 1, 21986: 2, 21985: 3, 21984: 3, 21983: 3, 21982: 3, 21981: 2, 21980: 3, 21979: 2, 21978: 11, 21977: 5, 21976: 3, 21975: 4, 21974: 7, 21973: 7, 21972: 2, 21971: 2, 21970: 5, 21969: 6, 21968: 4, 21967: 1, 21966: 2, 21965: 2, 21964: 2, 21963: 4, 21962: 1, 21961: 2, 21960: 3, 21959: 1, 21958: 2, 21957: 4, 21956: 2, 21955: 12, 21954: 12, 21953: 7, 21952: 4, 21951: 5, 21950: 3, 21949: 3, 21948: 2, 21947: 3, 21946: 2, 21945: 2, 21944: 5, 21943: 3, 21942: 3, 21941: 2, 21940: 2, 21939: 12, 21938: 9, 21937: 15, 21936: 4, 21935: 2, 21934: 1, 21933: 1, 21932: 3, 21931: 3, 21930: 1, 21929: 1, 21928: 5, 21927: 3, 21926: 4, 21925: 2, 21924: 3, 21923: 2, 21922: 3, 21921: 9, 21920: 5, 21919: 3, 21918: 6, 21917: 7, 21916: 3, 21915: 5, 21914: 3, 21913: 4, 21912: 5, 21911: 4, 21910: 5, 21909: 2, 21908: 1, 21907: 3, 21906: 3, 21905: 1, 21904: 5, 21903: 2, 21902: 2, 21901: 4, 21900: 2, 21899: 1, 21898: 1, 21897: 2, 21896: 6, 21895: 2, 21894: 6, 21893: 2, 21892: 3, 21891: 9, 21890: 6, 21889: 5, 21888: 2, 21887: 6, 21886: 10, 21885: 5, 21884: 8, 21883: 10, 21882: 6, 21881: 8, 21880: 5, 21879: 6, 21878: 7, 21877: 0, 21876: 0, 21875: 0, 21874: 1, 21873: 0, 21872: 1, 21871: 1, 21870: 1, 21869: 1, 21868: 9, 21867: 11, 21866: 7, 21865: 1, 21864: 2, 21863: 2, 21862: 1, 21861: 1, 21860: 4, 21859: 4, 21858: 1, 21857: 4, 21856: 6, 21855: 3, 21854: 3, 21853: 3, 21852: 2, 21851: 10, 21850: 4, 21849: 3, 21848: 2, 21847: 2, 21846: 3, 21845: 10, 21844: 3, 21843: 4, 21842: 1, 21841: 1, 21840: 5, 21839: 9, 21838: 3, 21837: 0, 21836: 3, 21835: 3, 21834: 4, 21833: 2, 21832: 1, 21831: 1, 21830: 4, 21829: 5, 21828: 2, 21827: 1, 21826: 1, 21825: 4, 21824: 2, 21823: 2, 21822: 4, 21821: 1, 21820: 4, 21819: 2, 21818: 5, 21817: 3, 21816: 3, 21815: 3, 21814: 3, 21813: 6, 21812: 3, 21811: 3, 21810: 1, 21809: 10, 21808: 0, 21807: 1, 21806: 21, 21805: 1, 21804: 2, 21803: 1, 21802: 1, 21801: 1, 21800: 1, 21799: 0, 21798: 2, 21797: 4, 21796: 3, 21795: 6, 21794: 2, 21793: 5, 21792: 3, 21791: 2, 21790: 4, 21789: 3, 21788: 3, 21787: 1, 21786: 9, 21785: 8, 21784: 4, 21783: 5, 21782: 4, 21781: 2, 21780: 7, 21779: 7, 21778: 3, 21777: 1, 21776: 2, 21775: 3, 21774: 4, 21773: 3, 21772: 4, 21771: 3, 21770: 1, 21769: 3, 21768: 2, 21767: 6, 21766: 8, 21765: 6, 21764: 0, 21763: 4, 21762: 4, 21761: 7, 21760: 3, 21759: 4, 21758: 2, 21757: 1, 21756: 2, 21755: 2, 21754: 2, 21753: 1, 21752: 4, 21751: 1, 21750: 3, 21749: 2, 21748: 2, 21747: 5, 21746: 5, 21745: 5, 21744: 2, 21743: 0, 21742: 3, 21741: 1, 21740: 0, 21739: 4, 21738: 4, 21737: 3, 21736: 4, 21735: 1, 21734: 1, 21733: 2, 21732: 1, 21731: 2, 21730: 3, 21729: 5, 21728: 1, 21727: 4, 21726: 1, 21725: 2, 21724: 2, 21723: 1, 21722: 2, 21721: 2, 21720: 5, 21719: 7, 21718: 6, 21717: 1, 21716: 3, 21715: 1, 21714: 6, 21713: 10, 21712: 0, 21711: 5, 21710: 2, 21709: 4, 21708: 2, 21707: 5, 21706: 1, 21705: 22, 21704: 8, 21703: 0, 21702: 8, 21701: 2, 21700: 4, 21699: 6, 21698: 3, 21697: 2, 21696: 4, 21695: 1, 21694: 16, 21693: 5, 21692: 3, 21691: 2, 21690: 5, 21689: 2, 21688: 9, 21687: 3, 21686: 5, 21685: 2, 21684: 2, 21683: 2, 21682: 2, 21681: 3, 21680: 0, 21679: 2, 21678: 2, 21677: 3, 21676: 6, 21675: 8, 21674: 9, 21673: 6, 21672: 0, 21671: 4, 21670: 3, 21669: 2, 21668: 6, 21667: 3, 21666: 2, 21665: 1, 21664: 4, 21663: 5, 21662: 1, 21661: 10, 21660: 9, 21659: 7, 21658: 2, 21657: 25, 21656: 6, 21655: 5, 21654: 10, 21653: 9, 21652: 25, 21651: 4, 21650: 5, 21649: 1, 21648: 2, 21647: 6, 21646: 3, 21645: 2, 21644: 4, 21643: 2, 21642: 9, 21641: 13, 21640: 3, 21639: 3, 21638: 1, 21637: 5, 21636: 6, 21635: 5, 21634: 1, 21633: 2, 21632: 9, 21631: 10, 21630: 7, 21629: 8, 21628: 6, 21627: 8, 21626: 8, 21625: 1, 21624: 4, 21623: 4, 21622: 6, 21621: 7, 21620: 3, 21619: 3, 21618: 3, 21617: 1, 21616: 1, 21615: 12, 21614: 1, 21613: 3, 21612: 4, 21611: 1, 21610: 2, 21609: 5, 21608: 3, 21607: 1, 21606: 1, 21605: 2, 21604: 2, 21603: 1, 21602: 2, 21601: 0, 21600: 1, 21599: 1, 21598: 3, 21597: 2, 21596: 3, 21595: 4, 21594: 5, 21593: 5, 21592: 10, 21591: 3, 21590: 3, 21589: 3, 21588: 5, 21587: 2, 21586: 6, 21585: 4, 21584: 5, 21583: 4, 21582: 5, 21581: 4, 21580: 5, 21579: 6, 21578: 0, 21577: 4, 21576: 1, 21575: 1, 21574: 6, 21573: 4, 21572: 1, 21571: 1, 21570: 1, 21569: 1, 21568: 2, 21567: 3, 21566: 2, 21565: 5, 21564: 2, 21563: 2, 21562: 4, 21561: 4, 21560: 5, 21559: 8, 21558: 19, 21557: 2, 21556: 4, 21555: 4, 21554: 1, 21553: 13, 21552: 5, 21551: 9, 21550: 1, 21549: 3, 21548: 3, 21547: 4, 21546: 2, 21545: 3, 21544: 2, 21543: 5, 21542: 4, 21541: 0, 21540: 3, 21539: 0, 21538: 7, 21537: 10, 21536: 6, 21535: 5, 21534: 2, 21533: 1, 21532: 1, 21531: 5, 21530: 1, 21529: 1, 21528: 7, 21527: 2, 21526: 4, 21525: 2, 21524: 3, 21523: 4, 21522: 1, 21521: 3, 21520: 0, 21519: 2, 21518: 4, 21517: 21, 21516: 3, 21515: 2, 21514: 2, 21513: 4, 21512: 9, 21511: 5, 21510: 2, 21509: 1, 21508: 4, 21507: 5, 21506: 10, 21505: 2, 21504: 4, 21503: 3, 21502: 2, 21501: 3, 21500: 1, 21499: 3, 21498: 1, 21497: 4, 21496: 1, 21495: 3, 21494: 1, 21493: 1, 21492: 1, 21491: 1, 21490: 7, 21489: 3, 21488: 3, 21487: 2, 21486: 2, 21485: 2, 21484: 1, 21483: 0, 21482: 7, 21481: 0, 21480: 6, 21479: 1, 21478: 6, 21477: 2, 21476: 5, 21475: 1, 21474: 0, 21473: 0, 21472: 3, 21471: 3, 21470: 0, 21469: 6, 21468: 11, 21467: 3, 21466: 16, 21465: 4, 21464: 0, 21463: 2, 21462: 4, 21461: 16, 21460: 20, 21459: 4, 21458: 6, 21457: 4, 21456: 4, 21455: 2, 21454: 1, 21453: 4, 21452: 3, 21451: 4, 21450: 4, 21449: 1, 21448: 5, 21447: 4, 21446: 3, 21445: 3, 21444: 1, 21443: 4, 21442: 3, 21441: 2, 21440: 1, 21439: 1, 21438: 2, 21437: 3, 21436: 1, 21435: 1, 21434: 2, 21433: 1, 21432: 4, 21431: 4, 21430: 3, 21429: 1, 21428: 9, 21427: 1, 21426: 2, 21425: 2, 21424: 2, 21423: 2, 21422: 1, 21421: 1, 21420: 0, 21419: 4, 21418: 3, 21417: 5, 21416: 4, 21415: 2, 21414: 4, 21413: 4, 21412: 3, 21411: 2, 21410: 2, 21409: 2, 21408: 7, 21407: 2, 21406: 6, 21405: 7, 21404: 7, 21403: 3, 21402: 7, 21401: 3, 21400: 2, 21399: 2, 21398: 2, 21397: 3, 21396: 6, 21395: 10, 21394: 1, 21393: 2, 21392: 1, 21391: 1, 21390: 2, 21389: 2, 21388: 5, 21387: 3, 21386: 1, 21385: 4, 21384: 5, 21383: 1, 21382: 2, 21381: 4, 21380: 9, 21379: 5, 21378: 5, 21377: 3, 21376: 12, 21375: 9, 21374: 5, 21373: 1, 21372: 1, 21371: 1, 21370: 3, 21369: 5, 21368: 1, 21367: 12, 21366: 1, 21365: 3, 21364: 7, 21363: 11, 21362: 2, 21361: 5, 21360: 2, 21359: 4, 21358: 3, 21357: 0, 21356: 11, 21355: 2, 21354: 0, 21353: 6, 21352: 2, 21351: 1, 21350: 1, 21349: 11, 21348: 2, 21347: 2, 21346: 2, 21345: 3, 21344: 3, 21343: 1, 21342: 0, 21341: 2, 21340: 5, 21339: 4, 21338: 3, 21337: 12, 21336: 2, 21335: 4, 21334: 4, 21333: 2, 21332: 9, 21331: 4, 21330: 0, 21329: 3, 21328: 2, 21327: 3, 21326: 4, 21325: 6, 21324: 4, 21323: 1, 21322: 2, 21321: 1, 21320: 3, 21319: 1, 21318: 3, 21317: 3, 21316: 2, 21315: 11, 21314: 2, 21313: 5, 21312: 1, 21311: 0, 21310: 5, 21309: 9, 21308: 16, 21307: 4, 21306: 4, 21305: 4, 21304: 4, 21303: 4, 21302: 1, 21301: 3, 21300: 3, 21299: 5, 21298: 6, 21297: 6, 21296: 7, 21295: 3, 21294: 3, 21293: 2, 21292: 1, 21291: 6, 21290: 3, 21289: 5, 21288: 2, 21287: 4, 21286: 8, 21285: 1, 21284: 4, 21283: 4, 21282: 3, 21281: 1, 21280: 1, 21279: 1, 21278: 0, 21277: 1, 21276: 1, 21275: 2, 21274: 0, 21273: 4, 21272: 5, 21271: 4, 21270: 2, 21269: 2, 21268: 7, 21267: 2, 21266: 1, 21265: 2, 21264: 7, 21263: 2, 21262: 0, 21261: 3, 21260: 2, 21259: 3, 21258: 4, 21257: 3, 21256: 4, 21255: 4, 21254: 4, 21253: 2, 21252: 19, 21251: 6, 21250: 8, 21249: 2, 21248: 4, 21247: 2, 21246: 1, 21245: 1, 21244: 1, 21243: 1, 21242: 7, 21241: 2, 21240: 3, 21239: 10, 21238: 2, 21237: 3, 21236: 5, 21235: 14, 21234: 1, 21233: 6, 21232: 3, 21231: 1, 21230: 6, 21229: 9, 21228: 14, 21227: 12, 21226: 11, 21225: 12, 21224: 14, 21223: 8, 21222: 11, 21221: 10, 21220: 2, 21219: 3, 21218: 9, 21217: 2, 21216: 1, 21215: 2, 21214: 3, 21213: 2, 21212: 5, 21211: 0, 21210: 1, 21209: 4, 21208: 5, 21207: 4, 21206: 4, 21205: 0, 21204: 2, 21203: 7, 21202: 11, 21201: 6, 21200: 5, 21199: 3, 21198: 3, 21197: 4, 21196: 2, 21195: 1, 21194: 1, 21193: 2, 21192: 1, 21191: 3, 21190: 2, 21189: 15, 21188: 5, 21187: 1, 21186: 5, 21185: 2, 21184: 3, 21183: 3, 21182: 1, 21181: 2, 21180: 3, 21179: 1, 21178: 1, 21177: 6, 21176: 3, 21175: 2, 21174: 1, 21173: 8, 21172: 10, 21171: 9, 21170: 9, 21169: 4, 21168: 10, 21167: 9, 21166: 1, 21165: 1, 21164: 4, 21163: 1, 21162: 4, 21161: 1, 21160: 1, 21159: 6, 21158: 3, 21157: 6, 21156: 10, 21155: 7, 21154: 3, 21153: 8, 21152: 2, 21151: 1, 21150: 2, 21149: 4, 21148: 3, 21147: 3, 21146: 18, 21145: 1, 21144: 1, 21143: 1, 21142: 5, 21141: 2, 21140: 4, 21139: 5, 21138: 2, 21137: 8, 21136: 6, 21135: 1, 21134: 1, 21133: 1, 21132: 1, 21131: 2, 21130: 9, 21129: 19, 21128: 3, 21127: 3, 21126: 2, 21125: 2, 21124: 4, 21123: 4, 21122: 3, 21121: 3, 21120: 4, 21119: 4, 21118: 2, 21117: 4, 21116: 3, 21115: 5, 21114: 2, 21113: 2, 21112: 2, 21111: 2, 21110: 3, 21109: 1, 21108: 4, 21107: 3, 21106: 6, 21105: 7, 21104: 7, 21103: 6, 21102: 5, 21101: 1, 21100: 6, 21099: 7, 21098: 6, 21097: 3, 21096: 7, 21095: 1, 21094: 4, 21093: 4, 21092: 4, 21091: 8, 21090: 2, 21089: 5, 21088: 10, 21087: 2, 21086: 2, 21085: 3, 21084: 1, 21083: 2, 21082: 6, 21081: 6, 21080: 3, 21079: 1, 21078: 1, 21077: 1, 21076: 1, 21075: 6, 21074: 4, 21073: 3, 21072: 4, 21071: 4, 21070: 7, 21069: 10, 21068: 8, 21067: 7, 21066: 1, 21065: 0, 21064: 17, 21063: 0, 21062: 2, 21061: 1, 21060: 2, 21059: 3, 21058: 4, 21057: 4, 21056: 5, 21055: 6, 21054: 3, 21053: 3, 21052: 5, 21051: 4, 21050: 3, 21049: 1, 21048: 7, 21047: 8, 21046: 8, 21045: 8, 21044: 5, 21043: 12, 21042: 7, 21041: 11, 21040: 8, 21039: 5, 21038: 7, 21037: 1, 21036: 5, 21035: 3, 21034: 6, 21033: 4, 21032: 0, 21031: 1, 21030: 1, 21029: 3, 21028: 1, 21027: 1, 21026: 2, 21025: 2, 21024: 1, 21023: 1, 21022: 0, 21021: 2, 21020: 1, 21019: 3, 21018: 2, 21017: 3, 21016: 2, 21015: 3, 21014: 16, 21013: 0, 21012: 2, 21011: 0, 21010: 3, 21009: 11, 21008: 5, 21007: 3, 21006: 4, 21005: 3, 21004: 2, 21003: 5, 21002: 2, 21001: 3, 21000: 1, 20999: 1, 20998: 1, 20997: 0, 20996: 3, 20995: 5, 20994: 3, 20993: 3, 20992: 4, 20991: 3, 20990: 3, 20989: 3, 20988: 0, 20987: 1, 20986: 1, 20985: 2, 20984: 0, 20983: 1, 20982: 2, 20981: 1, 20980: 1, 20979: 4, 20978: 6, 20977: 1, 20976: 8, 20975: 6, 20974: 11, 20973: 1, 20972: 2, 20971: 2, 20970: 5, 20969: 1, 20968: 2, 20967: 2, 20966: 0, 20965: 4, 20964: 0, 20963: 2, 20962: 1, 20961: 6, 20960: 9, 20959: 5, 20958: 8, 20957: 5, 20956: 3, 20955: 3, 20954: 1, 20953: 10, 20952: 1, 20951: 0, 20950: 1, 20949: 7, 20948: 4, 20947: 7, 20946: 10, 20945: 2, 20944: 3, 20943: 3, 20942: 3, 20941: 7, 20940: 4, 20939: 4, 20938: 1, 20937: 2, 20936: 1, 20935: 1, 20934: 1, 20933: 2, 20932: 2, 20931: 2, 20930: 10, 20929: 13, 20928: 9, 20927: 1, 20926: 1, 20925: 4, 20924: 3, 20923: 11, 20922: 1, 20921: 5, 20920: 1, 20919: 9, 20918: 5, 20917: 2, 20916: 4, 20915: 1, 20914: 2, 20913: 3, 20912: 2, 20911: 1, 20910: 0, 20909: 2, 20908: 2, 20907: 1, 20906: 2, 20905: 4, 20904: 2, 20903: 4, 20902: 2, 20901: 0, 20900: 1, 20899: 8, 20898: 3, 20897: 1, 20896: 2, 20895: 3, 20894: 0, 20893: 0, 20892: 2, 20891: 2, 20890: 1, 20889: 5, 20888: 2, 20887: 8, 20886: 2, 20885: 3, 20884: 7, 20883: 6, 20882: 4, 20881: 7, 20880: 8, 20879: 6, 20878: 1, 20877: 3, 20876: 2, 20875: 2, 20874: 1, 20873: 2, 20872: 1, 20871: 3, 20870: 4, 20869: 7, 20868: 6, 20867: 5, 20866: 5, 20865: 4, 20864: 5, 20863: 5, 20862: 3, 20861: 4, 20860: 5, 20859: 3, 20858: 5, 20857: 5, 20856: 5, 20855: 3, 20854: 7, 20853: 2, 20852: 5, 20851: 3, 20850: 1, 20849: 6, 20848: 1, 20847: 1, 20846: 2, 20845: 2, 20844: 2, 20843: 7, 20842: 0, 20841: 3, 20840: 10, 20839: 3, 20838: 2, 20837: 2, 20836: 5, 20835: 3, 20834: 3, 20833: 5, 20832: 5, 20831: 1, 20830: 16, 20829: 1, 20828: 2, 20827: 8, 20826: 8, 20825: 1, 20824: 2, 20823: 1, 20822: 7, 20821: 6, 20820: 6, 20819: 7, 20818: 1, 20817: 5, 20816: 6, 20815: 8, 20814: 7, 20813: 3, 20812: 2, 20811: 2, 20810: 3, 20809: 2, 20808: 8, 20807: 3, 20806: 6, 20805: 2, 20804: 2, 20803: 3, 20802: 3, 20801: 1, 20800: 2, 20799: 2, 20798: 1, 20797: 1, 20796: 5, 20795: 3, 20794: 9, 20793: 8, 20792: 4, 20791: 3, 20790: 1, 20789: 0, 20788: 4, 20787: 3, 20786: 3, 20785: 9, 20784: 0, 20783: 6, 20782: 3, 20781: 1, 20780: 7, 20779: 6, 20778: 8, 20777: 8, 20776: 3, 20775: 6, 20774: 3, 20773: 4, 20772: 1, 20771: 5, 20770: 4, 20769: 7, 20768: 5, 20767: 11, 20766: 5, 20765: 7, 20764: 15, 20763: 3, 20762: 1, 20761: 0, 20760: 6, 20759: 5, 20758: 0, 20757: 3, 20756: 1, 20755: 11, 20754: 3, 20753: 1, 20752: 1, 20751: 6, 20750: 2, 20749: 3, 20748: 4, 20747: 2, 20746: 5, 20745: 2, 20744: 0, 20743: 12, 20742: 7, 20741: 12, 20740: 11, 20739: 1, 20738: 3, 20737: 2, 20736: 6, 20735: 3, 20734: 12, 20733: 5, 20732: 4, 20731: 0, 20730: 5, 20729: 5, 20728: 6, 20727: 4, 20726: 2, 20725: 3, 20724: 17, 20723: 3, 20722: 2, 20721: 2, 20720: 9, 20719: 7, 20718: 20, 20717: 7, 20716: 6, 20715: 9, 20714: 14, 20713: 9, 20712: 8, 20711: 2, 20710: 10, 20709: 2, 20708: 6, 20707: 15, 20706: 4, 20705: 3, 20704: 4, 20703: 4, 20702: 3, 20701: 5, 20700: 8, 20699: 3, 20698: 9, 20697: 3, 20696: 6, 20695: 7, 20694: 4, 20693: 1, 20692: 9, 20691: 1, 20690: 0, 20689: 1, 20688: 2, 20687: 6, 20686: 8, 20685: 1, 20684: 6, 20683: 2, 20682: 1, 20681: 0, 20680: 3, 20679: 4, 20678: 6, 20677: 2, 20676: 2, 20675: 11, 20674: 5, 20673: 5, 20672: 6, 20671: 6, 20670: 2, 20669: 1, 20668: 1, 20667: 1, 20666: 0, 20665: 5, 20664: 3, 20663: 2, 20662: 1, 20661: 2, 20660: 2, 20659: 4, 20658: 0, 20657: 1, 20656: 8, 20655: 1, 20654: 1, 20653: 3, 20652: 2, 20651: 7, 20650: 7, 20649: 5, 20648: 7, 20647: 3, 20646: 6, 20645: 2, 20644: 1, 20643: 5, 20642: 2, 20641: 3, 20640: 13, 20639: 3, 20638: 3, 20637: 3, 20636: 3, 20635: 12, 20634: 1, 20633: 3, 20632: 11, 20631: 6, 20630: 1, 20629: 2, 20628: 3, 20627: 7, 20626: 12, 20625: 7, 20624: 11, 20623: 1, 20622: 12, 20621: 13, 20620: 14, 20619: 12, 20618: 15, 20617: 14, 20616: 13, 20615: 18, 20614: 14, 20613: 20, 20612: 12, 20611: 15, 20610: 2, 20609: 2, 20608: 3, 20607: 8, 20606: 1, 20605: 3, 20604: 4, 20603: 10, 20602: 9, 20601: 7, 20600: 2, 20599: 3, 20598: 12, 20597: 2, 20596: 5, 20595: 4, 20594: 2, 20593: 4, 20592: 3, 20591: 6, 20590: 9, 20589: 2, 20588: 0, 20587: 3, 20586: 1, 20585: 6, 20584: 14, 20583: 12, 20582: 12, 20581: 12, 20580: 13, 20579: 4, 20578: 3, 20577: 3, 20576: 3, 20575: 5, 20574: 4, 20573: 4, 20572: 5, 20571: 6, 20570: 7, 20569: 23, 20568: 10, 20567: 11, 20566: 10, 20565: 2, 20564: 5, 20563: 4, 20562: 3, 20561: 7, 20560: 6, 20559: 4, 20558: 3, 20557: 6, 20556: 0, 20555: 3, 20554: 2, 20553: 6, 20552: 1, 20551: 1, 20550: 1, 20549: 2, 20548: 0, 20547: 8, 20546: 7, 20545: 9, 20544: 7, 20543: 5, 20542: 4, 20541: 6, 20540: 1, 20539: 3, 20538: 2, 20537: 2, 20536: 1, 20535: 2, 20534: 3, 20533: 5, 20532: 0, 20531: 8, 20530: 11, 20529: 0, 20528: 1, 20527: 1, 20526: 1, 20525: 11, 20524: 1, 20523: 2, 20522: 3, 20521: 3, 20520: 2, 20519: 1, 20518: 2, 20517: 2, 20516: 2, 20515: 3, 20514: 4, 20513: 5, 20512: 3, 20511: 4, 20510: 4, 20509: 2, 20508: 6, 20507: 10, 20506: 10, 20505: 1, 20504: 5, 20503: 3, 20502: 2, 20501: 2, 20500: 4, 20499: 4, 20498: 3, 20497: 2, 20496: 8, 20495: 2, 20494: 2, 20493: 3, 20492: 2, 20491: 3, 20490: 4, 20489: 2, 20488: 3, 20487: 1, 20486: 6, 20485: 2, 20484: 3, 20483: 5, 20482: 4, 20481: 5, 20480: 4, 20479: 1, 20478: 2, 20477: 1, 20476: 4, 20475: 3, 20474: 6, 20473: 4, 20472: 2, 20471: 2, 20470: 5, 20469: 2, 20468: 2, 20467: 4, 20466: 0, 20465: 9, 20464: 2, 20463: 2, 20462: 9, 20461: 2, 20460: 3, 20459: 2, 20458: 3, 20457: 3, 20456: 12, 20455: 5, 20454: 7, 20453: 5, 20452: 3, 20451: 6, 20450: 5, 20449: 1, 20448: 5, 20447: 3, 20446: 4, 20445: 3, 20444: 4, 20443: 2, 20442: 1, 20441: 4, 20440: 1, 20439: 2, 20438: 1, 20437: 12, 20436: 2, 20435: 7, 20434: 2, 20433: 3, 20432: 3, 20431: 3, 20430: 2, 20429: 5, 20428: 1, 20427: 2, 20426: 0, 20425: 1, 20424: 5, 20423: 1, 20422: 4, 20421: 2, 20420: 0, 20419: 1, 20418: 3, 20417: 0, 20416: 7, 20415: 8, 20414: 10, 20413: 7, 20412: 4, 20411: 3, 20410: 7, 20409: 4, 20408: 5, 20407: 3, 20406: 3, 20405: 3, 20404: 1, 20403: 16, 20402: 7, 20401: 0, 20400: 1, 20399: 5, 20398: 1, 20397: 4, 20396: 1, 20395: 0, 20394: 1, 20393: 6, 20392: 3, 20391: 3, 20390: 4, 20389: 2, 20388: 1, 20387: 2, 20386: 2, 20385: 7, 20384: 3, 20383: 2, 20382: 1, 20381: 2, 20380: 2, 20379: 3, 20378: 0, 20377: 1, 20376: 2, 20375: 1, 20374: 2, 20373: 3, 20372: 6, 20371: 0, 20370: 0, 20369: 2, 20368: 2, 20367: 7, 20366: 0, 20365: 10, 20364: 1, 20363: 1, 20362: 5, 20361: 3, 20360: 8, 20359: 4, 20358: 5, 20357: 1, 20356: 0, 20355: 0, 20354: 2, 20353: 3, 20352: 4, 20351: 7, 20350: 1, 20349: 5, 20348: 3, 20347: 3, 20346: 6, 20345: 4, 20344: 2, 20343: 1, 20342: 2, 20341: 2, 20340: 1, 20339: 0, 20338: 21, 20337: 1, 20336: 1, 20335: 1, 20334: 3, 20333: 5, 20332: 6, 20331: 5, 20330: 7, 20329: 3, 20328: 5, 20327: 0, 20326: 4, 20325: 4, 20324: 0, 20323: 5, 20322: 0, 20321: 3, 20320: 2, 20319: 2, 20318: 1, 20317: 2, 20316: 1, 20315: 9, 20314: 5, 20313: 0, 20312: 0, 20311: 3, 20310: 1, 20309: 1, 20308: 1, 20307: 4, 20306: 1, 20305: 1, 20304: 3, 20303: 5, 20302: 0, 20301: 2, 20300: 2, 20299: 2, 20298: 2, 20297: 2, 20296: 4, 20295: 4, 20294: 2, 20293: 2, 20292: 4, 20291: 5, 20290: 8, 20289: 3, 20288: 3, 20287: 1, 20286: 7, 20285: 8, 20284: 1, 20283: 1, 20282: 5, 20281: 2, 20280: 2, 20279: 8, 20278: 4, 20277: 0, 20276: 3, 20275: 3, 20274: 1, 20273: 0, 20272: 1, 20271: 1, 20270: 4, 20269: 1, 20268: 2, 20267: 0, 20266: 4, 20265: 2, 20264: 0, 20263: 2, 20262: 3, 20261: 8, 20260: 5, 20259: 1, 20258: 0, 20257: 1, 20256: 5, 20255: 3, 20254: 2, 20253: 2, 20252: 0, 20251: 1, 20250: 5, 20249: 1, 20248: 3, 20247: 4, 20246: 0, 20245: 4, 20244: 0, 20243: 2, 20242: 3, 20241: 1, 20240: 1, 20239: 6, 20238: 0, 20237: 1, 20236: 0, 20235: 4, 20234: 2, 20233: 2, 20232: 1, 20231: 2, 20230: 0, 20229: 3, 20228: 4, 20227: 17, 20226: 1, 20225: 1, 20224: 2, 20223: 3, 20222: 1, 20221: 0, 20220: 1, 20219: 1, 20218: 4, 20217: 2, 20216: 2, 20215: 1, 20214: 5, 20213: 3, 20212: 4, 20211: 5, 20210: 1, 20209: 7, 20208: 1, 20207: 1, 20206: 1, 20205: 5, 20204: 3, 20203: 1, 20202: 2, 20201: 1, 20200: 2, 20199: 2, 20198: 3, 20197: 3, 20196: 2, 20195: 0, 20194: 0, 20193: 2, 20192: 3, 20191: 4, 20190: 6, 20189: 8, 20188: 5, 20187: 1, 20186: 3, 20185: 2, 20184: 1, 20183: 1, 20182: 1, 20181: 4, 20180: 1, 20179: 7, 20178: 8, 20177: 4, 20176: 3, 20175: 2, 20174: 1, 20173: 6, 20172: 5, 20171: 3, 20170: 0, 20169: 4, 20168: 4, 20167: 4, 20166: 0, 20165: 1, 20164: 4, 20163: 1, 20162: 0, 20161: 3, 20160: 1, 20159: 3, 20158: 6, 20157: 6, 20156: 5, 20155: 1, 20154: 2, 20153: 1, 20152: 4, 20151: 2, 20150: 0, 20149: 1, 20148: 3, 20147: 1, 20146: 2, 20145: 0, 20144: 0, 20143: 1, 20142: 3, 20141: 1, 20140: 0, 20139: 1, 20138: 1, 20137: 1, 20136: 0, 20135: 1, 20134: 2, 20133: 13, 20132: 1, 20131: 1, 20130: 2, 20129: 8, 20128: 2, 20127: 0, 20126: 2, 20125: 0, 20124: 2, 20123: 2, 20122: 5, 20121: 1, 20120: 20, 20119: 3, 20118: 6, 20117: 4, 20116: 2, 20115: 2, 20114: 4, 20113: 6, 20112: 2, 20111: 1, 20110: 2, 20109: 2, 20108: 0, 20107: 4, 20106: 0, 20105: 3, 20104: 6, 20103: 3, 20102: 6, 20101: 5, 20100: 1, 20099: 1, 20098: 3, 20097: 2, 20096: 3, 20095: 8, 20094: 2, 20093: 0, 20092: 2, 20091: 3, 20090: 1, 20089: 2, 20088: 2, 20087: 4, 20086: 1, 20085: 5, 20084: 4, 20083: 1, 20082: 2, 20081: 1, 20080: 3, 20079: 2, 20078: 2, 20077: 0, 20076: 5, 20075: 6, 20074: 5, 20073: 1, 20072: 1, 20071: 2, 20070: 6, 20069: 5, 20068: 1, 20067: 2, 20066: 3, 20065: 13, 20064: 1, 20063: 1, 20062: 1, 20061: 15, 20060: 4, 20059: 3, 20058: 2, 20057: 10, 20056: 1, 20055: 1, 20054: 5, 20053: 2, 20052: 3, 20051: 2, 20050: 8, 20049: 2, 20048: 2, 20047: 0, 20046: 3, 20045: 2, 20044: 6, 20043: 4, 20042: 3, 20041: 3, 20040: 1, 20039: 2, 20038: 2, 20037: 2, 20036: 2, 20035: 2, 20034: 5, 20033: 5, 20032: 2, 20031: 2, 20030: 2, 20029: 1, 20028: 1, 20027: 1, 20026: 1, 20025: 2, 20024: 1, 20023: 4, 20022: 0, 20021: 5, 20020: 4, 20019: 3, 20018: 0, 20017: 2, 20016: 0, 20015: 2, 20014: 12, 20013: 3, 20012: 1, 20011: 2, 20010: 1, 20009: 0, 20008: 4, 20007: 2, 20006: 1, 20005: 2, 20004: 6, 20003: 5, 20002: 8, 20001: 8, 20000: 4, 19999: 1, 19998: 1, 19997: 1, 19996: 3, 19995: 2, 19994: 3, 19993: 6, 19992: 3, 19991: 5, 19990: 9, 19989: 5, 19988: 3, 19987: 4, 19986: 2, 19985: 2, 19984: 1, 19983: 2, 19982: 1, 19981: 2, 19980: 0, 19979: 4, 19978: 5, 19977: 3, 19976: 1, 19975: 3, 19974: 3, 19973: 2, 19972: 8, 19971: 4, 19970: 4, 19969: 2, 19968: 2, 19967: 0, 19966: 6, 19965: 4, 19964: 2, 19963: 2, 19962: 2, 19961: 0, 19960: 5, 19959: 0, 19958: 2, 19957: 6, 19956: 1, 19955: 0, 19954: 2, 19953: 1, 19952: 3, 19951: 2, 19950: 3, 19949: 5, 19948: 2, 19947: 1, 19946: 1, 19945: 0, 19944: 1, 19943: 0, 19942: 2, 19941: 0, 19940: 3, 19939: 1, 19938: 9, 19937: 1, 19936: 2, 19935: 1, 19934: 2, 19933: 1, 19932: 5, 19931: 1, 19930: 3, 19929: 2, 19928: 3, 19927: 3, 19926: 0, 19925: 4, 19924: 3, 19923: 6, 19922: 7, 19921: 2, 19920: 2, 19919: 2, 19918: 4, 19917: 2, 19916: 2, 19915: 2, 19914: 2, 19913: 0, 19912: 2, 19911: 7, 19910: 5, 19909: 3, 19908: 1, 19907: 11, 19906: 2, 19905: 3, 19904: 3, 19903: 8, 19902: 8, 19901: 3, 19900: 1, 19899: 7, 19898: 3, 19897: 0, 19896: 3, 19895: 3, 19894: 4, 19893: 13, 19892: 2, 19891: 2, 19890: 2, 19889: 10, 19888: 2, 19887: 1, 19886: 2, 19885: 1, 19884: 2, 19883: 1, 19882: 0, 19881: 0, 19880: 8, 19879: 3, 19878: 1, 19877: 2, 19876: 10, 19875: 2, 19874: 3, 19873: 2, 19872: 13, 19871: 3, 19870: 2, 19869: 3, 19868: 0, 19867: 2, 19866: 42, 19865: 5, 19864: 6, 19863: 2, 19862: 5, 19861: 1, 19860: 1, 19859: 7, 19858: 2, 19857: 1, 19856: 6, 19855: 6, 19854: 2, 19853: 3, 19852: 2, 19851: 1, 19850: 2, 19849: 0, 19848: 4, 19847: 7, 19846: 2, 19845: 2, 19844: 2, 19843: 2, 19842: 2, 19841: 3, 19840: 2, 19839: 2, 19838: 1, 19837: 3, 19836: 3, 19835: 5, 19834: 5, 19833: 14, 19832: 4, 19831: 8, 19830: 13, 19829: 2, 19828: 3, 19827: 2, 19826: 1, 19825: 1, 19824: 1, 19823: 5, 19822: 4, 19821: 1, 19820: 2, 19819: 3, 19818: 3, 19817: 3, 19816: 5, 19815: 0, 19814: 4, 19813: 4, 19812: 2, 19811: 1, 19810: 10, 19809: 16, 19808: 4, 19807: 10, 19806: 9, 19805: 8, 19804: 4, 19803: 5, 19802: 2, 19801: 3, 19800: 4, 19799: 8, 19798: 4, 19797: 1, 19796: 2, 19795: 7, 19794: 6, 19793: 3, 19792: 4, 19791: 2, 19790: 4, 19789: 3, 19788: 0, 19787: 6, 19786: 3, 19785: 3, 19784: 3, 19783: 0, 19782: 3, 19781: 2, 19780: 3, 19779: 10, 19778: 2, 19777: 3, 19776: 2, 19775: 2, 19774: 6, 19773: 0, 19772: 6, 19771: 15, 19770: 1, 19769: 4, 19768: 0, 19767: 2, 19766: 3, 19765: 4, 19764: 1, 19763: 2, 19762: 2, 19761: 5, 19760: 3, 19759: 3, 19758: 4, 19757: 3, 19756: 5, 19755: 4, 19754: 1, 19753: 2, 19752: 2, 19751: 12, 19750: 3, 19749: 7, 19748: 1, 19747: 0, 19746: 1, 19745: 5, 19744: 1, 19743: 2, 19742: 19, 19741: 10, 19740: 8, 19739: 22, 19738: 28, 19737: 0, 19736: 2, 19735: 4, 19734: 2, 19733: 0, 19732: 3, 19731: 2, 19730: 7, 19729: 3, 19728: 5, 19727: 6, 19726: 2, 19725: 2, 19724: 6, 19723: 3, 19722: 5, 19721: 6, 19720: 5, 19719: 2, 19718: 3, 19717: 4, 19716: 0, 19715: 3, 19714: 2, 19713: 2, 19712: 4, 19711: 4, 19710: 2, 19709: 8, 19708: 2, 19707: 1, 19706: 2, 19705: 1, 19704: 4, 19703: 6, 19702: 5, 19701: 0, 19700: 4, 19699: 3, 19698: 3, 19697: 2, 19696: 5, 19695: 1, 19694: 3, 19693: 7, 19692: 2, 19691: 5, 19690: 5, 19689: 1, 19688: 5, 19687: 7, 19686: 0, 19685: 3, 19684: 2, 19683: 1, 19682: 1, 19681: 2, 19680: 1, 19679: 2, 19678: 6, 19677: 4, 19676: 1, 19675: 2, 19674: 2, 19673: 2, 19672: 1, 19671: 5, 19670: 0, 19669: 6, 19668: 2, 19667: 1, 19666: 7, 19665: 1, 19664: 1, 19663: 4, 19662: 1, 19661: 4, 19660: 2, 19659: 0, 19658: 5, 19657: 3, 19656: 1, 19655: 3, 19654: 0, 19653: 14, 19652: 3, 19651: 2, 19650: 4, 19649: 3, 19648: 13, 19647: 2, 19646: 2, 19645: 3, 19644: 3, 19643: 2, 19642: 5, 19641: 6, 19640: 3, 19639: 2, 19638: 1, 19637: 3, 19636: 1, 19635: 4, 19634: 8, 19633: 3, 19632: 13, 19631: 0, 19630: 2, 19629: 4, 19628: 3, 19627: 2, 19626: 3, 19625: 7, 19624: 4, 19623: 7, 19622: 3, 19621: 4, 19620: 1, 19619: 1, 19618: 13, 19617: 4, 19616: 0, 19615: 11, 19614: 5, 19613: 2, 19612: 4, 19611: 2, 19610: 1, 19609: 6, 19608: 1, 19607: 2, 19606: 2, 19605: 2, 19604: 2, 19603: 1, 19602: 3, 19601: 4, 19600: 3, 19599: 0, 19598: 2, 19597: 1, 19596: 2, 19595: 2, 19594: 2, 19593: 2, 19592: 4, 19591: 1, 19590: 2, 19589: 4, 19588: 1, 19587: 1, 19586: 0, 19585: 2, 19584: 7, 19583: 5, 19582: 11, 19581: 5, 19580: 2, 19579: 5, 19578: 1, 19577: 3, 19576: 0, 19575: 0, 19574: 3, 19573: 3, 19572: 1, 19571: 6, 19570: 1, 19569: 2, 19568: 1, 19567: 2, 19566: 6, 19565: 1, 19564: 3, 19563: 2, 19562: 5, 19561: 2, 19560: 1, 19559: 3, 19558: 5, 19557: 1, 19556: 4, 19555: 22, 19554: 4, 19553: 3, 19552: 3, 19551: 3, 19550: 3, 19549: 3, 19548: 3, 19547: 3, 19546: 1, 19545: 3, 19544: 5, 19543: 3, 19542: 2, 19541: 3, 19540: 5, 19539: 1, 19538: 3, 19537: 7, 19536: 7, 19535: 0, 19534: 3, 19533: 3, 19532: 5, 19531: 2, 19530: 2, 19529: 3, 19528: 3, 19527: 8, 19526: 4, 19525: 9, 19524: 3, 19523: 7, 19522: 3, 19521: 32, 19520: 24, 19519: 4, 19518: 2, 19517: 3, 19516: 0, 19515: 1, 19514: 1, 19513: 2, 19512: 4, 19511: 1, 19510: 4, 19509: 1, 19508: 2, 19507: 7, 19506: 6, 19505: 2, 19504: 2, 19503: 5, 19502: 5, 19501: 10, 19500: 1, 19499: 1, 19498: 1, 19497: 2, 19496: 5, 19495: 6, 19494: 0, 19493: 4, 19492: 1, 19491: 11, 19490: 2, 19489: 3, 19488: 3, 19487: 1, 19486: 4, 19485: 6, 19484: 2, 19483: 5, 19482: 6, 19481: 12, 19480: 9, 19479: 11, 19478: 8, 19477: 3, 19476: 1, 19475: 2, 19474: 2, 19473: 7, 19472: 0, 19471: 1, 19470: 3, 19469: 3, 19468: 9, 19467: 1, 19466: 5, 19465: 2, 19464: 0, 19463: 2, 19462: 6, 19461: 1, 19460: 2, 19459: 4, 19458: 2, 19457: 1, 19456: 3, 19455: 0, 19454: 3, 19453: 3, 19452: 7, 19451: 7, 19450: 5, 19449: 1, 19448: 2, 19447: 1, 19446: 2, 19445: 2, 19444: 15, 19443: 3, 19442: 0, 19441: 4, 19440: 4, 19439: 5, 19438: 2, 19437: 0, 19436: 3, 19435: 3, 19434: 8, 19433: 4, 19432: 1, 19431: 4, 19430: 5, 19429: 4, 19428: 5, 19427: 4, 19426: 3, 19425: 1, 19424: 9, 19423: 8, 19422: 4, 19421: 1, 19420: 3, 19419: 4, 19418: 1, 19417: 1, 19416: 3, 19415: 4, 19414: 3, 19413: 1, 19412: 1, 19411: 17, 19410: 1, 19409: 1, 19408: 1, 19407: 1, 19406: 2, 19405: 0, 19404: 0, 19403: 1, 19402: 6, 19401: 1, 19400: 3, 19399: 2, 19398: 3, 19397: 1, 19396: 3, 19395: 1, 19394: 12, 19393: 8, 19392: 10, 19391: 3, 19390: 2, 19389: 1, 19388: 3, 19387: 1, 19386: 1, 19385: 1, 19384: 4, 19383: 1, 19382: 0, 19381: 2, 19380: 1, 19379: 5, 19378: 1, 19377: 4, 19376: 1, 19375: 0, 19374: 9, 19373: 11, 19372: 4, 19371: 6, 19370: 4, 19369: 5, 19368: 7, 19367: 9, 19366: 5, 19365: 4, 19364: 8, 19363: 12, 19362: 6, 19361: 2, 19360: 1, 19359: 2, 19358: 4, 19357: 3, 19356: 3, 19355: 2, 19354: 3, 19353: 0, 19352: 4, 19351: 4, 19350: 7, 19349: 0, 19348: 4, 19347: 6, 19346: 2, 19345: 2, 19344: 4, 19343: 2, 19342: 6, 19341: 3, 19340: 2, 19339: 2, 19338: 3, 19337: 3, 19336: 1, 19335: 5, 19334: 23, 19333: 2, 19332: 5, 19331: 0, 19330: 2, 19329: 1, 19328: 4, 19327: 3, 19326: 3, 19325: 3, 19324: 16, 19323: 3, 19322: 2, 19321: 2, 19320: 2, 19319: 3, 19318: 3, 19317: 1, 19316: 1, 19315: 2, 19314: 2, 19313: 1, 19312: 3, 19311: 9, 19310: 10, 19309: 14, 19308: 6, 19307: 0, 19306: 8, 19305: 2, 19304: 1, 19303: 0, 19302: 1, 19301: 4, 19300: 4, 19299: 4, 19298: 2, 19297: 2, 19296: 6, 19295: 2, 19294: 1, 19293: 2, 19292: 2, 19291: 3, 19290: 3, 19289: 8, 19288: 6, 19287: 2, 19286: 2, 19285: 1, 19284: 5, 19283: 3, 19282: 4, 19281: 1, 19280: 3, 19279: 2, 19278: 0, 19277: 1, 19276: 2, 19275: 1, 19274: 3, 19273: 12, 19272: 1, 19271: 6, 19270: 0, 19269: 1, 19268: 1, 19267: 2, 19266: 3, 19265: 1, 19264: 3, 19263: 2, 19262: 3, 19261: 1, 19260: 4, 19259: 6, 19258: 4, 19257: 5, 19256: 3, 19255: 2, 19254: 5, 19253: 3, 19252: 0, 19251: 3, 19250: 6, 19249: 8, 19248: 2, 19247: 1, 19246: 0, 19245: 5, 19244: 3, 19243: 3, 19242: 1, 19241: 2, 19240: 3, 19239: 5, 19238: 14, 19237: 4, 19236: 3, 19235: 3, 19234: 2, 19233: 2, 19232: 1, 19231: 2, 19230: 7, 19229: 5, 19228: 2, 19227: 3, 19226: 3, 19225: 9, 19224: 12, 19223: 7, 19222: 7, 19221: 9, 19220: 0, 19219: 1, 19218: 2, 19217: 2, 19216: 0, 19215: 6, 19214: 3, 19213: 3, 19212: 3, 19211: 1, 19210: 0, 19209: 1, 19208: 4, 19207: 0, 19206: 1, 19205: 2, 19204: 2, 19203: 6, 19202: 11, 19201: 14, 19200: 13, 19199: 4, 19198: 6, 19197: 5, 19196: 11, 19195: 7, 19194: 11, 19193: 1, 19192: 1, 19191: 1, 19190: 9, 19189: 0, 19188: 0, 19187: 2, 19186: 2, 19185: 11, 19184: 3, 19183: 1, 19182: 2, 19181: 2, 19180: 7, 19179: 4, 19178: 2, 19177: 0, 19176: 7, 19175: 6, 19174: 6, 19173: 1, 19172: 4, 19171: 3, 19170: 6, 19169: 0, 19168: 2, 19167: 4, 19166: 4, 19165: 4, 19164: 10, 19163: 2, 19162: 3, 19161: 1, 19160: 2, 19159: 2, 19158: 2, 19157: 1, 19156: 1, 19155: 4, 19154: 2, 19153: 4, 19152: 3, 19151: 1, 19150: 3, 19149: 1, 19148: 2, 19147: 4, 19146: 1, 19145: 3, 19144: 1, 19143: 4, 19142: 5, 19141: 0, 19140: 1, 19139: 1, 19138: 2, 19137: 3, 19136: 3, 19135: 7, 19134: 1, 19133: 2, 19132: 4, 19131: 7, 19130: 3, 19129: 4, 19128: 2, 19127: 2, 19126: 1, 19125: 2, 19124: 2, 19123: 3, 19122: 0, 19121: 2, 19120: 5, 19119: 5, 19118: 4, 19117: 3, 19116: 5, 19115: 1, 19114: 3, 19113: 3, 19112: 0, 19111: 1, 19110: 3, 19109: 5, 19108: 7, 19107: 1, 19106: 3, 19105: 6, 19104: 12, 19103: 3, 19102: 3, 19101: 10, 19100: 6, 19099: 6, 19098: 2, 19097: 2, 19096: 7, 19095: 2, 19094: 2, 19093: 12, 19092: 1, 19091: 0, 19090: 3, 19089: 6, 19088: 18, 19087: 4, 19086: 4, 19085: 0, 19084: 9, 19083: 2, 19082: 3, 19081: 5, 19080: 9, 19079: 15, 19078: 8, 19077: 2, 19076: 2, 19075: 0, 19074: 4, 19073: 2, 19072: 3, 19071: 7, 19070: 3, 19069: 1, 19068: 3, 19067: 1, 19066: 5, 19065: 2, 19064: 0, 19063: 1, 19062: 0, 19061: 7, 19060: 2, 19059: 3, 19058: 4, 19057: 8, 19056: 5, 19055: 8, 19054: 8, 19053: 6, 19052: 18, 19051: 7, 19050: 1, 19049: 7, 19048: 0, 19047: 0, 19046: 1, 19045: 1, 19044: 2, 19043: 3, 19042: 3, 19041: 3, 19040: 1, 19039: 0, 19038: 2, 19037: 1, 19036: 1, 19035: 3, 19034: 7, 19033: 4, 19032: 3, 19031: 4, 19030: 0, 19029: 4, 19028: 1, 19027: 1, 19026: 8, 19025: 4, 19024: 1, 19023: 1, 19022: 2, 19021: 8, 19020: 3, 19019: 3, 19018: 3, 19017: 1, 19016: 3, 19015: 4, 19014: 2, 19013: 0, 19012: 12, 19011: 7, 19010: 0, 19009: 1, 19008: 4, 19007: 4, 19006: 2, 19005: 3, 19004: 9, 19003: 2, 19002: 9, 19001: 6, 19000: 6, 18999: 5, 18998: 6, 18997: 4, 18996: 0, 18995: 5, 18994: 4, 18993: 8, 18992: 3, 18991: 3, 18990: 2, 18989: 5, 18988: 1, 18987: 1, 18986: 0, 18985: 3, 18984: 4, 18983: 1, 18982: 3, 18981: 4, 18980: 4, 18979: 1, 18978: 1, 18977: 2, 18976: 3, 18975: 6, 18974: 7, 18973: 5, 18972: 11, 18971: 17, 18970: 1, 18969: 0, 18968: 2, 18967: 5, 18966: 7, 18965: 4, 18964: 1, 18963: 3, 18962: 4, 18961: 3, 18960: 14, 18959: 14, 18958: 12, 18957: 53, 18956: 1, 18955: 1, 18954: 2, 18953: 5, 18952: 9, 18951: 1, 18950: 4, 18949: 3, 18948: 1, 18947: 3, 18946: 2, 18945: 2, 18944: 7, 18943: 1, 18942: 2, 18941: 5, 18940: 1, 18939: 1, 18938: 5, 18937: 4, 18936: 11, 18935: 0, 18934: 2, 18933: 1, 18932: 3, 18931: 5, 18930: 7, 18929: 4, 18928: 2, 18927: 0, 18926: 2, 18925: 2, 18924: 2, 18923: 2, 18922: 2, 18921: 2, 18920: 4, 18919: 2, 18918: 4, 18917: 3, 18916: 12, 18915: 4, 18914: 5, 18913: 1, 18912: 0, 18911: 4, 18910: 6, 18909: 2, 18908: 5, 18907: 4, 18906: 3, 18905: 5, 18904: 3, 18903: 0, 18902: 2, 18901: 3, 18900: 2, 18899: 4, 18898: 4, 18897: 4, 18896: 2, 18895: 2, 18894: 2, 18893: 2, 18892: 1, 18891: 5, 18890: 9, 18889: 1, 18888: 1, 18887: 3, 18886: 4, 18885: 3, 18884: 3, 18883: 8, 18882: 3, 18881: 2, 18880: 3, 18879: 4, 18878: 5, 18877: 4, 18876: 3, 18875: 3, 18874: 8, 18873: 1, 18872: 1, 18871: 22, 18870: 11, 18869: 3, 18868: 1, 18867: 3, 18866: 2, 18865: 1, 18864: 2, 18863: 7, 18862: 2, 18861: 7, 18860: 5, 18859: 5, 18858: 6, 18857: 8, 18856: 4, 18855: 4, 18854: 2, 18853: 13, 18852: 14, 18851: 3, 18850: 1, 18849: 4, 18848: 3, 18847: 2, 18846: 1, 18845: 0, 18844: 12, 18843: 3, 18842: 1, 18841: 4, 18840: 2, 18839: 1, 18838: 3, 18837: 4, 18836: 0, 18835: 6, 18834: 3, 18833: 3, 18832: 4, 18831: 0, 18830: 2, 18829: 4, 18828: 4, 18827: 1, 18826: 10, 18825: 1, 18824: 3, 18823: 4, 18822: 8, 18821: 4, 18820: 6, 18819: 2, 18818: 2, 18817: 3, 18816: 2, 18815: 1, 18814: 5, 18813: 3, 18812: 9, 18811: 0, 18810: 4, 18809: 6, 18808: 7, 18807: 2, 18806: 1, 18805: 4, 18804: 3, 18803: 2, 18802: 2, 18801: 10, 18800: 10, 18799: 4, 18798: 5, 18797: 5, 18796: 3, 18795: 3, 18794: 6, 18793: 6, 18792: 4, 18791: 0, 18790: 1, 18789: 0, 18788: 4, 18787: 3, 18786: 1, 18785: 0, 18784: 1, 18783: 2, 18782: 2, 18781: 1, 18780: 0, 18779: 0, 18778: 2, 18777: 1, 18776: 0, 18775: 1, 18774: 1, 18773: 3, 18772: 0, 18771: 4, 18770: 4, 18769: 3, 18768: 4, 18767: 2, 18766: 1, 18765: 1, 18764: 6, 18763: 1, 18762: 4, 18761: 5, 18760: 7, 18759: 1, 18758: 10, 18757: 1, 18756: 0, 18755: 1, 18754: 5, 18753: 1, 18752: 1, 18751: 1, 18750: 10, 18749: 4, 18748: 4, 18747: 2, 18746: 2, 18745: 1, 18744: 3, 18743: 1, 18742: 2, 18741: 4, 18740: 0, 18739: 8, 18738: 3, 18737: 3, 18736: 3, 18735: 5, 18734: 2, 18733: 2, 18732: 2, 18731: 5, 18730: 1, 18729: 7, 18728: 2, 18727: 4, 18726: 1, 18725: 1, 18724: 12, 18723: 3, 18722: 3, 18721: 0, 18720: 3, 18719: 0, 18718: 0, 18717: 1, 18716: 3, 18715: 4, 18714: 0, 18713: 2, 18712: 2, 18711: 7, 18710: 3, 18709: 1, 18708: 2, 18707: 3, 18706: 7, 18705: 2, 18704: 9, 18703: 6, 18702: 4, 18701: 1, 18700: 3, 18699: 4, 18698: 3, 18697: 7, 18696: 1, 18695: 4, 18694: 5, 18693: 7, 18692: 8, 18691: 11, 18690: 11, 18689: 7, 18688: 5, 18687: 4, 18686: 10, 18685: 12, 18684: 2, 18683: 1, 18682: 1, 18681: 0, 18680: 6, 18679: 5, 18678: 8, 18677: 6, 18676: 0, 18675: 2, 18674: 3, 18673: 5, 18672: 5, 18671: 3, 18670: 1, 18669: 1, 18668: 2, 18667: 2, 18666: 2, 18665: 4, 18664: 2, 18663: 5, 18662: 4, 18661: 6, 18660: 8, 18659: 2, 18658: 1, 18657: 3, 18656: 1, 18655: 2, 18654: 1, 18653: 3, 18652: 2, 18651: 1, 18650: 3, 18649: 7, 18648: 1, 18647: 2, 18646: 1, 18645: 5, 18644: 12, 18643: 3, 18642: 3, 18641: 6, 18640: 1, 18639: 2, 18638: 1, 18637: 4, 18636: 4, 18635: 5, 18634: 3, 18633: 6, 18632: 2, 18631: 4, 18630: 6, 18629: 4, 18628: 7, 18627: 1, 18626: 5, 18625: 13, 18624: 1, 18623: 5, 18622: 1, 18621: 1, 18620: 2, 18619: 6, 18618: 4, 18617: 6, 18616: 4, 18615: 5, 18614: 0, 18613: 5, 18612: 3, 18611: 3, 18610: 4, 18609: 3, 18608: 4, 18607: 1, 18606: 1, 18605: 1, 18604: 0, 18603: 0, 18602: 1, 18601: 25, 18600: 1, 18599: 3, 18598: 10, 18597: 3, 18596: 0, 18595: 11, 18594: 2, 18593: 3, 18592: 2, 18591: 1, 18590: 9, 18589: 1, 18588: 1, 18587: 1, 18586: 1, 18585: 2, 18584: 3, 18583: 4, 18582: 5, 18581: 5, 18580: 5, 18579: 2, 18578: 3, 18577: 3, 18576: 5, 18575: 3, 18574: 3, 18573: 4, 18572: 1, 18571: 1, 18570: 2, 18569: 7, 18568: 4, 18567: 7, 18566: 3, 18565: 0, 18564: 3, 18563: 2, 18562: 2, 18561: 8, 18560: 4, 18559: 3, 18558: 1, 18557: 0, 18556: 2, 18555: 2, 18554: 13, 18553: 1, 18552: 2, 18551: 2, 18550: 2, 18549: 2, 18548: 4, 18547: 2, 18546: 7, 18545: 4, 18544: 1, 18543: 6, 18542: 1, 18541: 10, 18540: 2, 18539: 2, 18538: 1, 18537: 5, 18536: 6, 18535: 10, 18534: 11, 18533: 1, 18532: 6, 18531: 2, 18530: 3, 18529: 2, 18528: 1, 18527: 3, 18526: 4, 18525: 8, 18524: 4, 18523: 4, 18522: 2, 18521: 3, 18520: 2, 18519: 2, 18518: 3, 18517: 1, 18516: 2, 18515: 1, 18514: 1, 18513: 3, 18512: 6, 18511: 4, 18510: 9, 18509: 9, 18508: 11, 18507: 11, 18506: 19, 18505: 2, 18504: 1, 18503: 1, 18502: 5, 18501: 3, 18500: 3, 18499: 3, 18498: 3, 18497: 4, 18496: 3, 18495: 2, 18494: 5, 18493: 1, 18492: 2, 18491: 0, 18490: 3, 18489: 5, 18488: 18, 18487: 18, 18486: 26, 18485: 1, 18484: 25, 18483: 18, 18482: 22, 18481: 21, 18480: 23, 18479: 3, 18478: 21, 18477: 3, 18476: 23, 18475: 19, 18474: 2, 18473: 19, 18472: 16, 18471: 17, 18470: 2, 18469: 1, 18468: 3, 18467: 6, 18466: 3, 18465: 3, 18464: 1, 18463: 3, 18462: 2, 18461: 2, 18460: 2, 18459: 5, 18458: 0, 18457: 1, 18456: 0, 18455: 1, 18454: 11, 18453: 7, 18452: 2, 18451: 1, 18450: 2, 18449: 2, 18448: 6, 18447: 3, 18446: 8, 18445: 7, 18444: 8, 18443: 4, 18442: 9, 18441: 1, 18440: 1, 18439: 4, 18438: 8, 18437: 5, 18436: 9, 18435: 15, 18434: 2, 18433: 2, 18432: 1, 18431: 6, 18430: 4, 18429: 3, 18428: 5, 18427: 2, 18426: 3, 18425: 3, 18424: 2, 18423: 3, 18422: 1, 18421: 5, 18420: 3, 18419: 3, 18418: 5, 18417: 7, 18416: 6, 18415: 2, 18414: 0, 18413: 4, 18412: 2, 18411: 2, 18410: 2, 18409: 2, 18408: 0, 18407: 4, 18406: 0, 18405: 0, 18404: 1, 18403: 1, 18402: 4, 18401: 1, 18400: 0, 18399: 4, 18398: 8, 18397: 1, 18396: 1, 18395: 1, 18394: 4, 18393: 1, 18392: 3, 18391: 6, 18390: 0, 18389: 12, 18388: 22, 18387: 23, 18386: 25, 18385: 18, 18384: 4, 18383: 2, 18382: 1, 18381: 6, 18380: 5, 18379: 5, 18378: 7, 18377: 1, 18376: 2, 18375: 1, 18374: 2, 18373: 2, 18372: 6, 18371: 0, 18370: 2, 18369: 6, 18368: 2, 18367: 17, 18366: 2, 18365: 1, 18364: 0, 18363: 1, 18362: 3, 18361: 3, 18360: 2, 18359: 3, 18358: 2, 18357: 10, 18356: 6, 18355: 11, 18354: 0, 18353: 5, 18352: 12, 18351: 2, 18350: 1, 18349: 5, 18348: 8, 18347: 5, 18346: 2, 18345: 1, 18344: 1, 18343: 2, 18342: 4, 18341: 4, 18340: 3, 18339: 5, 18338: 7, 18337: 2, 18336: 1, 18335: 5, 18334: 2, 18333: 8, 18332: 11, 18331: 6, 18330: 8, 18329: 9, 18328: 9, 18327: 7, 18326: 12, 18325: 7, 18324: 5, 18323: 9, 18322: 2, 18321: 1, 18320: 2, 18319: 1, 18318: 1, 18317: 2, 18316: 1, 18315: 2, 18314: 6, 18313: 4, 18312: 1, 18311: 8, 18310: 1, 18309: 5, 18308: 8, 18307: 4, 18306: 1, 18305: 5, 18304: 3, 18303: 3, 18302: 1, 18301: 0, 18300: 1, 18299: 0, 18298: 1, 18297: 2, 18296: 4, 18295: 1, 18294: 3, 18293: 2, 18292: 3, 18291: 1, 18290: 1, 18289: 3, 18288: 6, 18287: 5, 18286: 12, 18285: 4, 18284: 4, 18283: 2, 18282: 2, 18281: 1, 18280: 2, 18279: 2, 18278: 1, 18277: 3, 18276: 1, 18275: 3, 18274: 4, 18273: 2, 18272: 1, 18271: 2, 18270: 3, 18269: 5, 18268: 2, 18267: 15, 18266: 11, 18265: 1, 18264: 3, 18263: 8, 18262: 6, 18261: 13, 18260: 5, 18259: 11, 18258: 5, 18257: 3, 18256: 3, 18255: 2, 18254: 4, 18253: 3, 18252: 2, 18251: 3, 18250: 3, 18249: 7, 18248: 10, 18247: 8, 18246: 5, 18245: 4, 18244: 8, 18243: 9, 18242: 5, 18241: 2, 18240: 1, 18239: 0, 18238: 1, 18237: 0, 18236: 2, 18235: 0, 18234: 0, 18233: 3, 18232: 2, 18231: 4, 18230: 5, 18229: 1, 18228: 1, 18227: 2, 18226: 1, 18225: 3, 18224: 5, 18223: 3, 18222: 19, 18221: 6, 18220: 5, 18219: 10, 18218: 1, 18217: 3, 18216: 3, 18215: 6, 18214: 7, 18213: 3, 18212: 6, 18211: 4, 18210: 2, 18209: 6, 18208: 7, 18207: 3, 18206: 4, 18205: 3, 18204: 3, 18203: 3, 18202: 15, 18201: 3, 18200: 4, 18199: 2, 18198: 2, 18197: 3, 18196: 2, 18195: 1, 18194: 2, 18193: 8, 18192: 5, 18191: 4, 18190: 7, 18189: 2, 18188: 2, 18187: 2, 18186: 5, 18185: 3, 18184: 4, 18183: 3, 18182: 3, 18181: 3, 18180: 21, 18179: 4, 18178: 1, 18177: 3, 18176: 0, 18175: 2, 18174: 3, 18173: 1, 18172: 2, 18171: 2, 18170: 1, 18169: 0, 18168: 1, 18167: 0, 18166: 1, 18165: 9, 18164: 3, 18163: 5, 18162: 4, 18161: 5, 18160: 3, 18159: 7, 18158: 2, 18157: 2, 18156: 6, 18155: 0, 18154: 3, 18153: 5, 18152: 0, 18151: 6, 18150: 5, 18149: 2, 18148: 7, 18147: 3, 18146: 9, 18145: 4, 18144: 2, 18143: 0, 18142: 1, 18141: 5, 18140: 1, 18139: 1, 18138: 2, 18137: 5, 18136: 6, 18135: 16, 18134: 6, 18133: 9, 18132: 3, 18131: 1, 18130: 2, 18129: 2, 18128: 2, 18127: 2, 18126: 5, 18125: 2, 18124: 3, 18123: 3, 18122: 1, 18121: 1, 18120: 5, 18119: 1, 18118: 1, 18117: 2, 18116: 4, 18115: 2, 18114: 1, 18113: 1, 18112: 8, 18111: 1, 18110: 6, 18109: 8, 18108: 4, 18107: 3, 18106: 2, 18105: 3, 18104: 1, 18103: 3, 18102: 1, 18101: 8, 18100: 4, 18099: 4, 18098: 2, 18097: 3, 18096: 1, 18095: 2, 18094: 5, 18093: 4, 18092: 2, 18091: 4, 18090: 14, 18089: 3, 18088: 5, 18087: 0, 18086: 6, 18085: 16, 18084: 27, 18083: 17, 18082: 25, 18081: 16, 18080: 0, 18079: 1, 18078: 10, 18077: 2, 18076: 2, 18075: 2, 18074: 5, 18073: 2, 18072: 2, 18071: 2, 18070: 0, 18069: 0, 18068: 3, 18067: 3, 18066: 1, 18065: 1, 18064: 1, 18063: 2, 18062: 3, 18061: 2, 18060: 1, 18059: 1, 18058: 3, 18057: 9, 18056: 5, 18055: 4, 18054: 3, 18053: 3, 18052: 3, 18051: 2, 18050: 1, 18049: 1, 18048: 3, 18047: 4, 18046: 4, 18045: 2, 18044: 1, 18043: 1, 18042: 7, 18041: 2, 18040: 5, 18039: 16, 18038: 16, 18037: 15, 18036: 5, 18035: 1, 18034: 5, 18033: 2, 18032: 3, 18031: 5, 18030: 1, 18029: 6, 18028: 4, 18027: 3, 18026: 2, 18025: 1, 18024: 2, 18023: 4, 18022: 2, 18021: 2, 18020: 7, 18019: 4, 18018: 5, 18017: 3, 18016: 8, 18015: 7, 18014: 3, 18013: 4, 18012: 3, 18011: 1, 18010: 9, 18009: 4, 18008: 4, 18007: 3, 18006: 2, 18005: 2, 18004: 2, 18003: 2, 18002: 2, 18001: 5, 18000: 1, 17999: 2, 17998: 0, 17997: 2, 17996: 0, 17995: 0, 17994: 1, 17993: 2, 17992: 7, 17991: 3, 17990: 1, 17989: 0, 17988: 2, 17987: 0, 17986: 1, 17985: 2, 17984: 1, 17983: 2, 17982: 5, 17981: 4, 17980: 6, 17979: 2, 17978: 1, 17977: 2, 17976: 1, 17975: 2, 17974: 4, 17973: 0, 17972: 0, 17971: 1, 17970: 2, 17969: 9, 17968: 0, 17967: 2, 17966: 4, 17965: 1, 17964: 4, 17963: 1, 17962: 5, 17961: 0, 17960: 9, 17959: 8, 17958: 3, 17957: 1, 17956: 1, 17955: 4, 17954: 0, 17953: 0, 17952: 5, 17951: 1, 17950: 1, 17949: 1, 17948: 2, 17947: 3, 17946: 1, 17945: 4, 17944: 5, 17943: 1, 17942: 1, 17941: 3, 17940: 1, 17939: 3, 17938: 2, 17937: 1, 17936: 0, 17935: 6, 17934: 5, 17933: 4, 17932: 1, 17931: 1, 17930: 4, 17929: 12, 17928: 2, 17927: 1, 17926: 1, 17925: 11, 17924: 6, 17923: 2, 17922: 3, 17921: 0, 17920: 3, 17919: 1, 17918: 1, 17917: 2, 17916: 1, 17915: 2, 17914: 4, 17913: 3, 17912: 3, 17911: 2, 17910: 1, 17909: 8, 17908: 0, 17907: 0, 17906: 2, 17905: 0, 17904: 4, 17903: 2, 17902: 5, 17901: 0, 17900: 3, 17899: 0, 17898: 1, 17897: 2, 17896: 9, 17895: 4, 17894: 8, 17893: 0, 17892: 1, 17891: 3, 17890: 6, 17889: 2, 17888: 29, 17887: 1, 17886: 5, 17885: 0, 17884: 1, 17883: 1, 17882: 3, 17881: 10, 17880: 1, 17879: 3, 17878: 3, 17877: 1, 17876: 2, 17875: 0, 17874: 4, 17873: 3, 17872: 1, 17871: 1, 17870: 1, 17869: 2, 17868: 1, 17867: 1, 17866: 3, 17865: 0, 17864: 1, 17863: 1, 17862: 2, 17861: 3, 17860: 0, 17859: 5, 17858: 2, 17857: 0, 17856: 0, 17855: 2, 17854: 8, 17853: 9, 17852: 5, 17851: 1, 17850: 2, 17849: 2, 17848: 3, 17847: 3, 17846: 2, 17845: 3, 17844: 2, 17843: 6, 17842: 3, 17841: 2, 17840: 3, 17839: 5, 17838: 2, 17837: 5, 17836: 5, 17835: 6, 17834: 1, 17833: 2, 17832: 1, 17831: 1, 17830: 0, 17829: 1, 17828: 1, 17827: 0, 17826: 6, 17825: 2, 17824: 2, 17823: 5, 17822: 1, 17821: 3, 17820: 3, 17819: 2, 17818: 3, 17817: 4, 17816: 2, 17815: 2, 17814: 7, 17813: 0, 17812: 5, 17811: 2, 17810: 8, 17809: 5, 17808: 0, 17807: 2, 17806: 0, 17805: 0, 17804: 2, 17803: 1, 17802: 0, 17801: 3, 17800: 0, 17799: 1, 17798: 1, 17797: 3, 17796: 4, 17795: 0, 17794: 2, 17793: 0, 17792: 10, 17791: 23, 17790: 2, 17789: 0, 17788: 1, 17787: 3, 17786: 8, 17785: 3, 17784: 3, 17783: 1, 17782: 4, 17781: 1, 17780: 1, 17779: 2, 17778: 4, 17777: 5, 17776: 2, 17775: 2, 17774: 5, 17773: 0, 17772: 6, 17771: 4, 17770: 1, 17769: 2, 17768: 1, 17767: 2, 17766: 9, 17765: 3, 17764: 3, 17763: 3, 17762: 1, 17761: 1, 17760: 3, 17759: 3, 17758: 2, 17757: 2, 17756: 4, 17755: 5, 17754: 1, 17753: 0, 17752: 1, 17751: 1, 17750: 7, 17749: 4, 17748: 5, 17747: 0, 17746: 9, 17745: 3, 17744: 4, 17743: 2, 17742: 2, 17741: 2, 17740: 3, 17739: 7, 17738: 3, 17737: 4, 17736: 3, 17735: 2, 17734: 3, 17733: 2, 17732: 1, 17731: 4, 17730: 4, 17729: 3, 17728: 3, 17727: 0, 17726: 4, 17725: 4, 17724: 4, 17723: 2, 17722: 3, 17721: 6, 17720: 1, 17719: 4, 17718: 2, 17717: 4, 17716: 1, 17715: 10, 17714: 9, 17713: 2, 17712: 1, 17711: 2, 17710: 1, 17709: 8, 17708: 4, 17707: 7, 17706: 5, 17705: 1, 17704: 6, 17703: 3, 17702: 0, 17701: 1, 17700: 3, 17699: 1, 17698: 3, 17697: 3, 17696: 12, 17695: 2, 17694: 4, 17693: 0, 17692: 1, 17691: 2, 17690: 2, 17689: 2, 17688: 1, 17687: 2, 17686: 1, 17685: 11, 17684: 1, 17683: 0, 17682: 4, 17681: 1, 17680: 1, 17679: 4, 17678: 3, 17677: 1, 17676: 2, 17675: 3, 17674: 0, 17673: 0, 17672: 7, 17671: 2, 17670: 2, 17669: 5, 17668: 2, 17667: 3, 17666: 3, 17665: 0, 17664: 4, 17663: 2, 17662: 1, 17661: 2, 17660: 3, 17659: 0, 17658: 1, 17657: 1, 17656: 1, 17655: 11, 17654: 2, 17653: 11, 17652: 1, 17651: 3, 17650: 7, 17649: 1, 17648: 1, 17647: 4, 17646: 6, 17645: 9, 17644: 7, 17643: 2, 17642: 5, 17641: 0, 17640: 0, 17639: 1, 17638: 4, 17637: 3, 17636: 14, 17635: 2, 17634: 2, 17633: 2, 17632: 1, 17631: 0, 17630: 6, 17629: 7, 17628: 6, 17627: 1, 17626: 1, 17625: 0, 17624: 1, 17623: 3, 17622: 1, 17621: 1, 17620: 0, 17619: 3, 17618: 8, 17617: 1, 17616: 2, 17615: 4, 17614: 3, 17613: 5, 17612: 9, 17611: 0, 17610: 5, 17609: 3, 17608: 1, 17607: 1, 17606: 2, 17605: 7, 17604: 1, 17603: 12, 17602: 2, 17601: 2, 17600: 0, 17599: 1, 17598: 7, 17597: 2, 17596: 2, 17595: 4, 17594: 4, 17593: 1, 17592: 2, 17591: 5, 17590: 0, 17589: 1, 17588: 8, 17587: 4, 17586: 3, 17585: 6, 17584: 1, 17583: 1, 17582: 4, 17581: 6, 17580: 1, 17579: 0, 17578: 3, 17577: 4, 17576: 4, 17575: 0, 17574: 6, 17573: 3, 17572: 2, 17571: 2, 17570: 0, 17569: 1, 17568: 2, 17567: 2, 17566: 0, 17565: 3, 17564: 9, 17563: 0, 17562: 2, 17561: 2, 17560: 3, 17559: 0, 17558: 1, 17557: 3, 17556: 2, 17555: 6, 17554: 2, 17553: 0, 17552: 4, 17551: 3, 17550: 2, 17549: 7, 17548: 1, 17547: 2, 17546: 0, 17545: 3, 17544: 3, 17543: 1, 17542: 2, 17541: 4, 17540: 3, 17539: 1, 17538: 1, 17537: 6, 17536: 5, 17535: 4, 17534: 4, 17533: 3, 17532: 2, 17531: 0, 17530: 6, 17529: 7, 17528: 3, 17527: 0, 17526: 2, 17525: 2, 17524: 2, 17523: 1, 17522: 0, 17521: 3, 17520: 2, 17519: 0, 17518: 1, 17517: 1, 17516: 8, 17515: 2, 17514: 5, 17513: 8, 17512: 5, 17511: 5, 17510: 1, 17509: 3, 17508: 4, 17507: 3, 17506: 1, 17505: 6, 17504: 4, 17503: 13, 17502: 6, 17501: 1, 17500: 7, 17499: 2, 17498: 4, 17497: 1, 17496: 5, 17495: 7, 17494: 4, 17493: 4, 17492: 5, 17491: 2, 17490: 7, 17489: 4, 17488: 7, 17487: 0, 17486: 2, 17485: 5, 17484: 1, 17483: 4, 17482: 2, 17481: 2, 17480: 0, 17479: 2, 17478: 1, 17477: 4, 17476: 0, 17475: 1, 17474: 2, 17473: 3, 17472: 5, 17471: 2, 17470: 7, 17469: 2, 17468: 3, 17467: 1, 17466: 1, 17465: 4, 17464: 1, 17463: 1, 17462: 3, 17461: 1, 17460: 3, 17459: 3, 17458: 4, 17457: 1, 17456: 1, 17455: 1, 17454: 5, 17453: 0, 17452: 2, 17451: 0, 17450: 12, 17449: 1, 17448: 2, 17447: 2, 17446: 4, 17445: 4, 17444: 6, 17443: 5, 17442: 4, 17441: 1, 17440: 0, 17439: 11, 17438: 5, 17437: 3, 17436: 3, 17435: 0, 17434: 0, 17433: 3, 17432: 2, 17431: 2, 17430: 1, 17429: 3, 17428: 3, 17427: 7, 17426: 3, 17425: 1, 17424: 3, 17423: 7, 17422: 0, 17421: 0, 17420: 2, 17419: 5, 17418: 0, 17417: 2, 17416: 4, 17415: 2, 17414: 2, 17413: 2, 17412: 3, 17411: 2, 17410: 0, 17409: 1, 17408: 1, 17407: 6, 17406: 2, 17405: 7, 17404: 0, 17403: 0, 17402: 4, 17401: 3, 17400: 0, 17399: 1, 17398: 2, 17397: 7, 17396: 2, 17395: 1, 17394: 1, 17393: 1, 17392: 5, 17391: 3, 17390: 0, 17389: 2, 17388: 2, 17387: 2, 17386: 4, 17385: 1, 17384: 1, 17383: 2, 17382: 2, 17381: 3, 17380: 3, 17379: 0, 17378: 2, 17377: 1, 17376: 3, 17375: 3, 17374: 5, 17373: 7, 17372: 2, 17371: 1, 17370: 4, 17369: 2, 17368: 2, 17367: 0, 17366: 0, 17365: 1, 17364: 1, 17363: 3, 17362: 2, 17361: 2, 17360: 1, 17359: 5, 17358: 8, 17357: 4, 17356: 4, 17355: 7, 17354: 3, 17353: 4, 17352: 8, 17351: 0, 17350: 2, 17349: 4, 17348: 5, 17347: 4, 17346: 4, 17345: 0, 17344: 2, 17343: 1, 17342: 5, 17341: 1, 17340: 0, 17339: 3, 17338: 3, 17337: 5, 17336: 1, 17335: 2, 17334: 3, 17333: 2, 17332: 0, 17331: 11, 17330: 4, 17329: 19, 17328: 17, 17327: 5, 17326: 7, 17325: 3, 17324: 5, 17323: 1, 17322: 2, 17321: 3, 17320: 5, 17319: 1, 17318: 4, 17317: 5, 17316: 4, 17315: 2, 17314: 5, 17313: 9, 17312: 6, 17311: 1, 17310: 2, 17309: 18, 17308: 0, 17307: 2, 17306: 1, 17305: 3, 17304: 7, 17303: 7, 17302: 0, 17301: 3, 17300: 1, 17299: 8, 17298: 0, 17297: 7, 17296: 4, 17295: 1, 17294: 1, 17293: 2, 17292: 3, 17291: 4, 17290: 4, 17289: 7, 17288: 1, 17287: 3, 17286: 7, 17285: 6, 17284: 2, 17283: 2, 17282: 6, 17281: 3, 17280: 2, 17279: 0, 17278: 1, 17277: 0, 17276: 1, 17275: 2, 17274: 4, 17273: 1, 17272: 2, 17271: 2, 17270: 1, 17269: 3, 17268: 1, 17267: 2, 17266: 2, 17265: 3, 17264: 0, 17263: 3, 17262: 4, 17261: 0, 17260: 0, 17259: 0, 17258: 2, 17257: 0, 17256: 5, 17255: 2, 17254: 2, 17253: 6, 17252: 1, 17251: 1, 17250: 0, 17249: 4, 17248: 3, 17247: 3, 17246: 4, 17245: 3, 17244: 2, 17243: 1, 17242: 0, 17241: 2, 17240: 1, 17239: 7, 17238: 5, 17237: 2, 17236: 24, 17235: 2, 17234: 2, 17233: 2, 17232: 4, 17231: 2, 17230: 0, 17229: 2, 17228: 2, 17227: 4, 17226: 2, 17225: 0, 17224: 3, 17223: 2, 17222: 5, 17221: 1, 17220: 2, 17219: 4, 17218: 3, 17217: 3, 17216: 1, 17215: 0, 17214: 2, 17213: 3, 17212: 4, 17211: 5, 17210: 0, 17209: 3, 17208: 4, 17207: 4, 17206: 1, 17205: 3, 17204: 1, 17203: 1, 17202: 5, 17201: 5, 17200: 2, 17199: 0, 17198: 2, 17197: 6, 17196: 2, 17195: 2, 17194: 2, 17193: 2, 17192: 6, 17191: 2, 17190: 1, 17189: 15, 17188: 4, 17187: 2, 17186: 4, 17185: 3, 17184: 5, 17183: 2, 17182: 5, 17181: 3, 17180: 1, 17179: 9, 17178: 2, 17177: 0, 17176: 4, 17175: 6, 17174: 3, 17173: 2, 17172: 13, 17171: 16, 17170: 3, 17169: 6, 17168: 23, 17167: 41, 17166: 5, 17165: 6, 17164: 5, 17163: 33, 17162: 1, 17161: 3, 17160: 6, 17159: 7, 17158: 7, 17157: 6, 17156: 7, 17155: 7, 17154: 1, 17153: 7, 17152: 5, 17151: 2, 17150: 2, 17149: 2, 17148: 1, 17147: 3, 17146: 1, 17145: 1, 17144: 5, 17143: 2, 17142: 0, 17141: 5, 17140: 6, 17139: 11, 17138: 2, 17137: 3, 17136: 1, 17135: 5, 17134: 1, 17133: 2, 17132: 2, 17131: 5, 17130: 0, 17129: 11, 17128: 4, 17127: 3, 17126: 5, 17125: 3, 17124: 16, 17123: 15, 17122: 4, 17121: 4, 17120: 3, 17119: 6, 17118: 1, 17117: 3, 17116: 4, 17115: 6, 17114: 4, 17113: 3, 17112: 4, 17111: 1, 17110: 5, 17109: 2, 17108: 4, 17107: 1, 17106: 2, 17105: 12, 17104: 3, 17103: 4, 17102: 2, 17101: 1, 17100: 3, 17099: 2, 17098: 0, 17097: 2, 17096: 2, 17095: 3, 17094: 16, 17093: 7, 17092: 3, 17091: 2, 17090: 3, 17089: 3, 17088: 5, 17087: 3, 17086: 2, 17085: 2, 17084: 2, 17083: 4, 17082: 2, 17081: 2, 17080: 1, 17079: 0, 17078: 9, 17077: 4, 17076: 3, 17075: 39, 17074: 5, 17073: 5, 17072: 3, 17071: 1, 17070: 1, 17069: 6, 17068: 0, 17067: 1, 17066: 0, 17065: 1, 17064: 3, 17063: 4, 17062: 1, 17061: 2, 17060: 2, 17059: 2, 17058: 5, 17057: 5, 17056: 5, 17055: 1, 17054: 3, 17053: 15, 17052: 7, 17051: 1, 17050: 2, 17049: 2, 17048: 3, 17047: 3, 17046: 6, 17045: 2, 17044: 3, 17043: 4, 17042: 0, 17041: 1, 17040: 1, 17039: 3, 17038: 9, 17037: 4, 17036: 1, 17035: 2, 17034: 3, 17033: 2, 17032: 17, 17031: 1, 17030: 10, 17029: 2, 17028: 1, 17027: 2, 17026: 1, 17025: 1, 17024: 0, 17023: 7, 17022: 13, 17021: 2, 17020: 2, 17019: 3, 17018: 1, 17017: 6, 17016: 2, 17015: 0, 17014: 1, 17013: 1, 17012: 1, 17011: 1, 17010: 1, 17009: 2, 17008: 3, 17007: 1, 17006: 4, 17005: 4, 17004: 2, 17003: 2, 17002: 6, 17001: 3, 17000: 2, 16999: 1, 16998: 2, 16997: 2, 16996: 2, 16995: 2, 16994: 3, 16993: 9, 16992: 4, 16991: 5, 16990: 5, 16989: 1, 16988: 0, 16987: 0, 16986: 2, 16985: 5, 16984: 1, 16983: 2, 16982: 1, 16981: 2, 16980: 1, 16979: 1, 16978: 3, 16977: 4, 16976: 1, 16975: 0, 16974: 1, 16973: 20, 16972: 17, 16971: 3, 16970: 2, 16969: 2, 16968: 0, 16967: 4, 16966: 12, 16965: 3, 16964: 16, 16963: 5, 16962: 16, 16961: 5, 16960: 10, 16959: 1, 16958: 9, 16957: 7, 16956: 0, 16955: 4, 16954: 2, 16953: 7, 16952: 7, 16951: 4, 16950: 0, 16949: 4, 16948: 2, 16947: 0, 16946: 0, 16945: 0, 16944: 1, 16943: 2, 16942: 5, 16941: 3, 16940: 1, 16939: 9, 16938: 2, 16937: 3, 16936: 2, 16935: 3, 16934: 9, 16933: 5, 16932: 1, 16931: 0, 16930: 5, 16929: 5, 16928: 2, 16927: 3, 16926: 2, 16925: 3, 16924: 1, 16923: 1, 16922: 7, 16921: 1, 16920: 1, 16919: 10, 16918: 2, 16917: 7, 16916: 13, 16915: 5, 16914: 4, 16913: 1, 16912: 3, 16911: 2, 16910: 4, 16909: 4, 16908: 5, 16907: 3, 16906: 2, 16905: 2, 16904: 11, 16903: 5, 16902: 3, 16901: 3, 16900: 1, 16899: 8, 16898: 17, 16897: 1, 16896: 4, 16895: 2, 16894: 1, 16893: 1, 16892: 0, 16891: 4, 16890: 3, 16889: 8, 16888: 3, 16887: 7, 16886: 2, 16885: 4, 16884: 6, 16883: 6, 16882: 8, 16881: 3, 16880: 8, 16879: 4, 16878: 8, 16877: 4, 16876: 3, 16875: 4, 16874: 5, 16873: 1, 16872: 1, 16871: 1, 16870: 2, 16869: 9, 16868: 12, 16867: 15, 16866: 14, 16865: 8, 16864: 5, 16863: 8, 16862: 4, 16861: 2, 16860: 2, 16859: 7, 16858: 5, 16857: 5, 16856: 5, 16855: 3, 16854: 2, 16853: 6, 16852: 2, 16851: 1, 16850: 2, 16849: 1, 16848: 2, 16847: 1, 16846: 1, 16845: 3, 16844: 2, 16843: 1, 16842: 1, 16841: 1, 16840: 1, 16839: 4, 16838: 3, 16837: 1, 16836: 0, 16835: 2, 16834: 6, 16833: 6, 16832: 10, 16831: 3, 16830: 2, 16829: 2, 16828: 2, 16827: 3, 16826: 2, 16825: 2, 16824: 1, 16823: 1, 16822: 5, 16821: 6, 16820: 3, 16819: 6, 16818: 2, 16817: 1, 16816: 2, 16815: 1, 16814: 3, 16813: 11, 16812: 0, 16811: 0, 16810: 1, 16809: 3, 16808: 1, 16807: 2, 16806: 0, 16805: 4, 16804: 1, 16803: 4, 16802: 2, 16801: 5, 16800: 7, 16799: 2, 16798: 3, 16797: 1, 16796: 2, 16795: 2, 16794: 10, 16793: 2, 16792: 8, 16791: 7, 16790: 3, 16789: 2, 16788: 2, 16787: 2, 16786: 14, 16785: 1, 16784: 1, 16783: 2, 16782: 3, 16781: 1, 16780: 1, 16779: 1, 16778: 1, 16777: 3, 16776: 2, 16775: 5, 16774: 2, 16773: 3, 16772: 5, 16771: 8, 16770: 1, 16769: 9, 16768: 3, 16767: 2, 16766: 1, 16765: 3, 16764: 2, 16763: 6, 16762: 7, 16761: 8, 16760: 1, 16759: 5, 16758: 1, 16757: 1, 16756: 12, 16755: 3, 16754: 4, 16753: 4, 16752: 2, 16751: 1, 16750: 2, 16749: 7, 16748: 10, 16747: 8, 16746: 3, 16745: 5, 16744: 2, 16743: 1, 16742: 16, 16741: 1, 16740: 2, 16739: 2, 16738: 2, 16737: 1, 16736: 6, 16735: 3, 16734: 6, 16733: 2, 16732: 7, 16731: 11, 16730: 3, 16729: 2, 16728: 2, 16727: 5, 16726: 4, 16725: 1, 16724: 2, 16723: 1, 16722: 2, 16721: 3, 16720: 2, 16719: 4, 16718: 1, 16717: 5, 16716: 3, 16715: 1, 16714: 1, 16713: 1, 16712: 2, 16711: 1, 16710: 0, 16709: 3, 16708: 1, 16707: 7, 16706: 2, 16705: 0, 16704: 6, 16703: 2, 16702: 3, 16701: 7, 16700: 1, 16699: 4, 16698: 1, 16697: 12, 16696: 9, 16695: 1, 16694: 5, 16693: 8, 16692: 4, 16691: 2, 16690: 3, 16689: 2, 16688: 5, 16687: 12, 16686: 14, 16685: 4, 16684: 5, 16683: 3, 16682: 4, 16681: 1, 16680: 6, 16679: 3, 16678: 3, 16677: 1, 16676: 5, 16675: 1, 16674: 2, 16673: 3, 16672: 4, 16671: 2, 16670: 6, 16669: 1, 16668: 5, 16667: 1, 16666: 3, 16665: 2, 16664: 4, 16663: 2, 16662: 0, 16661: 1, 16660: 2, 16659: 3, 16658: 5, 16657: 2, 16656: 1, 16655: 10, 16654: 1, 16653: 3, 16652: 1, 16651: 0, 16650: 4, 16649: 3, 16648: 5, 16647: 3, 16646: 2, 16645: 0, 16644: 2, 16643: 6, 16642: 2, 16641: 9, 16640: 5, 16639: 2, 16638: 3, 16637: 1, 16636: 0, 16635: 2, 16634: 7, 16633: 10, 16632: 4, 16631: 2, 16630: 4, 16629: 1, 16628: 1, 16627: 2, 16626: 7, 16625: 5, 16624: 4, 16623: 8, 16622: 5, 16621: 1, 16620: 4, 16619: 5, 16618: 4, 16617: 2, 16616: 9, 16615: 6, 16614: 1, 16613: 5, 16612: 5, 16611: 6, 16610: 4, 16609: 4, 16608: 2, 16607: 3, 16606: 8, 16605: 4, 16604: 3, 16603: 8, 16602: 5, 16601: 1, 16600: 5, 16599: 3, 16598: 7, 16597: 10, 16596: 3, 16595: 1, 16594: 5, 16593: 1, 16592: 3, 16591: 3, 16590: 5, 16589: 1, 16588: 1, 16587: 2, 16586: 9, 16585: 2, 16584: 2, 16583: 4, 16582: 3, 16581: 3, 16580: 13, 16579: 4, 16578: 3, 16577: 3, 16576: 5, 16575: 0, 16574: 4, 16573: 1, 16572: 2, 16571: 4, 16570: 1, 16569: 5, 16568: 4, 16567: 3, 16566: 2, 16565: 3, 16564: 3, 16563: 0, 16562: 5, 16561: 2, 16560: 2, 16559: 3, 16558: 3, 16557: 2, 16556: 1, 16555: 5, 16554: 2, 16553: 5, 16552: 1, 16551: 1, 16550: 6, 16549: 1, 16548: 3, 16547: 1, 16546: 2, 16545: 5, 16544: 1, 16543: 5, 16542: 3, 16541: 4, 16540: 4, 16539: 2, 16538: 4, 16537: 7, 16536: 1, 16535: 10, 16534: 1, 16533: 2, 16532: 3, 16531: 4, 16530: 3, 16529: 4, 16528: 0, 16527: 1, 16526: 3, 16525: 3, 16524: 1, 16523: 6, 16522: 1, 16521: 1, 16520: 1, 16519: 1, 16518: 3, 16517: 3, 16516: 5, 16515: 2, 16514: 6, 16513: 1, 16512: 2, 16511: 1, 16510: 3, 16509: 1, 16508: 3, 16507: 3, 16506: 2, 16505: 1, 16504: 4, 16503: 5, 16502: 2, 16501: 0, 16500: 2, 16499: 2, 16498: 0, 16497: 2, 16496: 10, 16495: 1, 16494: 2, 16493: 2, 16492: 1, 16491: 7, 16490: 3, 16489: 4, 16488: 1, 16487: 3, 16486: 5, 16485: 1, 16484: 1, 16483: 2, 16482: 4, 16481: 6, 16480: 1, 16479: 5, 16478: 7, 16477: 2, 16476: 2, 16475: 0, 16474: 1, 16473: 3, 16472: 2, 16471: 2, 16470: 1, 16469: 2, 16468: 1, 16467: 1, 16466: 1, 16465: 12, 16464: 1, 16463: 0, 16462: 0, 16461: 2, 16460: 2, 16459: 5, 16458: 15, 16457: 8, 16456: 8, 16455: 6, 16454: 1, 16453: 4, 16452: 5, 16451: 13, 16450: 4, 16449: 3, 16448: 2, 16447: 1, 16446: 2, 16445: 4, 16444: 3, 16443: 3, 16442: 1, 16441: 0, 16440: 1, 16439: 1, 16438: 6, 16437: 8, 16436: 9, 16435: 5, 16434: 11, 16433: 3, 16432: 1, 16431: 11, 16430: 6, 16429: 2, 16428: 0, 16427: 11, 16426: 1, 16425: 1, 16424: 2, 16423: 0, 16422: 0, 16421: 1, 16420: 4, 16419: 2, 16418: 11, 16417: 7, 16416: 6, 16415: 1, 16414: 2, 16413: 3, 16412: 1, 16411: 3, 16410: 1, 16409: 2, 16408: 6, 16407: 3, 16406: 1, 16405: 0, 16404: 0, 16403: 0, 16402: 2, 16401: 1, 16400: 1, 16399: 1, 16398: 1, 16397: 1, 16396: 9, 16395: 0, 16394: 3, 16393: 10, 16392: 5, 16391: 1, 16390: 0, 16389: 0, 16388: 0, 16387: 0, 16386: 0, 16385: 2, 16384: 2, 16383: 2, 16382: 0, 16381: 1, 16380: 8, 16379: 8, 16378: 11, 16377: 7, 16376: 1, 16375: 3, 16374: 2, 16373: 5, 16372: 0, 16371: 6, 16370: 1, 16369: 2, 16368: 4, 16367: 5, 16366: 3, 16365: 2, 16364: 1, 16363: 2, 16362: 1, 16361: 3, 16360: 1, 16359: 1, 16358: 3, 16357: 0, 16356: 2, 16355: 2, 16354: 3, 16353: 1, 16352: 4, 16351: 0, 16350: 1, 16349: 0, 16348: 4, 16347: 2, 16346: 6, 16345: 4, 16344: 6, 16343: 1, 16342: 0, 16341: 3, 16340: 3, 16339: 15, 16338: 1, 16337: 4, 16336: 3, 16335: 2, 16334: 3, 16333: 1, 16332: 7, 16331: 6, 16330: 10, 16329: 7, 16328: 4, 16327: 2, 16326: 2, 16325: 3, 16324: 2, 16323: 2, 16322: 5, 16321: 0, 16320: 2, 16319: 1, 16318: 6, 16317: 12, 16316: 5, 16315: 1, 16314: 1, 16313: 12, 16312: 9, 16311: 5, 16310: 10, 16309: 1, 16308: 8, 16307: 1, 16306: 3, 16305: 4, 16304: 5, 16303: 15, 16302: 10, 16301: 1, 16300: 3, 16299: 1, 16298: 0, 16297: 3, 16296: 1, 16295: 1, 16294: 1, 16293: 4, 16292: 3, 16291: 3, 16290: 3, 16289: 6, 16288: 6, 16287: 2, 16286: 2, 16285: 4, 16284: 3, 16283: 10, 16282: 4, 16281: 5, 16280: 5, 16279: 3, 16278: 4, 16277: 4, 16276: 1, 16275: 1, 16274: 1, 16273: 1, 16272: 2, 16271: 1, 16270: 2, 16269: 6, 16268: 2, 16267: 3, 16266: 3, 16265: 5, 16264: 1, 16263: 7, 16262: 4, 16261: 10, 16260: 5, 16259: 1, 16258: 7, 16257: 4, 16256: 7, 16255: 6, 16254: 5, 16253: 2, 16252: 2, 16251: 4, 16250: 5, 16249: 7, 16248: 3, 16247: 3, 16246: 2, 16245: 1, 16244: 2, 16243: 0, 16242: 4, 16241: 6, 16240: 5, 16239: 2, 16238: 3, 16237: 8, 16236: 3, 16235: 4, 16234: 4, 16233: 2, 16232: 2, 16231: 2, 16230: 2, 16229: 3, 16228: 6, 16227: 2, 16226: 11, 16225: 9, 16224: 4, 16223: 3, 16222: 3, 16221: 1, 16220: 3, 16219: 27, 16218: 5, 16217: 1, 16216: 4, 16215: 5, 16214: 0, 16213: 0, 16212: 5, 16211: 5, 16210: 3, 16209: 2, 16208: 4, 16207: 3, 16206: 2, 16205: 0, 16204: 4, 16203: 1, 16202: 1, 16201: 7, 16200: 8, 16199: 6, 16198: 2, 16197: 1, 16196: 4, 16195: 4, 16194: 4, 16193: 3, 16192: 10, 16191: 3, 16190: 8, 16189: 4, 16188: 0, 16187: 1, 16186: 5, 16185: 1, 16184: 3, 16183: 3, 16182: 2, 16181: 0, 16180: 2, 16179: 6, 16178: 4, 16177: 3, 16176: 1, 16175: 2, 16174: 1, 16173: 1, 16172: 0, 16171: 2, 16170: 3, 16169: 3, 16168: 4, 16167: 0, 16166: 3, 16165: 5, 16164: 2, 16163: 5, 16162: 7, 16161: 11, 16160: 9, 16159: 3, 16158: 7, 16157: 4, 16156: 2, 16155: 2, 16154: 10, 16153: 1, 16152: 6, 16151: 1, 16150: 5, 16149: 4, 16148: 1, 16147: 3, 16146: 1, 16145: 1, 16144: 0, 16143: 1, 16142: 4, 16141: 6, 16140: 13, 16139: 5, 16138: 6, 16137: 2, 16136: 3, 16135: 0, 16134: 9, 16133: 2, 16132: 2, 16131: 2, 16130: 8, 16129: 4, 16128: 10, 16127: 7, 16126: 5, 16125: 4, 16124: 2, 16123: 1, 16122: 21, 16121: 1, 16120: 2, 16119: 8, 16118: 1, 16117: 3, 16116: 1, 16115: 2, 16114: 2, 16113: 2, 16112: 8, 16111: 4, 16110: 5, 16109: 5, 16108: 2, 16107: 5, 16106: 7, 16105: 2, 16104: 3, 16103: 2, 16102: 2, 16101: 2, 16100: 2, 16099: 4, 16098: 1, 16097: 6, 16096: 5, 16095: 8, 16094: 5, 16093: 10, 16092: 7, 16091: 1, 16090: 6, 16089: 4, 16088: 4, 16087: 2, 16086: 5, 16085: 3, 16084: 5, 16083: 4, 16082: 3, 16081: 3, 16080: 8, 16079: 0, 16078: 3, 16077: 7, 16076: 9, 16075: 6, 16074: 4, 16073: 6, 16072: 7, 16071: 2, 16070: 7, 16069: 1, 16068: 9, 16067: 1, 16066: 4, 16065: 2, 16064: 9, 16063: 3, 16062: 1, 16061: 1, 16060: 3, 16059: 6, 16058: 1, 16057: 7, 16056: 10, 16055: 2, 16054: 2, 16053: 0, 16052: 2, 16051: 1, 16050: 6, 16049: 10, 16048: 6, 16047: 6, 16046: 1, 16045: 3, 16044: 4, 16043: 4, 16042: 2, 16041: 0, 16040: 1, 16039: 1, 16038: 3, 16037: 2, 16036: 5, 16035: 1, 16034: 6, 16033: 10, 16032: 3, 16031: 2, 16030: 12, 16029: 4, 16028: 5, 16027: 2, 16026: 3, 16025: 2, 16024: 8, 16023: 4, 16022: 5, 16021: 2, 16020: 8, 16019: 1, 16018: 2, 16017: 0, 16016: 2, 16015: 7, 16014: 10, 16013: 1, 16012: 0, 16011: 2, 16010: 2, 16009: 2, 16008: 2, 16007: 1, 16006: 5, 16005: 6, 16004: 3, 16003: 1, 16002: 3, 16001: 2, 16000: 9, 15999: 3, 15998: 2, 15997: 11, 15996: 3, 15995: 14, 15994: 4, 15993: 2, 15992: 3, 15991: 9, 15990: 1, 15989: 1, 15988: 3, 15987: 7, 15986: 0, 15985: 6, 15984: 3, 15983: 1, 15982: 1, 15981: 6, 15980: 4, 15979: 2, 15978: 0, 15977: 2, 15976: 1, 15975: 4, 15974: 3, 15973: 2, 15972: 11, 15971: 7, 15970: 9, 15969: 6, 15968: 8, 15967: 8, 15966: 8, 15965: 11, 15964: 9, 15963: 8, 15962: 10, 15961: 1, 15960: 1, 15959: 3, 15958: 3, 15957: 6, 15956: 5, 15955: 4, 15954: 1, 15953: 3, 15952: 0, 15951: 1, 15950: 4, 15949: 3, 15948: 7, 15947: 9, 15946: 5, 15945: 14, 15944: 3, 15943: 10, 15942: 3, 15941: 3, 15940: 2, 15939: 2, 15938: 4, 15937: 6, 15936: 2, 15935: 5, 15934: 10, 15933: 1, 15932: 4, 15931: 3, 15930: 2, 15929: 1, 15928: 4, 15927: 10, 15926: 4, 15925: 8, 15924: 5, 15923: 5, 15922: 3, 15921: 8, 15920: 4, 15919: 2, 15918: 4, 15917: 3, 15916: 1, 15915: 2, 15914: 7, 15913: 4, 15912: 2, 15911: 1, 15910: 2, 15909: 5, 15908: 2, 15907: 1, 15906: 3, 15905: 3, 15904: 2, 15903: 10, 15902: 9, 15901: 21, 15900: 1, 15899: 1, 15898: 5, 15897: 14, 15896: 1, 15895: 9, 15894: 6, 15893: 5, 15892: 3, 15891: 2, 15890: 9, 15889: 2, 15888: 1, 15887: 0, 15886: 1, 15885: 3, 15884: 8, 15883: 5, 15882: 2, 15881: 3, 15880: 3, 15879: 4, 15878: 4, 15877: 4, 15876: 5, 15875: 11, 15874: 1, 15873: 8, 15872: 2, 15871: 4, 15870: 6, 15869: 9, 15868: 1, 15867: 1, 15866: 2, 15865: 3, 15864: 3, 15863: 4, 15862: 5, 15861: 1, 15860: 2, 15859: 7, 15858: 9, 15857: 5, 15856: 6, 15855: 5, 15854: 6, 15853: 3, 15852: 6, 15851: 4, 15850: 4, 15849: 5, 15848: 8, 15847: 3, 15846: 1, 15845: 9, 15844: 4, 15843: 7, 15842: 7, 15841: 2, 15840: 2, 15839: 2, 15838: 1, 15837: 2, 15836: 1, 15835: 4, 15834: 7, 15833: 3, 15832: 7, 15831: 1, 15830: 1, 15829: 4, 15828: 4, 15827: 3, 15826: 2, 15825: 3, 15824: 16, 15823: 5, 15822: 9, 15821: 5, 15820: 4, 15819: 4, 15818: 2, 15817: 9, 15816: 2, 15815: 4, 15814: 14, 15813: 1, 15812: 0, 15811: 3, 15810: 1, 15809: 3, 15808: 2, 15807: 6, 15806: 3, 15805: 1, 15804: 1, 15803: 3, 15802: 2, 15801: 8, 15800: 1, 15799: 12, 15798: 2, 15797: 3, 15796: 5, 15795: 2, 15794: 1, 15793: 10, 15792: 1, 15791: 5, 15790: 29, 15789: 3, 15788: 7, 15787: 14, 15786: 2, 15785: 6, 15784: 10, 15783: 12, 15782: 7, 15781: 10, 15780: 1, 15779: 2, 15778: 1, 15777: 5, 15776: 0, 15775: 3, 15774: 1, 15773: 2, 15772: 0, 15771: 1, 15770: 2, 15769: 8, 15768: 5, 15767: 6, 15766: 1, 15765: 0, 15764: 11, 15763: 15, 15762: 21, 15761: 16, 15760: 19, 15759: 4, 15758: 2, 15757: 5, 15756: 2, 15755: 1, 15754: 3, 15753: 2, 15752: 8, 15751: 2, 15750: 10, 15749: 2, 15748: 16, 15747: 6, 15746: 1, 15745: 6, 15744: 3, 15743: 4, 15742: 9, 15741: 2, 15740: 5, 15739: 2, 15738: 1, 15737: 3, 15736: 0, 15735: 0, 15734: 1, 15733: 11, 15732: 2, 15731: 5, 15730: 0, 15729: 7, 15728: 5, 15727: 4, 15726: 5, 15725: 1, 15724: 0, 15723: 3, 15722: 12, 15721: 1, 15720: 3, 15719: 12, 15718: 1, 15717: 2, 15716: 1, 15715: 1, 15714: 0, 15713: 1, 15712: 16, 15711: 1, 15710: 1, 15709: 0, 15708: 0, 15707: 6, 15706: 0, 15705: 1, 15704: 2, 15703: 3, 15702: 1, 15701: 1, 15700: 14, 15699: 1, 15698: 1, 15697: 1, 15696: 2, 15695: 1, 15694: 1, 15693: 3, 15692: 4, 15691: 1, 15690: 5, 15689: 1, 15688: 4, 15687: 1, 15686: 0, 15685: 3, 15684: 8, 15683: 2, 15682: 0, 15681: 4, 15680: 3, 15679: 2, 15678: 6, 15677: 3, 15676: 2, 15675: 2, 15674: 0, 15673: 1, 15672: 3, 15671: 1, 15670: 3, 15669: 1, 15668: 2, 15667: 2, 15666: 3, 15665: 0, 15664: 3, 15663: 7, 15662: 4, 15661: 0, 15660: 0, 15659: 1, 15658: 1, 15657: 2, 15656: 1, 15655: 1, 15654: 1, 15653: 0, 15652: 1, 15651: 0, 15650: 3, 15649: 2, 15648: 4, 15647: 5, 15646: 5, 15645: 2, 15644: 1, 15643: 1, 15642: 1, 15641: 4, 15640: 1, 15639: 1, 15638: 1, 15637: 4, 15636: 1, 15635: 1, 15634: 4, 15633: 3, 15632: 4, 15631: 1, 15630: 2, 15629: 4, 15628: 5, 15627: 2, 15626: 4, 15625: 2, 15624: 2, 15623: 0, 15622: 14, 15621: 4, 15620: 1, 15619: 1, 15618: 9, 15617: 14, 15616: 5, 15615: 1, 15614: 0, 15613: 2, 15612: 2, 15611: 2, 15610: 3, 15609: 0, 15608: 1, 15607: 2, 15606: 1, 15605: 3, 15604: 0, 15603: 2, 15602: 2, 15601: 1, 15600: 1, 15599: 2, 15598: 8, 15597: 3, 15596: 0, 15595: 5, 15594: 2, 15593: 1, 15592: 1, 15591: 1, 15590: 0, 15589: 6, 15588: 4, 15587: 3, 15586: 2, 15585: 6, 15584: 1, 15583: 2, 15582: 7, 15581: 0, 15580: 5, 15579: 1, 15578: 4, 15577: 7, 15576: 5, 15575: 0, 15574: 2, 15573: 5, 15572: 2, 15571: 7, 15570: 1, 15569: 2, 15568: 3, 15567: 2, 15566: 1, 15565: 0, 15564: 0, 15563: 7, 15562: 13, 15561: 13, 15560: 2, 15559: 6, 15558: 16, 15557: 1, 15556: 21, 15555: 1, 15554: 6, 15553: 3, 15552: 2, 15551: 0, 15550: 3, 15549: 9, 15548: 1, 15547: 1, 15546: 1, 15545: 2, 15544: 10, 15543: 3, 15542: 3, 15541: 2, 15540: 0, 15539: 4, 15538: 6, 15537: 0, 15536: 6, 15535: 4, 15534: 3, 15533: 0, 15532: 2, 15531: 1, 15530: 1, 15529: 1, 15528: 1, 15527: 1, 15526: 3, 15525: 2, 15524: 3, 15523: 6, 15522: 1, 15521: 2, 15520: 12, 15519: 5, 15518: 5, 15517: 2, 15516: 1, 15515: 13, 15514: 7, 15513: 2, 15512: 2, 15511: 1, 15510: 2, 15509: 2, 15508: 3, 15507: 10, 15506: 3, 15505: 12, 15504: 5, 15503: 3, 15502: 3, 15501: 1, 15500: 2, 15499: 1, 15498: 4, 15497: 0, 15496: 16, 15495: 2, 15494: 3, 15493: 3, 15492: 1, 15491: 1, 15490: 1, 15489: 0, 15488: 7, 15487: 3, 15486: 2, 15485: 3, 15484: 14, 15483: 5, 15482: 19, 15481: 1, 15480: 3, 15479: 2, 15478: 6, 15477: 1, 15476: 1, 15475: 3, 15474: 3, 15473: 5, 15472: 0, 15471: 1, 15470: 5, 15469: 6, 15468: 5, 15467: 0, 15466: 2, 15465: 2, 15464: 1, 15463: 2, 15462: 1, 15461: 1, 15460: 4, 15459: 2, 15458: 1, 15457: 1, 15456: 2, 15455: 5, 15454: 2, 15453: 1, 15452: 1, 15451: 3, 15450: 2, 15449: 2, 15448: 8, 15447: 1, 15446: 1, 15445: 1, 15444: 1, 15443: 2, 15442: 2, 15441: 1, 15440: 1, 15439: 2, 15438: 4, 15437: 7, 15436: 1, 15435: 1, 15434: 2, 15433: 1, 15432: 1, 15431: 2, 15430: 3, 15429: 2, 15428: 2, 15427: 9, 15426: 1, 15425: 1, 15424: 7, 15423: 3, 15422: 2, 15421: 1, 15420: 3, 15419: 5, 15418: 2, 15417: 2, 15416: 1, 15415: 1, 15414: 2, 15413: 1, 15412: 2, 15411: 0, 15410: 2, 15409: 2, 15408: 4, 15407: 6, 15406: 3, 15405: 6, 15404: 3, 15403: 10, 15402: 1, 15401: 1, 15400: 1, 15399: 4, 15398: 3, 15397: 6, 15396: 4, 15395: 3, 15394: 2, 15393: 0, 15392: 2, 15391: 2, 15390: 4, 15389: 3, 15388: 2, 15387: 1, 15386: 4, 15385: 2, 15384: 4, 15383: 7, 15382: 2, 15381: 3, 15380: 1, 15379: 2, 15378: 0, 15377: 3, 15376: 3, 15375: 0, 15374: 5, 15373: 2, 15372: 6, 15371: 8, 15370: 0, 15369: 1, 15368: 2, 15367: 10, 15366: 3, 15365: 2, 15364: 5, 15363: 26, 15362: 0, 15361: 0, 15360: 2, 15359: 1, 15358: 4, 15357: 1, 15356: 2, 15355: 15, 15354: 1, 15353: 7, 15352: 2, 15351: 1, 15350: 6, 15349: 5, 15348: 6, 15347: 1, 15346: 2, 15345: 2, 15344: 7, 15343: 4, 15342: 7, 15341: 4, 15340: 3, 15339: 1, 15338: 3, 15337: 2, 15336: 2, 15335: 2, 15334: 2, 15333: 0, 15332: 0, 15331: 1, 15330: 6, 15329: 1, 15328: 1, 15327: 2, 15326: 2, 15325: 1, 15324: 2, 15323: 4, 15322: 1, 15321: 14, 15320: 9, 15319: 7, 15318: 2, 15317: 3, 15316: 1, 15315: 2, 15314: 6, 15313: 0, 15312: 3, 15311: 3, 15310: 8, 15309: 2, 15308: 12, 15307: 7, 15306: 3, 15305: 1, 15304: 3, 15303: 0, 15302: 1, 15301: 6, 15300: 10, 15299: 8, 15298: 1, 15297: 1, 15296: 2, 15295: 1, 15294: 2, 15293: 8, 15292: 1, 15291: 3, 15290: 4, 15289: 1, 15288: 2, 15287: 2, 15286: 25, 15285: 3, 15284: 2, 15283: 2, 15282: 4, 15281: 1, 15280: 1, 15279: 0, 15278: 1, 15277: 0, 15276: 3, 15275: 5, 15274: 0, 15273: 14, 15272: 2, 15271: 7, 15270: 3, 15269: 6, 15268: 1, 15267: 1, 15266: 1, 15265: 1, 15264: 1, 15263: 1, 15262: 12, 15261: 2, 15260: 5, 15259: 0, 15258: 4, 15257: 7, 15256: 2, 15255: 11, 15254: 3, 15253: 3, 15252: 3, 15251: 4, 15250: 2, 15249: 1, 15248: 10, 15247: 6, 15246: 5, 15245: 3, 15244: 6, 15243: 5, 15242: 4, 15241: 5, 15240: 8, 15239: 1, 15238: 1, 15237: 6, 15236: 1, 15235: 1, 15234: 6, 15233: 6, 15232: 1, 15231: 1, 15230: 9, 15229: 7, 15228: 1, 15227: 6, 15226: 2, 15225: 1, 15224: 8, 15223: 2, 15222: 13, 15221: 5, 15220: 3, 15219: 1, 15218: 3, 15217: 7, 15216: 3, 15215: 5, 15214: 7, 15213: 1, 15212: 3, 15211: 3, 15210: 2, 15209: 0, 15208: 1, 15207: 3, 15206: 4, 15205: 1, 15204: 3, 15203: 4, 15202: 1, 15201: 8, 15200: 9, 15199: 3, 15198: 1, 15197: 3, 15196: 4, 15195: 17, 15194: 2, 15193: 4, 15192: 3, 15191: 1, 15190: 4, 15189: 1, 15188: 1, 15187: 1, 15186: 3, 15185: 6, 15184: 2, 15183: 4, 15182: 3, 15181: 2, 15180: 3, 15179: 3, 15178: 8, 15177: 3, 15176: 7, 15175: 2, 15174: 3, 15173: 1, 15172: 2, 15171: 5, 15170: 2, 15169: 3, 15168: 2, 15167: 3, 15166: 2, 15165: 1, 15164: 2, 15163: 1, 15162: 1, 15161: 4, 15160: 3, 15159: 4, 15158: 1, 15157: 3, 15156: 2, 15155: 5, 15154: 1, 15153: 1, 15152: 2, 15151: 1, 15150: 1, 15149: 21, 15148: 2, 15147: 0, 15146: 4, 15145: 2, 15144: 8, 15143: 2, 15142: 2, 15141: 1, 15140: 5, 15139: 1, 15138: 5, 15137: 4, 15136: 2, 15135: 3, 15134: 2, 15133: 1, 15132: 3, 15131: 2, 15130: 3, 15129: 1, 15128: 1, 15127: 1, 15126: 2, 15125: 17, 15124: 0, 15123: 9, 15122: 1, 15121: 3, 15120: 5, 15119: 2, 15118: 3, 15117: 2, 15116: 3, 15115: 2, 15114: 2, 15113: 4, 15112: 6, 15111: 1, 15110: 4, 15109: 3, 15108: 4, 15107: 4, 15106: 1, 15105: 4, 15104: 8, 15103: 22, 15102: 1, 15101: 5, 15100: 1, 15099: 6, 15098: 0, 15097: 2, 15096: 6, 15095: 1, 15094: 3, 15093: 3, 15092: 2, 15091: 6, 15090: 1, 15089: 7, 15088: 3, 15087: 4, 15086: 4, 15085: 3, 15084: 1, 15083: 7, 15082: 1, 15081: 2, 15080: 0, 15079: 2, 15078: 1, 15077: 3, 15076: 2, 15075: 2, 15074: 3, 15073: 5, 15072: 2, 15071: 3, 15070: 2, 15069: 5, 15068: 6, 15067: 4, 15066: 3, 15065: 1, 15064: 8, 15063: 0, 15062: 5, 15061: 8, 15060: 2, 15059: 1, 15058: 2, 15057: 0, 15056: 1, 15055: 5, 15054: 1, 15053: 3, 15052: 3, 15051: 1, 15050: 4, 15049: 3, 15048: 0, 15047: 1, 15046: 5, 15045: 1, 15044: 1, 15043: 1, 15042: 0, 15041: 1, 15040: 3, 15039: 6, 15038: 3, 15037: 0, 15036: 0, 15035: 1, 15034: 6, 15033: 3, 15032: 5, 15031: 2, 15030: 2, 15029: 3, 15028: 6, 15027: 5, 15026: 5, 15025: 4, 15024: 4, 15023: 1, 15022: 2, 15021: 0, 15020: 1, 15019: 2, 15018: 2, 15017: 6, 15016: 4, 15015: 9, 15014: 1, 15013: 1, 15012: 14, 15011: 6, 15010: 1, 15009: 20, 15008: 8, 15007: 11, 15006: 14, 15005: 2, 15004: 2, 15003: 1, 15002: 4, 15001: 0, 15000: 2, 14999: 7, 14998: 2, 14997: 3, 14996: 2, 14995: 1, 14994: 1, 14993: 4, 14992: 2, 14991: 4, 14990: 2, 14989: 8, 14988: 11, 14987: 6, 14986: 11, 14985: 5, 14984: 6, 14983: 8, 14982: 4, 14981: 3, 14980: 3, 14979: 1, 14978: 6, 14977: 1, 14976: 31, 14975: 1, 14974: 9, 14973: 2, 14972: 5, 14971: 4, 14970: 2, 14969: 3, 14968: 2, 14967: 10, 14966: 13, 14965: 3, 14964: 1, 14963: 2, 14962: 20, 14961: 4, 14960: 0, 14959: 0, 14958: 1, 14957: 1, 14956: 2, 14955: 5, 14954: 1, 14953: 2, 14952: 0, 14951: 2, 14950: 1, 14949: 1, 14948: 4, 14947: 3, 14946: 1, 14945: 3, 14944: 1, 14943: 0, 14942: 8, 14941: 2, 14940: 1, 14939: 2, 14938: 0, 14937: 1, 14936: 0, 14935: 2, 14934: 5, 14933: 5, 14932: 3, 14931: 3, 14930: 6, 14929: 8, 14928: 4, 14927: 14, 14926: 1, 14925: 16, 14924: 1, 14923: 4, 14922: 4, 14921: 2, 14920: 2, 14919: 5, 14918: 4, 14917: 5, 14916: 6, 14915: 3, 14914: 3, 14913: 1, 14912: 1, 14911: 1, 14910: 0, 14909: 10, 14908: 5, 14907: 2, 14906: 4, 14905: 0, 14904: 21, 14903: 3, 14902: 5, 14901: 27, 14900: 2, 14899: 17, 14898: 6, 14897: 13, 14896: 2, 14895: 2, 14894: 1, 14893: 2, 14892: 1, 14891: 2, 14890: 3, 14889: 1, 14888: 0, 14887: 2, 14886: 4, 14885: 2, 14884: 2, 14883: 19, 14882: 1, 14881: 0, 14880: 0, 14879: 9, 14878: 0, 14877: 4, 14876: 2, 14875: 2, 14874: 5, 14873: 6, 14872: 4, 14871: 5, 14870: 6, 14869: 3, 14868: 5, 14867: 5, 14866: 2, 14865: 7, 14864: 2, 14863: 2, 14862: 2, 14861: 4, 14860: 12, 14859: 2, 14858: 5, 14857: 12, 14856: 1, 14855: 7, 14854: 2, 14853: 2, 14852: 3, 14851: 7, 14850: 1, 14849: 5, 14848: 5, 14847: 5, 14846: 0, 14845: 7, 14844: 5, 14843: 2, 14842: 2, 14841: 4, 14840: 4, 14839: 4, 14838: 4, 14837: 6, 14836: 7, 14835: 1, 14834: 1, 14833: 5, 14832: 1, 14831: 6, 14830: 2, 14829: 3, 14828: 7, 14827: 4, 14826: 7, 14825: 6, 14824: 5, 14823: 2, 14822: 6, 14821: 2, 14820: 1, 14819: 5, 14818: 3, 14817: 4, 14816: 4, 14815: 1, 14814: 3, 14813: 2, 14812: 13, 14811: 3, 14810: 0, 14809: 3, 14808: 3, 14807: 3, 14806: 2, 14805: 4, 14804: 6, 14803: 4, 14802: 3, 14801: 2, 14800: 2, 14799: 5, 14798: 1, 14797: 1, 14796: 2, 14795: 1, 14794: 1, 14793: 1, 14792: 10, 14791: 1, 14790: 20, 14789: 1, 14788: 4, 14787: 4, 14786: 6, 14785: 1, 14784: 3, 14783: 2, 14782: 3, 14781: 2, 14780: 2, 14779: 7, 14778: 3, 14777: 3, 14776: 2, 14775: 0, 14774: 1, 14773: 4, 14772: 3, 14771: 4, 14770: 8, 14769: 4, 14768: 7, 14767: 2, 14766: 2, 14765: 2, 14764: 4, 14763: 5, 14762: 2, 14761: 8, 14760: 4, 14759: 3, 14758: 3, 14757: 3, 14756: 1, 14755: 5, 14754: 4, 14753: 1, 14752: 6, 14751: 6, 14750: 3, 14749: 1, 14748: 3, 14747: 1, 14746: 5, 14745: 3, 14744: 4, 14743: 1, 14742: 1, 14741: 3, 14740: 0, 14739: 10, 14738: 8, 14737: 11, 14736: 4, 14735: 0, 14734: 3, 14733: 8, 14732: 8, 14731: 6, 14730: 2, 14729: 1, 14728: 2, 14727: 1, 14726: 0, 14725: 2, 14724: 5, 14723: 5, 14722: 1, 14721: 4, 14720: 2, 14719: 4, 14718: 3, 14717: 4, 14716: 3, 14715: 3, 14714: 0, 14713: 7, 14712: 12, 14711: 8, 14710: 2, 14709: 9, 14708: 0, 14707: 3, 14706: 2, 14705: 1, 14704: 8, 14703: 2, 14702: 4, 14701: 2, 14700: 5, 14699: 2, 14698: 2, 14697: 1, 14696: 2, 14695: 4, 14694: 1, 14693: 1, 14692: 1, 14691: 3, 14690: 3, 14689: 0, 14688: 6, 14687: 2, 14686: 2, 14685: 1, 14684: 2, 14683: 2, 14682: 4, 14681: 2, 14680: 3, 14679: 10, 14678: 2, 14677: 1, 14676: 4, 14675: 2, 14674: 4, 14673: 2, 14672: 0, 14671: 3, 14670: 7, 14669: 7, 14668: 17, 14667: 2, 14666: 3, 14665: 1, 14664: 0, 14663: 0, 14662: 0, 14661: 2, 14660: 0, 14659: 6, 14658: 2, 14657: 2, 14656: 0, 14655: 10, 14654: 2, 14653: 0, 14652: 1, 14651: 3, 14650: 4, 14649: 7, 14648: 13, 14647: 7, 14646: 7, 14645: 7, 14644: 18, 14643: 13, 14642: 1, 14641: 5, 14640: 2, 14639: 1, 14638: 0, 14637: 3, 14636: 1, 14635: 2, 14634: 4, 14633: 6, 14632: 4, 14631: 3, 14630: 5, 14629: 3, 14628: 2, 14627: 2, 14626: 1, 14625: 1, 14624: 4, 14623: 3, 14622: 3, 14621: 1, 14620: 0, 14619: 1, 14618: 4, 14617: 4, 14616: 0, 14615: 2, 14614: 1, 14613: 2, 14612: 2, 14611: 3, 14610: 3, 14609: 2, 14608: 2, 14607: 2, 14606: 7, 14605: 1, 14604: 1, 14603: 4, 14602: 7, 14601: 5, 14600: 12, 14599: 2, 14598: 1, 14597: 3, 14596: 2, 14595: 2, 14594: 2, 14593: 6, 14592: 2, 14591: 2, 14590: 2, 14589: 2, 14588: 2, 14587: 3, 14586: 1, 14585: 3, 14584: 2, 14583: 1, 14582: 3, 14581: 8, 14580: 3, 14579: 14, 14578: 3, 14577: 2, 14576: 1, 14575: 5, 14574: 3, 14573: 11, 14572: 3, 14571: 4, 14570: 5, 14569: 19, 14568: 2, 14567: 2, 14566: 3, 14565: 3, 14564: 2, 14563: 2, 14562: 10, 14561: 3, 14560: 2, 14559: 4, 14558: 3, 14557: 1, 14556: 1, 14555: 3, 14554: 2, 14553: 3, 14552: 2, 14551: 8, 14550: 3, 14549: 4, 14548: 5, 14547: 2, 14546: 1, 14545: 2, 14544: 2, 14543: 2, 14542: 2, 14541: 3, 14540: 7, 14539: 3, 14538: 2, 14537: 2, 14536: 5, 14535: 1, 14534: 1, 14533: 3, 14532: 4, 14531: 0, 14530: 2, 14529: 2, 14528: 2, 14527: 1, 14526: 1, 14525: 2, 14524: 3, 14523: 0, 14522: 1, 14521: 1, 14520: 0, 14519: 4, 14518: 3, 14517: 2, 14516: 2, 14515: 6, 14514: 2, 14513: 1, 14512: 3, 14511: 3, 14510: 2, 14509: 2, 14508: 3, 14507: 3, 14506: 3, 14505: 1, 14504: 0, 14503: 5, 14502: 3, 14501: 3, 14500: 3, 14499: 1, 14498: 1, 14497: 2, 14496: 10, 14495: 1, 14494: 5, 14493: 5, 14492: 0, 14491: 1, 14490: 2, 14489: 2, 14488: 3, 14487: 0, 14486: 0, 14485: 3, 14484: 6, 14483: 3, 14482: 2, 14481: 5, 14480: 6, 14479: 7, 14478: 3, 14477: 3, 14476: 7, 14475: 5, 14474: 1, 14473: 4, 14472: 2, 14471: 5, 14470: 7, 14469: 0, 14468: 2, 14467: 2, 14466: 1, 14465: 3, 14464: 4, 14463: 1, 14462: 4, 14461: 2, 14460: 1, 14459: 0, 14458: 0, 14457: 5, 14456: 0, 14455: 1, 14454: 4, 14453: 3, 14452: 1, 14451: 3, 14450: 2, 14449: 3, 14448: 13, 14447: 12, 14446: 19, 14445: 19, 14444: 3, 14443: 20, 14442: 1, 14441: 1, 14440: 4, 14439: 3, 14438: 1, 14437: 2, 14436: 1, 14435: 6, 14434: 1, 14433: 6, 14432: 4, 14431: 4, 14430: 5, 14429: 3, 14428: 2, 14427: 0, 14426: 2, 14425: 4, 14424: 6, 14423: 5, 14422: 3, 14421: 7, 14420: 4, 14419: 3, 14418: 0, 14417: 1, 14416: 3, 14415: 4, 14414: 5, 14413: 2, 14412: 2, 14411: 2, 14410: 19, 14409: 4, 14408: 2, 14407: 21, 14406: 2, 14405: 12, 14404: 1, 14403: 3, 14402: 2, 14401: 2, 14400: 0, 14399: 3, 14398: 4, 14397: 2, 14396: 1, 14395: 3, 14394: 1, 14393: 1, 14392: 1, 14391: 5, 14390: 5, 14389: 1, 14388: 5, 14387: 0, 14386: 13, 14385: 2, 14384: 3, 14383: 3, 14382: 1, 14381: 4, 14380: 6, 14379: 2, 14378: 1, 14377: 1, 14376: 2, 14375: 3, 14374: 4, 14373: 3, 14372: 6, 14371: 7, 14370: 2, 14369: 9, 14368: 11, 14367: 2, 14366: 1, 14365: 0, 14364: 5, 14363: 11, 14362: 2, 14361: 6, 14360: 4, 14359: 2, 14358: 5, 14357: 3, 14356: 3, 14355: 2, 14354: 1, 14353: 1, 14352: 2, 14351: 9, 14350: 4, 14349: 2, 14348: 5, 14347: 2, 14346: 1, 14345: 4, 14344: 2, 14343: 1, 14342: 16, 14341: 15, 14340: 1, 14339: 4, 14338: 3, 14337: 9, 14336: 3, 14335: 6, 14334: 1, 14333: 5, 14332: 5, 14331: 2, 14330: 5, 14329: 3, 14328: 4, 14327: 3, 14326: 5, 14325: 4, 14324: 4, 14323: 2, 14322: 1, 14321: 2, 14320: 5, 14319: 5, 14318: 8, 14317: 10, 14316: 15, 14315: 3, 14314: 4, 14313: 8, 14312: 0, 14311: 0, 14310: 2, 14309: 0, 14308: 1, 14307: 2, 14306: 9, 14305: 2, 14304: 4, 14303: 1, 14302: 1, 14301: 4, 14300: 4, 14299: 3, 14298: 36, 14297: 5, 14296: 11, 14295: 1, 14294: 2, 14293: 1, 14292: 2, 14291: 3, 14290: 3, 14289: 14, 14288: 3, 14287: 1, 14286: 2, 14285: 4, 14284: 1, 14283: 2, 14282: 5, 14281: 1, 14280: 0, 14279: 3, 14278: 1, 14277: 12, 14276: 3, 14275: 2, 14274: 3, 14273: 4, 14272: 0, 14271: 19, 14270: 3, 14269: 5, 14268: 6, 14267: 1, 14266: 0, 14265: 0, 14264: 1, 14263: 5, 14262: 3, 14261: 1, 14260: 1, 14259: 2, 14258: 2, 14257: 0, 14256: 8, 14255: 11, 14254: 0, 14253: 1, 14252: 9, 14251: 3, 14250: 3, 14249: 4, 14248: 6, 14247: 4, 14246: 4, 14245: 5, 14244: 3, 14243: 23, 14242: 2, 14241: 1, 14240: 2, 14239: 4, 14238: 0, 14237: 3, 14236: 4, 14235: 2, 14234: 1, 14233: 0, 14232: 4, 14231: 3, 14230: 0, 14229: 4, 14228: 1, 14227: 2, 14226: 2, 14225: 2, 14224: 0, 14223: 5, 14222: 2, 14221: 0, 14220: 4, 14219: 2, 14218: 1, 14217: 3, 14216: 4, 14215: 2, 14214: 2, 14213: 7, 14212: 5, 14211: 1, 14210: 1, 14209: 2, 14208: 2, 14207: 0, 14206: 6, 14205: 10, 14204: 10, 14203: 7, 14202: 2, 14201: 2, 14200: 1, 14199: 2, 14198: 4, 14197: 4, 14196: 22, 14195: 3, 14194: 6, 14193: 0, 14192: 3, 14191: 2, 14190: 1, 14189: 8, 14188: 9, 14187: 1, 14186: 7, 14185: 3, 14184: 3, 14183: 1, 14182: 4, 14181: 0, 14180: 2, 14179: 0, 14178: 1, 14177: 6, 14176: 0, 14175: 1, 14174: 0, 14173: 5, 14172: 13, 14171: 7, 14170: 8, 14169: 9, 14168: 10, 14167: 11, 14166: 2, 14165: 2, 14164: 9, 14163: 3, 14162: 1, 14161: 7, 14160: 0, 14159: 1, 14158: 4, 14157: 9, 14156: 1, 14155: 3, 14154: 4, 14153: 1, 14152: 4, 14151: 1, 14150: 3, 14149: 2, 14148: 2, 14147: 1, 14146: 1, 14145: 5, 14144: 3, 14143: 2, 14142: 2, 14141: 2, 14140: 0, 14139: 2, 14138: 6, 14137: 1, 14136: 4, 14135: 1, 14134: 4, 14133: 3, 14132: 2, 14131: 1, 14130: 8, 14129: 9, 14128: 1, 14127: 2, 14126: 0, 14125: 5, 14124: 1, 14123: 8, 14122: 2, 14121: 5, 14120: 7, 14119: 4, 14118: 0, 14117: 1, 14116: 6, 14115: 8, 14114: 1, 14113: 3, 14112: 4, 14111: 2, 14110: 4, 14109: 4, 14108: 5, 14107: 19, 14106: 2, 14105: 2, 14104: 7, 14103: 15, 14102: 19, 14101: 15, 14100: 16, 14099: 12, 14098: 21, 14097: 16, 14096: 14, 14095: 1, 14094: 1, 14093: 2, 14092: 2, 14091: 2, 14090: 6, 14089: 6, 14088: 7, 14087: 5, 14086: 6, 14085: 4, 14084: 4, 14083: 14, 14082: 3, 14081: 6, 14080: 3, 14079: 1, 14078: 6, 14077: 6, 14076: 0, 14075: 2, 14074: 4, 14073: 5, 14072: 1, 14071: 11, 14070: 11, 14069: 2, 14068: 0, 14067: 5, 14066: 2, 14065: 1, 14064: 2, 14063: 2, 14062: 2, 14061: 0, 14060: 4, 14059: 0, 14058: 1, 14057: 3, 14056: 3, 14055: 3, 14054: 2, 14053: 2, 14052: 3, 14051: 2, 14050: 7, 14049: 3, 14048: 1, 14047: 4, 14046: 4, 14045: 3, 14044: 2, 14043: 3, 14042: 1, 14041: 6, 14040: 7, 14039: 4, 14038: 3, 14037: 4, 14036: 24, 14035: 8, 14034: 14, 14033: 3, 14032: 2, 14031: 3, 14030: 4, 14029: 3, 14028: 1, 14027: 1, 14026: 2, 14025: 2, 14024: 3, 14023: 2, 14022: 1, 14021: 4, 14020: 2, 14019: 2, 14018: 4, 14017: 5, 14016: 2, 14015: 1, 14014: 5, 14013: 5, 14012: 20, 14011: 24, 14010: 14, 14009: 3, 14008: 7, 14007: 14, 14006: 4, 14005: 5, 14004: 4, 14003: 4, 14002: 6, 14001: 1, 14000: 7, 13999: 3, 13998: 5, 13997: 6, 13996: 0, 13995: 11, 13994: 4, 13993: 4, 13992: 3, 13991: 6, 13990: 4, 13989: 2, 13988: 2, 13987: 1, 13986: 3, 13985: 2, 13984: 10, 13983: 3, 13982: 3, 13981: 1, 13980: 2, 13979: 11, 13978: 3, 13977: 2, 13976: 3, 13975: 1, 13974: 4, 13973: 1, 13972: 5, 13971: 1, 13970: 2, 13969: 0, 13968: 3, 13967: 2, 13966: 4, 13965: 1, 13964: 1, 13963: 3, 13962: 11, 13961: 6, 13960: 9, 13959: 11, 13958: 9, 13957: 5, 13956: 9, 13955: 12, 13954: 6, 13953: 2, 13952: 1, 13951: 2, 13950: 5, 13949: 1, 13948: 2, 13947: 4, 13946: 5, 13945: 2, 13944: 2, 13943: 7, 13942: 2, 13941: 4, 13940: 6, 13939: 2, 13938: 2, 13937: 9, 13936: 3, 13935: 4, 13934: 4, 13933: 3, 13932: 5, 13931: 8, 13930: 7, 13929: 17, 13928: 17, 13927: 17, 13926: 16, 13925: 14, 13924: 19, 13923: 5, 13922: 4, 13921: 3, 13920: 7, 13919: 5, 13918: 4, 13917: 4, 13916: 6, 13915: 3, 13914: 2, 13913: 0, 13912: 3, 13911: 0, 13910: 0, 13909: 2, 13908: 3, 13907: 10, 13906: 3, 13905: 5, 13904: 11, 13903: 4, 13902: 4, 13901: 3, 13900: 2, 13899: 0, 13898: 2, 13897: 1, 13896: 1, 13895: 5, 13894: 4, 13893: 3, 13892: 11, 13891: 7, 13890: 6, 13889: 15, 13888: 5, 13887: 2, 13886: 1, 13885: 14, 13884: 11, 13883: 1, 13882: 4, 13881: 2, 13880: 2, 13879: 0, 13878: 0, 13877: 6, 13876: 3, 13875: 12, 13874: 11, 13873: 17, 13872: 6, 13871: 7, 13870: 3, 13869: 3, 13868: 18, 13867: 1, 13866: 3, 13865: 1, 13864: 6, 13863: 0, 13862: 16, 13861: 8, 13860: 10, 13859: 4, 13858: 1, 13857: 3, 13856: 4, 13855: 3, 13854: 3, 13853: 5, 13852: 1, 13851: 4, 13850: 1, 13849: 2, 13848: 2, 13847: 8, 13846: 2, 13845: 4, 13844: 2, 13843: 5, 13842: 1, 13841: 1, 13840: 1, 13839: 3, 13838: 1, 13837: 1, 13836: 0, 13835: 6, 13834: 5, 13833: 3, 13832: 5, 13831: 0, 13830: 1, 13829: 2, 13828: 3, 13827: 2, 13826: 4, 13825: 2, 13824: 3, 13823: 9, 13822: 4, 13821: 2, 13820: 8, 13819: 8, 13818: 4, 13817: 4, 13816: 10, 13815: 0, 13814: 2, 13813: 3, 13812: 2, 13811: 5, 13810: 4, 13809: 6, 13808: 6, 13807: 3, 13806: 2, 13805: 1, 13804: 2, 13803: 5, 13802: 1, 13801: 1, 13800: 5, 13799: 2, 13798: 4, 13797: 6, 13796: 2, 13795: 2, 13794: 3, 13793: 5, 13792: 4, 13791: 3, 13790: 4, 13789: 0, 13788: 11, 13787: 2, 13786: 1, 13785: 5, 13784: 4, 13783: 0, 13782: 6, 13781: 4, 13780: 2, 13779: 5, 13778: 19, 13777: 4, 13776: 2, 13775: 1, 13774: 2, 13773: 9, 13772: 4, 13771: 2, 13770: 1, 13769: 1, 13768: 2, 13767: 1, 13766: 10, 13765: 0, 13764: 3, 13763: 2, 13762: 1, 13761: 5, 13760: 2, 13759: 2, 13758: 1, 13757: 5, 13756: 2, 13755: 1, 13754: 3, 13753: 2, 13752: 4, 13751: 2, 13750: 3, 13749: 2, 13748: 7, 13747: 1, 13746: 3, 13745: 3, 13744: 7, 13743: 5, 13742: 5, 13741: 0, 13740: 0, 13739: 6, 13738: 2, 13737: 3, 13736: 4, 13735: 8, 13734: 2, 13733: 2, 13732: 9, 13731: 1, 13730: 1, 13729: 3, 13728: 4, 13727: 9, 13726: 1, 13725: 2, 13724: 1, 13723: 2, 13722: 14, 13721: 2, 13720: 2, 13719: 1, 13718: 1, 13717: 2, 13716: 4, 13715: 2, 13714: 12, 13713: 3, 13712: 2, 13711: 3, 13710: 8, 13709: 8, 13708: 2, 13707: 3, 13706: 2, 13705: 4, 13704: 3, 13703: 8, 13702: 10, 13701: 7, 13700: 0, 13699: 3, 13698: 1, 13697: 4, 13696: 5, 13695: 5, 13694: 2, 13693: 26, 13692: 6, 13691: 4, 13690: 5, 13689: 1, 13688: 0, 13687: 2, 13686: 5, 13685: 3, 13684: 6, 13683: 1, 13682: 3, 13681: 16, 13680: 20, 13679: 2, 13678: 2, 13677: 2, 13676: 1, 13675: 1, 13674: 0, 13673: 1, 13672: 0, 13671: 1, 13670: 2, 13669: 2, 13668: 3, 13667: 1, 13666: 1, 13665: 8, 13664: 3, 13663: 3, 13662: 4, 13661: 10, 13660: 5, 13659: 15, 13658: 13, 13657: 5, 13656: 5, 13655: 1, 13654: 2, 13653: 1, 13652: 0, 13651: 15, 13650: 1, 13649: 1, 13648: 1, 13647: 4, 13646: 8, 13645: 4, 13644: 4, 13643: 4, 13642: 1, 13641: 2, 13640: 15, 13639: 11, 13638: 15, 13637: 9, 13636: 10, 13635: 14, 13634: 14, 13633: 12, 13632: 14, 13631: 20, 13630: 19, 13629: 1, 13628: 2, 13627: 4, 13626: 1, 13625: 2, 13624: 2, 13623: 15, 13622: 18, 13621: 4, 13620: 12, 13619: 11, 13618: 3, 13617: 0, 13616: 0, 13615: 3, 13614: 2, 13613: 2, 13612: 2, 13611: 2, 13610: 4, 13609: 1, 13608: 5, 13607: 5, 13606: 4, 13605: 7, 13604: 8, 13603: 0, 13602: 1, 13601: 28, 13600: 2, 13599: 6, 13598: 10, 13597: 10, 13596: 4, 13595: 1, 13594: 3, 13593: 1, 13592: 0, 13591: 3, 13590: 2, 13589: 5, 13588: 3, 13587: 3, 13586: 4, 13585: 6, 13584: 1, 13583: 4, 13582: 0, 13581: 14, 13580: 1, 13579: 3, 13578: 2, 13577: 5, 13576: 2, 13575: 24, 13574: 3, 13573: 2, 13572: 3, 13571: 5, 13570: 10, 13569: 5, 13568: 16, 13567: 1, 13566: 4, 13565: 5, 13564: 4, 13563: 4, 13562: 3, 13561: 4, 13560: 1, 13559: 1, 13558: 4, 13557: 2, 13556: 2, 13555: 5, 13554: 4, 13553: 16, 13552: 21, 13551: 4, 13550: 3, 13549: 7, 13548: 1, 13547: 5, 13546: 2, 13545: 0, 13544: 1, 13543: 1, 13542: 1, 13541: 2, 13540: 3, 13539: 2, 13538: 12, 13537: 3, 13536: 1, 13535: 10, 13534: 5, 13533: 13, 13532: 6, 13531: 2, 13530: 1, 13529: 4, 13528: 7, 13527: 2, 13526: 2, 13525: 2, 13524: 1, 13523: 4, 13522: 7, 13521: 2, 13520: 4, 13519: 4, 13518: 3, 13517: 6, 13516: 5, 13515: 6, 13514: 4, 13513: 4, 13512: 8, 13511: 5, 13510: 4, 13509: 4, 13508: 1, 13507: 12, 13506: 5, 13505: 3, 13504: 0, 13503: 5, 13502: 9, 13501: 2, 13500: 6, 13499: 2, 13498: 2, 13497: 4, 13496: 2, 13495: 4, 13494: 5, 13493: 12, 13492: 18, 13491: 15, 13490: 13, 13489: 16, 13488: 15, 13487: 15, 13486: 15, 13485: 18, 13484: 15, 13483: 17, 13482: 16, 13481: 17, 13480: 13, 13479: 18, 13478: 4, 13477: 4, 13476: 1, 13475: 0, 13474: 1, 13473: 0, 13472: 6, 13471: 3, 13470: 14, 13469: 1, 13468: 2, 13467: 2, 13466: 6, 13465: 24, 13464: 8, 13463: 4, 13462: 3, 13461: 2, 13460: 4, 13459: 6, 13458: 1, 13457: 3, 13456: 19, 13455: 6, 13454: 3, 13453: 4, 13452: 6, 13451: 4, 13450: 0, 13449: 2, 13448: 0, 13447: 2, 13446: 0, 13445: 6, 13444: 4, 13443: 5, 13442: 7, 13441: 7, 13440: 6, 13439: 9, 13438: 1, 13437: 4, 13436: 9, 13435: 2, 13434: 5, 13433: 1, 13432: 0, 13431: 2, 13430: 4, 13429: 3, 13428: 3, 13427: 10, 13426: 2, 13425: 2, 13424: 0, 13423: 18, 13422: 0, 13421: 4, 13420: 6, 13419: 8, 13418: 1, 13417: 1, 13416: 1, 13415: 1, 13414: 0, 13413: 2, 13412: 11, 13411: 8, 13410: 3, 13409: 1, 13408: 1, 13407: 1, 13406: 1, 13405: 1, 13404: 4, 13403: 1, 13402: 2, 13401: 0, 13400: 4, 13399: 4, 13398: 5, 13397: 1, 13396: 5, 13395: 3, 13394: 3, 13393: 0, 13392: 0, 13391: 4, 13390: 4, 13389: 1, 13388: 6, 13387: 1, 13386: 1, 13385: 3, 13384: 2, 13383: 1, 13382: 4, 13381: 3, 13380: 2, 13379: 0, 13378: 1, 13377: 7, 13376: 1, 13375: 3, 13374: 1, 13373: 13, 13372: 1, 13371: 7, 13370: 2, 13369: 4, 13368: 0, 13367: 1, 13366: 4, 13365: 3, 13364: 2, 13363: 1, 13362: 1, 13361: 0, 13360: 7, 13359: 1, 13358: 0, 13357: 2, 13356: 4, 13355: 0, 13354: 2, 13353: 4, 13352: 2, 13351: 6, 13350: 1, 13349: 8, 13348: 1, 13347: 0, 13346: 3, 13345: 3, 13344: 1, 13343: 13, 13342: 6, 13341: 21, 13340: 3, 13339: 4, 13338: 10, 13337: 3, 13336: 3, 13335: 5, 13334: 30, 13333: 0, 13332: 5, 13331: 3, 13330: 2, 13329: 3, 13328: 3, 13327: 4, 13326: 4, 13325: 2, 13324: 1, 13323: 1, 13322: 3, 13321: 5, 13320: 8, 13319: 7, 13318: 2, 13317: 25, 13316: 2, 13315: 5, 13314: 3, 13313: 4, 13312: 1, 13311: 2, 13310: 2, 13309: 7, 13308: 1, 13307: 0, 13306: 2, 13305: 9, 13304: 4, 13303: 1, 13302: 3, 13301: 1, 13300: 8, 13299: 1, 13298: 3, 13297: 2, 13296: 2, 13295: 2, 13294: 2, 13293: 0, 13292: 2, 13291: 1, 13290: 1, 13289: 12, 13288: 4, 13287: 3, 13286: 3, 13285: 1, 13284: 0, 13283: 2, 13282: 9, 13281: 2, 13280: 3, 13279: 1, 13278: 3, 13277: 8, 13276: 0, 13275: 1, 13274: 8, 13273: 1, 13272: 3, 13271: 5, 13270: 5, 13269: 1, 13268: 5, 13267: 4, 13266: 5, 13265: 7, 13264: 0, 13263: 7, 13262: 2, 13261: 7, 13260: 2, 13259: 6, 13258: 3, 13257: 1, 13256: 13, 13255: 6, 13254: 3, 13253: 4, 13252: 7, 13251: 11, 13250: 5, 13249: 5, 13248: 2, 13247: 4, 13246: 3, 13245: 8, 13244: 9, 13243: 2, 13242: 3, 13241: 1, 13240: 2, 13239: 6, 13238: 2, 13237: 3, 13236: 4, 13235: 3, 13234: 4, 13233: 4, 13232: 2, 13231: 9, 13230: 0, 13229: 1, 13228: 0, 13227: 3, 13226: 1, 13225: 3, 13224: 1, 13223: 1, 13222: 4, 13221: 1, 13220: 1, 13219: 1, 13218: 3, 13217: 3, 13216: 0, 13215: 4, 13214: 1, 13213: 2, 13212: 1, 13211: 11, 13210: 0, 13209: 2, 13208: 20, 13207: 2, 13206: 0, 13205: 3, 13204: 3, 13203: 2, 13202: 3, 13201: 1, 13200: 3, 13199: 0, 13198: 4, 13197: 0, 13196: 0, 13195: 2, 13194: 3, 13193: 5, 13192: 14, 13191: 1, 13190: 0, 13189: 4, 13188: 4, 13187: 3, 13186: 5, 13185: 1, 13184: 2, 13183: 2, 13182: 5, 13181: 3, 13180: 4, 13179: 4, 13178: 3, 13177: 4, 13176: 0, 13175: 2, 13174: 3, 13173: 2, 13172: 4, 13171: 7, 13170: 5, 13169: 4, 13168: 3, 13167: 3, 13166: 1, 13165: 2, 13164: 7, 13163: 1, 13162: 3, 13161: 11, 13160: 4, 13159: 3, 13158: 4, 13157: 2, 13156: 8, 13155: 1, 13154: 10, 13153: 14, 13152: 1, 13151: 5, 13150: 3, 13149: 4, 13148: 5, 13147: 4, 13146: 1, 13145: 3, 13144: 2, 13143: 4, 13142: 1, 13141: 1, 13140: 4, 13139: 3, 13138: 5, 13137: 5, 13136: 9, 13135: 1, 13134: 1, 13133: 2, 13132: 2, 13131: 1, 13130: 3, 13129: 5, 13128: 2, 13127: 5, 13126: 2, 13125: 0, 13124: 2, 13123: 5, 13122: 1, 13121: 8, 13120: 5, 13119: 0, 13118: 1, 13117: 2, 13116: 5, 13115: 0, 13114: 0, 13113: 1, 13112: 7, 13111: 18, 13110: 4, 13109: 3, 13108: 5, 13107: 2, 13106: 4, 13105: 3, 13104: 3, 13103: 4, 13102: 3, 13101: 2, 13100: 9, 13099: 12, 13098: 10, 13097: 11, 13096: 2, 13095: 3, 13094: 0, 13093: 1, 13092: 0, 13091: 0, 13090: 2, 13089: 7, 13088: 3, 13087: 0, 13086: 4, 13085: 3, 13084: 4, 13083: 6, 13082: 8, 13081: 4, 13080: 1, 13079: 3, 13078: 2, 13077: 3, 13076: 10, 13075: 3, 13074: 2, 13073: 1, 13072: 1, 13071: 6, 13070: 2, 13069: 1, 13068: 2, 13067: 2, 13066: 1, 13065: 2, 13064: 0, 13063: 0, 13062: 6, 13061: 1, 13060: 2, 13059: 0, 13058: 8, 13057: 3, 13056: 3, 13055: 3, 13054: 2, 13053: 0, 13052: 3, 13051: 8, 13050: 2, 13049: 1, 13048: 1, 13047: 0, 13046: 2, 13045: 2, 13044: 1, 13043: 7, 13042: 1, 13041: 5, 13040: 2, 13039: 2, 13038: 6, 13037: 3, 13036: 3, 13035: 1, 13034: 3, 13033: 4, 13032: 1, 13031: 1, 13030: 2, 13029: 5, 13028: 1, 13027: 1, 13026: 2, 13025: 3, 13024: 0, 13023: 4, 13022: 1, 13021: 2, 13020: 8, 13019: 7, 13018: 1, 13017: 2, 13016: 0, 13015: 0, 13014: 0, 13013: 6, 13012: 22, 13011: 1, 13010: 5, 13009: 7, 13008: 3, 13007: 0, 13006: 2, 13005: 2, 13004: 2, 13003: 2, 13002: 0, 13001: 7, 13000: 16, 12999: 8, 12998: 2, 12997: 8, 12996: 1, 12995: 10, 12994: 1, 12993: 3, 12992: 1, 12991: 1, 12990: 3, 12989: 3, 12988: 2, 12987: 5, 12986: 4, 12985: 5, 12984: 2, 12983: 4, 12982: 4, 12981: 6, 12980: 3, 12979: 2, 12978: 1, 12977: 2, 12976: 0, 12975: 3, 12974: 1, 12973: 1, 12972: 1, 12971: 3, 12970: 3, 12969: 10, 12968: 8, 12967: 14, 12966: 3, 12965: 1, 12964: 1, 12963: 1, 12962: 2, 12961: 7, 12960: 7, 12959: 4, 12958: 2, 12957: 7, 12956: 3, 12955: 3, 12954: 0, 12953: 2, 12952: 1, 12951: 6, 12950: 7, 12949: 1, 12948: 1, 12947: 10, 12946: 2, 12945: 3, 12944: 10, 12943: 6, 12942: 3, 12941: 4, 12940: 4, 12939: 6, 12938: 5, 12937: 2, 12936: 0, 12935: 3, 12934: 2, 12933: 2, 12932: 3, 12931: 14, 12930: 3, 12929: 2, 12928: 6, 12927: 5, 12926: 2, 12925: 2, 12924: 5, 12923: 15, 12922: 10, 12921: 3, 12920: 2, 12919: 3, 12918: 13, 12917: 3, 12916: 4, 12915: 16, 12914: 2, 12913: 2, 12912: 3, 12911: 4, 12910: 4, 12909: 0, 12908: 3, 12907: 4, 12906: 3, 12905: 3, 12904: 0, 12903: 8, 12902: 1, 12901: 2, 12900: 2, 12899: 1, 12898: 1, 12897: 3, 12896: 2, 12895: 0, 12894: 2, 12893: 2, 12892: 1, 12891: 1, 12890: 3, 12889: 12, 12888: 0, 12887: 21, 12886: 11, 12885: 3, 12884: 1, 12883: 3, 12882: 1, 12881: 3, 12880: 3, 12879: 2, 12878: 2, 12877: 6, 12876: 1, 12875: 2, 12874: 2, 12873: 4, 12872: 3, 12871: 3, 12870: 1, 12869: 14, 12868: 2, 12867: 4, 12866: 3, 12865: 3, 12864: 4, 12863: 2, 12862: 15, 12861: 3, 12860: 3, 12859: 5, 12858: 0, 12857: 7, 12856: 5, 12855: 1, 12854: 6, 12853: 2, 12852: 4, 12851: 0, 12850: 5, 12849: 2, 12848: 2, 12847: 0, 12846: 5, 12845: 9, 12844: 3, 12843: 3, 12842: 2, 12841: 6, 12840: 6, 12839: 3, 12838: 3, 12837: 1, 12836: 0, 12835: 1, 12834: 5, 12833: 1, 12832: 2, 12831: 0, 12830: 3, 12829: 5, 12828: 1, 12827: 1, 12826: 2, 12825: 1, 12824: 3, 12823: 4, 12822: 1, 12821: 8, 12820: 21, 12819: 5, 12818: 0, 12817: 0, 12816: 2, 12815: 4, 12814: 1, 12813: 1, 12812: 2, 12811: 3, 12810: 9, 12809: 6, 12808: 6, 12807: 9, 12806: 6, 12805: 8, 12804: 0, 12803: 4, 12802: 2, 12801: 5, 12800: 3, 12799: 1, 12798: 6, 12797: 4, 12796: 7, 12795: 5, 12794: 3, 12793: 1, 12792: 2, 12791: 1, 12790: 1, 12789: 6, 12788: 2, 12787: 2, 12786: 2, 12785: 1, 12784: 8, 12783: 4, 12782: 3, 12781: 2, 12780: 2, 12779: 10, 12778: 2, 12777: 2, 12776: 2, 12775: 1, 12774: 4, 12773: 3, 12772: 3, 12771: 0, 12770: 5, 12769: 9, 12768: 2, 12767: 0, 12766: 1, 12765: 0, 12764: 1, 12763: 3, 12762: 6, 12761: 5, 12760: 2, 12759: 2, 12758: 9, 12757: 1, 12756: 2, 12755: 7, 12754: 1, 12753: 3, 12752: 2, 12751: 5, 12750: 5, 12749: 3, 12748: 3, 12747: 6, 12746: 7, 12745: 2, 12744: 4, 12743: 8, 12742: 2, 12741: 12, 12740: 2, 12739: 0, 12738: 0, 12737: 1, 12736: 9, 12735: 1, 12734: 2, 12733: 2, 12732: 0, 12731: 2, 12730: 6, 12729: 4, 12728: 4, 12727: 3, 12726: 10, 12725: 8, 12724: 3, 12723: 4, 12722: 5, 12721: 3, 12720: 3, 12719: 2, 12718: 3, 12717: 3, 12716: 2, 12715: 2, 12714: 2, 12713: 3, 12712: 4, 12711: 1, 12710: 2, 12709: 5, 12708: 3, 12707: 6, 12706: 2, 12705: 0, 12704: 2, 12703: 2, 12702: 6, 12701: 5, 12700: 4, 12699: 5, 12698: 3, 12697: 4, 12696: 5, 12695: 3, 12694: 2, 12693: 4, 12692: 1, 12691: 3, 12690: 2, 12689: 3, 12688: 3, 12687: 3, 12686: 4, 12685: 0, 12684: 2, 12683: 1, 12682: 2, 12681: 0, 12680: 6, 12679: 2, 12678: 9, 12677: 1, 12676: 22, 12675: 1, 12674: 0, 12673: 6, 12672: 1, 12671: 2, 12670: 5, 12669: 11, 12668: 3, 12667: 6, 12666: 13, 12665: 1, 12664: 1, 12663: 3, 12662: 3, 12661: 4, 12660: 1, 12659: 0, 12658: 2, 12657: 3, 12656: 3, 12655: 3, 12654: 2, 12653: 2, 12652: 2, 12651: 0, 12650: 1, 12649: 1, 12648: 3, 12647: 1, 12646: 1, 12645: 6, 12644: 6, 12643: 3, 12642: 2, 12641: 2, 12640: 5, 12639: 4, 12638: 6, 12637: 0, 12636: 2, 12635: 1, 12634: 5, 12633: 2, 12632: 7, 12631: 6, 12630: 9, 12629: 6, 12628: 2, 12627: 9, 12626: 4, 12625: 13, 12624: 0, 12623: 12, 12622: 8, 12621: 2, 12620: 5, 12619: 1, 12618: 5, 12617: 4, 12616: 6, 12615: 2, 12614: 3, 12613: 4, 12612: 5, 12611: 0, 12610: 4, 12609: 2, 12608: 5, 12607: 5, 12606: 6, 12605: 8, 12604: 1, 12603: 5, 12602: 3, 12601: 3, 12600: 19, 12599: 2, 12598: 1, 12597: 4, 12596: 7, 12595: 7, 12594: 2, 12593: 10, 12592: 7, 12591: 2, 12590: 1, 12589: 1, 12588: 2, 12587: 1, 12586: 0, 12585: 1, 12584: 7, 12583: 1, 12582: 5, 12581: 4, 12580: 2, 12579: 4, 12578: 3, 12577: 3, 12576: 3, 12575: 3, 12574: 4, 12573: 1, 12572: 1, 12571: 3, 12570: 1, 12569: 8, 12568: 5, 12567: 5, 12566: 9, 12565: 1, 12564: 2, 12563: 2, 12562: 1, 12561: 3, 12560: 1, 12559: 8, 12558: 3, 12557: 1, 12556: 2, 12555: 3, 12554: 3, 12553: 2, 12552: 18, 12551: 4, 12550: 1, 12549: 3, 12548: 4, 12547: 1, 12546: 3, 12545: 2, 12544: 1, 12543: 5, 12542: 4, 12541: 1, 12540: 2, 12539: 3, 12538: 1, 12537: 6, 12536: 4, 12535: 4, 12534: 6, 12533: 1, 12532: 5, 12531: 3, 12530: 5, 12529: 2, 12528: 1, 12527: 1, 12526: 3, 12525: 11, 12524: 4, 12523: 1, 12522: 1, 12521: 16, 12520: 2, 12519: 3, 12518: 4, 12517: 3, 12516: 4, 12515: 2, 12514: 7, 12513: 3, 12512: 9, 12511: 6, 12510: 0, 12509: 0, 12508: 0, 12507: 1, 12506: 6, 12505: 1, 12504: 2, 12503: 11, 12502: 8, 12501: 6, 12500: 2, 12499: 9, 12498: 0, 12497: 1, 12496: 1, 12495: 2, 12494: 1, 12493: 4, 12492: 1, 12491: 6, 12490: 3, 12489: 2, 12488: 3, 12487: 1, 12486: 1, 12485: 1, 12484: 1, 12483: 1, 12482: 7, 12481: 2, 12480: 7, 12479: 6, 12478: 1, 12477: 1, 12476: 1, 12475: 1, 12474: 0, 12473: 1, 12472: 1, 12471: 2, 12470: 3, 12469: 4, 12468: 3, 12467: 1, 12466: 2, 12465: 1, 12464: 3, 12463: 12, 12462: 1, 12461: 2, 12460: 7, 12459: 11, 12458: 2, 12457: 5, 12456: 11, 12455: 3, 12454: 1, 12453: 2, 12452: 3, 12451: 7, 12450: 10, 12449: 1, 12448: 5, 12447: 5, 12446: 3, 12445: 9, 12444: 1, 12443: 2, 12442: 2, 12441: 1, 12440: 1, 12439: 4, 12438: 10, 12437: 4, 12436: 3, 12435: 2, 12434: 6, 12433: 4, 12432: 2, 12431: 6, 12430: 1, 12429: 4, 12428: 2, 12427: 3, 12426: 3, 12425: 1, 12424: 4, 12423: 1, 12422: 6, 12421: 2, 12420: 3, 12419: 4, 12418: 2, 12417: 2, 12416: 2, 12415: 0, 12414: 1, 12413: 5, 12412: 6, 12411: 1, 12410: 2, 12409: 16, 12408: 7, 12407: 10, 12406: 4, 12405: 1, 12404: 1, 12403: 1, 12402: 18, 12401: 1, 12400: 2, 12399: 2, 12398: 3, 12397: 4, 12396: 6, 12395: 3, 12394: 3, 12393: 3, 12392: 1, 12391: 7, 12390: 4, 12389: 7, 12388: 8, 12387: 5, 12386: 1, 12385: 4, 12384: 2, 12383: 0, 12382: 5, 12381: 3, 12380: 1, 12379: 2, 12378: 5, 12377: 1, 12376: 0, 12375: 0, 12374: 7, 12373: 2, 12372: 10, 12371: 2, 12370: 12, 12369: 1, 12368: 1, 12367: 6, 12366: 2, 12365: 0, 12364: 0, 12363: 3, 12362: 1, 12361: 3, 12360: 3, 12359: 10, 12358: 1, 12357: 1, 12356: 3, 12355: 8, 12354: 4, 12353: 1, 12352: 10, 12351: 4, 12350: 7, 12349: 1, 12348: 12, 12347: 3, 12346: 3, 12345: 2, 12344: 0, 12343: 1, 12342: 5, 12341: 4, 12340: 2, 12339: 2, 12338: 2, 12337: 2, 12336: 3, 12335: 1, 12334: 1, 12333: 2, 12332: 0, 12331: 2, 12330: 0, 12329: 2, 12328: 3, 12327: 6, 12326: 3, 12325: 1, 12324: 4, 12323: 6, 12322: 4, 12321: 3, 12320: 3, 12319: 3, 12318: 1, 12317: 9, 12316: 1, 12315: 12, 12314: 1, 12313: 2, 12312: 4, 12311: 12, 12310: 3, 12309: 1, 12308: 5, 12307: 5, 12306: 3, 12305: 2, 12304: 14, 12303: 4, 12302: 6, 12301: 4, 12300: 1, 12299: 1, 12298: 2, 12297: 2, 12296: 1, 12295: 1, 12294: 1, 12293: 0, 12292: 2, 12291: 2, 12290: 4, 12289: 3, 12288: 4, 12287: 11, 12286: 3, 12285: 3, 12284: 3, 12283: 5, 12282: 0, 12281: 6, 12280: 1, 12279: 2, 12278: 3, 12277: 1, 12276: 11, 12275: 14, 12274: 9, 12273: 5, 12272: 6, 12271: 2, 12270: 2, 12269: 5, 12268: 1, 12267: 3, 12266: 2, 12265: 3, 12264: 1, 12263: 6, 12262: 2, 12261: 11, 12260: 2, 12259: 5, 12258: 2, 12257: 8, 12256: 3, 12255: 17, 12254: 5, 12253: 3, 12252: 3, 12251: 2, 12250: 2, 12249: 0, 12248: 2, 12247: 16, 12246: 2, 12245: 2, 12244: 1, 12243: 4, 12242: 4, 12241: 3, 12240: 17, 12239: 2, 12238: 3, 12237: 3, 12236: 3, 12235: 4, 12234: 5, 12233: 0, 12232: 0, 12231: 4, 12230: 1, 12229: 4, 12228: 4, 12227: 2, 12226: 5, 12225: 2, 12224: 3, 12223: 3, 12222: 10, 12221: 3, 12220: 0, 12219: 2, 12218: 0, 12217: 1, 12216: 2, 12215: 1, 12214: 5, 12213: 0, 12212: 5, 12211: 3, 12210: 1, 12209: 3, 12208: 2, 12207: 4, 12206: 1, 12205: 17, 12204: 2, 12203: 2, 12202: 2, 12201: 3, 12200: 12, 12199: 9, 12198: 2, 12197: 1, 12196: 2, 12195: 5, 12194: 2, 12193: 2, 12192: 7, 12191: 4, 12190: 2, 12189: 2, 12188: 6, 12187: 4, 12186: 1, 12185: 3, 12184: 3, 12183: 2, 12182: 6, 12181: 2, 12180: 3, 12179: 20, 12178: 1, 12177: 0, 12176: 3, 12175: 5, 12174: 3, 12173: 4, 12172: 1, 12171: 1, 12170: 5, 12169: 14, 12168: 0, 12167: 2, 12166: 10, 12165: 10, 12164: 14, 12163: 10, 12162: 10, 12161: 10, 12160: 12, 12159: 8, 12158: 2, 12157: 1, 12156: 1, 12155: 0, 12154: 2, 12153: 1, 12152: 1, 12151: 19, 12150: 4, 12149: 6, 12148: 3, 12147: 2, 12146: 1, 12145: 7, 12144: 2, 12143: 7, 12142: 7, 12141: 5, 12140: 4, 12139: 4, 12138: 3, 12137: 4, 12136: 4, 12135: 5, 12134: 2, 12133: 6, 12132: 4, 12131: 6, 12130: 3, 12129: 6, 12128: 0, 12127: 3, 12126: 1, 12125: 3, 12124: 5, 12123: 5, 12122: 2, 12121: 1, 12120: 4, 12119: 19, 12118: 3, 12117: 11, 12116: 2, 12115: 3, 12114: 3, 12113: 7, 12112: 9, 12111: 6, 12110: 4, 12109: 7, 12108: 4, 12107: 1, 12106: 4, 12105: 2, 12104: 4, 12103: 4, 12102: 4, 12101: 3, 12100: 4, 12099: 2, 12098: 2, 12097: 1, 12096: 15, 12095: 0, 12094: 1, 12093: 1, 12092: 7, 12091: 3, 12090: 2, 12089: 7, 12088: 1, 12087: 3, 12086: 1, 12085: 2, 12084: 2, 12083: 3, 12082: 1, 12081: 3, 12080: 2, 12079: 2, 12078: 6, 12077: 2, 12076: 3, 12075: 2, 12074: 4, 12073: 1, 12072: 1, 12071: 3, 12070: 1, 12069: 6, 12068: 3, 12067: 2, 12066: 3, 12065: 5, 12064: 7, 12063: 2, 12062: 3, 12061: 6, 12060: 1, 12059: 12, 12058: 0, 12057: 7, 12056: 1, 12055: 1, 12054: 1, 12053: 1, 12052: 2, 12051: 2, 12050: 0, 12049: 0, 12048: 4, 12047: 1, 12046: 9, 12045: 16, 12044: 25, 12043: 1, 12042: 1, 12041: 1, 12040: 3, 12039: 2, 12038: 1, 12037: 9, 12036: 5, 12035: 5, 12034: 4, 12033: 2, 12032: 4, 12031: 5, 12030: 6, 12029: 15, 12028: 12, 12027: 2, 12026: 2, 12025: 3, 12024: 2, 12023: 0, 12022: 0, 12021: 5, 12020: 4, 12019: 0, 12018: 6, 12017: 1, 12016: 4, 12015: 1, 12014: 3, 12013: 1, 12012: 4, 12011: 0, 12010: 2, 12009: 7, 12008: 8, 12007: 2, 12006: 3, 12005: 1, 12004: 2, 12003: 2, 12002: 3, 12001: 2, 12000: 3, 11999: 2, 11998: 10, 11997: 2, 11996: 4, 11995: 6, 11994: 3, 11993: 6, 11992: 5, 11991: 9, 11990: 5, 11989: 1, 11988: 2, 11987: 2, 11986: 3, 11985: 2, 11984: 60, 11983: 1, 11982: 3, 11981: 1, 11980: 1, 11979: 3, 11978: 11, 11977: 22, 11976: 2, 11975: 9, 11974: 5, 11973: 8, 11972: 9, 11971: 14, 11970: 10, 11969: 9, 11968: 2, 11967: 5, 11966: 3, 11965: 4, 11964: 7, 11963: 2, 11962: 0, 11961: 0, 11960: 2, 11959: 4, 11958: 1, 11957: 3, 11956: 3, 11955: 0, 11954: 2, 11953: 1, 11952: 2, 11951: 5, 11950: 1, 11949: 7, 11948: 6, 11947: 5, 11946: 2, 11945: 3, 11944: 8, 11943: 1, 11942: 1, 11941: 5, 11940: 1, 11939: 13, 11938: 7, 11937: 4, 11936: 5, 11935: 5, 11934: 0, 11933: 4, 11932: 3, 11931: 2, 11930: 1, 11929: 2, 11928: 9, 11927: 1, 11926: 9, 11925: 5, 11924: 1, 11923: 3, 11922: 3, 11921: 4, 11920: 2, 11919: 4, 11918: 2, 11917: 2, 11916: 7, 11915: 2, 11914: 2, 11913: 1, 11912: 2, 11911: 1, 11910: 8, 11909: 2, 11908: 3, 11907: 4, 11906: 4, 11905: 13, 11904: 8, 11903: 3, 11902: 3, 11901: 1, 11900: 3, 11899: 7, 11898: 5, 11897: 5, 11896: 7, 11895: 3, 11894: 3, 11893: 5, 11892: 3, 11891: 7, 11890: 1, 11889: 1, 11888: 3, 11887: 5, 11886: 4, 11885: 2, 11884: 2, 11883: 2, 11882: 2, 11881: 7, 11880: 11, 11879: 0, 11878: 1, 11877: 3, 11876: 3, 11875: 0, 11874: 2, 11873: 7, 11872: 2, 11871: 21, 11870: 5, 11869: 5, 11868: 7, 11867: 2, 11866: 5, 11865: 5, 11864: 6, 11863: 1, 11862: 3, 11861: 1, 11860: 2, 11859: 4, 11858: 4, 11857: 1, 11856: 3, 11855: 8, 11854: 2, 11853: 8, 11852: 4, 11851: 12, 11850: 2, 11849: 3, 11848: 2, 11847: 10, 11846: 4, 11845: 10, 11844: 1, 11843: 10, 11842: 4, 11841: 2, 11840: 4, 11839: 0, 11838: 1, 11837: 8, 11836: 4, 11835: 4, 11834: 3, 11833: 2, 11832: 2, 11831: 6, 11830: 1, 11829: 2, 11828: 5, 11827: 1, 11826: 3, 11825: 4, 11824: 4, 11823: 1, 11822: 5, 11821: 3, 11820: 4, 11819: 4, 11818: 7, 11817: 6, 11816: 2, 11815: 2, 11814: 4, 11813: 3, 11812: 2, 11811: 3, 11810: 2, 11809: 2, 11808: 2, 11807: 2, 11806: 4, 11805: 3, 11804: 4, 11803: 4, 11802: 5, 11801: 3, 11800: 3, 11799: 3, 11798: 5, 11797: 2, 11796: 6, 11795: 1, 11794: 2, 11793: 8, 11792: 11, 11791: 3, 11790: 0, 11789: 1, 11788: 2, 11787: 3, 11786: 6, 11785: 6, 11784: 3, 11783: 4, 11782: 2, 11781: 10, 11780: 4, 11779: 8, 11778: 9, 11777: 7, 11776: 4, 11775: 3, 11774: 2, 11773: 1, 11772: 2, 11771: 0, 11770: 0, 11769: 1, 11768: 1, 11767: 1, 11766: 1, 11765: 3, 11764: 5, 11763: 10, 11762: 11, 11761: 2, 11760: 1, 11759: 0, 11758: 1, 11757: 2, 11756: 0, 11755: 2, 11754: 2, 11753: 3, 11752: 1, 11751: 0, 11750: 4, 11749: 3, 11748: 7, 11747: 2, 11746: 4, 11745: 8, 11744: 2, 11743: 7, 11742: 3, 11741: 4, 11740: 3, 11739: 3, 11738: 4, 11737: 1, 11736: 1, 11735: 2, 11734: 5, 11733: 3, 11732: 9, 11731: 5, 11730: 5, 11729: 2, 11728: 3, 11727: 2, 11726: 6, 11725: 1, 11724: 2, 11723: 1, 11722: 9, 11721: 8, 11720: 0, 11719: 2, 11718: 2, 11717: 3, 11716: 2, 11715: 1, 11714: 1, 11713: 6, 11712: 5, 11711: 4, 11710: 5, 11709: 6, 11708: 4, 11707: 6, 11706: 2, 11705: 0, 11704: 8, 11703: 3, 11702: 3, 11701: 4, 11700: 5, 11699: 2, 11698: 1, 11697: 1, 11696: 1, 11695: 2, 11694: 2, 11693: 2, 11692: 8, 11691: 1, 11690: 10, 11689: 1, 11688: 4, 11687: 2, 11686: 11, 11685: 2, 11684: 15, 11683: 1, 11682: 3, 11681: 10, 11680: 6, 11679: 1, 11678: 0, 11677: 5, 11676: 1, 11675: 1, 11674: 2, 11673: 2, 11672: 4, 11671: 2, 11670: 9, 11669: 2, 11668: 12, 11667: 5, 11666: 10, 11665: 1, 11664: 3, 11663: 4, 11662: 1, 11661: 3, 11660: 3, 11659: 6, 11658: 4, 11657: 1, 11656: 1, 11655: 1, 11654: 0, 11653: 5, 11652: 12, 11651: 13, 11650: 4, 11649: 13, 11648: 4, 11647: 35, 11646: 0, 11645: 0, 11644: 4, 11643: 7, 11642: 6, 11641: 4, 11640: 11, 11639: 4, 11638: 3, 11637: 7, 11636: 1, 11635: 3, 11634: 6, 11633: 1, 11632: 0, 11631: 6, 11630: 0, 11629: 12, 11628: 8, 11627: 0, 11626: 0, 11625: 4, 11624: 7, 11623: 6, 11622: 3, 11621: 3, 11620: 2, 11619: 1, 11618: 2, 11617: 2, 11616: 1, 11615: 3, 11614: 6, 11613: 2, 11612: 0, 11611: 0, 11610: 0, 11609: 3, 11608: 2, 11607: 2, 11606: 1, 11605: 4, 11604: 2, 11603: 4, 11602: 4, 11601: 6, 11600: 3, 11599: 4, 11598: 5, 11597: 4, 11596: 2, 11595: 3, 11594: 1, 11593: 1, 11592: 1, 11591: 1, 11590: 4, 11589: 1, 11588: 4, 11587: 17, 11586: 8, 11585: 1, 11584: 6, 11583: 8, 11582: 1, 11581: 7, 11580: 7, 11579: 22, 11578: 6, 11577: 7, 11576: 5, 11575: 2, 11574: 3, 11573: 4, 11572: 1, 11571: 1, 11570: 3, 11569: 3, 11568: 3, 11567: 6, 11566: 1, 11565: 1, 11564: 8, 11563: 4, 11562: 4, 11561: 1, 11560: 1, 11559: 18, 11558: 5, 11557: 13, 11556: 4, 11555: 2, 11554: 2, 11553: 2, 11552: 1, 11551: 1, 11550: 4, 11549: 1, 11548: 4, 11547: 11, 11546: 2, 11545: 3, 11544: 7, 11543: 3, 11542: 6, 11541: 3, 11540: 7, 11539: 4, 11538: 2, 11537: 2, 11536: 2, 11535: 3, 11534: 3, 11533: 1, 11532: 9, 11531: 1, 11530: 2, 11529: 13, 11528: 21, 11527: 6, 11526: 5, 11525: 6, 11524: 5, 11523: 8, 11522: 7, 11521: 1, 11520: 13, 11519: 2, 11518: 8, 11517: 1, 11516: 4, 11515: 1, 11514: 1, 11513: 8, 11512: 1, 11511: 5, 11510: 6, 11509: 2, 11508: 2, 11507: 1, 11506: 4, 11505: 3, 11504: 2, 11503: 1, 11502: 3, 11501: 1, 11500: 1, 11499: 3, 11498: 2, 11497: 1, 11496: 0, 11495: 12, 11494: 14, 11493: 4, 11492: 1, 11491: 4, 11490: 1, 11489: 2, 11488: 1, 11487: 3, 11486: 1, 11485: 2, 11484: 3, 11483: 0, 11482: 5, 11481: 4, 11480: 5, 11479: 2, 11478: 2, 11477: 6, 11476: 5, 11475: 3, 11474: 0, 11473: 2, 11472: 1, 11471: 9, 11470: 6, 11469: 9, 11468: 8, 11467: 6, 11466: 0, 11465: 6, 11464: 0, 11463: 6, 11462: 2, 11461: 1, 11460: 0, 11459: 6, 11458: 5, 11457: 1, 11456: 0, 11455: 3, 11454: 3, 11453: 1, 11452: 0, 11451: 3, 11450: 3, 11449: 2, 11448: 3, 11447: 5, 11446: 5, 11445: 5, 11444: 5, 11443: 4, 11442: 2, 11441: 1, 11440: 8, 11439: 2, 11438: 2, 11437: 1, 11436: 2, 11435: 1, 11434: 7, 11433: 3, 11432: 0, 11431: 5, 11430: 2, 11429: 9, 11428: 5, 11427: 1, 11426: 0, 11425: 2, 11424: 1, 11423: 17, 11422: 13, 11421: 2, 11420: 2, 11419: 6, 11418: 7, 11417: 1, 11416: 6, 11415: 2, 11414: 6, 11413: 4, 11412: 2, 11411: 1, 11410: 3, 11409: 4, 11408: 1, 11407: 4, 11406: 1, 11405: 2, 11404: 5, 11403: 5, 11402: 4, 11401: 2, 11400: 3, 11399: 2, 11398: 1, 11397: 2, 11396: 1, 11395: 1, 11394: 1, 11393: 2, 11392: 1, 11391: 8, 11390: 11, 11389: 1, 11388: 3, 11387: 0, 11386: 0, 11385: 2, 11384: 2, 11383: 1, 11382: 0, 11381: 0, 11380: 2, 11379: 2, 11378: 6, 11377: 1, 11376: 1, 11375: 1, 11374: 0, 11373: 2, 11372: 1, 11371: 1, 11370: 2, 11369: 1, 11368: 2, 11367: 57, 11366: 4, 11365: 13, 11364: 3, 11363: 2, 11362: 5, 11361: 4, 11360: 2, 11359: 1, 11358: 0, 11357: 1, 11356: 14, 11355: 1, 11354: 1, 11353: 3, 11352: 1, 11351: 4, 11350: 6, 11349: 1, 11348: 1, 11347: 0, 11346: 0, 11345: 0, 11344: 8, 11343: 5, 11342: 2, 11341: 1, 11340: 7, 11339: 6, 11338: 1, 11337: 2, 11336: 3, 11335: 9, 11334: 5, 11333: 2, 11332: 11, 11331: 2, 11330: 20, 11329: 1, 11328: 1, 11327: 3, 11326: 1, 11325: 1, 11324: 11, 11323: 3, 11322: 4, 11321: 2, 11320: 1, 11319: 2, 11318: 1, 11317: 4, 11316: 3, 11315: 1, 11314: 2, 11313: 1, 11312: 11, 11311: 0, 11310: 4, 11309: 9, 11308: 1, 11307: 3, 11306: 1, 11305: 5, 11304: 2, 11303: 2, 11302: 3, 11301: 2, 11300: 2, 11299: 0, 11298: 0, 11297: 7, 11296: 1, 11295: 2, 11294: 1, 11293: 2, 11292: 3, 11291: 2, 11290: 3, 11289: 2, 11288: 8, 11287: 4, 11286: 2, 11285: 6, 11284: 3, 11283: 1, 11282: 3, 11281: 2, 11280: 1, 11279: 4, 11278: 2, 11277: 1, 11276: 2, 11275: 2, 11274: 2, 11273: 1, 11272: 2, 11271: 1, 11270: 6, 11269: 15, 11268: 11, 11267: 4, 11266: 5, 11265: 4, 11264: 5, 11263: 1, 11262: 6, 11261: 4, 11260: 1, 11259: 2, 11258: 1, 11257: 2, 11256: 1, 11255: 7, 11254: 21, 11253: 6, 11252: 3, 11251: 2, 11250: 1, 11249: 0, 11248: 4, 11247: 3, 11246: 2, 11245: 4, 11244: 1, 11243: 3, 11242: 4, 11241: 10, 11240: 1, 11239: 1, 11238: 4, 11237: 13, 11236: 8, 11235: 6, 11234: 5, 11233: 4, 11232: 3, 11231: 1, 11230: 1, 11229: 3, 11228: 11, 11227: 5, 11226: 6, 11225: 4, 11224: 28, 11223: 0, 11222: 2, 11221: 2, 11220: 7, 11219: 5, 11218: 0, 11217: 1, 11216: 0, 11215: 3, 11214: 3, 11213: 2, 11212: 3, 11211: 1, 11210: 2, 11209: 16, 11208: 7, 11207: 6, 11206: 3, 11205: 6, 11204: 4, 11203: 2, 11202: 1, 11201: 7, 11200: 7, 11199: 0, 11198: 9, 11197: 3, 11196: 13, 11195: 1, 11194: 14, 11193: 0, 11192: 4, 11191: 4, 11190: 6, 11189: 15, 11188: 2, 11187: 5, 11186: 2, 11185: 1, 11184: 2, 11183: 4, 11182: 4, 11181: 3, 11180: 2, 11179: 1, 11178: 0, 11177: 13, 11176: 6, 11175: 2, 11174: 2, 11173: 2, 11172: 1, 11171: 2, 11170: 0, 11169: 2, 11168: 21, 11167: 3, 11166: 2, 11165: 6, 11164: 0, 11163: 0, 11162: 0, 11161: 3, 11160: 1, 11159: 2, 11158: 3, 11157: 5, 11156: 6, 11155: 2, 11154: 2, 11153: 1, 11152: 3, 11151: 1, 11150: 0, 11149: 0, 11148: 3, 11147: 3, 11146: 7, 11145: 9, 11144: 12, 11143: 6, 11142: 4, 11141: 4, 11140: 2, 11139: 8, 11138: 4, 11137: 1, 11136: 4, 11135: 3, 11134: 2, 11133: 1, 11132: 1, 11131: 9, 11130: 1, 11129: 4, 11128: 17, 11127: 3, 11126: 6, 11125: 6, 11124: 4, 11123: 6, 11122: 8, 11121: 1, 11120: 1, 11119: 3, 11118: 2, 11117: 4, 11116: 1, 11115: 2, 11114: 5, 11113: 5, 11112: 1, 11111: 18, 11110: 1, 11109: 2, 11108: 2, 11107: 0, 11106: 3, 11105: 0, 11104: 2, 11103: 4, 11102: 8, 11101: 3, 11100: 2, 11099: 5, 11098: 2, 11097: 2, 11096: 2, 11095: 5, 11094: 1, 11093: 0, 11092: 0, 11091: 6, 11090: 7, 11089: 2, 11088: 1, 11087: 1, 11086: 2, 11085: 5, 11084: 0, 11083: 7, 11082: 4, 11081: 0, 11080: 1, 11079: 1, 11078: 2, 11077: 6, 11076: 6, 11075: 1, 11074: 0, 11073: 5, 11072: 6, 11071: 1, 11070: 2, 11069: 1, 11068: 6, 11067: 5, 11066: 3, 11065: 3, 11064: 4, 11063: 1, 11062: 7, 11061: 1, 11060: 1, 11059: 0, 11058: 7, 11057: 2, 11056: 5, 11055: 5, 11054: 2, 11053: 4, 11052: 5, 11051: 5, 11050: 0, 11049: 1, 11048: 5, 11047: 2, 11046: 5, 11045: 8, 11044: 1, 11043: 3, 11042: 1, 11041: 6, 11040: 2, 11039: 0, 11038: 1, 11037: 4, 11036: 4, 11035: 3, 11034: 4, 11033: 3, 11032: 2, 11031: 4, 11030: 2, 11029: 0, 11028: 3, 11027: 3, 11026: 3, 11025: 5, 11024: 1, 11023: 6, 11022: 1, 11021: 20, 11020: 4, 11019: 3, 11018: 0, 11017: 1, 11016: 9, 11015: 12, 11014: 1, 11013: 4, 11012: 14, 11011: 2, 11010: 2, 11009: 7, 11008: 0, 11007: 2, 11006: 2, 11005: 1, 11004: 1, 11003: 4, 11002: 7, 11001: 1, 11000: 3, 10999: 1, 10998: 1, 10997: 3, 10996: 5, 10995: 2, 10994: 0, 10993: 1, 10992: 6, 10991: 0, 10990: 6, 10989: 5, 10988: 5, 10987: 2, 10986: 3, 10985: 5, 10984: 2, 10983: 2, 10982: 1, 10981: 2, 10980: 2, 10979: 3, 10978: 2, 10977: 3, 10976: 1, 10975: 7, 10974: 2, 10973: 1, 10972: 0, 10971: 5, 10970: 0, 10969: 2, 10968: 3, 10967: 4, 10966: 6, 10965: 3, 10964: 1, 10963: 5, 10962: 0, 10961: 7, 10960: 2, 10959: 2, 10958: 1, 10957: 4, 10956: 5, 10955: 2, 10954: 1, 10953: 2, 10952: 2, 10951: 0, 10950: 7, 10949: 11, 10948: 9, 10947: 1, 10946: 3, 10945: 5, 10944: 1, 10943: 5, 10942: 0, 10941: 7, 10940: 3, 10939: 2, 10938: 3, 10937: 7, 10936: 4, 10935: 3, 10934: 2, 10933: 2, 10932: 4, 10931: 1, 10930: 4, 10929: 1, 10928: 2, 10927: 3, 10926: 2, 10925: 2, 10924: 2, 10923: 4, 10922: 5, 10921: 1, 10920: 1, 10919: 0, 10918: 10, 10917: 2, 10916: 2, 10915: 0, 10914: 1, 10913: 6, 10912: 4, 10911: 0, 10910: 5, 10909: 2, 10908: 1, 10907: 12, 10906: 1, 10905: 3, 10904: 4, 10903: 1, 10902: 4, 10901: 5, 10900: 1, 10899: 1, 10898: 9, 10897: 1, 10896: 3, 10895: 3, 10894: 1, 10893: 6, 10892: 5, 10891: 4, 10890: 5, 10889: 0, 10888: 3, 10887: 4, 10886: 0, 10885: 2, 10884: 2, 10883: 3, 10882: 1, 10881: 8, 10880: 7, 10879: 4, 10878: 5, 10877: 4, 10876: 3, 10875: 9, 10874: 0, 10873: 8, 10872: 1, 10871: 7, 10870: 2, 10869: 1, 10868: 1, 10867: 1, 10866: 1, 10865: 4, 10864: 2, 10863: 3, 10862: 3, 10861: 4, 10860: 22, 10859: 0, 10858: 4, 10857: 3, 10856: 2, 10855: 2, 10854: 5, 10853: 6, 10852: 4, 10851: 3, 10850: 1, 10849: 3, 10848: 7, 10847: 7, 10846: 1, 10845: 1, 10844: 1, 10843: 7, 10842: 1, 10841: 2, 10840: 1, 10839: 5, 10838: 1, 10837: 3, 10836: 1, 10835: 4, 10834: 4, 10833: 2, 10832: 8, 10831: 15, 10830: 5, 10829: 3, 10828: 2, 10827: 5, 10826: 1, 10825: 8, 10824: 0, 10823: 7, 10822: 3, 10821: 7, 10820: 2, 10819: 5, 10818: 13, 10817: 1, 10816: 6, 10815: 3, 10814: 11, 10813: 3, 10812: 2, 10811: 13, 10810: 1, 10809: 4, 10808: 2, 10807: 4, 10806: 5, 10805: 11, 10804: 2, 10803: 3, 10802: 1, 10801: 1, 10800: 4, 10799: 1, 10798: 2, 10797: 9, 10796: 7, 10795: 12, 10794: 8, 10793: 7, 10792: 12, 10791: 3, 10790: 2, 10789: 3, 10788: 1, 10787: 4, 10786: 1, 10785: 2, 10784: 1, 10783: 11, 10782: 5, 10781: 6, 10780: 6, 10779: 20, 10778: 6, 10777: 13, 10776: 4, 10775: 3, 10774: 0, 10773: 2, 10772: 7, 10771: 28, 10770: 1, 10769: 3, 10768: 2, 10767: 6, 10766: 0, 10765: 7, 10764: 4, 10763: 1, 10762: 2, 10761: 2, 10760: 1, 10759: 2, 10758: 6, 10757: 2, 10756: 3, 10755: 5, 10754: 11, 10753: 5, 10752: 1, 10751: 2, 10750: 1, 10749: 5, 10748: 1, 10747: 4, 10746: 3, 10745: 5, 10744: 0, 10743: 7, 10742: 1, 10741: 1, 10740: 4, 10739: 14, 10738: 12, 10737: 0, 10736: 3, 10735: 1, 10734: 3, 10733: 5, 10732: 0, 10731: 2, 10730: 4, 10729: 8, 10728: 3, 10727: 3, 10726: 3, 10725: 3, 10724: 1, 10723: 12, 10722: 3, 10721: 2, 10720: 6, 10719: 2, 10718: 8, 10717: 3, 10716: 2, 10715: 3, 10714: 2, 10713: 8, 10712: 4, 10711: 4, 10710: 4, 10709: 1, 10708: 1, 10707: 1, 10706: 0, 10705: 1, 10704: 8, 10703: 2, 10702: 9, 10701: 7, 10700: 4, 10699: 6, 10698: 5, 10697: 6, 10696: 6, 10695: 6, 10694: 3, 10693: 1, 10692: 2, 10691: 6, 10690: 3, 10689: 2, 10688: 3, 10687: 7, 10686: 3, 10685: 3, 10684: 4, 10683: 4, 10682: 6, 10681: 4, 10680: 3, 10679: 3, 10678: 2, 10677: 2, 10676: 3, 10675: 2, 10674: 3, 10673: 0, 10672: 4, 10671: 4, 10670: 5, 10669: 8, 10668: 0, 10667: 1, 10666: 3, 10665: 8, 10664: 3, 10663: 0, 10662: 29, 10661: 1, 10660: 4, 10659: 7, 10658: 14, 10657: 5, 10656: 13, 10655: 15, 10654: 42, 10653: 6, 10652: 1, 10651: 2, 10650: 4, 10649: 1, 10648: 1, 10647: 6, 10646: 5, 10645: 6, 10644: 1, 10643: 2, 10642: 1, 10641: 3, 10640: 3, 10639: 1, 10638: 3, 10637: 2, 10636: 1, 10635: 6, 10634: 2, 10633: 3, 10632: 2, 10631: 3, 10630: 2, 10629: 7, 10628: 3, 10627: 2, 10626: 4, 10625: 8, 10624: 5, 10623: 3, 10622: 8, 10621: 8, 10620: 0, 10619: 1, 10618: 2, 10617: 1, 10616: 3, 10615: 1, 10614: 6, 10613: 2, 10612: 2, 10611: 3, 10610: 4, 10609: 5, 10608: 5, 10607: 2, 10606: 4, 10605: 1, 10604: 1, 10603: 2, 10602: 5, 10601: 4, 10600: 5, 10599: 6, 10598: 1, 10597: 2, 10596: 8, 10595: 3, 10594: 4, 10593: 9, 10592: 1, 10591: 7, 10590: 4, 10589: 5, 10588: 2, 10587: 1, 10586: 2, 10585: 2, 10584: 6, 10583: 1, 10582: 0, 10581: 0, 10580: 12, 10579: 5, 10578: 4, 10577: 1, 10576: 5, 10575: 19, 10574: 1, 10573: 1, 10572: 6, 10571: 5, 10570: 11, 10569: 5, 10568: 1, 10567: 0, 10566: 3, 10565: 3, 10564: 2, 10563: 2, 10562: 8, 10561: 2, 10560: 5, 10559: 23, 10558: 1, 10557: 2, 10556: 3, 10555: 2, 10554: 0, 10553: 3, 10552: 1, 10551: 2, 10550: 4, 10549: 2, 10548: 2, 10547: 1, 10546: 1, 10545: 2, 10544: 5, 10543: 9, 10542: 8, 10541: 4, 10540: 1, 10539: 3, 10538: 1, 10537: 6, 10536: 10, 10535: 0, 10534: 1, 10533: 14, 10532: 4, 10531: 1, 10530: 4, 10529: 2, 10528: 3, 10527: 4, 10526: 4, 10525: 4, 10524: 2, 10523: 2, 10522: 3, 10521: 3, 10520: 3, 10519: 1, 10518: 2, 10517: 1, 10516: 7, 10515: 1, 10514: 2, 10513: 6, 10512: 2, 10511: 7, 10510: 0, 10509: 1, 10508: 8, 10507: 1, 10506: 4, 10505: 3, 10504: 2, 10503: 5, 10502: 14, 10501: 6, 10500: 40, 10499: 4, 10498: 1, 10497: 3, 10496: 2, 10495: 1, 10494: 1, 10493: 0, 10492: 2, 10491: 1, 10490: 5, 10489: 4, 10488: 3, 10487: 1, 10486: 3, 10485: 3, 10484: 5, 10483: 2, 10482: 10, 10481: 5, 10480: 11, 10479: 47, 10478: 2, 10477: 16, 10476: 0, 10475: 1, 10474: 18, 10473: 2, 10472: 4, 10471: 2, 10470: 2, 10469: 3, 10468: 1, 10467: 1, 10466: 2, 10465: 1, 10464: 9, 10463: 6, 10462: 0, 10461: 2, 10460: 16, 10459: 7, 10458: 8, 10457: 8, 10456: 2, 10455: 2, 10454: 24, 10453: 9, 10452: 9, 10451: 5, 10450: 3, 10449: 3, 10448: 7, 10447: 4, 10446: 2, 10445: 3, 10444: 16, 10443: 3, 10442: 1, 10441: 5, 10440: 8, 10439: 11, 10438: 3, 10437: 1, 10436: 2, 10435: 3, 10434: 2, 10433: 3, 10432: 2, 10431: 1, 10430: 5, 10429: 3, 10428: 15, 10427: 3, 10426: 0, 10425: 5, 10424: 1, 10423: 11, 10422: 0, 10421: 6, 10420: 3, 10419: 4, 10418: 4, 10417: 11, 10416: 4, 10415: 2, 10414: 3, 10413: 12, 10412: 3, 10411: 1, 10410: 4, 10409: 6, 10408: 2, 10407: 7, 10406: 1, 10405: 1, 10404: 8, 10403: 2, 10402: 1, 10401: 5, 10400: 1, 10399: 4, 10398: 3, 10397: 2, 10396: 2, 10395: 5, 10394: 1, 10393: 2, 10392: 3, 10391: 9, 10390: 3, 10389: 4, 10388: 2, 10387: 3, 10386: 4, 10385: 7, 10384: 1, 10383: 9, 10382: 2, 10381: 2, 10380: 2, 10379: 9, 10378: 8, 10377: 1, 10376: 2, 10375: 2, 10374: 0, 10373: 1, 10372: 3, 10371: 4, 10370: 5, 10369: 11, 10368: 0, 10367: 15, 10366: 1, 10365: 3, 10364: 4, 10363: 5, 10362: 3, 10361: 5, 10360: 3, 10359: 2, 10358: 7, 10357: 0, 10356: 1, 10355: 12, 10354: 37, 10353: 34, 10352: 2, 10351: 4, 10350: 9, 10349: 16, 10348: 1, 10347: 6, 10346: 9, 10345: 11, 10344: 6, 10343: 0, 10342: 1, 10341: 1, 10340: 1, 10339: 3, 10338: 4, 10337: 2, 10336: 2, 10335: 3, 10334: 2, 10333: 3, 10332: 2, 10331: 1, 10330: 0, 10329: 5, 10328: 4, 10327: 3, 10326: 2, 10325: 4, 10324: 3, 10323: 3, 10322: 7, 10321: 1, 10320: 1, 10319: 3, 10318: 1, 10317: 1, 10316: 1, 10315: 7, 10314: 4, 10313: 10, 10312: 8, 10311: 7, 10310: 9, 10309: 7, 10308: 3, 10307: 1, 10306: 6, 10305: 0, 10304: 7, 10303: 2, 10302: 2, 10301: 6, 10300: 0, 10299: 1, 10298: 7, 10297: 3, 10296: 4, 10295: 1, 10294: 1, 10293: 2, 10292: 1, 10291: 7, 10290: 5, 10289: 4, 10288: 1, 10287: 4, 10286: 14, 10285: 0, 10284: 1, 10283: 4, 10282: 3, 10281: 9, 10280: 3, 10279: 12, 10278: 3, 10277: 1, 10276: 6, 10275: 2, 10274: 1, 10273: 2, 10272: 1, 10271: 6, 10270: 3, 10269: 6, 10268: 6, 10267: 0, 10266: 0, 10265: 4, 10264: 2, 10263: 2, 10262: 9, 10261: 1, 10260: 3, 10259: 4, 10258: 3, 10257: 4, 10256: 0, 10255: 3, 10254: 2, 10253: 0, 10252: 10, 10251: 0, 10250: 2, 10249: 4, 10248: 2, 10247: 2, 10246: 1, 10245: 0, 10244: 5, 10243: 2, 10242: 2, 10241: 1, 10240: 1, 10239: 6, 10238: 10, 10237: 4, 10236: 10, 10235: 10, 10234: 2, 10233: 3, 10232: 3, 10231: 12, 10230: 17, 10229: 1, 10228: 3, 10227: 4, 10226: 9, 10225: 4, 10224: 7, 10223: 4, 10222: 1, 10221: 2, 10220: 3, 10219: 3, 10218: 2, 10217: 7, 10216: 2, 10215: 0, 10214: 13, 10213: 22, 10212: 3, 10211: 6, 10210: 1, 10209: 8, 10208: 4, 10207: 0, 10206: 4, 10205: 11, 10204: 1, 10203: 1, 10202: 2, 10201: 1, 10200: 2, 10199: 3, 10198: 7, 10197: 1, 10196: 4, 10195: 3, 10194: 1, 10193: 2, 10192: 1, 10191: 1, 10190: 1, 10189: 2, 10188: 0, 10187: 11, 10186: 5, 10185: 8, 10184: 6, 10183: 1, 10182: 2, 10181: 1, 10180: 21, 10179: 2, 10178: 3, 10177: 4, 10176: 27, 10175: 3, 10174: 2, 10173: 0, 10172: 8, 10171: 3, 10170: 14, 10169: 4, 10168: 3, 10167: 8, 10166: 7, 10165: 3, 10164: 3, 10163: 11, 10162: 1, 10161: 6, 10160: 0, 10159: 1, 10158: 6, 10157: 2, 10156: 3, 10155: 1, 10154: 1, 10153: 3, 10152: 3, 10151: 1, 10150: 2, 10149: 2, 10148: 1, 10147: 0, 10146: 2, 10145: 2, 10144: 2, 10143: 2, 10142: 4, 10141: 1, 10140: 2, 10139: 5, 10138: 7, 10137: 1, 10136: 2, 10135: 7, 10134: 4, 10133: 5, 10132: 7, 10131: 3, 10130: 5, 10129: 3, 10128: 6, 10127: 3, 10126: 5, 10125: 3, 10124: 4, 10123: 1, 10122: 8, 10121: 1, 10120: 7, 10119: 2, 10118: 0, 10117: 2, 10116: 2, 10115: 2, 10114: 2, 10113: 1, 10112: 0, 10111: 3, 10110: 11, 10109: 7, 10108: 9, 10107: 14, 10106: 2, 10105: 6, 10104: 3, 10103: 2, 10102: 10, 10101: 8, 10100: 8, 10099: 4, 10098: 2, 10097: 3, 10096: 4, 10095: 2, 10094: 1, 10093: 1, 10092: 7, 10091: 5, 10090: 3, 10089: 6, 10088: 9, 10087: 2, 10086: 2, 10085: 11, 10084: 2, 10083: 3, 10082: 3, 10081: 2, 10080: 5, 10079: 14, 10078: 7, 10077: 4, 10076: 6, 10075: 2, 10074: 3, 10073: 5, 10072: 15, 10071: 2, 10070: 11, 10069: 7, 10068: 8, 10067: 2, 10066: 3, 10065: 6, 10064: 1, 10063: 0, 10062: 3, 10061: 3, 10060: 7, 10059: 5, 10058: 3, 10057: 2, 10056: 4, 10055: 2, 10054: 3, 10053: 1, 10052: 1, 10051: 2, 10050: 7, 10049: 2, 10048: 1, 10047: 3, 10046: 4, 10045: 8, 10044: 4, 10043: 2, 10042: 5, 10041: 14, 10040: 3, 10039: 9, 10038: 7, 10037: 8, 10036: 5, 10035: 2, 10034: 4, 10033: 3, 10032: 6, 10031: 3, 10030: 10, 10029: 1, 10028: 9, 10027: 22, 10026: 1, 10025: 1, 10024: 4, 10023: 4, 10022: 7, 10021: 2, 10020: 6, 10019: 8, 10018: 4, 10017: 3, 10016: 5, 10015: 0, 10014: 10, 10013: 6, 10012: 10, 10011: 7, 10010: 11, 10009: 7, 10008: 9, 10007: 8, 10006: 8, 10005: 4, 10004: 7, 10003: 5, 10002: 0, 10001: 6, 10000: 0, 9999: 1, 9998: 16, 9997: 6, 9996: 24, 9995: 3, 9994: 1, 9993: 6, 9992: 26, 9991: 3, 9990: 3, 9989: 3, 9988: 2, 9987: 0, 9986: 6, 9985: 4, 9984: 1, 9983: 1, 9982: 12, 9981: 3, 9980: 2, 9979: 3, 9978: 1, 9977: 10, 9976: 11, 9975: 2, 9974: 10, 9973: 2, 9972: 2, 9971: 2, 9970: 2, 9969: 2, 9968: 8, 9967: 1, 9966: 5, 9965: 5, 9964: 2, 9963: 4, 9962: 3, 9961: 3, 9960: 9, 9959: 8, 9958: 5, 9957: 3, 9956: 13, 9955: 12, 9954: 11, 9953: 15, 9952: 6, 9951: 10, 9950: 9, 9949: 8, 9948: 3, 9947: 4, 9946: 3, 9945: 7, 9944: 10, 9943: 8, 9942: 2, 9941: 20, 9940: 4, 9939: 4, 9938: 10, 9937: 8, 9936: 5, 9935: 4, 9934: 4, 9933: 2, 9932: 3, 9931: 2, 9930: 15, 9929: 3, 9928: 3, 9927: 5, 9926: 3, 9925: 5, 9924: 3, 9923: 10, 9922: 36, 9921: 6, 9920: 7, 9919: 4, 9918: 6, 9917: 1, 9916: 8, 9915: 3, 9914: 2, 9913: 3, 9912: 5, 9911: 4, 9910: 8, 9909: 0, 9908: 12, 9907: 3, 9906: 8, 9905: 1, 9904: 4, 9903: 11, 9902: 5, 9901: 8, 9900: 6, 9899: 7, 9898: 4, 9897: 2, 9896: 2, 9895: 1, 9894: 9, 9893: 1, 9892: 2, 9891: 2, 9890: 4, 9889: 3, 9888: 1, 9887: 1, 9886: 8, 9885: 5, 9884: 2, 9883: 5, 9882: 2, 9881: 3, 9880: 8, 9879: 2, 9878: 1, 9877: 7, 9876: 0, 9875: 1, 9874: 7, 9873: 1, 9872: 4, 9871: 2, 9870: 4, 9869: 10, 9868: 10, 9867: 1, 9866: 1, 9865: 1, 9864: 8, 9863: 0, 9862: 3, 9861: 4, 9860: 0, 9859: 4, 9858: 5, 9857: 2, 9856: 8, 9855: 2, 9854: 1, 9853: 2, 9852: 1, 9851: 1, 9850: 1, 9849: 2, 9848: 2, 9847: 1, 9846: 6, 9845: 2, 9844: 1, 9843: 0, 9842: 11, 9841: 1, 9840: 1, 9839: 1, 9838: 8, 9837: 19, 9836: 3, 9835: 13, 9834: 2, 9833: 5, 9832: 3, 9831: 3, 9830: 13, 9829: 1, 9828: 2, 9827: 4, 9826: 0, 9825: 13, 9824: 3, 9823: 2, 9822: 2, 9821: 1, 9820: 3, 9819: 4, 9818: 2, 9817: 3, 9816: 18, 9815: 2, 9814: 3, 9813: 1, 9812: 1, 9811: 4, 9810: 2, 9809: 6, 9808: 3, 9807: 6, 9806: 6, 9805: 5, 9804: 0, 9803: 0, 9802: 4, 9801: 2, 9800: 26, 9799: 1, 9798: 14, 9797: 3, 9796: 2, 9795: 9, 9794: 5, 9793: 7, 9792: 1, 9791: 4, 9790: 0, 9789: 10, 9788: 7, 9787: 1, 9786: 0, 9785: 6, 9784: 1, 9783: 1, 9782: 6, 9781: 5, 9780: 8, 9779: 25, 9778: 8, 9777: 10, 9776: 2, 9775: 1, 9774: 0, 9773: 3, 9772: 3, 9771: 1, 9770: 6, 9769: 14, 9768: 6, 9767: 5, 9766: 0, 9765: 4, 9764: 3, 9763: 5, 9762: 2, 9761: 0, 9760: 7, 9759: 2, 9758: 0, 9757: 1, 9756: 1, 9755: 1, 9754: 6, 9753: 5, 9752: 3, 9751: 1, 9750: 3, 9749: 4, 9748: 1, 9747: 3, 9746: 11, 9745: 3, 9744: 2, 9743: 4, 9742: 1, 9741: 3, 9740: 2, 9739: 4, 9738: 3, 9737: 14, 9736: 2, 9735: 4, 9734: 0, 9733: 3, 9732: 3, 9731: 7, 9730: 13, 9729: 5, 9728: 1, 9727: 1, 9726: 3, 9725: 6, 9724: 3, 9723: 13, 9722: 0, 9721: 1, 9720: 2, 9719: 4, 9718: 16, 9717: 1, 9716: 1, 9715: 2, 9714: 0, 9713: 2, 9712: 2, 9711: 2, 9710: 1, 9709: 15, 9708: 1, 9707: 3, 9706: 3, 9705: 7, 9704: 1, 9703: 4, 9702: 5, 9701: 3, 9700: 2, 9699: 10, 9698: 3, 9697: 3, 9696: 7, 9695: 11, 9694: 4, 9693: 0, 9692: 4, 9691: 8, 9690: 3, 9689: 2, 9688: 0, 9687: 9, 9686: 1, 9685: 2, 9684: 4, 9683: 3, 9682: 4, 9681: 10, 9680: 23, 9679: 8, 9678: 14, 9677: 2, 9676: 0, 9675: 3, 9674: 6, 9673: 14, 9672: 9, 9671: 0, 9670: 1, 9669: 2, 9668: 5, 9667: 5, 9666: 4, 9665: 2, 9664: 4, 9663: 4, 9662: 0, 9661: 2, 9660: 19, 9659: 3, 9658: 3, 9657: 1, 9656: 2, 9655: 9, 9654: 21, 9653: 5, 9652: 1, 9651: 2, 9650: 3, 9649: 14, 9648: 9, 9647: 0, 9646: 0, 9645: 1, 9644: 2, 9643: 7, 9642: 2, 9641: 20, 9640: 3, 9639: 5, 9638: 0, 9637: 11, 9636: 3, 9635: 1, 9634: 1, 9633: 1, 9632: 5, 9631: 1, 9630: 1, 9629: 1, 9628: 5, 9627: 3, 9626: 0, 9625: 4, 9624: 1, 9623: 2, 9622: 3, 9621: 3, 9620: 9, 9619: 9, 9618: 5, 9617: 20, 9616: 7, 9615: 2, 9614: 6, 9613: 7, 9612: 1, 9611: 2, 9610: 1, 9609: 0, 9608: 8, 9607: 2, 9606: 2, 9605: 4, 9604: 3, 9603: 2, 9602: 4, 9601: 4, 9600: 0, 9599: 20, 9598: 11, 9597: 13, 9596: 2, 9595: 1, 9594: 0, 9593: 3, 9592: 2, 9591: 1, 9590: 0, 9589: 3, 9588: 1, 9587: 3, 9586: 2, 9585: 2, 9584: 3, 9583: 4, 9582: 2, 9581: 2, 9580: 32, 9579: 11, 9578: 6, 9577: 1, 9576: 9, 9575: 4, 9574: 0, 9573: 1, 9572: 1, 9571: 6, 9570: 13, 9569: 2, 9568: 3, 9567: 3, 9566: 33, 9565: 7, 9564: 4, 9563: 7, 9562: 4, 9561: 6, 9560: 5, 9559: 4, 9558: 1, 9557: 1, 9556: 0, 9555: 2, 9554: 2, 9553: 1, 9552: 7, 9551: 1, 9550: 2, 9549: 0, 9548: 3, 9547: 1, 9546: 11, 9545: 1, 9544: 0, 9543: 3, 9542: 0, 9541: 4, 9540: 16, 9539: 2, 9538: 6, 9537: 4, 9536: 5, 9535: 0, 9534: 9, 9533: 4, 9532: 1, 9531: 3, 9530: 5, 9529: 9, 9528: 2, 9527: 2, 9526: 2, 9525: 0, 9524: 9, 9523: 3, 9522: 1, 9521: 3, 9520: 7, 9519: 3, 9518: 4, 9517: 4, 9516: 5, 9515: 1, 9514: 3, 9513: 6, 9512: 4, 9511: 1, 9510: 0, 9509: 4, 9508: 1, 9507: 1, 9506: 3, 9505: 5, 9504: 1, 9503: 2, 9502: 7, 9501: 1, 9500: 1, 9499: 1, 9498: 13, 9497: 6, 9496: 3, 9495: 10, 9494: 2, 9493: 1, 9492: 3, 9491: 2, 9490: 4, 9489: 1, 9488: 1, 9487: 3, 9486: 1, 9485: 8, 9484: 1, 9483: 0, 9482: 3, 9481: 4, 9480: 8, 9479: 3, 9478: 6, 9477: 4, 9476: 2, 9475: 1, 9474: 4, 9473: 2, 9472: 1, 9471: 9, 9470: 1, 9469: 1, 9468: 1, 9467: 2, 9466: 9, 9465: 9, 9464: 3, 9463: 1, 9462: 17, 9461: 14, 9460: 11, 9459: 8, 9458: 11, 9457: 1, 9456: 3, 9455: 2, 9454: 2, 9453: 1, 9452: 3, 9451: 6, 9450: 4, 9449: 4, 9448: 4, 9447: 2, 9446: 1, 9445: 2, 9444: 24, 9443: 1, 9442: 7, 9441: 4, 9440: 2, 9439: 4, 9438: 7, 9437: 4, 9436: 1, 9435: 1, 9434: 6, 9433: 8, 9432: 10, 9431: 5, 9430: 7, 9429: 8, 9428: 6, 9427: 0, 9426: 1, 9425: 1, 9424: 15, 9423: 3, 9422: 11, 9421: 2, 9420: 3, 9419: 3, 9418: 2, 9417: 2, 9416: 12, 9415: 2, 9414: 4, 9413: 2, 9412: 1, 9411: 6, 9410: 2, 9409: 2, 9408: 4, 9407: 1, 9406: 5, 9405: 2, 9404: 2, 9403: 3, 9402: 2, 9401: 1, 9400: 1, 9399: 3, 9398: 3, 9397: 1, 9396: 1, 9395: 5, 9394: 3, 9393: 1, 9392: 5, 9391: 1, 9390: 3, 9389: 3, 9388: 1, 9387: 1, 9386: 5, 9385: 19, 9384: 4, 9383: 4, 9382: 1, 9381: 1, 9380: 9, 9379: 3, 9378: 2, 9377: 5, 9376: 4, 9375: 4, 9374: 28, 9373: 13, 9372: 17, 9371: 1, 9370: 1, 9369: 2, 9368: 2, 9367: 1, 9366: 13, 9365: 0, 9364: 2, 9363: 14, 9362: 3, 9361: 1, 9360: 1, 9359: 1, 9358: 6, 9357: 3, 9356: 8, 9355: 0, 9354: 2, 9353: 0, 9352: 1, 9351: 9, 9350: 2, 9349: 2, 9348: 0, 9347: 1, 9346: 21, 9345: 4, 9344: 7, 9343: 2, 9342: 3, 9341: 3, 9340: 9, 9339: 42, 9338: 6, 9337: 11, 9336: 36, 9335: 3, 9334: 2, 9333: 11, 9332: 5, 9331: 8, 9330: 15, 9329: 3, 9328: 1, 9327: 5, 9326: 7, 9325: 26, 9324: 20, 9323: 3, 9322: 2, 9321: 9, 9320: 3, 9319: 5, 9318: 3, 9317: 4, 9316: 3, 9315: 3, 9314: 4, 9313: 1, 9312: 2, 9311: 10, 9310: 2, 9309: 6, 9308: 5, 9307: 5, 9306: 13, 9305: 8, 9304: 19, 9303: 1, 9302: 7, 9301: 2, 9300: 5, 9299: 3, 9298: 2, 9297: 8, 9296: 2, 9295: 3, 9294: 5, 9293: 2, 9292: 0, 9291: 3, 9290: 1, 9289: 2, 9288: 1, 9287: 7, 9286: 5, 9285: 1, 9284: 3, 9283: 2, 9282: 2, 9281: 4, 9280: 1, 9279: 0, 9278: 1, 9277: 5, 9276: 1, 9275: 1, 9274: 1, 9273: 0, 9272: 11, 9271: 0, 9270: 1, 9269: 0, 9268: 1, 9267: 3, 9266: 6, 9265: 1, 9264: 18, 9263: 6, 9262: 2, 9261: 6, 9260: 4, 9259: 4, 9258: 1, 9257: 5, 9256: 9, 9255: 11, 9254: 2, 9253: 8, 9252: 5, 9251: 3, 9250: 1, 9249: 1, 9248: 18, 9247: 2, 9246: 2, 9245: 8, 9244: 3, 9243: 2, 9242: 5, 9241: 1, 9240: 9, 9239: 0, 9238: 5, 9237: 4, 9236: 4, 9235: 6, 9234: 0, 9233: 2, 9232: 2, 9231: 6, 9230: 4, 9229: 3, 9228: 3, 9227: 4, 9226: 6, 9225: 2, 9224: 1, 9223: 3, 9222: 6, 9221: 6, 9220: 1, 9219: 1, 9218: 6, 9217: 5, 9216: 4, 9215: 15, 9214: 4, 9213: 6, 9212: 4, 9211: 1, 9210: 2, 9209: 1, 9208: 3, 9207: 2, 9206: 1, 9205: 1, 9204: 2, 9203: 1, 9202: 4, 9201: 9, 9200: 2, 9199: 3, 9198: 11, 9197: 3, 9196: 7, 9195: 5, 9194: 9, 9193: 1, 9192: 3, 9191: 9, 9190: 1, 9189: 3, 9188: 4, 9187: 7, 9186: 7, 9185: 9, 9184: 3, 9183: 3, 9182: 18, 9181: 2, 9180: 2, 9179: 1, 9178: 3, 9177: 4, 9176: 4, 9175: 4, 9174: 2, 9173: 4, 9172: 6, 9171: 2, 9170: 7, 9169: 2, 9168: 10, 9167: 3, 9166: 0, 9165: 4, 9164: 0, 9163: 3, 9162: 4, 9161: 3, 9160: 5, 9159: 1, 9158: 1, 9157: 1, 9156: 0, 9155: 2, 9154: 3, 9153: 8, 9152: 2, 9151: 6, 9150: 1, 9149: 10, 9148: 1, 9147: 1, 9146: 10, 9145: 0, 9144: 2, 9143: 3, 9142: 18, 9141: 3, 9140: 2, 9139: 0, 9138: 6, 9137: 12, 9136: 6, 9135: 1, 9134: 19, 9133: 5, 9132: 7, 9131: 2, 9130: 0, 9129: 1, 9128: 1, 9127: 2, 9126: 3, 9125: 0, 9124: 2, 9123: 8, 9122: 0, 9121: 1, 9120: 1, 9119: 2, 9118: 0, 9117: 1, 9116: 3, 9115: 0, 9114: 2, 9113: 5, 9112: 3, 9111: 5, 9110: 50, 9109: 3, 9108: 3, 9107: 5, 9106: 1, 9105: 2, 9104: 2, 9103: 3, 9102: 3, 9101: 1, 9100: 3, 9099: 27, 9098: 0, 9097: 1, 9096: 2, 9095: 6, 9094: 3, 9093: 0, 9092: 1, 9091: 1, 9090: 4, 9089: 7, 9088: 1, 9087: 2, 9086: 4, 9085: 5, 9084: 3, 9083: 35, 9082: 3, 9081: 10, 9080: 1, 9079: 1, 9078: 2, 9077: 1, 9076: 5, 9075: 3, 9074: 1, 9073: 11, 9072: 16, 9071: 9, 9070: 3, 9069: 4, 9068: 4, 9067: 3, 9066: 19, 9065: 0, 9064: 1, 9063: 9, 9062: 3, 9061: 2, 9060: 0, 9059: 1, 9058: 1, 9057: 4, 9056: 1, 9055: 2, 9054: 1, 9053: 4, 9052: 3, 9051: 25, 9050: 2, 9049: 4, 9048: 4, 9047: 2, 9046: 4, 9045: 1, 9044: 2, 9043: 6, 9042: 2, 9041: 1, 9040: 2, 9039: 6, 9038: 3, 9037: 2, 9036: 3, 9035: 0, 9034: 1, 9033: 2, 9032: 3, 9031: 1, 9030: 3, 9029: 0, 9028: 10, 9027: 3, 9026: 1, 9025: 0, 9024: 2, 9023: 2, 9022: 3, 9021: 6, 9020: 1, 9019: 11, 9018: 4, 9017: 2, 9016: 5, 9015: 1, 9014: 6, 9013: 4, 9012: 4, 9011: 4, 9010: 3, 9009: 2, 9008: 1, 9007: 2, 9006: 0, 9005: 1, 9004: 0, 9003: 0, 9002: 3, 9001: 3, 9000: 1, 8999: 1, 8998: 4, 8997: 0, 8996: 1, 8995: 3, 8994: 3, 8993: 3, 8992: 4, 8991: 7, 8990: 5, 8989: 2, 8988: 2, 8987: 2, 8986: 3, 8985: 3, 8984: 2, 8983: 3, 8982: 1, 8981: 13, 8980: 1, 8979: 1, 8978: 15, 8977: 1, 8976: 0, 8975: 2, 8974: 2, 8973: 23, 8972: 7, 8971: 4, 8970: 1, 8969: 1, 8968: 2, 8967: 1, 8966: 3, 8965: 5, 8964: 4, 8963: 10, 8962: 9, 8961: 2, 8960: 6, 8959: 1, 8958: 1, 8957: 0, 8956: 3, 8955: 2, 8954: 2, 8953: 3, 8952: 4, 8951: 2, 8950: 0, 8949: 5, 8948: 3, 8947: 2, 8946: 3, 8945: 2, 8944: 6, 8943: 2, 8942: 0, 8941: 2, 8940: 6, 8939: 4, 8938: 1, 8937: 3, 8936: 3, 8935: 9, 8934: 8, 8933: 1, 8932: 3, 8931: 5, 8930: 3, 8929: 8, 8928: 3, 8927: 7, 8926: 4, 8925: 1, 8924: 5, 8923: 3, 8922: 0, 8921: 7, 8920: 2, 8919: 2, 8918: 2, 8917: 2, 8916: 4, 8915: 2, 8914: 3, 8913: 10, 8912: 5, 8911: 1, 8910: 0, 8909: 3, 8908: 4, 8907: 0, 8906: 0, 8905: 3, 8904: 3, 8903: 2, 8902: 9, 8901: 3, 8900: 3, 8899: 1, 8898: 13, 8897: 1, 8896: 11, 8895: 20, 8894: 15, 8893: 10, 8892: 11, 8891: 3, 8890: 3, 8889: 4, 8888: 2, 8887: 2, 8886: 10, 8885: 3, 8884: 1, 8883: 0, 8882: 2, 8881: 1, 8880: 6, 8879: 0, 8878: 4, 8877: 7, 8876: 12, 8875: 5, 8874: 19, 8873: 3, 8872: 2, 8871: 1, 8870: 8, 8869: 11, 8868: 1, 8867: 1, 8866: 5, 8865: 3, 8864: 4, 8863: 3, 8862: 1, 8861: 6, 8860: 4, 8859: 2, 8858: 7, 8857: 1, 8856: 1, 8855: 5, 8854: 8, 8853: 2, 8852: 13, 8851: 8, 8850: 9, 8849: 16, 8848: 1, 8847: 2, 8846: 3, 8845: 1, 8844: 2, 8843: 1, 8842: 5, 8841: 2, 8840: 9, 8839: 6, 8838: 3, 8837: 4, 8836: 9, 8835: 3, 8834: 3, 8833: 4, 8832: 2, 8831: 6, 8830: 1, 8829: 3, 8828: 4, 8827: 3, 8826: 7, 8825: 3, 8824: 3, 8823: 2, 8822: 4, 8821: 1, 8820: 5, 8819: 4, 8818: 4, 8817: 2, 8816: 2, 8815: 6, 8814: 9, 8813: 2, 8812: 0, 8811: 1, 8810: 1, 8809: 1, 8808: 4, 8807: 2, 8806: 0, 8805: 7, 8804: 7, 8803: 5, 8802: 2, 8801: 6, 8800: 5, 8799: 22, 8798: 0, 8797: 2, 8796: 3, 8795: 2, 8794: 3, 8793: 2, 8792: 3, 8791: 3, 8790: 0, 8789: 2, 8788: 3, 8787: 10, 8786: 3, 8785: 4, 8784: 1, 8783: 4, 8782: 3, 8781: 5, 8780: 12, 8779: 4, 8778: 5, 8777: 5, 8776: 2, 8775: 1, 8774: 0, 8773: 2, 8772: 1, 8771: 2, 8770: 2, 8769: 2, 8768: 4, 8767: 4, 8766: 4, 8765: 3, 8764: 15, 8763: 3, 8762: 4, 8761: 1, 8760: 26, 8759: 17, 8758: 2, 8757: 4, 8756: 1, 8755: 0, 8754: 2, 8753: 0, 8752: 10, 8751: 3, 8750: 6, 8749: 2, 8748: 20, 8747: 6, 8746: 4, 8745: 2, 8744: 2, 8743: 2, 8742: 5, 8741: 22, 8740: 3, 8739: 0, 8738: 1, 8737: 3, 8736: 6, 8735: 2, 8734: 3, 8733: 4, 8732: 2, 8731: 3, 8730: 2, 8729: 4, 8728: 3, 8727: 3, 8726: 9, 8725: 3, 8724: 9, 8723: 5, 8722: 3, 8721: 5, 8720: 5, 8719: 11, 8718: 7, 8717: 2, 8716: 8, 8715: 4, 8714: 1, 8713: 1, 8712: 2, 8711: 2, 8710: 4, 8709: 2, 8708: 1, 8707: 1, 8706: 2, 8705: 2, 8704: 0, 8703: 2, 8702: 7, 8701: 5, 8700: 3, 8699: 3, 8698: 5, 8697: 0, 8696: 2, 8695: 1, 8694: 2, 8693: 2, 8692: 3, 8691: 3, 8690: 3, 8689: 8, 8688: 2, 8687: 14, 8686: 7, 8685: 2, 8684: 4, 8683: 1, 8682: 1, 8681: 3, 8680: 0, 8679: 3, 8678: 3, 8677: 3, 8676: 8, 8675: 7, 8674: 10, 8673: 9, 8672: 9, 8671: 8, 8670: 10, 8669: 7, 8668: 6, 8667: 5, 8666: 6, 8665: 6, 8664: 14, 8663: 10, 8662: 10, 8661: 8, 8660: 12, 8659: 10, 8658: 13, 8657: 5, 8656: 10, 8655: 9, 8654: 8, 8653: 10, 8652: 1, 8651: 1, 8650: 3, 8649: 9, 8648: 6, 8647: 8, 8646: 4, 8645: 6, 8644: 9, 8643: 0, 8642: 1, 8641: 1, 8640: 2, 8639: 3, 8638: 0, 8637: 3, 8636: 3, 8635: 2, 8634: 3, 8633: 10, 8632: 12, 8631: 11, 8630: 18, 8629: 2, 8628: 2, 8627: 3, 8626: 2, 8625: 2, 8624: 4, 8623: 1, 8622: 5, 8621: 2, 8620: 1, 8619: 2, 8618: 3, 8617: 9, 8616: 4, 8615: 6, 8614: 3, 8613: 1, 8612: 3, 8611: 3, 8610: 2, 8609: 4, 8608: 3, 8607: 3, 8606: 2, 8605: 4, 8604: 4, 8603: 9, 8602: 9, 8601: 7, 8600: 3, 8599: 3, 8598: 3, 8597: 1, 8596: 3, 8595: 12, 8594: 12, 8593: 5, 8592: 2, 8591: 1, 8590: 1, 8589: 2, 8588: 8, 8587: 2, 8586: 2, 8585: 4, 8584: 16, 8583: 0, 8582: 6, 8581: 4, 8580: 4, 8579: 5, 8578: 4, 8577: 6, 8576: 3, 8575: 0, 8574: 4, 8573: 2, 8572: 1, 8571: 2, 8570: 9, 8569: 0, 8568: 1, 8567: 1, 8566: 3, 8565: 3, 8564: 16, 8563: 6, 8562: 4, 8561: 2, 8560: 4, 8559: 7, 8558: 3, 8557: 2, 8556: 5, 8555: 7, 8554: 11, 8553: 3, 8552: 10, 8551: 6, 8550: 5, 8549: 1, 8548: 0, 8547: 4, 8546: 1, 8545: 8, 8544: 6, 8543: 12, 8542: 1, 8541: 5, 8540: 3, 8539: 5, 8538: 3, 8537: 1, 8536: 0, 8535: 9, 8534: 13, 8533: 17, 8532: 1, 8531: 1, 8530: 10, 8529: 10, 8528: 13, 8527: 16, 8526: 5, 8525: 5, 8524: 8, 8523: 8, 8522: 5, 8521: 25, 8520: 2, 8519: 25, 8518: 3, 8517: 2, 8516: 7, 8515: 2, 8514: 2, 8513: 2, 8512: 8, 8511: 4, 8510: 2, 8509: 7, 8508: 0, 8507: 2, 8506: 1, 8505: 2, 8504: 10, 8503: 8, 8502: 2, 8501: 2, 8500: 5, 8499: 3, 8498: 4, 8497: 4, 8496: 0, 8495: 10, 8494: 9, 8493: 12, 8492: 12, 8491: 3, 8490: 4, 8489: 5, 8488: 3, 8487: 5, 8486: 7, 8485: 8, 8484: 0, 8483: 2, 8482: 3, 8481: 1, 8480: 11, 8479: 6, 8478: 1, 8477: 6, 8476: 3, 8475: 3, 8474: 2, 8473: 3, 8472: 0, 8471: 0, 8470: 8, 8469: 1, 8468: 2, 8467: 4, 8466: 2, 8465: 2, 8464: 2, 8463: 7, 8462: 1, 8461: 5, 8460: 9, 8459: 0, 8458: 1, 8457: 11, 8456: 1, 8455: 1, 8454: 1, 8453: 1, 8452: 2, 8451: 7, 8450: 6, 8449: 2, 8448: 2, 8447: 2, 8446: 2, 8445: 6, 8444: 6, 8443: 9, 8442: 4, 8441: 8, 8440: 1, 8439: 1, 8438: 1, 8437: 2, 8436: 3, 8435: 1, 8434: 5, 8433: 6, 8432: 2, 8431: 6, 8430: 0, 8429: 2, 8428: 1, 8427: 3, 8426: 1, 8425: 2, 8424: 4, 8423: 7, 8422: 1, 8421: 11, 8420: 1, 8419: 2, 8418: 3, 8417: 0, 8416: 13, 8415: 9, 8414: 3, 8413: 0, 8412: 3, 8411: 2, 8410: 3, 8409: 9, 8408: 7, 8407: 0, 8406: 3, 8405: 6, 8404: 16, 8403: 1, 8402: 3, 8401: 5, 8400: 8, 8399: 3, 8398: 4, 8397: 11, 8396: 1, 8395: 1, 8394: 1, 8393: 9, 8392: 1, 8391: 0, 8390: 2, 8389: 12, 8388: 0, 8387: 3, 8386: 1, 8385: 0, 8384: 2, 8383: 6, 8382: 6, 8381: 7, 8380: 5, 8379: 3, 8378: 8, 8377: 4, 8376: 10, 8375: 2, 8374: 3, 8373: 5, 8372: 3, 8371: 1, 8370: 3, 8369: 5, 8368: 9, 8367: 6, 8366: 7, 8365: 3, 8364: 4, 8363: 1, 8362: 8, 8361: 8, 8360: 3, 8359: 1, 8358: 3, 8357: 1, 8356: 8, 8355: 1, 8354: 3, 8353: 4, 8352: 2, 8351: 4, 8350: 3, 8349: 1, 8348: 3, 8347: 8, 8346: 15, 8345: 4, 8344: 1, 8343: 6, 8342: 0, 8341: 4, 8340: 1, 8339: 1, 8338: 3, 8337: 1, 8336: 2, 8335: 2, 8334: 1, 8333: 7, 8332: 4, 8331: 9, 8330: 2, 8329: 3, 8328: 2, 8327: 2, 8326: 12, 8325: 1, 8324: 1, 8323: 12, 8322: 4, 8321: 8, 8320: 9, 8319: 1, 8318: 1, 8317: 13, 8316: 6, 8315: 3, 8314: 3, 8313: 5, 8312: 16, 8311: 7, 8310: 1, 8309: 1, 8308: 1, 8307: 6, 8306: 7, 8305: 7, 8304: 3, 8303: 2, 8302: 4, 8301: 4, 8300: 3, 8299: 1, 8298: 5, 8297: 1, 8296: 13, 8295: 0, 8294: 4, 8293: 5, 8292: 1, 8291: 0, 8290: 2, 8289: 2, 8288: 1, 8287: 4, 8286: 1, 8285: 11, 8284: 2, 8283: 1, 8282: 5, 8281: 10, 8280: 1, 8279: 5, 8278: 0, 8277: 7, 8276: 21, 8275: 2, 8274: 0, 8273: 10, 8272: 1, 8271: 2, 8270: 2, 8269: 20, 8268: 8, 8267: 7, 8266: 1, 8265: 1, 8264: 2, 8263: 2, 8262: 0, 8261: 2, 8260: 0, 8259: 1, 8258: 2, 8257: 6, 8256: 7, 8255: 1, 8254: 2, 8253: 2, 8252: 6, 8251: 2, 8250: 2, 8249: 2, 8248: 1, 8247: 2, 8246: 7, 8245: 2, 8244: 1, 8243: 3, 8242: 1, 8241: 8, 8240: 4, 8239: 9, 8238: 9, 8237: 9, 8236: 6, 8235: 4, 8234: 2, 8233: 3, 8232: 0, 8231: 4, 8230: 1, 8229: 2, 8228: 1, 8227: 1, 8226: 1, 8225: 0, 8224: 2, 8223: 1, 8222: 3, 8221: 1, 8220: 1, 8219: 1, 8218: 6, 8217: 2, 8216: 2, 8215: 0, 8214: 5, 8213: 1, 8212: 25, 8211: 3, 8210: 1, 8209: 1, 8208: 1, 8207: 5, 8206: 2, 8205: 1, 8204: 4, 8203: 1, 8202: 1, 8201: 5, 8200: 2, 8199: 3, 8198: 3, 8197: 7, 8196: 4, 8195: 2, 8194: 9, 8193: 0, 8192: 3, 8191: 3, 8190: 2, 8189: 1, 8188: 8, 8187: 7, 8186: 1, 8185: 4, 8184: 1, 8183: 2, 8182: 2, 8181: 5, 8180: 3, 8179: 6, 8178: 3, 8177: 4, 8176: 3, 8175: 1, 8174: 8, 8173: 2, 8172: 4, 8171: 5, 8170: 1, 8169: 5, 8168: 4, 8167: 3, 8166: 5, 8165: 2, 8164: 6, 8163: 5, 8162: 1, 8161: 4, 8160: 1, 8159: 3, 8158: 7, 8157: 0, 8156: 4, 8155: 7, 8154: 5, 8153: 5, 8152: 1, 8151: 1, 8150: 7, 8149: 2, 8148: 2, 8147: 4, 8146: 12, 8145: 2, 8144: 2, 8143: 4, 8142: 3, 8141: 14, 8140: 3, 8139: 8, 8138: 1, 8137: 1, 8136: 0, 8135: 4, 8134: 2, 8133: 2, 8132: 7, 8131: 4, 8130: 5, 8129: 5, 8128: 3, 8127: 1, 8126: 9, 8125: 2, 8124: 4, 8123: 16, 8122: 6, 8121: 4, 8120: 2, 8119: 5, 8118: 2, 8117: 3, 8116: 1, 8115: 4, 8114: 3, 8113: 5, 8112: 20, 8111: 4, 8110: 0, 8109: 3, 8108: 2, 8107: 5, 8106: 3, 8105: 3, 8104: 1, 8103: 7, 8102: 3, 8101: 2, 8100: 13, 8099: 5, 8098: 2, 8097: 5, 8096: 4, 8095: 3, 8094: 6, 8093: 7, 8092: 5, 8091: 1, 8090: 3, 8089: 8, 8088: 3, 8087: 2, 8086: 6, 8085: 7, 8084: 4, 8083: 3, 8082: 0, 8081: 12, 8080: 7, 8079: 10, 8078: 8, 8077: 3, 8076: 3, 8075: 3, 8074: 1, 8073: 10, 8072: 2, 8071: 1, 8070: 1, 8069: 8, 8068: 1, 8067: 2, 8066: 15, 8065: 3, 8064: 4, 8063: 3, 8062: 2, 8061: 4, 8060: 7, 8059: 2, 8058: 0, 8057: 1, 8056: 3, 8055: 1, 8054: 15, 8053: 2, 8052: 0, 8051: 6, 8050: 3, 8049: 3, 8048: 2, 8047: 4, 8046: 2, 8045: 1, 8044: 1, 8043: 3, 8042: 6, 8041: 5, 8040: 22, 8039: 3, 8038: 10, 8037: 13, 8036: 21, 8035: 1, 8034: 2, 8033: 11, 8032: 6, 8031: 4, 8030: 0, 8029: 2, 8028: 11, 8027: 3, 8026: 2, 8025: 2, 8024: 1, 8023: 2, 8022: 0, 8021: 3, 8020: 1, 8019: 5, 8018: 8, 8017: 2, 8016: 10, 8015: 7, 8014: 7, 8013: 2, 8012: 3, 8011: 17, 8010: 2, 8009: 4, 8008: 3, 8007: 19, 8006: 8, 8005: 1, 8004: 6, 8003: 1, 8002: 2, 8001: 6, 8000: 8, 7999: 2, 7998: 6, 7997: 2, 7996: 6, 7995: 9, 7994: 5, 7993: 0, 7992: 1, 7991: 13, 7990: 33, 7989: 5, 7988: 2, 7987: 5, 7986: 5, 7985: 5, 7984: 3, 7983: 1, 7982: 1, 7981: 0, 7980: 1, 7979: 3, 7978: 2, 7977: 1, 7976: 7, 7975: 16, 7974: 5, 7973: 2, 7972: 2, 7971: 0, 7970: 1, 7969: 1, 7968: 1, 7967: 0, 7966: 6, 7965: 4, 7964: 1, 7963: 2, 7962: 2, 7961: 1, 7960: 3, 7959: 1, 7958: 1, 7957: 10, 7956: 1, 7955: 0, 7954: 9, 7953: 5, 7952: 2, 7951: 3, 7950: 6, 7949: 2, 7948: 3, 7947: 1, 7946: 2, 7945: 0, 7944: 3, 7943: 3, 7942: 1, 7941: 3, 7940: 11, 7939: 15, 7938: 4, 7937: 5, 7936: 1, 7935: 2, 7934: 3, 7933: 4, 7932: 1, 7931: 1, 7930: 2, 7929: 0, 7928: 6, 7927: 9, 7926: 1, 7925: 9, 7924: 2, 7923: 1, 7922: 1, 7921: 0, 7920: 6, 7919: 6, 7918: 0, 7917: 5, 7916: 2, 7915: 7, 7914: 1, 7913: 1, 7912: 11, 7911: 3, 7910: 3, 7909: 2, 7908: 3, 7907: 4, 7906: 5, 7905: 7, 7904: 2, 7903: 5, 7902: 4, 7901: 5, 7900: 5, 7899: 7, 7898: 2, 7897: 6, 7896: 4, 7895: 1, 7894: 6, 7893: 6, 7892: 6, 7891: 8, 7890: 5, 7889: 3, 7888: 3, 7887: 4, 7886: 2, 7885: 1, 7884: 4, 7883: 14, 7882: 2, 7881: 1, 7880: 15, 7879: 7, 7878: 0, 7877: 2, 7876: 3, 7875: 9, 7874: 1, 7873: 4, 7872: 3, 7871: 2, 7870: 1, 7869: 4, 7868: 3, 7867: 4, 7866: 3, 7865: 3, 7864: 3, 7863: 4, 7862: 2, 7861: 5, 7860: 4, 7859: 3, 7858: 2, 7857: 2, 7856: 1, 7855: 3, 7854: 7, 7853: 2, 7852: 5, 7851: 2, 7850: 3, 7849: 3, 7848: 3, 7847: 5, 7846: 7, 7845: 3, 7844: 1, 7843: 9, 7842: 4, 7841: 4, 7840: 7, 7839: 2, 7838: 2, 7837: 3, 7836: 8, 7835: 8, 7834: 4, 7833: 2, 7832: 7, 7831: 1, 7830: 6, 7829: 2, 7828: 16, 7827: 1, 7826: 6, 7825: 3, 7824: 1, 7823: 2, 7822: 3, 7821: 3, 7820: 3, 7819: 3, 7818: 2, 7817: 1, 7816: 13, 7815: 2, 7814: 1, 7813: 3, 7812: 2, 7811: 6, 7810: 7, 7809: 49, 7808: 2, 7807: 2, 7806: 2, 7805: 2, 7804: 4, 7803: 3, 7802: 4, 7801: 4, 7800: 2, 7799: 1, 7798: 0, 7797: 2, 7796: 1, 7795: 15, 7794: 2, 7793: 2, 7792: 1, 7791: 1, 7790: 4, 7789: 1, 7788: 11, 7787: 2, 7786: 0, 7785: 1, 7784: 6, 7783: 8, 7782: 3, 7781: 2, 7780: 2, 7779: 0, 7778: 7, 7777: 5, 7776: 2, 7775: 8, 7774: 2, 7773: 1, 7772: 5, 7771: 6, 7770: 4, 7769: 5, 7768: 1, 7767: 1, 7766: 4, 7765: 6, 7764: 1, 7763: 2, 7762: 4, 7761: 2, 7760: 4, 7759: 3, 7758: 2, 7757: 7, 7756: 6, 7755: 8, 7754: 3, 7753: 4, 7752: 3, 7751: 1, 7750: 2, 7749: 9, 7748: 2, 7747: 4, 7746: 7, 7745: 1, 7744: 4, 7743: 1, 7742: 4, 7741: 1, 7740: 2, 7739: 3, 7738: 2, 7737: 0, 7736: 4, 7735: 1, 7734: 2, 7733: 3, 7732: 2, 7731: 1, 7730: 2, 7729: 3, 7728: 5, 7727: 1, 7726: 3, 7725: 5, 7724: 2, 7723: 7, 7722: 0, 7721: 3, 7720: 3, 7719: 4, 7718: 1, 7717: 5, 7716: 2, 7715: 3, 7714: 2, 7713: 2, 7712: 2, 7711: 1, 7710: 2, 7709: 1, 7708: 7, 7707: 6, 7706: 1, 7705: 5, 7704: 2, 7703: 14, 7702: 2, 7701: 2, 7700: 4, 7699: 3, 7698: 7, 7697: 7, 7696: 5, 7695: 15, 7694: 5, 7693: 2, 7692: 4, 7691: 2, 7690: 2, 7689: 9, 7688: 1, 7687: 10, 7686: 6, 7685: 2, 7684: 4, 7683: 3, 7682: 1, 7681: 1, 7680: 3, 7679: 2, 7678: 4, 7677: 4, 7676: 0, 7675: 4, 7674: 1, 7673: 4, 7672: 9, 7671: 3, 7670: 3, 7669: 1, 7668: 3, 7667: 0, 7666: 2, 7665: 1, 7664: 2, 7663: 4, 7662: 10, 7661: 4, 7660: 5, 7659: 1, 7658: 2, 7657: 3, 7656: 2, 7655: 13, 7654: 5, 7653: 4, 7652: 2, 7651: 13, 7650: 4, 7649: 11, 7648: 2, 7647: 4, 7646: 8, 7645: 1, 7644: 2, 7643: 9, 7642: 1, 7641: 0, 7640: 0, 7639: 9, 7638: 0, 7637: 0, 7636: 1, 7635: 0, 7634: 10, 7633: 4, 7632: 4, 7631: 2, 7630: 5, 7629: 6, 7628: 3, 7627: 2, 7626: 6, 7625: 10, 7624: 4, 7623: 4, 7622: 5, 7621: 1, 7620: 7, 7619: 1, 7618: 2, 7617: 6, 7616: 10, 7615: 5, 7614: 6, 7613: 5, 7612: 1, 7611: 0, 7610: 3, 7609: 6, 7608: 5, 7607: 5, 7606: 2, 7605: 1, 7604: 3, 7603: 0, 7602: 10, 7601: 10, 7600: 10, 7599: 6, 7598: 5, 7597: 13, 7596: 9, 7595: 6, 7594: 1, 7593: 1, 7592: 2, 7591: 2, 7590: 1, 7589: 1, 7588: 2, 7587: 3, 7586: 4, 7585: 4, 7584: 3, 7583: 8, 7582: 3, 7581: 8, 7580: 5, 7579: 2, 7578: 1, 7577: 2, 7576: 2, 7575: 8, 7574: 7, 7573: 0, 7572: 2, 7571: 2, 7570: 2, 7569: 6, 7568: 9, 7567: 7, 7566: 10, 7565: 6, 7564: 7, 7563: 11, 7562: 11, 7561: 4, 7560: 1, 7559: 1, 7558: 2, 7557: 3, 7556: 1, 7555: 1, 7554: 4, 7553: 0, 7552: 0, 7551: 4, 7550: 1, 7549: 0, 7548: 5, 7547: 2, 7546: 2, 7545: 3, 7544: 5, 7543: 1, 7542: 1, 7541: 3, 7540: 3, 7539: 3, 7538: 11, 7537: 3, 7536: 4, 7535: 6, 7534: 5, 7533: 2, 7532: 1, 7531: 5, 7530: 2, 7529: 8, 7528: 4, 7527: 2, 7526: 10, 7525: 2, 7524: 0, 7523: 6, 7522: 2, 7521: 1, 7520: 6, 7519: 2, 7518: 4, 7517: 1, 7516: 1, 7515: 4, 7514: 10, 7513: 6, 7512: 3, 7511: 7, 7510: 8, 7509: 2, 7508: 5, 7507: 2, 7506: 13, 7505: 14, 7504: 6, 7503: 11, 7502: 0, 7501: 7, 7500: 1, 7499: 6, 7498: 2, 7497: 1, 7496: 5, 7495: 7, 7494: 1, 7493: 0, 7492: 8, 7491: 3, 7490: 4, 7489: 1, 7488: 3, 7487: 1, 7486: 2, 7485: 4, 7484: 6, 7483: 2, 7482: 1, 7481: 2, 7480: 3, 7479: 0, 7478: 0, 7477: 11, 7476: 0, 7475: 2, 7474: 5, 7473: 3, 7472: 3, 7471: 5, 7470: 0, 7469: 6, 7468: 11, 7467: 1, 7466: 4, 7465: 8, 7464: 3, 7463: 10, 7462: 5, 7461: 5, 7460: 2, 7459: 2, 7458: 1, 7457: 1, 7456: 6, 7455: 2, 7454: 1, 7453: 9, 7452: 0, 7451: 10, 7450: 1, 7449: 7, 7448: 10, 7447: 7, 7446: 3, 7445: 2, 7444: 1, 7443: 8, 7442: 6, 7441: 1, 7440: 2, 7439: 2, 7438: 4, 7437: 2, 7436: 2, 7435: 1, 7434: 2, 7433: 10, 7432: 2, 7431: 2, 7430: 2, 7429: 3, 7428: 5, 7427: 2, 7426: 3, 7425: 7, 7424: 3, 7423: 2, 7422: 1, 7421: 1, 7420: 7, 7419: 3, 7418: 2, 7417: 6, 7416: 0, 7415: 1, 7414: 1, 7413: 2, 7412: 3, 7411: 4, 7410: 13, 7409: 4, 7408: 2, 7407: 0, 7406: 3, 7405: 5, 7404: 1, 7403: 1, 7402: 5, 7401: 2, 7400: 6, 7399: 5, 7398: 9, 7397: 3, 7396: 2, 7395: 4, 7394: 3, 7393: 2, 7392: 1, 7391: 2, 7390: 1, 7389: 0, 7388: 13, 7387: 2, 7386: 3, 7385: 0, 7384: 1, 7383: 2, 7382: 2, 7381: 2, 7380: 8, 7379: 1, 7378: 6, 7377: 6, 7376: 4, 7375: 3, 7374: 2, 7373: 2, 7372: 1, 7371: 2, 7370: 2, 7369: 1, 7368: 3, 7367: 4, 7366: 3, 7365: 0, 7364: 1, 7363: 4, 7362: 3, 7361: 5, 7360: 5, 7359: 3, 7358: 2, 7357: 8, 7356: 3, 7355: 1, 7354: 7, 7353: 3, 7352: 4, 7351: 0, 7350: 3, 7349: 3, 7348: 3, 7347: 2, 7346: 7, 7345: 13, 7344: 6, 7343: 8, 7342: 0, 7341: 11, 7340: 3, 7339: 4, 7338: 2, 7337: 5, 7336: 2, 7335: 3, 7334: 1, 7333: 3, 7332: 2, 7331: 6, 7330: 3, 7329: 5, 7328: 4, 7327: 3, 7326: 5, 7325: 9, 7324: 10, 7323: 3, 7322: 5, 7321: 3, 7320: 1, 7319: 1, 7318: 1, 7317: 8, 7316: 3, 7315: 4, 7314: 5, 7313: 5, 7312: 4, 7311: 4, 7310: 1, 7309: 2, 7308: 15, 7307: 2, 7306: 3, 7305: 7, 7304: 2, 7303: 1, 7302: 1, 7301: 2, 7300: 6, 7299: 5, 7298: 4, 7297: 3, 7296: 2, 7295: 9, 7294: 1, 7293: 2, 7292: 4, 7291: 2, 7290: 1, 7289: 6, 7288: 2, 7287: 3, 7286: 3, 7285: 1, 7284: 10, 7283: 9, 7282: 2, 7281: 13, 7280: 3, 7279: 3, 7278: 5, 7277: 10, 7276: 19, 7275: 24, 7274: 0, 7273: 3, 7272: 4, 7271: 8, 7270: 8, 7269: 3, 7268: 3, 7267: 7, 7266: 10, 7265: 14, 7264: 1, 7263: 5, 7262: 2, 7261: 6, 7260: 2, 7259: 2, 7258: 6, 7257: 3, 7256: 5, 7255: 0, 7254: 10, 7253: 1, 7252: 0, 7251: 3, 7250: 0, 7249: 2, 7248: 4, 7247: 8, 7246: 5, 7245: 8, 7244: 8, 7243: 6, 7242: 2, 7241: 5, 7240: 7, 7239: 6, 7238: 1, 7237: 3, 7236: 6, 7235: 7, 7234: 5, 7233: 5, 7232: 1, 7231: 4, 7230: 12, 7229: 0, 7228: 2, 7227: 3, 7226: 1, 7225: 6, 7224: 5, 7223: 4, 7222: 2, 7221: 11, 7220: 2, 7219: 6, 7218: 5, 7217: 1, 7216: 4, 7215: 2, 7214: 0, 7213: 1, 7212: 13, 7211: 3, 7210: 18, 7209: 2, 7208: 8, 7207: 6, 7206: 2, 7205: 5, 7204: 3, 7203: 6, 7202: 1, 7201: 2, 7200: 3, 7199: 10, 7198: 5, 7197: 6, 7196: 2, 7195: 3, 7194: 3, 7193: 18, 7192: 3, 7191: 2, 7190: 4, 7189: 4, 7188: 18, 7187: 17, 7186: 3, 7185: 2, 7184: 29, 7183: 4, 7182: 12, 7181: 3, 7180: 4, 7179: 1, 7178: 2, 7177: 7, 7176: 4, 7175: 4, 7174: 12, 7173: 3, 7172: 9, 7171: 4, 7170: 2, 7169: 2, 7168: 1, 7167: 6, 7166: 2, 7165: 3, 7164: 0, 7163: 5, 7162: 5, 7161: 14, 7160: 11, 7159: 2, 7158: 1, 7157: 1, 7156: 1, 7155: 2, 7154: 5, 7153: 3, 7152: 1, 7151: 14, 7150: 1, 7149: 0, 7148: 7, 7147: 8, 7146: 0, 7145: 3, 7144: 4, 7143: 0, 7142: 4, 7141: 4, 7140: 6, 7139: 5, 7138: 5, 7137: 1, 7136: 4, 7135: 10, 7134: 4, 7133: 1, 7132: 6, 7131: 0, 7130: 11, 7129: 7, 7128: 4, 7127: 11, 7126: 4, 7125: 3, 7124: 5, 7123: 2, 7122: 5, 7121: 3, 7120: 11, 7119: 8, 7118: 2, 7117: 1, 7116: 2, 7115: 3, 7114: 3, 7113: 3, 7112: 2, 7111: 3, 7110: 0, 7109: 3, 7108: 2, 7107: 2, 7106: 8, 7105: 2, 7104: 1, 7103: 1, 7102: 2, 7101: 2, 7100: 10, 7099: 3, 7098: 3, 7097: 7, 7096: 15, 7095: 2, 7094: 5, 7093: 4, 7092: 2, 7091: 7, 7090: 1, 7089: 1, 7088: 2, 7087: 2, 7086: 3, 7085: 3, 7084: 4, 7083: 7, 7082: 5, 7081: 2, 7080: 4, 7079: 9, 7078: 1, 7077: 5, 7076: 2, 7075: 4, 7074: 2, 7073: 3, 7072: 2, 7071: 7, 7070: 3, 7069: 4, 7068: 3, 7067: 6, 7066: 7, 7065: 3, 7064: 0, 7063: 6, 7062: 0, 7061: 4, 7060: 1, 7059: 2, 7058: 1, 7057: 2, 7056: 2, 7055: 0, 7054: 3, 7053: 5, 7052: 6, 7051: 18, 7050: 1, 7049: 3, 7048: 2, 7047: 4, 7046: 2, 7045: 6, 7044: 7, 7043: 14, 7042: 1, 7041: 2, 7040: 1, 7039: 6, 7038: 1, 7037: 2, 7036: 7, 7035: 11, 7034: 2, 7033: 2, 7032: 1, 7031: 2, 7030: 9, 7029: 3, 7028: 4, 7027: 0, 7026: 2, 7025: 1, 7024: 0, 7023: 5, 7022: 3, 7021: 4, 7020: 0, 7019: 4, 7018: 2, 7017: 1, 7016: 3, 7015: 2, 7014: 2, 7013: 6, 7012: 8, 7011: 7, 7010: 6, 7009: 1, 7008: 4, 7007: 3, 7006: 0, 7005: 3, 7004: 5, 7003: 2, 7002: 6, 7001: 9, 7000: 9, 6999: 1, 6998: 1, 6997: 2, 6996: 7, 6995: 0, 6994: 0, 6993: 4, 6992: 1, 6991: 1, 6990: 1, 6989: 5, 6988: 5, 6987: 3, 6986: 3, 6985: 4, 6984: 4, 6983: 1, 6982: 6, 6981: 6, 6980: 2, 6979: 4, 6978: 1, 6977: 1, 6976: 1, 6975: 2, 6974: 2, 6973: 23, 6972: 0, 6971: 1, 6970: 8, 6969: 2, 6968: 7, 6967: 8, 6966: 8, 6965: 2, 6964: 0, 6963: 0, 6962: 1, 6961: 3, 6960: 4, 6959: 3, 6958: 0, 6957: 1, 6956: 0, 6955: 3, 6954: 5, 6953: 2, 6952: 8, 6951: 2, 6950: 9, 6949: 4, 6948: 2, 6947: 10, 6946: 1, 6945: 10, 6944: 1, 6943: 8, 6942: 2, 6941: 5, 6940: 3, 6939: 5, 6938: 4, 6937: 4, 6936: 6, 6935: 8, 6934: 2, 6933: 1, 6932: 2, 6931: 6, 6930: 10, 6929: 10, 6928: 1, 6927: 3, 6926: 37, 6925: 1, 6924: 1, 6923: 7, 6922: 3, 6921: 2, 6920: 2, 6919: 4, 6918: 6, 6917: 11, 6916: 10, 6915: 3, 6914: 2, 6913: 3, 6912: 1, 6911: 0, 6910: 2, 6909: 9, 6908: 3, 6907: 2, 6906: 2, 6905: 1, 6904: 2, 6903: 3, 6902: 3, 6901: 3, 6900: 3, 6899: 1, 6898: 1, 6897: 1, 6896: 0, 6895: 10, 6894: 1, 6893: 3, 6892: 4, 6891: 0, 6890: 1, 6889: 13, 6888: 2, 6887: 1, 6886: 2, 6885: 5, 6884: 2, 6883: 5, 6882: 3, 6881: 5, 6880: 3, 6879: 5, 6878: 9, 6877: 3, 6876: 4, 6875: 3, 6874: 4, 6873: 2, 6872: 13, 6871: 1, 6870: 1, 6869: 3, 6868: 2, 6867: 18, 6866: 1, 6865: 4, 6864: 1, 6863: 1, 6862: 4, 6861: 2, 6860: 3, 6859: 8, 6858: 0, 6857: 2, 6856: 3, 6855: 17, 6854: 16, 6853: 5, 6852: 2, 6851: 0, 6850: 1, 6849: 4, 6848: 3, 6847: 8, 6846: 0, 6845: 13, 6844: 3, 6843: 4, 6842: 3, 6841: 6, 6840: 5, 6839: 1, 6838: 1, 6837: 11, 6836: 0, 6835: 3, 6834: 3, 6833: 4, 6832: 4, 6831: 1, 6830: 2, 6829: 3, 6828: 1, 6827: 4, 6826: 2, 6825: 9, 6824: 5, 6823: 2, 6822: 5, 6821: 2, 6820: 7, 6819: 17, 6818: 1, 6817: 7, 6816: 4, 6815: 1, 6814: 4, 6813: 4, 6812: 9, 6811: 3, 6810: 1, 6809: 5, 6808: 1, 6807: 0, 6806: 8, 6805: 2, 6804: 3, 6803: 1, 6802: 0, 6801: 5, 6800: 1, 6799: 1, 6798: 20, 6797: 2, 6796: 2, 6795: 5, 6794: 10, 6793: 3, 6792: 11, 6791: 3, 6790: 5, 6789: 4, 6788: 3, 6787: 6, 6786: 3, 6785: 2, 6784: 2, 6783: 1, 6782: 1, 6781: 1, 6780: 3, 6779: 1, 6778: 16, 6777: 2, 6776: 1, 6775: 8, 6774: 6, 6773: 0, 6772: 4, 6771: 1, 6770: 0, 6769: 4, 6768: 4, 6767: 4, 6766: 0, 6765: 4, 6764: 3, 6763: 2, 6762: 5, 6761: 0, 6760: 1, 6759: 0, 6758: 2, 6757: 2, 6756: 2, 6755: 13, 6754: 2, 6753: 3, 6752: 5, 6751: 1, 6750: 0, 6749: 7, 6748: 2, 6747: 9, 6746: 1, 6745: 1, 6744: 0, 6743: 2, 6742: 15, 6741: 2, 6740: 2, 6739: 9, 6738: 5, 6737: 5, 6736: 3, 6735: 1, 6734: 3, 6733: 3, 6732: 2, 6731: 1, 6730: 1, 6729: 0, 6728: 2, 6727: 0, 6726: 8, 6725: 19, 6724: 3, 6723: 13, 6722: 0, 6721: 2, 6720: 8, 6719: 3, 6718: 3, 6717: 5, 6716: 1, 6715: 27, 6714: 5, 6713: 0, 6712: 13, 6711: 6, 6710: 1, 6709: 3, 6708: 1, 6707: 4, 6706: 6, 6705: 12, 6704: 1, 6703: 2, 6702: 1, 6701: 3, 6700: 3, 6699: 2, 6698: 5, 6697: 3, 6696: 1, 6695: 1, 6694: 1, 6693: 4, 6692: 4, 6691: 4, 6690: 3, 6689: 1, 6688: 4, 6687: 4, 6686: 2, 6685: 4, 6684: 4, 6683: 4, 6682: 10, 6681: 2, 6680: 2, 6679: 1, 6678: 3, 6677: 1, 6676: 3, 6675: 8, 6674: 3, 6673: 4, 6672: 2, 6671: 2, 6670: 1, 6669: 1, 6668: 7, 6667: 2, 6666: 1, 6665: 3, 6664: 2, 6663: 1, 6662: 2, 6661: 1, 6660: 1, 6659: 1, 6658: 3, 6657: 8, 6656: 3, 6655: 20, 6654: 1, 6653: 3, 6652: 5, 6651: 2, 6650: 4, 6649: 5, 6648: 3, 6647: 4, 6646: 7, 6645: 1, 6644: 1, 6643: 4, 6642: 1, 6641: 3, 6640: 3, 6639: 10, 6638: 8, 6637: 3, 6636: 3, 6635: 0, 6634: 10, 6633: 5, 6632: 1, 6631: 6, 6630: 2, 6629: 8, 6628: 6, 6627: 8, 6626: 2, 6625: 3, 6624: 6, 6623: 4, 6622: 5, 6621: 5, 6620: 8, 6619: 7, 6618: 5, 6617: 0, 6616: 2, 6615: 1, 6614: 1, 6613: 0, 6612: 6, 6611: 4, 6610: 3, 6609: 3, 6608: 2, 6607: 6, 6606: 2, 6605: 1, 6604: 31, 6603: 3, 6602: 3, 6601: 3, 6600: 1, 6599: 2, 6598: 0, 6597: 49, 6596: 5, 6595: 2, 6594: 10, 6593: 4, 6592: 2, 6591: 2, 6590: 15, 6589: 3, 6588: 8, 6587: 8, 6586: 10, 6585: 7, 6584: 8, 6583: 6, 6582: 7, 6581: 3, 6580: 0, 6579: 4, 6578: 4, 6577: 5, 6576: 6, 6575: 4, 6574: 1, 6573: 2, 6572: 1, 6571: 2, 6570: 1, 6569: 5, 6568: 5, 6567: 8, 6566: 4, 6565: 3, 6564: 2, 6563: 1, 6562: 10, 6561: 2, 6560: 5, 6559: 5, 6558: 4, 6557: 3, 6556: 0, 6555: 2, 6554: 0, 6553: 3, 6552: 1, 6551: 2, 6550: 5, 6549: 12, 6548: 6, 6547: 2, 6546: 2, 6545: 3, 6544: 3, 6543: 2, 6542: 2, 6541: 1, 6540: 0, 6539: 4, 6538: 3, 6537: 3, 6536: 8, 6535: 1, 6534: 3, 6533: 6, 6532: 2, 6531: 4, 6530: 1, 6529: 1, 6528: 20, 6527: 11, 6526: 3, 6525: 9, 6524: 6, 6523: 5, 6522: 3, 6521: 2, 6520: 5, 6519: 19, 6518: 1, 6517: 2, 6516: 5, 6515: 1, 6514: 3, 6513: 9, 6512: 1, 6511: 3, 6510: 1, 6509: 3, 6508: 2, 6507: 1, 6506: 5, 6505: 1, 6504: 0, 6503: 2, 6502: 1, 6501: 1, 6500: 3, 6499: 4, 6498: 3, 6497: 5, 6496: 13, 6495: 10, 6494: 5, 6493: 2, 6492: 0, 6491: 1, 6490: 2, 6489: 1, 6488: 1, 6487: 1, 6486: 1, 6485: 8, 6484: 5, 6483: 1, 6482: 5, 6481: 1, 6480: 3, 6479: 3, 6478: 3, 6477: 7, 6476: 10, 6475: 13, 6474: 27, 6473: 18, 6472: 12, 6471: 7, 6470: 6, 6469: 5, 6468: 11, 6467: 5, 6466: 8, 6465: 1, 6464: 6, 6463: 10, 6462: 9, 6461: 2, 6460: 1, 6459: 2, 6458: 0, 6457: 0, 6456: 1, 6455: 4, 6454: 2, 6453: 5, 6452: 11, 6451: 8, 6450: 17, 6449: 1, 6448: 10, 6447: 28, 6446: 5, 6445: 3, 6444: 4, 6443: 3, 6442: 5, 6441: 3, 6440: 5, 6439: 1, 6438: 7, 6437: 3, 6436: 1, 6435: 5, 6434: 3, 6433: 3, 6432: 3, 6431: 2, 6430: 9, 6429: 1, 6428: 15, 6427: 3, 6426: 0, 6425: 5, 6424: 2, 6423: 0, 6422: 2, 6421: 5, 6420: 5, 6419: 4, 6418: 1, 6417: 5, 6416: 4, 6415: 5, 6414: 6, 6413: 3, 6412: 3, 6411: 1, 6410: 2, 6409: 12, 6408: 2, 6407: 5, 6406: 4, 6405: 7, 6404: 11, 6403: 9, 6402: 4, 6401: 0, 6400: 3, 6399: 3, 6398: 3, 6397: 4, 6396: 12, 6395: 0, 6394: 10, 6393: 8, 6392: 8, 6391: 3, 6390: 10, 6389: 2, 6388: 0, 6387: 3, 6386: 1, 6385: 6, 6384: 3, 6383: 0, 6382: 0, 6381: 3, 6380: 6, 6379: 22, 6378: 17, 6377: 14, 6376: 1, 6375: 3, 6374: 1, 6373: 3, 6372: 8, 6371: 8, 6370: 9, 6369: 43, 6368: 2, 6367: 4, 6366: 3, 6365: 2, 6364: 8, 6363: 6, 6362: 2, 6361: 1, 6360: 5, 6359: 2, 6358: 5, 6357: 3, 6356: 1, 6355: 1, 6354: 0, 6353: 1, 6352: 3, 6351: 7, 6350: 4, 6349: 3, 6348: 3, 6347: 1, 6346: 3, 6345: 16, 6344: 5, 6343: 3, 6342: 4, 6341: 8, 6340: 5, 6339: 2, 6338: 10, 6337: 0, 6336: 3, 6335: 7, 6334: 5, 6333: 3, 6332: 0, 6331: 4, 6330: 10, 6329: 10, 6328: 7, 6327: 5, 6326: 1, 6325: 1, 6324: 2, 6323: 7, 6322: 2, 6321: 2, 6320: 2, 6319: 3, 6318: 2, 6317: 3, 6316: 3, 6315: 0, 6314: 11, 6313: 6, 6312: 3, 6311: 6, 6310: 2, 6309: 1, 6308: 5, 6307: 10, 6306: 5, 6305: 3, 6304: 3, 6303: 2, 6302: 4, 6301: 1, 6300: 2, 6299: 3, 6298: 4, 6297: 5, 6296: 6, 6295: 2, 6294: 1, 6293: 1, 6292: 2, 6291: 5, 6290: 3, 6289: 8, 6288: 6, 6287: 4, 6286: 20, 6285: 1, 6284: 2, 6283: 3, 6282: 3, 6281: 1, 6280: 2, 6279: 95, 6278: 7, 6277: 2, 6276: 8, 6275: 2, 6274: 4, 6273: 1, 6272: 2, 6271: 3, 6270: 2, 6269: 1, 6268: 4, 6267: 5, 6266: 3, 6265: 4, 6264: 2, 6263: 2, 6262: 2, 6261: 1, 6260: 7, 6259: 2, 6258: 7, 6257: 4, 6256: 5, 6255: 7, 6254: 9, 6253: 9, 6252: 9, 6251: 6, 6250: 23, 6249: 3, 6248: 4, 6247: 4, 6246: 1, 6245: 11, 6244: 16, 6243: 2, 6242: 2, 6241: 8, 6240: 1, 6239: 4, 6238: 5, 6237: 2, 6236: 1, 6235: 5, 6234: 6, 6233: 6, 6232: 1, 6231: 1, 6230: 0, 6229: 11, 6228: 7, 6227: 1, 6226: 5, 6225: 2, 6224: 4, 6223: 4, 6222: 27, 6221: 10, 6220: 1, 6219: 2, 6218: 8, 6217: 0, 6216: 1, 6215: 6, 6214: 6, 6213: 3, 6212: 2, 6211: 3, 6210: 14, 6209: 2, 6208: 22, 6207: 1, 6206: 4, 6205: 1, 6204: 1, 6203: 4, 6202: 10, 6201: 2, 6200: 15, 6199: 0, 6198: 13, 6197: 5, 6196: 7, 6195: 2, 6194: 6, 6193: 8, 6192: 1, 6191: 10, 6190: 4, 6189: 2, 6188: 0, 6187: 1, 6186: 1, 6185: 1, 6184: 4, 6183: 2, 6182: 2, 6181: 2, 6180: 2, 6179: 3, 6178: 1, 6177: 13, 6176: 0, 6175: 1, 6174: 8, 6173: 1, 6172: 3, 6171: 4, 6170: 2, 6169: 7, 6168: 2, 6167: 4, 6166: 3, 6165: 10, 6164: 1, 6163: 3, 6162: 11, 6161: 9, 6160: 0, 6159: 2, 6158: 4, 6157: 10, 6156: 3, 6155: 5, 6154: 2, 6153: 2, 6152: 2, 6151: 2, 6150: 2, 6149: 5, 6148: 5, 6147: 5, 6146: 7, 6145: 1, 6144: 19, 6143: 0, 6142: 2, 6141: 6, 6140: 9, 6139: 16, 6138: 1, 6137: 3, 6136: 4, 6135: 1, 6134: 17, 6133: 2, 6132: 8, 6131: 2, 6130: 4, 6129: 1, 6128: 3, 6127: 2, 6126: 4, 6125: 9, 6124: 6, 6123: 3, 6122: 5, 6121: 4, 6120: 6, 6119: 2, 6118: 7, 6117: 13, 6116: 4, 6115: 25, 6114: 14, 6113: 8, 6112: 10, 6111: 6, 6110: 4, 6109: 3, 6108: 9, 6107: 8, 6106: 8, 6105: 9, 6104: 7, 6103: 5, 6102: 2, 6101: 3, 6100: 7, 6099: 10, 6098: 5, 6097: 5, 6096: 7, 6095: 3, 6094: 4, 6093: 7, 6092: 3, 6091: 3, 6090: 1, 6089: 16, 6088: 2, 6087: 4, 6086: 6, 6085: 10, 6084: 9, 6083: 7, 6082: 5, 6081: 4, 6080: 2, 6079: 4, 6078: 4, 6077: 5, 6076: 5, 6075: 0, 6074: 2, 6073: 7, 6072: 3, 6071: 2, 6070: 2, 6069: 4, 6068: 6, 6067: 0, 6066: 3, 6065: 6, 6064: 0, 6063: 0, 6062: 3, 6061: 0, 6060: 7, 6059: 10, 6058: 3, 6057: 1, 6056: 6, 6055: 8, 6054: 15, 6053: 9, 6052: 3, 6051: 10, 6050: 17, 6049: 3, 6048: 11, 6047: 10, 6046: 7, 6045: 3, 6044: 2, 6043: 5, 6042: 2, 6041: 6, 6040: 33, 6039: 0, 6038: 2, 6037: 2, 6036: 3, 6035: 5, 6034: 0, 6033: 2, 6032: 3, 6031: 3, 6030: 5, 6029: 6, 6028: 13, 6027: 2, 6026: 7, 6025: 1, 6024: 18, 6023: 2, 6022: 4, 6021: 1, 6020: 4, 6019: 2, 6018: 6, 6017: 3, 6016: 1, 6015: 2, 6014: 3, 6013: 3, 6012: 3, 6011: 2, 6010: 5, 6009: 4, 6008: 2, 6007: 40, 6006: 3, 6005: 3, 6004: 9, 6003: 6, 6002: 2, 6001: 5, 6000: 3, 5999: 5, 5998: 2, 5997: 1, 5996: 3, 5995: 1, 5994: 6, 5993: 1, 5992: 1, 5991: 3, 5990: 6, 5989: 1, 5988: 2, 5987: 1, 5986: 9, 5985: 3, 5984: 2, 5983: 4, 5982: 1, 5981: 1, 5980: 6, 5979: 2, 5978: 5, 5977: 12, 5976: 4, 5975: 4, 5974: 2, 5973: 7, 5972: 4, 5971: 5, 5970: 10, 5969: 4, 5968: 8, 5967: 7, 5966: 6, 5965: 1, 5964: 9, 5963: 10, 5962: 9, 5961: 9, 5960: 5, 5959: 4, 5958: 5, 5957: 1, 5956: 1, 5955: 1, 5954: 5, 5953: 4, 5952: 5, 5951: 5, 5950: 10, 5949: 5, 5948: 2, 5947: 1, 5946: 1, 5945: 1, 5944: 4, 5943: 10, 5942: 4, 5941: 1, 5940: 3, 5939: 1, 5938: 0, 5937: 5, 5936: 6, 5935: 4, 5934: 5, 5933: 10, 5932: 6, 5931: 3, 5930: 2, 5929: 1, 5928: 1, 5927: 1, 5926: 4, 5925: 28, 5924: 6, 5923: 0, 5922: 13, 5921: 7, 5920: 1, 5919: 9, 5918: 1, 5917: 2, 5916: 1, 5915: 3, 5914: 1, 5913: 2, 5912: 4, 5911: 3, 5910: 2, 5909: 13, 5908: 2, 5907: 2, 5906: 1, 5905: 12, 5904: 0, 5903: 0, 5902: 1, 5901: 4, 5900: 0, 5899: 2, 5898: 5, 5897: 2, 5896: 8, 5895: 2, 5894: 1, 5893: 4, 5892: 3, 5891: 5, 5890: 12, 5889: 1, 5888: 3, 5887: 1, 5886: 1, 5885: 1, 5884: 2, 5883: 4, 5882: 2, 5881: 2, 5880: 4, 5879: 0, 5878: 1, 5877: 6, 5876: 2, 5875: 0, 5874: 9, 5873: 7, 5872: 2, 5871: 5, 5870: 2, 5869: 0, 5868: 26, 5867: 2, 5866: 2, 5865: 4, 5864: 1, 5863: 10, 5862: 2, 5861: 7, 5860: 1, 5859: 3, 5858: 2, 5857: 2, 5856: 3, 5855: 3, 5854: 3, 5853: 2, 5852: 3, 5851: 2, 5850: 6, 5849: 10, 5848: 1, 5847: 7, 5846: 1, 5845: 4, 5844: 0, 5843: 4, 5842: 3, 5841: 2, 5840: 5, 5839: 1, 5838: 2, 5837: 19, 5836: 5, 5835: 5, 5834: 4, 5833: 9, 5832: 7, 5831: 6, 5830: 9, 5829: 1, 5828: 10, 5827: 8, 5826: 0, 5825: 12, 5824: 3, 5823: 5, 5822: 7, 5821: 4, 5820: 12, 5819: 1, 5818: 0, 5817: 1, 5816: 4, 5815: 3, 5814: 5, 5813: 2, 5812: 17, 5811: 2, 5810: 2, 5809: 10, 5808: 3, 5807: 0, 5806: 20, 5805: 4, 5804: 3, 5803: 28, 5802: 3, 5801: 7, 5800: 5, 5799: 3, 5798: 1, 5797: 8, 5796: 7, 5795: 4, 5794: 2, 5793: 4, 5792: 2, 5791: 4, 5790: 2, 5789: 2, 5788: 1, 5787: 0, 5786: 4, 5785: 1, 5784: 3, 5783: 0, 5782: 4, 5781: 1, 5780: 1, 5779: 0, 5778: 5, 5777: 1, 5776: 6, 5775: 2, 5774: 8, 5773: 12, 5772: 15, 5771: 3, 5770: 3, 5769: 2, 5768: 2, 5767: 6, 5766: 3, 5765: 1, 5764: 3, 5763: 0, 5762: 1, 5761: 4, 5760: 1, 5759: 4, 5758: 5, 5757: 2, 5756: 5, 5755: 1, 5754: 6, 5753: 1, 5752: 7, 5751: 5, 5750: 3, 5749: 2, 5748: 7, 5747: 2, 5746: 4, 5745: 1, 5744: 0, 5743: 0, 5742: 4, 5741: 1, 5740: 13, 5739: 5, 5738: 0, 5737: 0, 5736: 4, 5735: 3, 5734: 3, 5733: 2, 5732: 3, 5731: 4, 5730: 1, 5729: 2, 5728: 2, 5727: 2, 5726: 7, 5725: 9, 5724: 3, 5723: 6, 5722: 1, 5721: 2, 5720: 1, 5719: 2, 5718: 2, 5717: 2, 5716: 9, 5715: 0, 5714: 1, 5713: 4, 5712: 2, 5711: 1, 5710: 1, 5709: 2, 5708: 0, 5707: 17, 5706: 1, 5705: 6, 5704: 2, 5703: 0, 5702: 4, 5701: 4, 5700: 3, 5699: 2, 5698: 39, 5697: 1, 5696: 0, 5695: 3, 5694: 3, 5693: 3, 5692: 1, 5691: 5, 5690: 2, 5689: 2, 5688: 1, 5687: 6, 5686: 2, 5685: 4, 5684: 1, 5683: 6, 5682: 2, 5681: 11, 5680: 5, 5679: 6, 5678: 1, 5677: 2, 5676: 5, 5675: 1, 5674: 4, 5673: 14, 5672: 13, 5671: 7, 5670: 3, 5669: 0, 5668: 2, 5667: 1, 5666: 5, 5665: 7, 5664: 5, 5663: 3, 5662: 2, 5661: 4, 5660: 4, 5659: 8, 5658: 5, 5657: 8, 5656: 3, 5655: 1, 5654: 3, 5653: 2, 5652: 6, 5651: 3, 5650: 2, 5649: 2, 5648: 0, 5647: 3, 5646: 0, 5645: 5, 5644: 3, 5643: 4, 5642: 2, 5641: 0, 5640: 1, 5639: 4, 5638: 9, 5637: 2, 5636: 7, 5635: 3, 5634: 17, 5633: 10, 5632: 2, 5631: 1, 5630: 1, 5629: 1, 5628: 3, 5627: 3, 5626: 1, 5625: 0, 5624: 4, 5623: 3, 5622: 4, 5621: 9, 5620: 1, 5619: 4, 5618: 7, 5617: 2, 5616: 1, 5615: 7, 5614: 5, 5613: 8, 5612: 3, 5611: 11, 5610: 5, 5609: 4, 5608: 4, 5607: 4, 5606: 3, 5605: 0, 5604: 1, 5603: 3, 5602: 3, 5601: 6, 5600: 2, 5599: 4, 5598: 2, 5597: 1, 5596: 11, 5595: 1, 5594: 4, 5593: 1, 5592: 0, 5591: 4, 5590: 1, 5589: 3, 5588: 5, 5587: 3, 5586: 4, 5585: 1, 5584: 1, 5583: 0, 5582: 10, 5581: 0, 5580: 1, 5579: 6, 5578: 6, 5577: 2, 5576: 2, 5575: 3, 5574: 1, 5573: 3, 5572: 11, 5571: 6, 5570: 4, 5569: 4, 5568: 2, 5567: 0, 5566: 2, 5565: 1, 5564: 3, 5563: 10, 5562: 2, 5561: 1, 5560: 3, 5559: 5, 5558: 2, 5557: 3, 5556: 6, 5555: 2, 5554: 0, 5553: 2, 5552: 3, 5551: 3, 5550: 0, 5549: 10, 5548: 3, 5547: 4, 5546: 44, 5545: 10, 5544: 1, 5543: 4, 5542: 2, 5541: 2, 5540: 5, 5539: 1, 5538: 2, 5537: 19, 5536: 4, 5535: 5, 5534: 1, 5533: 3, 5532: 8, 5531: 5, 5530: 2, 5529: 2, 5528: 1, 5527: 1, 5526: 3, 5525: 3, 5524: 1, 5523: 15, 5522: 6, 5521: 2, 5520: 2, 5519: 7, 5518: 4, 5517: 1, 5516: 4, 5515: 0, 5514: 4, 5513: 14, 5512: 7, 5511: 40, 5510: 4, 5509: 0, 5508: 2, 5507: 7, 5506: 25, 5505: 0, 5504: 3, 5503: 1, 5502: 1, 5501: 43, 5500: 0, 5499: 1, 5498: 8, 5497: 3, 5496: 2, 5495: 2, 5494: 1, 5493: 3, 5492: 5, 5491: 11, 5490: 0, 5489: 5, 5488: 1, 5487: 0, 5486: 2, 5485: 4, 5484: 2, 5483: 7, 5482: 4, 5481: 1, 5480: 1, 5479: 2, 5478: 1, 5477: 5, 5476: 0, 5475: 6, 5474: 9, 5473: 3, 5472: 6, 5471: 10, 5470: 8, 5469: 1, 5468: 4, 5467: 1, 5466: 5, 5465: 4, 5464: 1, 5463: 5, 5462: 4, 5461: 5, 5460: 0, 5459: 5, 5458: 3, 5457: 29, 5456: 2, 5455: 1, 5454: 5, 5453: 3, 5452: 5, 5451: 9, 5450: 8, 5449: 1, 5448: 5, 5447: 19, 5446: 9, 5445: 1, 5444: 6, 5443: 2, 5442: 6, 5441: 4, 5440: 6, 5439: 1, 5438: 8, 5437: 7, 5436: 0, 5435: 9, 5434: 5, 5433: 3, 5432: 6, 5431: 1, 5430: 6, 5429: 7, 5428: 5, 5427: 2, 5426: 1, 5425: 24, 5424: 1, 5423: 1, 5422: 7, 5421: 4, 5420: 12, 5419: 7, 5418: 3, 5417: 2, 5416: 5, 5415: 0, 5414: 1, 5413: 1, 5412: 9, 5411: 6, 5410: 3, 5409: 2, 5408: 2, 5407: 5, 5406: 5, 5405: 5, 5404: 3, 5403: 6, 5402: 1, 5401: 1, 5400: 2, 5399: 5, 5398: 6, 5397: 5, 5396: 3, 5395: 8, 5394: 4, 5393: 6, 5392: 3, 5391: 3, 5390: 6, 5389: 3, 5388: 12, 5387: 6, 5386: 4, 5385: 3, 5384: 12, 5383: 2, 5382: 1, 5381: 6, 5380: 11, 5379: 4, 5378: 11, 5377: 1, 5376: 5, 5375: 4, 5374: 3, 5373: 1, 5372: 2, 5371: 2, 5370: 7, 5369: 1, 5368: 2, 5367: 3, 5366: 3, 5365: 2, 5364: 1, 5363: 3, 5362: 2, 5361: 8, 5360: 3, 5359: 1, 5358: 20, 5357: 7, 5356: 30, 5355: 17, 5354: 8, 5353: 0, 5352: 4, 5351: 4, 5350: 2, 5349: 13, 5348: 1, 5347: 2, 5346: 12, 5345: 5, 5344: 10, 5343: 2, 5342: 1, 5341: 6, 5340: 14, 5339: 9, 5338: 2, 5337: 16, 5336: 4, 5335: 3, 5334: 2, 5333: 4, 5332: 7, 5331: 5, 5330: 4, 5329: 5, 5328: 1, 5327: 6, 5326: 8, 5325: 2, 5324: 6, 5323: 8, 5322: 1, 5321: 3, 5320: 9, 5319: 5, 5318: 2, 5317: 1, 5316: 1, 5315: 1, 5314: 23, 5313: 3, 5312: 3, 5311: 3, 5310: 8, 5309: 5, 5308: 1, 5307: 2, 5306: 2, 5305: 18, 5304: 2, 5303: 8, 5302: 1, 5301: 1, 5300: 1, 5299: 2, 5298: 2, 5297: 4, 5296: 2, 5295: 1, 5294: 3, 5293: 2, 5292: 1, 5291: 2, 5290: 1, 5289: 1, 5288: 3, 5287: 4, 5286: 2, 5285: 4, 5284: 11, 5283: 2, 5282: 14, 5281: 3, 5280: 1, 5279: 1, 5278: 4, 5277: 6, 5276: 2, 5275: 4, 5274: 1, 5273: 3, 5272: 0, 5271: 30, 5270: 0, 5269: 2, 5268: 7, 5267: 1, 5266: 3, 5265: 0, 5264: 5, 5263: 6, 5262: 1, 5261: 7, 5260: 1, 5259: 11, 5258: 3, 5257: 6, 5256: 5, 5255: 12, 5254: 1, 5253: 4, 5252: 2, 5251: 6, 5250: 1, 5249: 1, 5248: 6, 5247: 6, 5246: 2, 5245: 2, 5244: 5, 5243: 4, 5242: 9, 5241: 1, 5240: 3, 5239: 10, 5238: 5, 5237: 9, 5236: 17, 5235: 68, 5234: 2, 5233: 31, 5232: 1, 5231: 1, 5230: 2, 5229: 21, 5228: 3, 5227: 4, 5226: 2, 5225: 5, 5224: 11, 5223: 2, 5222: 14, 5221: 7, 5220: 7, 5219: 7, 5218: 2, 5217: 6, 5216: 4, 5215: 1, 5214: 11, 5213: 5, 5212: 4, 5211: 22, 5210: 6, 5209: 1, 5208: 5, 5207: 0, 5206: 21, 5205: 5, 5204: 20, 5203: 4, 5202: 1, 5201: 3, 5200: 4, 5199: 9, 5198: 1, 5197: 5, 5196: 9, 5195: 0, 5194: 6, 5193: 7, 5192: 2, 5191: 2, 5190: 2, 5189: 2, 5188: 1, 5187: 1, 5186: 17, 5185: 0, 5184: 6, 5183: 4, 5182: 3, 5181: 2, 5180: 1, 5179: 6, 5178: 1, 5177: 1, 5176: 5, 5175: 2, 5174: 0, 5173: 0, 5172: 3, 5171: 1, 5170: 4, 5169: 5, 5168: 2, 5167: 3, 5166: 10, 5165: 13, 5164: 2, 5163: 2, 5162: 2, 5161: 15, 5160: 4, 5159: 12, 5158: 8, 5157: 4, 5156: 1, 5155: 7, 5154: 1, 5153: 1, 5152: 0, 5151: 1, 5150: 0, 5149: 2, 5148: 1, 5147: 11, 5146: 0, 5145: 13, 5144: 3, 5143: 1, 5142: 3, 5141: 1, 5140: 6, 5139: 8, 5138: 3, 5137: 21, 5136: 7, 5135: 1, 5134: 1, 5133: 5, 5132: 8, 5131: 2, 5130: 3, 5129: 8, 5128: 5, 5127: 3, 5126: 2, 5125: 7, 5124: 3, 5123: 4, 5122: 5, 5121: 2, 5120: 3, 5119: 9, 5118: 0, 5117: 41, 5116: 3, 5115: 6, 5114: 23, 5113: 3, 5112: 2, 5111: 5, 5110: 0, 5109: 3, 5108: 4, 5107: 7, 5106: 1, 5105: 14, 5104: 0, 5103: 3, 5102: 5, 5101: 4, 5100: 4, 5099: 1, 5098: 1, 5097: 2, 5096: 4, 5095: 1, 5094: 10, 5093: 6, 5092: 2, 5091: 10, 5090: 2, 5089: 4, 5088: 1, 5087: 4, 5086: 8, 5085: 4, 5084: 3, 5083: 7, 5082: 1, 5081: 3, 5080: 8, 5079: 1, 5078: 2, 5077: 3, 5076: 2, 5075: 4, 5074: 21, 5073: 2, 5072: 25, 5071: 2, 5070: 1, 5069: 3, 5068: 5, 5067: 20, 5066: 22, 5065: 3, 5064: 3, 5063: 6, 5062: 4, 5061: 2, 5060: 2, 5059: 9, 5058: 10, 5057: 0, 5056: 32, 5055: 1, 5054: 3, 5053: 4, 5052: 4, 5051: 2, 5050: 2, 5049: 3, 5048: 1, 5047: 3, 5046: 4, 5045: 3, 5044: 2, 5043: 2, 5042: 5, 5041: 2, 5040: 2, 5039: 1, 5038: 5, 5037: 8, 5036: 1, 5035: 13, 5034: 5, 5033: 6, 5032: 2, 5031: 2, 5030: 4, 5029: 5, 5028: 6, 5027: 3, 5026: 4, 5025: 4, 5024: 6, 5023: 4, 5022: 3, 5021: 9, 5020: 4, 5019: 5, 5018: 10, 5017: 14, 5016: 3, 5015: 5, 5014: 4, 5013: 4, 5012: 4, 5011: 4, 5010: 14, 5009: 4, 5008: 5, 5007: 5, 5006: 4, 5005: 4, 5004: 3, 5003: 2, 5002: 3, 5001: 5, 5000: 0, 4999: 3, 4998: 0, 4997: 3, 4996: 7, 4995: 7, 4994: 6, 4993: 3, 4992: 8, 4991: 1, 4990: 0, 4989: 2, 4988: 11, 4987: 1, 4986: 2, 4985: 6, 4984: 7, 4983: 4, 4982: 7, 4981: 1, 4980: 10, 4979: 3, 4978: 4, 4977: 6, 4976: 1, 4975: 7, 4974: 8, 4973: 2, 4972: 6, 4971: 16, 4970: 6, 4969: 2, 4968: 3, 4967: 10, 4966: 4, 4965: 3, 4964: 5, 4963: 5, 4962: 4, 4961: 14, 4960: 6, 4959: 3, 4958: 4, 4957: 3, 4956: 2, 4955: 2, 4954: 2, 4953: 4, 4952: 8, 4951: 1, 4950: 2, 4949: 4, 4948: 3, 4947: 2, 4946: 7, 4945: 7, 4944: 1, 4943: 1, 4942: 2, 4941: 2, 4940: 3, 4939: 10, 4938: 7, 4937: 5, 4936: 2, 4935: 4, 4934: 6, 4933: 3, 4932: 4, 4931: 8, 4930: 10, 4929: 3, 4928: 12, 4927: 5, 4926: 9, 4925: 1, 4924: 2, 4923: 4, 4922: 7, 4921: 7, 4920: 5, 4919: 6, 4918: 2, 4917: 8, 4916: 4, 4915: 1, 4914: 1, 4913: 3, 4912: 7, 4911: 2, 4910: 1, 4909: 4, 4908: 9, 4907: 5, 4906: 2, 4905: 4, 4904: 2, 4903: 7, 4902: 3, 4901: 5, 4900: 4, 4899: 4, 4898: 1, 4897: 3, 4896: 7, 4895: 3, 4894: 10, 4893: 2, 4892: 4, 4891: 2, 4890: 1, 4889: 4, 4888: 4, 4887: 0, 4886: 4, 4885: 3, 4884: 6, 4883: 0, 4882: 1, 4881: 2, 4880: 0, 4879: 3, 4878: 1, 4877: 8, 4876: 6, 4875: 0, 4874: 20, 4873: 1, 4872: 5, 4871: 1, 4870: 0, 4869: 1, 4868: 5, 4867: 0, 4866: 5, 4865: 6, 4864: 3, 4863: 0, 4862: 2, 4861: 2, 4860: 9, 4859: 7, 4858: 36, 4857: 24, 4856: 1, 4855: 2, 4854: 5, 4853: 5, 4852: 7, 4851: 10, 4850: 3, 4849: 5, 4848: 5, 4847: 0, 4846: 2, 4845: 0, 4844: 4, 4843: 1, 4842: 2, 4841: 5, 4840: 2, 4839: 2, 4838: 11, 4837: 4, 4836: 3, 4835: 7, 4834: 4, 4833: 2, 4832: 0, 4831: 10, 4830: 5, 4829: 2, 4828: 3, 4827: 7, 4826: 17, 4825: 5, 4824: 8, 4823: 2, 4822: 0, 4821: 12, 4820: 13, 4819: 2, 4818: 4, 4817: 11, 4816: 5, 4815: 7, 4814: 0, 4813: 4, 4812: 0, 4811: 0, 4810: 2, 4809: 12, 4808: 1, 4807: 5, 4806: 4, 4805: 1, 4804: 9, 4803: 8, 4802: 1, 4801: 3, 4800: 11, 4799: 2, 4798: 3, 4797: 9, 4796: 9, 4795: 1, 4794: 26, 4793: 4, 4792: 6, 4791: 0, 4790: 14, 4789: 5, 4788: 12, 4787: 8, 4786: 3, 4785: 8, 4784: 2, 4783: 1, 4782: 2, 4781: 1, 4780: 3, 4779: 9, 4778: 5, 4777: 6, 4776: 2, 4775: 2, 4774: 2, 4773: 1, 4772: 3, 4771: 4, 4770: 2, 4769: 1, 4768: 2, 4767: 2, 4766: 5, 4765: 1, 4764: 3, 4763: 2, 4762: 8, 4761: 1, 4760: 11, 4759: 1, 4758: 4, 4757: 3, 4756: 3, 4755: 15, 4754: 1, 4753: 3, 4752: 3, 4751: 1, 4750: 3, 4749: 2, 4748: 1, 4747: 0, 4746: 6, 4745: 4, 4744: 1, 4743: 0, 4742: 3, 4741: 5, 4740: 2, 4739: 10, 4738: 3, 4737: 2, 4736: 5, 4735: 1, 4734: 1, 4733: 2, 4732: 2, 4731: 2, 4730: 3, 4729: 7, 4728: 2, 4727: 6, 4726: 2, 4725: 5, 4724: 1, 4723: 22, 4722: 0, 4721: 4, 4720: 3, 4719: 3, 4718: 1, 4717: 0, 4716: 6, 4715: 0, 4714: 2, 4713: 19, 4712: 9, 4711: 7, 4710: 4, 4709: 5, 4708: 13, 4707: 5, 4706: 13, 4705: 1, 4704: 2, 4703: 3, 4702: 7, 4701: 2, 4700: 2, 4699: 7, 4698: 5, 4697: 4, 4696: 10, 4695: 8, 4694: 6, 4693: 1, 4692: 1, 4691: 0, 4690: 9, 4689: 5, 4688: 2, 4687: 3, 4686: 1, 4685: 9, 4684: 9, 4683: 0, 4682: 2, 4681: 4, 4680: 6, 4679: 2, 4678: 4, 4677: 2, 4676: 4, 4675: 1, 4674: 18, 4673: 3, 4672: 2, 4671: 2, 4670: 7, 4669: 10, 4668: 2, 4667: 7, 4666: 5, 4665: 1, 4664: 7, 4663: 9, 4662: 3, 4661: 6, 4660: 3, 4659: 13, 4658: 5, 4657: 7, 4656: 2, 4655: 2, 4654: 10, 4653: 5, 4652: 2, 4651: 2, 4650: 20, 4649: 1, 4648: 0, 4647: 6, 4646: 2, 4645: 2, 4644: 4, 4643: 3, 4642: 2, 4641: 8, 4640: 0, 4639: 1, 4638: 7, 4637: 4, 4636: 2, 4635: 5, 4634: 8, 4633: 0, 4632: 2, 4631: 4, 4630: 1, 4629: 5, 4628: 5, 4627: 1, 4626: 3, 4625: 1, 4624: 0, 4623: 2, 4622: 0, 4621: 11, 4620: 1, 4619: 5, 4618: 1, 4617: 7, 4616: 14, 4615: 7, 4614: 1, 4613: 2, 4612: 4, 4611: 5, 4610: 12, 4609: 8, 4608: 3, 4607: 8, 4606: 2, 4605: 34, 4604: 4, 4603: 4, 4602: 1, 4601: 40, 4600: 6, 4599: 5, 4598: 1, 4597: 2, 4596: 3, 4595: 3, 4594: 9, 4593: 0, 4592: 2, 4591: 1, 4590: 2, 4589: 8, 4588: 3, 4587: 0, 4586: 2, 4585: 2, 4584: 6, 4583: 5, 4582: 4, 4581: 22, 4580: 1, 4579: 10, 4578: 4, 4577: 9, 4576: 12, 4575: 2, 4574: 22, 4573: 0, 4572: 0, 4571: 14, 4570: 1, 4569: 4, 4568: 8, 4567: 1, 4566: 5, 4565: 1, 4564: 3, 4563: 7, 4562: 1, 4561: 5, 4560: 8, 4559: 3, 4558: 7, 4557: 6, 4556: 2, 4555: 2, 4554: 6, 4553: 2, 4552: 2, 4551: 2, 4550: 2, 4549: 9, 4548: 3, 4547: 25, 4546: 4, 4545: 3, 4544: 6, 4543: 2, 4542: 5, 4541: 3, 4540: 3, 4539: 5, 4538: 7, 4537: 1, 4536: 2, 4535: 4, 4534: 5, 4533: 9, 4532: 2, 4531: 4, 4530: 1, 4529: 4, 4528: 4, 4527: 5, 4526: 6, 4525: 2, 4524: 4, 4523: 2, 4522: 2, 4521: 4, 4520: 1, 4519: 1, 4518: 1, 4517: 15, 4516: 17, 4515: 1, 4514: 3, 4513: 3, 4512: 1, 4511: 2, 4510: 9, 4509: 5, 4508: 10, 4507: 2, 4506: 5, 4505: 0, 4504: 1, 4503: 4, 4502: 5, 4501: 0, 4500: 4, 4499: 27, 4498: 8, 4497: 3, 4496: 1, 4495: 3, 4494: 4, 4493: 3, 4492: 1, 4491: 7, 4490: 6, 4489: 5, 4488: 0, 4487: 3, 4486: 0, 4485: 1, 4484: 0, 4483: 1, 4482: 1, 4481: 3, 4480: 10, 4479: 3, 4478: 0, 4477: 1, 4476: 2, 4475: 8, 4474: 5, 4473: 6, 4472: 8, 4471: 1, 4470: 4, 4469: 9, 4468: 2, 4467: 1, 4466: 9, 4465: 2, 4464: 43, 4463: 47, 4462: 6, 4461: 5, 4460: 4, 4459: 2, 4458: 1, 4457: 3, 4456: 5, 4455: 3, 4454: 0, 4453: 2, 4452: 3, 4451: 3, 4450: 14, 4449: 3, 4448: 2, 4447: 8, 4446: 0, 4445: 4, 4444: 3, 4443: 0, 4442: 3, 4441: 3, 4440: 14, 4439: 1, 4438: 5, 4437: 6, 4436: 3, 4435: 21, 4434: 2, 4433: 1, 4432: 2, 4431: 0, 4430: 4, 4429: 5, 4428: 2, 4427: 4, 4426: 5, 4425: 14, 4424: 9, 4423: 2, 4422: 5, 4421: 26, 4420: 8, 4419: 12, 4418: 4, 4417: 2, 4416: 1, 4415: 3, 4414: 2, 4413: 6, 4412: 1, 4411: 5, 4410: 3, 4409: 4, 4408: 4, 4407: 4, 4406: 1, 4405: 15, 4404: 1, 4403: 2, 4402: 7, 4401: 10, 4400: 1, 4399: 1, 4398: 0, 4397: 4, 4396: 4, 4395: 1, 4394: 10, 4393: 9, 4392: 6, 4391: 3, 4390: 3, 4389: 3, 4388: 2, 4387: 0, 4386: 9, 4385: 9, 4384: 3, 4383: 25, 4382: 9, 4381: 3, 4380: 1, 4379: 0, 4378: 3, 4377: 5, 4376: 2, 4375: 7, 4374: 7, 4373: 5, 4372: 13, 4371: 2, 4370: 2, 4369: 8, 4368: 4, 4367: 1, 4366: 3, 4365: 1, 4364: 11, 4363: 3, 4362: 4, 4361: 6, 4360: 6, 4359: 4, 4358: 5, 4357: 6, 4356: 6, 4355: 7, 4354: 4, 4353: 7, 4352: 1, 4351: 4, 4350: 2, 4349: 5, 4348: 1, 4347: 2, 4346: 3, 4345: 2, 4344: 2, 4343: 10, 4342: 4, 4341: 7, 4340: 11, 4339: 11, 4338: 7, 4337: 2, 4336: 3, 4335: 2, 4334: 4, 4333: 5, 4332: 2, 4331: 2, 4330: 3, 4329: 9, 4328: 0, 4327: 8, 4326: 2, 4325: 2, 4324: 3, 4323: 9, 4322: 10, 4321: 5, 4320: 3, 4319: 23, 4318: 4, 4317: 4, 4316: 3, 4315: 5, 4314: 2, 4313: 7, 4312: 0, 4311: 3, 4310: 4, 4309: 2, 4308: 5, 4307: 3, 4306: 12, 4305: 1, 4304: 6, 4303: 1, 4302: 3, 4301: 5, 4300: 4, 4299: 4, 4298: 3, 4297: 1, 4296: 1, 4295: 1, 4294: 18, 4293: 23, 4292: 5, 4291: 4, 4290: 2, 4289: 4, 4288: 10, 4287: 8, 4286: 17, 4285: 1, 4284: 6, 4283: 12, 4282: 10, 4281: 5, 4280: 4, 4279: 3, 4278: 6, 4277: 24, 4276: 3, 4275: 3, 4274: 4, 4273: 3, 4272: 0, 4271: 2, 4270: 11, 4269: 7, 4268: 5, 4267: 15, 4266: 1, 4265: 1, 4264: 8, 4263: 6, 4262: 3, 4261: 5, 4260: 5, 4259: 3, 4258: 7, 4257: 7, 4256: 2, 4255: 8, 4254: 3, 4253: 0, 4252: 14, 4251: 0, 4250: 4, 4249: 5, 4248: 4, 4247: 6, 4246: 1, 4245: 2, 4244: 6, 4243: 11, 4242: 13, 4241: 8, 4240: 5, 4239: 17, 4238: 3, 4237: 3, 4236: 1, 4235: 11, 4234: 3, 4233: 18, 4232: 6, 4231: 5, 4230: 6, 4229: 4, 4228: 1, 4227: 8, 4226: 5, 4225: 1, 4224: 2, 4223: 5, 4222: 1, 4221: 0, 4220: 6, 4219: 7, 4218: 2, 4217: 2, 4216: 6, 4215: 8, 4214: 15, 4213: 10, 4212: 4, 4211: 12, 4210: 16, 4209: 31, 4208: 8, 4207: 2, 4206: 1, 4205: 2, 4204: 16, 4203: 1, 4202: 9, 4201: 2, 4200: 3, 4199: 4, 4198: 5, 4197: 1, 4196: 1, 4195: 1, 4194: 11, 4193: 2, 4192: 11, 4191: 3, 4190: 5, 4189: 1, 4188: 3, 4187: 4, 4186: 3, 4185: 1, 4184: 1, 4183: 4, 4182: 3, 4181: 8, 4180: 1, 4179: 4, 4178: 3, 4177: 4, 4176: 1, 4175: 0, 4174: 3, 4173: 4, 4172: 8, 4171: 3, 4170: 3, 4169: 2, 4168: 5, 4167: 12, 4166: 8, 4165: 7, 4164: 10, 4163: 0, 4162: 3, 4161: 2, 4160: 3, 4159: 0, 4158: 2, 4157: 10, 4156: 19, 4155: 23, 4154: 5, 4153: 4, 4152: 3, 4151: 0, 4150: 1, 4149: 1, 4148: 2, 4147: 1, 4146: 3, 4145: 5, 4144: 2, 4143: 3, 4142: 5, 4141: 3, 4140: 3, 4139: 2, 4138: 10, 4137: 4, 4136: 10, 4135: 14, 4134: 6, 4133: 2, 4132: 5, 4131: 2, 4130: 5, 4129: 1, 4128: 6, 4127: 4, 4126: 3, 4125: 1, 4124: 3, 4123: 9, 4122: 8, 4121: 1, 4120: 1, 4119: 0, 4118: 3, 4117: 4, 4116: 3, 4115: 9, 4114: 3, 4113: 2, 4112: 15, 4111: 6, 4110: 2, 4109: 0, 4108: 2, 4107: 9, 4106: 8, 4105: 11, 4104: 4, 4103: 2, 4102: 0, 4101: 4, 4100: 4, 4099: 30, 4098: 9, 4097: 3, 4096: 1, 4095: 3, 4094: 5, 4093: 2, 4092: 2, 4091: 36, 4090: 2, 4089: 4, 4088: 9, 4087: 5, 4086: 5, 4085: 1, 4084: 7, 4083: 3, 4082: 1, 4081: 6, 4080: 6, 4079: 3, 4078: 3, 4077: 8, 4076: 4, 4075: 3, 4074: 4, 4073: 8, 4072: 2, 4071: 4, 4070: 8, 4069: 1, 4068: 2, 4067: 2, 4066: 8, 4065: 6, 4064: 10, 4063: 2, 4062: 11, 4061: 11, 4060: 4, 4059: 8, 4058: 1, 4057: 6, 4056: 30, 4055: 2, 4054: 4, 4053: 1, 4052: 0, 4051: 8, 4050: 6, 4049: 2, 4048: 3, 4047: 4, 4046: 3, 4045: 9, 4044: 10, 4043: 2, 4042: 6, 4041: 1, 4040: 2, 4039: 12, 4038: 5, 4037: 3, 4036: 1, 4035: 2, 4034: 4, 4033: 2, 4032: 0, 4031: 4, 4030: 0, 4029: 3, 4028: 11, 4027: 11, 4026: 2, 4025: 7, 4024: 3, 4023: 18, 4022: 5, 4021: 4, 4020: 2, 4019: 1, 4018: 0, 4017: 2, 4016: 7, 4015: 3, 4014: 6, 4013: 3, 4012: 5, 4011: 4, 4010: 22, 4009: 1, 4008: 3, 4007: 13, 4006: 2, 4005: 2, 4004: 9, 4003: 6, 4002: 0, 4001: 6, 4000: 8, 3999: 5, 3998: 7, 3997: 16, 3996: 15, 3995: 5, 3994: 3, 3993: 5, 3992: 6, 3991: 2, 3990: 1, 3989: 2, 3988: 2, 3987: 33, 3986: 2, 3985: 3, 3984: 15, 3983: 3, 3982: 4, 3981: 2, 3980: 6, 3979: 2, 3978: 11, 3977: 1, 3976: 2, 3975: 2, 3974: 3, 3973: 5, 3972: 2, 3971: 4, 3970: 5, 3969: 31, 3968: 1, 3967: 1, 3966: 9, 3965: 7, 3964: 2, 3963: 4, 3962: 2, 3961: 5, 3960: 18, 3959: 9, 3958: 5, 3957: 12, 3956: 16, 3955: 25, 3954: 0, 3953: 18, 3952: 1, 3951: 4, 3950: 1, 3949: 0, 3948: 5, 3947: 1, 3946: 4, 3945: 2, 3944: 5, 3943: 16, 3942: 6, 3941: 0, 3940: 12, 3939: 14, 3938: 1, 3937: 5, 3936: 4, 3935: 6, 3934: 6, 3933: 3, 3932: 6, 3931: 2, 3930: 1, 3929: 4, 3928: 1, 3927: 1, 3926: 1, 3925: 6, 3924: 2, 3923: 1, 3922: 2, 3921: 1, 3920: 2, 3919: 2, 3918: 6, 3917: 5, 3916: 4, 3915: 0, 3914: 2, 3913: 4, 3912: 4, 3911: 1, 3910: 4, 3909: 3, 3908: 10, 3907: 4, 3906: 3, 3905: 1, 3904: 2, 3903: 3, 3902: 12, 3901: 2, 3900: 7, 3899: 7, 3898: 1, 3897: 4, 3896: 0, 3895: 10, 3894: 5, 3893: 6, 3892: 0, 3891: 4, 3890: 8, 3889: 1, 3888: 5, 3887: 30, 3886: 4, 3885: 2, 3884: 2, 3883: 16, 3882: 2, 3881: 14, 3880: 11, 3879: 5, 3878: 2, 3877: 3, 3876: 2, 3875: 2, 3874: 4, 3873: 5, 3872: 6, 3871: 4, 3870: 3, 3869: 1, 3868: 1, 3867: 12, 3866: 5, 3865: 2, 3864: 5, 3863: 1, 3862: 4, 3861: 2, 3860: 15, 3859: 2, 3858: 51, 3857: 3, 3856: 0, 3855: 8, 3854: 2, 3853: 3, 3852: 9, 3851: 3, 3850: 1, 3849: 3, 3848: 6, 3847: 1, 3846: 7, 3845: 2, 3844: 4, 3843: 4, 3842: 6, 3841: 8, 3840: 0, 3839: 2, 3838: 8, 3837: 5, 3836: 1, 3835: 4, 3834: 12, 3833: 2, 3832: 5, 3831: 2, 3830: 50, 3829: 7, 3828: 0, 3827: 21, 3826: 2, 3825: 2, 3824: 5, 3823: 3, 3822: 6, 3821: 1, 3820: 2, 3819: 3, 3818: 6, 3817: 5, 3816: 7, 3815: 5, 3814: 7, 3813: 4, 3812: 4, 3811: 19, 3810: 5, 3809: 13, 3808: 6, 3807: 5, 3806: 2, 3805: 3, 3804: 2, 3803: 2, 3802: 5, 3801: 3, 3800: 0, 3799: 0, 3798: 1, 3797: 4, 3796: 3, 3795: 3, 3794: 10, 3793: 10, 3792: 2, 3791: 2, 3790: 5, 3789: 6, 3788: 1, 3787: 4, 3786: 0, 3785: 2, 3784: 2, 3783: 0, 3782: 0, 3781: 7, 3780: 5, 3779: 3, 3778: 2, 3777: 2, 3776: 7, 3775: 7, 3774: 1, 3773: 0, 3772: 2, 3771: 1, 3770: 3, 3769: 3, 3768: 3, 3767: 0, 3766: 5, 3765: 4, 3764: 1, 3763: 7, 3762: 4, 3761: 2, 3760: 11, 3759: 2, 3758: 1, 3757: 4, 3756: 1, 3755: 3, 3754: 1, 3753: 9, 3752: 4, 3751: 12, 3750: 4, 3749: 2, 3748: 3, 3747: 5, 3746: 4, 3745: 3, 3744: 3, 3743: 2, 3742: 2, 3741: 7, 3740: 1, 3739: 4, 3738: 9, 3737: 1, 3736: 1, 3735: 5, 3734: 3, 3733: 5, 3732: 7, 3731: 2, 3730: 2, 3729: 6, 3728: 4, 3727: 30, 3726: 12, 3725: 1, 3724: 3, 3723: 0, 3722: 5, 3721: 1, 3720: 5, 3719: 7, 3718: 5, 3717: 3, 3716: 6, 3715: 1, 3714: 1, 3713: 3, 3712: 4, 3711: 1, 3710: 4, 3709: 4, 3708: 4, 3707: 12, 3706: 8, 3705: 4, 3704: 2, 3703: 0, 3702: 1, 3701: 8, 3700: 13, 3699: 5, 3698: 16, 3697: 6, 3696: 2, 3695: 3, 3694: 7, 3693: 5, 3692: 2, 3691: 2, 3690: 12, 3689: 8, 3688: 2, 3687: 1, 3686: 1, 3685: 3, 3684: 2, 3683: 4, 3682: 5, 3681: 4, 3680: 7, 3679: 2, 3678: 2, 3677: 3, 3676: 0, 3675: 2, 3674: 2, 3673: 8, 3672: 8, 3671: 2, 3670: 4, 3669: 8, 3668: 9, 3667: 12, 3666: 4, 3665: 6, 3664: 9, 3663: 21, 3662: 6, 3661: 4, 3660: 1, 3659: 8, 3658: 0, 3657: 5, 3656: 3, 3655: 7, 3654: 2, 3653: 6, 3652: 5, 3651: 3, 3650: 0, 3649: 3, 3648: 7, 3647: 2, 3646: 13, 3645: 0, 3644: 17, 3643: 1, 3642: 22, 3641: 3, 3640: 44, 3639: 5, 3638: 14, 3637: 5, 3636: 9, 3635: 2, 3634: 19, 3633: 4, 3632: 5, 3631: 31, 3630: 4, 3629: 3, 3628: 9, 3627: 2, 3626: 21, 3625: 1, 3624: 4, 3623: 20, 3622: 9, 3621: 11, 3620: 7, 3619: 5, 3618: 2, 3617: 2, 3616: 7, 3615: 8, 3614: 3, 3613: 4, 3612: 8, 3611: 2, 3610: 1, 3609: 3, 3608: 1, 3607: 14, 3606: 5, 3605: 3, 3604: 0, 3603: 6, 3602: 3, 3601: 3, 3600: 3, 3599: 1, 3598: 0, 3597: 1, 3596: 1, 3595: 0, 3594: 0, 3593: 3, 3592: 4, 3591: 9, 3590: 3, 3589: 8, 3588: 3, 3587: 5, 3586: 8, 3585: 5, 3584: 14, 3583: 4, 3582: 2, 3581: 3, 3580: 2, 3579: 0, 3578: 4, 3577: 9, 3576: 2, 3575: 2, 3574: 10, 3573: 10, 3572: 4, 3571: 4, 3570: 7, 3569: 2, 3568: 1, 3567: 7, 3566: 5, 3565: 7, 3564: 2, 3563: 5, 3562: 1, 3561: 2, 3560: 3, 3559: 2, 3558: 2, 3557: 3, 3556: 5, 3555: 2, 3554: 7, 3553: 6, 3552: 8, 3551: 1, 3550: 3, 3549: 1, 3548: 0, 3547: 3, 3546: 4, 3545: 2, 3544: 1, 3543: 2, 3542: 4, 3541: 2, 3540: 2, 3539: 9, 3538: 6, 3537: 1, 3536: 4, 3535: 2, 3534: 6, 3533: 4, 3532: 8, 3531: 0, 3530: 2, 3529: 4, 3528: 7, 3527: 5, 3526: 2, 3525: 2, 3524: 3, 3523: 4, 3522: 5, 3521: 3, 3520: 128, 3519: 3, 3518: 4, 3517: 2, 3516: 1, 3515: 7, 3514: 7, 3513: 1, 3512: 6, 3511: 39, 3510: 8, 3509: 19, 3508: 23, 3507: 5, 3506: 7, 3505: 9, 3504: 4, 3503: 1, 3502: 2, 3501: 16, 3500: 5, 3499: 34, 3498: 3, 3497: 10, 3496: 1, 3495: 5, 3494: 2, 3493: 4, 3492: 5, 3491: 2, 3490: 5, 3489: 3, 3488: 1, 3487: 10, 3486: 1, 3485: 14, 3484: 9, 3483: 2, 3482: 9, 3481: 12, 3480: 1, 3479: 4, 3478: 4, 3477: 1, 3476: 9, 3475: 15, 3474: 4, 3473: 1, 3472: 0, 3471: 4, 3470: 0, 3469: 7, 3468: 0, 3467: 10, 3466: 1, 3465: 1, 3464: 3, 3463: 4, 3462: 1, 3461: 2, 3460: 3, 3459: 16, 3458: 2, 3457: 2, 3456: 0, 3455: 2, 3454: 10, 3453: 1, 3452: 8, 3451: 2, 3450: 20, 3449: 2, 3448: 5, 3447: 0, 3446: 1, 3445: 5, 3444: 4, 3443: 2, 3442: 12, 3441: 9, 3440: 6, 3439: 13, 3438: 8, 3437: 7, 3436: 1, 3435: 9, 3434: 4, 3433: 13, 3432: 6, 3431: 13, 3430: 4, 3429: 2, 3428: 1, 3427: 1, 3426: 10, 3425: 24, 3424: 3, 3423: 1, 3422: 3, 3421: 2, 3420: 4, 3419: 5, 3418: 4, 3417: 16, 3416: 4, 3415: 3, 3414: 3, 3413: 10, 3412: 2, 3411: 3, 3410: 3, 3409: 0, 3408: 6, 3407: 3, 3406: 6, 3405: 21, 3404: 3, 3403: 4, 3402: 1, 3401: 0, 3400: 2, 3399: 3, 3398: 3, 3397: 2, 3396: 4, 3395: 8, 3394: 3, 3393: 4, 3392: 5, 3391: 5, 3390: 4, 3389: 7, 3388: 3, 3387: 4, 3386: 5, 3385: 30, 3384: 4, 3383: 7, 3382: 1, 3381: 3, 3380: 5, 3379: 27, 3378: 2, 3377: 19, 3376: 7, 3375: 4, 3374: 2, 3373: 3, 3372: 8, 3371: 40, 3370: 8, 3369: 2, 3368: 6, 3367: 5, 3366: 9, 3365: 17, 3364: 3, 3363: 37, 3362: 6, 3361: 17, 3360: 6, 3359: 3, 3358: 3, 3357: 3, 3356: 2, 3355: 2, 3354: 3, 3353: 1, 3352: 1, 3351: 3, 3350: 25, 3349: 5, 3348: 3, 3347: 1, 3346: 0, 3345: 2, 3344: 24, 3343: 11, 3342: 21, 3341: 3, 3340: 4, 3339: 1, 3338: 3, 3337: 1, 3336: 0, 3335: 2, 3334: 0, 3333: 3, 3332: 5, 3331: 5, 3330: 0, 3329: 3, 3328: 4, 3327: 0, 3326: 8, 3325: 5, 3324: 2, 3323: 24, 3322: 10, 3321: 14, 3320: 9, 3319: 3, 3318: 7, 3317: 3, 3316: 1, 3315: 10, 3314: 7, 3313: 4, 3312: 3, 3311: 2, 3310: 7, 3309: 1, 3308: 9, 3307: 15, 3306: 10, 3305: 7, 3304: 2, 3303: 14, 3302: 3, 3301: 1, 3300: 1, 3299: 20, 3298: 3, 3297: 2, 3296: 2, 3295: 0, 3294: 2, 3293: 7, 3292: 2, 3291: 5, 3290: 2, 3289: 2, 3288: 6, 3287: 21, 3286: 11, 3285: 3, 3284: 3, 3283: 9, 3282: 3, 3281: 5, 3280: 0, 3279: 11, 3278: 7, 3277: 1, 3276: 4, 3275: 9, 3274: 3, 3273: 2, 3272: 1, 3271: 5, 3270: 2, 3269: 2, 3268: 6, 3267: 28, 3266: 20, 3265: 2, 3264: 5, 3263: 5, 3262: 6, 3261: 6, 3260: 7, 3259: 6, 3258: 3, 3257: 2, 3256: 1, 3255: 1, 3254: 2, 3253: 8, 3252: 1, 3251: 6, 3250: 3, 3249: 4, 3248: 1, 3247: 22, 3246: 5, 3245: 3, 3244: 3, 3243: 2, 3242: 24, 3241: 2, 3240: 8, 3239: 4, 3238: 10, 3237: 6, 3236: 6, 3235: 4, 3234: 4, 3233: 1, 3232: 2, 3231: 3, 3230: 3, 3229: 1, 3228: 4, 3227: 4, 3226: 4, 3225: 2, 3224: 3, 3223: 4, 3222: 7, 3221: 1, 3220: 2, 3219: 3, 3218: 10, 3217: 9, 3216: 3, 3215: 3, 3214: 3, 3213: 10, 3212: 3, 3211: 2, 3210: 2, 3209: 4, 3208: 4, 3207: 1, 3206: 5, 3205: 9, 3204: 6, 3203: 3, 3202: 4, 3201: 3, 3200: 1, 3199: 25, 3198: 0, 3197: 8, 3196: 3, 3195: 1, 3194: 4, 3193: 2, 3192: 1, 3191: 3, 3190: 3, 3189: 2, 3188: 7, 3187: 2, 3186: 4, 3185: 2, 3184: 0, 3183: 9, 3182: 1, 3181: 1, 3180: 7, 3179: 8, 3178: 2, 3177: 2, 3176: 4, 3175: 3, 3174: 9, 3173: 10, 3172: 1, 3171: 22, 3170: 19, 3169: 11, 3168: 3, 3167: 15, 3166: 2, 3165: 16, 3164: 18, 3163: 9, 3162: 18, 3161: 13, 3160: 8, 3159: 3, 3158: 9, 3157: 5, 3156: 5, 3155: 6, 3154: 2, 3153: 3, 3152: 5, 3151: 1, 3150: 3, 3149: 5, 3148: 2, 3147: 3, 3146: 7, 3145: 28, 3144: 4, 3143: 4, 3142: 17, 3141: 3, 3140: 14, 3139: 8, 3138: 7, 3137: 2, 3136: 7, 3135: 1, 3134: 18, 3133: 3, 3132: 4, 3131: 6, 3130: 0, 3129: 2, 3128: 9, 3127: 8, 3126: 5, 3125: 5, 3124: 3, 3123: 4, 3122: 2, 3121: 6, 3120: 6, 3119: 7, 3118: 3, 3117: 8, 3116: 4, 3115: 0, 3114: 4, 3113: 1, 3112: 2, 3111: 31, 3110: 6, 3109: 8, 3108: 4, 3107: 4, 3106: 1, 3105: 8, 3104: 5, 3103: 4, 3102: 20, 3101: 6, 3100: 1, 3099: 1, 3098: 12, 3097: 3, 3096: 3, 3095: 4, 3094: 3, 3093: 3, 3092: 4, 3091: 8, 3090: 4, 3089: 1, 3088: 4, 3087: 4, 3086: 5, 3085: 6, 3084: 1, 3083: 9, 3082: 13, 3081: 1, 3080: 17, 3079: 1, 3078: 7, 3077: 8, 3076: 44, 3075: 2, 3074: 0, 3073: 3, 3072: 6, 3071: 9, 3070: 5, 3069: 15, 3068: 9, 3067: 7, 3066: 3, 3065: 0, 3064: 13, 3063: 21, 3062: 2, 3061: 4, 3060: 10, 3059: 4, 3058: 5, 3057: 4, 3056: 5, 3055: 7, 3054: 6, 3053: 2, 3052: 9, 3051: 0, 3050: 1, 3049: 6, 3048: 3, 3047: 0, 3046: 1, 3045: 3, 3044: 2, 3043: 3, 3042: 1, 3041: 5, 3040: 4, 3039: 11, 3038: 0, 3037: 3, 3036: 3, 3035: 8, 3034: 0, 3033: 7, 3032: 1, 3031: 1, 3030: 9, 3029: 5, 3028: 3, 3027: 1, 3026: 2, 3025: 5, 3024: 9, 3023: 26, 3022: 4, 3021: 14, 3020: 7, 3019: 2, 3018: 2, 3017: 2, 3016: 3, 3015: 0, 3014: 2, 3013: 10, 3012: 14, 3011: 5, 3010: 19, 3009: 4, 3008: 1, 3007: 1, 3006: 25, 3005: 3, 3004: 8, 3003: 1, 3002: 7, 3001: 6, 3000: 7, 2999: 1, 2998: 1, 2997: 12, 2996: 1, 2995: 2, 2994: 6, 2993: 1, 2992: 2, 2991: 3, 2990: 8, 2989: 3, 2988: 8, 2987: 6, 2986: 8, 2985: 1, 2984: 3, 2983: 6, 2982: 6, 2981: 2, 2980: 7, 2979: 7, 2978: 7, 2977: 0, 2976: 16, 2975: 7, 2974: 3, 2973: 9, 2972: 13, 2971: 2, 2970: 11, 2969: 3, 2968: 1, 2967: 5, 2966: 3, 2965: 2, 2964: 4, 2963: 2, 2962: 6, 2961: 0, 2960: 6, 2959: 4, 2958: 9, 2957: 2, 2956: 4, 2955: 15, 2954: 1, 2953: 8, 2952: 3, 2951: 22, 2950: 10, 2949: 3, 2948: 4, 2947: 3, 2946: 6, 2945: 2, 2944: 4, 2943: 4, 2942: 7, 2941: 4, 2940: 3, 2939: 6, 2938: 7, 2937: 5, 2936: 2, 2935: 12, 2934: 9, 2933: 2, 2932: 36, 2931: 6, 2930: 3, 2929: 1, 2928: 18, 2927: 8, 2926: 1, 2925: 8, 2924: 7, 2923: 8, 2922: 1, 2921: 0, 2920: 5, 2919: 6, 2918: 3, 2917: 3, 2916: 1, 2915: 7, 2914: 5, 2913: 2, 2912: 1, 2911: 17, 2910: 5, 2909: 5, 2908: 3, 2907: 1, 2906: 7, 2905: 8, 2904: 9, 2903: 5, 2902: 8, 2901: 2, 2900: 3, 2899: 3, 2898: 6, 2897: 0, 2896: 2, 2895: 1, 2894: 23, 2893: 16, 2892: 6, 2891: 17, 2890: 4, 2889: 13, 2888: 11, 2887: 7, 2886: 4, 2885: 18, 2884: 12, 2883: 2, 2882: 0, 2881: 2, 2880: 1, 2879: 1, 2878: 9, 2877: 2, 2876: 2, 2875: 7, 2874: 3, 2873: 9, 2872: 8, 2871: 4, 2870: 3, 2869: 2, 2868: 8, 2867: 3, 2866: 2, 2865: 12, 2864: 7, 2863: 5, 2862: 6, 2861: 5, 2860: 9, 2859: 2, 2858: 4, 2857: 3, 2856: 3, 2855: 7, 2854: 6, 2853: 1, 2852: 4, 2851: 26, 2850: 1, 2849: 19, 2848: 10, 2847: 3, 2846: 1, 2845: 10, 2844: 3, 2843: 2, 2842: 2, 2841: 4, 2840: 7, 2839: 5, 2838: 7, 2837: 6, 2836: 2, 2835: 3, 2834: 2, 2833: 4, 2832: 4, 2831: 5, 2830: 3, 2829: 8, 2828: 1, 2827: 2, 2826: 2, 2825: 12, 2824: 4, 2823: 0, 2822: 5, 2821: 5, 2820: 3, 2819: 3, 2818: 2, 2817: 3, 2816: 5, 2815: 3, 2814: 4, 2813: 2, 2812: 2, 2811: 2, 2810: 21, 2809: 13, 2808: 0, 2807: 4, 2806: 5, 2805: 16, 2804: 18, 2803: 5, 2802: 4, 2801: 3, 2800: 28, 2799: 1, 2798: 22, 2797: 14, 2796: 4, 2795: 0, 2794: 2, 2793: 2, 2792: 4, 2791: 6, 2790: 1, 2789: 3, 2788: 6, 2787: 7, 2786: 1, 2785: 1, 2784: 10, 2783: 4, 2782: 6, 2781: 2, 2780: 1, 2779: 2, 2778: 2, 2777: 21, 2776: 8, 2775: 9, 2774: 22, 2773: 1, 2772: 5, 2771: 6, 2770: 0, 2769: 4, 2768: 18, 2767: 10, 2766: 4, 2765: 6, 2764: 2, 2763: 1, 2762: 13, 2761: 2, 2760: 1, 2759: 7, 2758: 9, 2757: 4, 2756: 1, 2755: 6, 2754: 8, 2753: 4, 2752: 2, 2751: 2, 2750: 1, 2749: 5, 2748: 2, 2747: 3, 2746: 45, 2745: 2, 2744: 12, 2743: 9, 2742: 11, 2741: 1, 2740: 0, 2739: 3, 2738: 3, 2737: 0, 2736: 6, 2735: 2, 2734: 6, 2733: 12, 2732: 2, 2731: 7, 2730: 8, 2729: 2, 2728: 5, 2727: 6, 2726: 2, 2725: 6, 2724: 4, 2723: 20, 2722: 3, 2721: 1, 2720: 4, 2719: 3, 2718: 1, 2717: 1, 2716: 1, 2715: 23, 2714: 1, 2713: 13, 2712: 12, 2711: 1, 2710: 6, 2709: 7, 2708: 12, 2707: 11, 2706: 5, 2705: 1, 2704: 0, 2703: 6, 2702: 11, 2701: 6, 2700: 5, 2699: 4, 2698: 8, 2697: 2, 2696: 3, 2695: 1, 2694: 2, 2693: 7, 2692: 5, 2691: 4, 2690: 14, 2689: 6, 2688: 7, 2687: 8, 2686: 4, 2685: 13, 2684: 2, 2683: 1, 2682: 2, 2681: 2, 2680: 3, 2679: 4, 2678: 7, 2677: 1, 2676: 3, 2675: 5, 2674: 5, 2673: 3, 2672: 1, 2671: 0, 2670: 13, 2669: 4, 2668: 7, 2667: 2, 2666: 2, 2665: 1, 2664: 1, 2663: 2, 2662: 8, 2661: 4, 2660: 20, 2659: 0, 2658: 3, 2657: 7, 2656: 1, 2655: 2, 2654: 4, 2653: 7, 2652: 3, 2651: 6, 2650: 3, 2649: 2, 2648: 4, 2647: 7, 2646: 22, 2645: 8, 2644: 3, 2643: 3, 2642: 4, 2641: 5, 2640: 9, 2639: 1, 2638: 7, 2637: 4, 2636: 4, 2635: 5, 2634: 4, 2633: 1, 2632: 5, 2631: 4, 2630: 5, 2629: 6, 2628: 5, 2627: 6, 2626: 1, 2625: 2, 2624: 0, 2623: 2, 2622: 11, 2621: 4, 2620: 13, 2619: 2, 2618: 1, 2617: 0, 2616: 1, 2615: 3, 2614: 5, 2613: 2, 2612: 24, 2611: 5, 2610: 5, 2609: 11, 2608: 57, 2607: 2, 2606: 2, 2605: 1, 2604: 10, 2603: 2, 2602: 9, 2601: 2, 2600: 3, 2599: 8, 2598: 9, 2597: 7, 2596: 10, 2595: 2, 2594: 10, 2593: 3, 2592: 4, 2591: 2, 2590: 1, 2589: 6, 2588: 1, 2587: 6, 2586: 4, 2585: 2, 2584: 1, 2583: 3, 2582: 3, 2581: 5, 2580: 1, 2579: 1, 2578: 7, 2577: 17, 2576: 3, 2575: 12, 2574: 8, 2573: 3, 2572: 10, 2571: 85, 2570: 1, 2569: 3, 2568: 2, 2567: 3, 2566: 5, 2565: 1, 2564: 11, 2563: 3, 2562: 2, 2561: 6, 2560: 1, 2559: 3, 2558: 1, 2557: 4, 2556: 1, 2555: 2, 2554: 27, 2553: 1, 2552: 12, 2551: 19, 2550: 16, 2549: 18, 2548: 10, 2547: 3, 2546: 0, 2545: 2, 2544: 8, 2543: 3, 2542: 6, 2541: 10, 2540: 24, 2539: 6, 2538: 6, 2537: 5, 2536: 3, 2535: 2, 2534: 6, 2533: 4, 2532: 3, 2531: 1, 2530: 4, 2529: 2, 2528: 12, 2527: 9, 2526: 8, 2525: 3, 2524: 1, 2523: 2, 2522: 5, 2521: 3, 2520: 5, 2519: 3, 2518: 7, 2517: 5, 2516: 2, 2515: 7, 2514: 8, 2513: 6, 2512: 14, 2511: 9, 2510: 12, 2509: 4, 2508: 1, 2507: 2, 2506: 5, 2505: 2, 2504: 0, 2503: 3, 2502: 5, 2501: 2, 2500: 3, 2499: 11, 2498: 1, 2497: 5, 2496: 6, 2495: 13, 2494: 7, 2493: 3, 2492: 1, 2491: 2, 2490: 5, 2489: 0, 2488: 4, 2487: 12, 2486: 20, 2485: 3, 2484: 5, 2483: 2, 2482: 2, 2481: 13, 2480: 3, 2479: 8, 2478: 1, 2477: 4, 2476: 2, 2475: 5, 2474: 25, 2473: 5, 2472: 2, 2471: 2, 2470: 3, 2469: 2, 2468: 5, 2467: 6, 2466: 0, 2465: 1, 2464: 1, 2463: 15, 2462: 5, 2461: 6, 2460: 10, 2459: 5, 2458: 2, 2457: 25, 2456: 3, 2455: 1, 2454: 3, 2453: 5, 2452: 6, 2451: 4, 2450: 0, 2449: 2, 2448: 5, 2447: 13, 2446: 3, 2445: 0, 2444: 7, 2443: 7, 2442: 1, 2441: 4, 2440: 3, 2439: 1, 2438: 6, 2437: 24, 2436: 4, 2435: 2, 2434: 8, 2433: 6, 2432: 1, 2431: 4, 2430: 9, 2429: 3, 2428: 4, 2427: 3, 2426: 3, 2425: 10, 2424: 1, 2423: 5, 2422: 16, 2421: 4, 2420: 20, 2419: 5, 2418: 3, 2417: 2, 2416: 7, 2415: 16, 2414: 4, 2413: 2, 2412: 7, 2411: 2, 2410: 16, 2409: 5, 2408: 6, 2407: 3, 2406: 3, 2405: 3, 2404: 2, 2403: 9, 2402: 9, 2401: 5, 2400: 16, 2399: 15, 2398: 0, 2397: 6, 2396: 6, 2395: 4, 2394: 11, 2393: 4, 2392: 0, 2391: 3, 2390: 3, 2389: 4, 2388: 5, 2387: 5, 2386: 2, 2385: 6, 2384: 0, 2383: 2, 2382: 15, 2381: 3, 2380: 1, 2379: 6, 2378: 2, 2377: 2, 2376: 2, 2375: 11, 2374: 7, 2373: 6, 2372: 9, 2371: 2, 2370: 4, 2369: 5, 2368: 13, 2367: 4, 2366: 4, 2365: 1, 2364: 4, 2363: 18, 2362: 1, 2361: 1, 2360: 2, 2359: 0, 2358: 4, 2357: 16, 2356: 6, 2355: 3, 2354: 3, 2353: 4, 2352: 4, 2351: 5, 2350: 3, 2349: 19, 2348: 3, 2347: 11, 2346: 1, 2345: 4, 2344: 6, 2343: 15, 2342: 2, 2341: 3, 2340: 1, 2339: 4, 2338: 3, 2337: 3, 2336: 2, 2335: 5, 2334: 4, 2333: 11, 2332: 7, 2331: 9, 2330: 4, 2329: 0, 2328: 9, 2327: 11, 2326: 3, 2325: 2, 2324: 2, 2323: 2, 2322: 0, 2321: 3, 2320: 7, 2319: 8, 2318: 1, 2317: 4, 2316: 1, 2315: 2, 2314: 2, 2313: 27, 2312: 1, 2311: 2, 2310: 3, 2309: 2, 2308: 22, 2307: 30, 2306: 2, 2305: 4, 2304: 6, 2303: 5, 2302: 18, 2301: 3, 2300: 10, 2299: 6, 2298: 18, 2297: 18, 2296: 11, 2295: 4, 2294: 8, 2293: 5, 2292: 5, 2291: 4, 2290: 19, 2289: 13, 2288: 2, 2287: 15, 2286: 4, 2285: 3, 2284: 10, 2283: 1, 2282: 4, 2281: 9, 2280: 24, 2279: 0, 2278: 2, 2277: 5, 2276: 8, 2275: 3, 2274: 8, 2273: 5, 2272: 5, 2271: 1, 2270: 4, 2269: 3, 2268: 1, 2267: 7, 2266: 3, 2265: 25, 2264: 18, 2263: 12, 2262: 4, 2261: 1, 2260: 1, 2259: 3, 2258: 0, 2257: 6, 2256: 3, 2255: 1, 2254: 3, 2253: 4, 2252: 31, 2251: 1, 2250: 8, 2249: 1, 2248: 4, 2247: 5, 2246: 2, 2245: 9, 2244: 4, 2243: 9, 2242: 26, 2241: 4, 2240: 8, 2239: 3, 2238: 3, 2237: 13, 2236: 11, 2235: 19, 2234: 0, 2233: 7, 2232: 3, 2231: 27, 2230: 4, 2229: 4, 2228: 1, 2227: 12, 2226: 1, 2225: 2, 2224: 8, 2223: 2, 2222: 6, 2221: 2, 2220: 6, 2219: 4, 2218: 2, 2217: 5, 2216: 2, 2215: 1, 2214: 11, 2213: 52, 2212: 6, 2211: 0, 2210: 3, 2209: 5, 2208: 6, 2207: 7, 2206: 4, 2205: 1, 2204: 6, 2203: 9, 2202: 9, 2201: 3, 2200: 13, 2199: 1, 2198: 2, 2197: 9, 2196: 24, 2195: 3, 2194: 9, 2193: 0, 2192: 0, 2191: 2, 2190: 5, 2189: 4, 2188: 1, 2187: 3, 2186: 3, 2185: 27, 2184: 3, 2183: 5, 2182: 3, 2181: 11, 2180: 4, 2179: 5, 2178: 4, 2177: 5, 2176: 15, 2175: 10, 2174: 8, 2173: 18, 2172: 2, 2171: 5, 2170: 0, 2169: 2, 2168: 1, 2167: 12, 2166: 2, 2165: 15, 2164: 6, 2163: 8, 2162: 5, 2161: 5, 2160: 8, 2159: 24, 2158: 14, 2157: 2, 2156: 3, 2155: 21, 2154: 7, 2153: 2, 2152: 3, 2151: 24, 2150: 10, 2149: 4, 2148: 4, 2147: 5, 2146: 9, 2145: 3, 2144: 3, 2143: 10, 2142: 3, 2141: 3, 2140: 4, 2139: 4, 2138: 1, 2137: 1, 2136: 1, 2135: 1, 2134: 5, 2133: 5, 2132: 16, 2131: 1, 2130: 2, 2129: 9, 2128: 7, 2127: 5, 2126: 1, 2125: 1, 2124: 2, 2123: 0, 2122: 5, 2121: 10, 2120: 2, 2119: 2, 2118: 2, 2117: 1, 2116: 3, 2115: 2, 2114: 16, 2113: 30, 2112: 5, 2111: 2, 2110: 2, 2109: 0, 2108: 8, 2107: 3, 2106: 3, 2105: 1, 2104: 6, 2103: 8, 2102: 11, 2101: 2, 2100: 5, 2099: 1, 2098: 4, 2097: 4, 2096: 4, 2095: 4, 2094: 4, 2093: 3, 2092: 3, 2091: 3, 2090: 1, 2089: 4, 2088: 3, 2087: 2, 2086: 1, 2085: 18, 2084: 1, 2083: 6, 2082: 4, 2081: 1, 2080: 0, 2079: 3, 2078: 4, 2077: 6, 2076: 4, 2075: 2, 2074: 9, 2073: 3, 2072: 3, 2071: 1, 2070: 2, 2069: 10, 2068: 3, 2067: 1, 2066: 8, 2065: 1, 2064: 2, 2063: 5, 2062: 1, 2061: 0, 2060: 23, 2059: 3, 2058: 2, 2057: 21, 2056: 2, 2055: 12, 2054: 14, 2053: 2, 2052: 4, 2051: 8, 2050: 3, 2049: 6, 2048: 15, 2047: 1, 2046: 10, 2045: 1, 2044: 2, 2043: 14, 2042: 4, 2041: 7, 2040: 0, 2039: 7, 2038: 1, 2037: 2, 2036: 2, 2035: 0, 2034: 3, 2033: 3, 2032: 1, 2031: 7, 2030: 1, 2029: 5, 2028: 2, 2027: 2, 2026: 0, 2025: 3, 2024: 15, 2023: 14, 2022: 12, 2021: 2, 2020: 7, 2019: 19, 2018: 3, 2017: 35, 2016: 3, 2015: 2, 2014: 0, 2013: 2, 2012: 1, 2011: 0, 2010: 2, 2009: 2, 2008: 25, 2007: 5, 2006: 5, 2005: 4, 2004: 5, 2003: 2, 2002: 1, 2001: 7, 2000: 8, 1999: 5, 1998: 0, 1997: 3, 1996: 5, 1995: 15, 1994: 4, 1993: 1, 1992: 2, 1991: 7, 1990: 3, 1989: 7, 1988: 4, 1987: 10, 1986: 5, 1985: 2, 1984: 3, 1983: 3, 1982: 4, 1981: 1, 1980: 3, 1979: 5, 1978: 4, 1977: 1, 1976: 1, 1975: 4, 1974: 3, 1973: 7, 1972: 5, 1971: 1, 1970: 2, 1969: 9, 1968: 6, 1967: 3, 1966: 15, 1965: 7, 1964: 1, 1963: 8, 1962: 2, 1961: 1, 1960: 17, 1959: 13, 1958: 3, 1957: 4, 1956: 7, 1955: 3, 1954: 20, 1953: 1, 1952: 0, 1951: 1, 1950: 2, 1949: 3, 1948: 6, 1947: 7, 1946: 7, 1945: 10, 1944: 9, 1943: 8, 1942: 5, 1941: 1, 1940: 11, 1939: 1, 1938: 6, 1937: 2, 1936: 1, 1935: 6, 1934: 37, 1933: 5, 1932: 6, 1931: 5, 1930: 3, 1929: 1, 1928: 4, 1927: 11, 1926: 1, 1925: 6, 1924: 1, 1923: 7, 1922: 3, 1921: 7, 1920: 1, 1919: 18, 1918: 2, 1917: 3, 1916: 8, 1915: 8, 1914: 3, 1913: 0, 1912: 11, 1911: 1, 1910: 6, 1909: 1, 1908: 2, 1907: 0, 1906: 2, 1905: 3, 1904: 12, 1903: 1, 1902: 12})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree = data.g.degree()\n",
    "degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  3,  6, ..., 12,  1, 12])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(degree)[: , 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 8: 0,\n",
       " 7: 0,\n",
       " 6: 0,\n",
       " 5: 0,\n",
       " 4: 0,\n",
       " 3: 0,\n",
       " 2: 0,\n",
       " 1: 0,\n",
       " 80: 0,\n",
       " 79: 1.0,\n",
       " 78: 0.16666666666666666,\n",
       " 77: 0,\n",
       " 76: 0,\n",
       " 75: 0.3333333333333333,\n",
       " 74: 0.06666666666666667,\n",
       " 73: 0,\n",
       " 72: 0.13333333333333333,\n",
       " 71: 0.6666666666666666,\n",
       " 70: 1.0,\n",
       " 69: 0,\n",
       " 68: 1.0,\n",
       " 67: 0.5714285714285714,\n",
       " 66: 1.0,\n",
       " 65: 0,\n",
       " 64: 0,\n",
       " 63: 0.19047619047619047,\n",
       " 62: 0,\n",
       " 61: 0.3,\n",
       " 60: 0,\n",
       " 59: 0.05138339920948617,\n",
       " 58: 0.3333333333333333,\n",
       " 57: 0,\n",
       " 56: 0.05555555555555555,\n",
       " 55: 0.03571428571428571,\n",
       " 54: 0,\n",
       " 53: 0.4,\n",
       " 52: 0,\n",
       " 51: 0.5,\n",
       " 50: 0,\n",
       " 49: 0,\n",
       " 48: 0.6,\n",
       " 47: 0,\n",
       " 46: 0,\n",
       " 45: 0,\n",
       " 44: 0,\n",
       " 43: 0,\n",
       " 42: 0,\n",
       " 41: 0,\n",
       " 40: 0,\n",
       " 39: 0,\n",
       " 38: 1.0,\n",
       " 37: 0.3333333333333333,\n",
       " 36: 0.3333333333333333,\n",
       " 35: 0.16666666666666666,\n",
       " 34: 0,\n",
       " 33: 0.26666666666666666,\n",
       " 32: 0,\n",
       " 31: 0,\n",
       " 30: 0,\n",
       " 29: 0,\n",
       " 28: 0,\n",
       " 27: 0,\n",
       " 26: 1.0,\n",
       " 25: 0,\n",
       " 24: 0,\n",
       " 23: 0,\n",
       " 22: 0,\n",
       " 21: 0,\n",
       " 20: 0,\n",
       " 19: 0,\n",
       " 18: 0,\n",
       " 17: 0.3333333333333333,\n",
       " 16: 1.0,\n",
       " 15: 0,\n",
       " 14: 0,\n",
       " 13: 0,\n",
       " 12: 0,\n",
       " 11: 0.06666666666666667,\n",
       " 10: 0,\n",
       " 9: 0,\n",
       " 1901: 0.9,\n",
       " 1900: 0,\n",
       " 1899: 0.03571428571428571,\n",
       " 1898: 0.3333333333333333,\n",
       " 1897: 0.3333333333333333,\n",
       " 1896: 0,\n",
       " 1895: 0,\n",
       " 1894: 0.14285714285714285,\n",
       " 1893: 0.041666666666666664,\n",
       " 1892: 0.3333333333333333,\n",
       " 1891: 0,\n",
       " 1890: 0,\n",
       " 1889: 0.023391812865497075,\n",
       " 1888: 0.6666666666666666,\n",
       " 1887: 0.047619047619047616,\n",
       " 1886: 0.05194805194805195,\n",
       " 1885: 0,\n",
       " 1884: 0.2,\n",
       " 1883: 0,\n",
       " 1882: 0,\n",
       " 1881: 0.03571428571428571,\n",
       " 1880: 0.06060606060606061,\n",
       " 1879: 0.2,\n",
       " 1878: 0.12727272727272726,\n",
       " 1877: 0.027777777777777776,\n",
       " 1876: 0,\n",
       " 1875: 0.26666666666666666,\n",
       " 1874: 0.05128205128205128,\n",
       " 1873: 0,\n",
       " 1872: 0.1,\n",
       " 1871: 0.13333333333333333,\n",
       " 1870: 0.2,\n",
       " 1869: 0.6,\n",
       " 1868: 0,\n",
       " 1867: 0.5333333333333333,\n",
       " 1866: 0,\n",
       " 1865: 0,\n",
       " 1864: 0.1,\n",
       " 1863: 0,\n",
       " 1862: 0.3333333333333333,\n",
       " 1861: 0.3,\n",
       " 1860: 0,\n",
       " 1859: 0.5,\n",
       " 1858: 0,\n",
       " 1857: 0.3,\n",
       " 1856: 0.2857142857142857,\n",
       " 1855: 0.16666666666666666,\n",
       " 1854: 0,\n",
       " 1853: 0,\n",
       " 1852: 0,\n",
       " 1851: 0.3333333333333333,\n",
       " 1850: 0,\n",
       " 1849: 0,\n",
       " 1848: 0,\n",
       " 1847: 0,\n",
       " 1846: 1.0,\n",
       " 1845: 1.0,\n",
       " 1844: 0,\n",
       " 1843: 0.047619047619047616,\n",
       " 1842: 0.25,\n",
       " 1841: 0.08791208791208792,\n",
       " 1840: 0,\n",
       " 1839: 0.044444444444444446,\n",
       " 1838: 0.038306451612903226,\n",
       " 1837: 0,\n",
       " 1836: 0.6666666666666666,\n",
       " 1835: 0.10909090909090909,\n",
       " 1834: 0,\n",
       " 1833: 0,\n",
       " 1832: 0.2,\n",
       " 1831: 0,\n",
       " 1830: 0.3333333333333333,\n",
       " 1829: 0.6666666666666666,\n",
       " 1828: 1.0,\n",
       " 1827: 0.6666666666666666,\n",
       " 1826: 0,\n",
       " 1825: 0.2,\n",
       " 1824: 0,\n",
       " 1823: 1.0,\n",
       " 1822: 1.0,\n",
       " 1821: 0,\n",
       " 1820: 0.2,\n",
       " 1819: 0,\n",
       " 1818: 0,\n",
       " 1817: 0,\n",
       " 1816: 0,\n",
       " 1815: 0,\n",
       " 1814: 0.2,\n",
       " 1813: 0.26666666666666666,\n",
       " 1812: 0,\n",
       " 1811: 0.16666666666666666,\n",
       " 1810: 0,\n",
       " 1809: 0.23809523809523808,\n",
       " 1808: 0,\n",
       " 1807: 0,\n",
       " 1806: 0,\n",
       " 1805: 1.0,\n",
       " 1804: 0.03571428571428571,\n",
       " 1803: 0.26666666666666666,\n",
       " 1802: 0.16666666666666666,\n",
       " 1801: 0,\n",
       " 1800: 0.16483516483516483,\n",
       " 1799: 0,\n",
       " 1798: 0.2,\n",
       " 1797: 0.05454545454545454,\n",
       " 1796: 0,\n",
       " 1795: 0,\n",
       " 1794: 0.23891625615763548,\n",
       " 1793: 0.3333333333333333,\n",
       " 1792: 0,\n",
       " 1791: 0.3333333333333333,\n",
       " 1790: 0,\n",
       " 1789: 0.03571428571428571,\n",
       " 1788: 0.47619047619047616,\n",
       " 1787: 0,\n",
       " 1786: 0,\n",
       " 1785: 0,\n",
       " 1784: 0.16666666666666666,\n",
       " 1783: 0.6373626373626373,\n",
       " 1782: 0,\n",
       " 1781: 0,\n",
       " 1780: 0.3333333333333333,\n",
       " 1779: 0,\n",
       " 1778: 0,\n",
       " 1777: 0.06842105263157895,\n",
       " 1776: 0,\n",
       " 1775: 0.1,\n",
       " 1774: 0,\n",
       " 1773: 0,\n",
       " 1772: 0,\n",
       " 1771: 0.1895424836601307,\n",
       " 1770: 0.5166666666666667,\n",
       " 1769: 0.1388888888888889,\n",
       " 1768: 0,\n",
       " 1767: 0.13333333333333333,\n",
       " 1766: 0,\n",
       " 1765: 0,\n",
       " 1764: 0.3333333333333333,\n",
       " 1763: 0.26495726495726496,\n",
       " 1762: 0,\n",
       " 1761: 0,\n",
       " 1760: 0.6666666666666666,\n",
       " 1759: 0.045454545454545456,\n",
       " 1758: 0.2,\n",
       " 1757: 0.13333333333333333,\n",
       " 1756: 0.5833333333333334,\n",
       " 1755: 0,\n",
       " 1754: 0,\n",
       " 1753: 0,\n",
       " 1752: 0.3333333333333333,\n",
       " 1751: 0.14285714285714285,\n",
       " 1750: 0.6428571428571429,\n",
       " 1749: 0.3333333333333333,\n",
       " 1748: 1.0,\n",
       " 1747: 0,\n",
       " 1746: 0,\n",
       " 1745: 0.3333333333333333,\n",
       " 1744: 0,\n",
       " 1743: 0,\n",
       " 1742: 0,\n",
       " 1741: 0,\n",
       " 1740: 0,\n",
       " 1739: 0,\n",
       " 1738: 0.2,\n",
       " 1737: 0,\n",
       " 1736: 0.06666666666666667,\n",
       " 1735: 0.3111111111111111,\n",
       " 1734: 0,\n",
       " 1733: 0,\n",
       " 1732: 0.2,\n",
       " 1731: 0.2222222222222222,\n",
       " 1730: 0.3333333333333333,\n",
       " 1729: 1.0,\n",
       " 1728: 0.3055555555555556,\n",
       " 1727: 0,\n",
       " 1726: 0,\n",
       " 1725: 0,\n",
       " 1724: 0.3333333333333333,\n",
       " 1723: 0.18614718614718614,\n",
       " 1722: 0.1111111111111111,\n",
       " 1721: 0,\n",
       " 1720: 0,\n",
       " 1719: 0.2,\n",
       " 1718: 0,\n",
       " 1717: 0.16666666666666666,\n",
       " 1716: 0,\n",
       " 1715: 0,\n",
       " 1714: 0.09523809523809523,\n",
       " 1713: 0.5441176470588235,\n",
       " 1712: 0,\n",
       " 1711: 0.19047619047619047,\n",
       " 1710: 0.16666666666666666,\n",
       " 1709: 0.6666666666666666,\n",
       " 1708: 1.0,\n",
       " 1707: 0.5,\n",
       " 1706: 0.1111111111111111,\n",
       " 1705: 1.0,\n",
       " 1704: 0.6666666666666666,\n",
       " 1703: 0.5,\n",
       " 1702: 0.6666666666666666,\n",
       " 1701: 0.14285714285714285,\n",
       " 1700: 0.3,\n",
       " 1699: 0,\n",
       " 1698: 0.3333333333333333,\n",
       " 1697: 0,\n",
       " 1696: 0.027777777777777776,\n",
       " 1695: 0,\n",
       " 1694: 0,\n",
       " 1693: 0.0989010989010989,\n",
       " 1692: 0.13333333333333333,\n",
       " 1691: 0.047619047619047616,\n",
       " 1690: 0,\n",
       " 1689: 0,\n",
       " 1688: 0.044444444444444446,\n",
       " 1687: 0.13725490196078433,\n",
       " 1686: 0.1,\n",
       " 1685: 0.4722222222222222,\n",
       " 1684: 0.34285714285714286,\n",
       " 1683: 0.42424242424242425,\n",
       " 1682: 0.358974358974359,\n",
       " 1681: 0.45454545454545453,\n",
       " 1680: 0.5555555555555556,\n",
       " 1679: 0.5714285714285714,\n",
       " 1678: 0.5357142857142857,\n",
       " 1677: 0.5272727272727272,\n",
       " 1676: 0.6,\n",
       " 1675: 0.047619047619047616,\n",
       " 1674: 0.42483660130718953,\n",
       " 1673: 0.3333333333333333,\n",
       " 1672: 0.3333333333333333,\n",
       " 1671: 0.3333333333333333,\n",
       " 1670: 0,\n",
       " 1669: 0,\n",
       " 1668: 0.15151515151515152,\n",
       " 1667: 0,\n",
       " 1666: 0,\n",
       " 1665: 0.21818181818181817,\n",
       " 1664: 0.16666666666666666,\n",
       " 1663: 0.05454545454545454,\n",
       " 1662: 0.3333333333333333,\n",
       " 1661: 0,\n",
       " 1660: 0,\n",
       " 1659: 0.12727272727272726,\n",
       " 1658: 0,\n",
       " 1657: 0.25263157894736843,\n",
       " 1656: 1.0,\n",
       " 1655: 0.3333333333333333,\n",
       " 1654: 0,\n",
       " 1653: 0,\n",
       " 1652: 0.6,\n",
       " 1651: 0,\n",
       " 1650: 0.3333333333333333,\n",
       " 1649: 0,\n",
       " 1648: 0.8,\n",
       " 1647: 0,\n",
       " 1646: 0.06666666666666667,\n",
       " 1645: 0,\n",
       " 1644: 0,\n",
       " 1643: 0,\n",
       " 1642: 0.16666666666666666,\n",
       " 1641: 0.07142857142857142,\n",
       " 1640: 0,\n",
       " 1639: 0.6666666666666666,\n",
       " 1638: 0,\n",
       " 1637: 0,\n",
       " 1636: 0,\n",
       " 1635: 0,\n",
       " 1634: 0.15789473684210525,\n",
       " 1633: 0.0989010989010989,\n",
       " 1632: 0,\n",
       " 1631: 0,\n",
       " 1630: 0.06593406593406594,\n",
       " 1629: 0.13333333333333333,\n",
       " 1628: 0.3333333333333333,\n",
       " 1627: 0,\n",
       " 1626: 0.05580693815987934,\n",
       " 1625: 0.2,\n",
       " 1624: 0,\n",
       " 1623: 1.0,\n",
       " 1622: 0,\n",
       " 1621: 0,\n",
       " 1620: 0.6222222222222222,\n",
       " 1619: 0,\n",
       " 1618: 0.05128205128205128,\n",
       " 1617: 0.6666666666666666,\n",
       " 1616: 0,\n",
       " 1615: 0,\n",
       " 1614: 0.036231884057971016,\n",
       " 1613: 0.3333333333333333,\n",
       " 1612: 0.12727272727272726,\n",
       " 1611: 0.3333333333333333,\n",
       " 1610: 0,\n",
       " 1609: 0.14035087719298245,\n",
       " 1608: 0.3333333333333333,\n",
       " 1607: 0,\n",
       " 1606: 0,\n",
       " 1605: 0,\n",
       " 1604: 0,\n",
       " 1603: 0.5333333333333333,\n",
       " 1602: 0,\n",
       " 1601: 0,\n",
       " 1600: 0.6666666666666666,\n",
       " 1599: 0,\n",
       " 1598: 0.38011695906432746,\n",
       " 1597: 0,\n",
       " 1596: 0,\n",
       " 1595: 0,\n",
       " 1594: 0.7333333333333333,\n",
       " 1593: 0.3333333333333333,\n",
       " 1592: 0.39285714285714285,\n",
       " 1591: 0.3333333333333333,\n",
       " 1590: 0,\n",
       " 1589: 0,\n",
       " 1588: 0,\n",
       " 1587: 1.0,\n",
       " 1586: 0.25,\n",
       " 1585: 0.16666666666666666,\n",
       " 1584: 0.10256410256410256,\n",
       " 1583: 0,\n",
       " 1582: 0.025,\n",
       " 1581: 0,\n",
       " 1580: 0.1,\n",
       " 1579: 0,\n",
       " 1578: 0.03571428571428571,\n",
       " 1577: 0.1111111111111111,\n",
       " 1576: 0.1388888888888889,\n",
       " 1575: 0.06666666666666667,\n",
       " 1574: 0,\n",
       " 1573: 0.2,\n",
       " 1572: 0.3333333333333333,\n",
       " 1571: 0,\n",
       " 1570: 0.06060606060606061,\n",
       " 1569: 0.16363636363636364,\n",
       " 1568: 0.07386363636363637,\n",
       " 1567: 0,\n",
       " 1566: 0,\n",
       " 1565: 0,\n",
       " 1564: 0,\n",
       " 1563: 0,\n",
       " 1562: 0.8,\n",
       " 1561: 0,\n",
       " 1560: 0.03908045977011494,\n",
       " 1559: 0.04097452934662237,\n",
       " 1558: 0,\n",
       " 1557: 0.2857142857142857,\n",
       " 1556: 0.6666666666666666,\n",
       " 1555: 0.13333333333333333,\n",
       " 1554: 0.2,\n",
       " 1553: 0,\n",
       " 1552: 0.047619047619047616,\n",
       " 1551: 0.35555555555555557,\n",
       " 1550: 0,\n",
       " 1549: 0,\n",
       " 1548: 0.5714285714285714,\n",
       " 1547: 0,\n",
       " 1546: 0,\n",
       " 1545: 0,\n",
       " 1544: 0.2,\n",
       " 1543: 0,\n",
       " 1542: 0.16666666666666666,\n",
       " 1541: 0,\n",
       " 1540: 0.16666666666666666,\n",
       " 1539: 0,\n",
       " 1538: 0,\n",
       " 1537: 0,\n",
       " 1536: 0.5,\n",
       " 1535: 0,\n",
       " 1534: 0.09090909090909091,\n",
       " 1533: 0,\n",
       " 1532: 0,\n",
       " 1531: 0.5,\n",
       " 1530: 0.3333333333333333,\n",
       " 1529: 0,\n",
       " 1528: 0,\n",
       " 1527: 0,\n",
       " 1526: 0,\n",
       " 1525: 0.09523809523809523,\n",
       " 1524: 0,\n",
       " 1523: 0,\n",
       " 1522: 0,\n",
       " 1521: 0,\n",
       " 1520: 0,\n",
       " 1519: 0,\n",
       " 1518: 0,\n",
       " 1517: 0,\n",
       " 1516: 0.3,\n",
       " 1515: 0.16666666666666666,\n",
       " 1514: 1.0,\n",
       " 1513: 0.0641025641025641,\n",
       " 1512: 0,\n",
       " 1511: 0,\n",
       " 1510: 0,\n",
       " 1509: 0,\n",
       " 1508: 0,\n",
       " 1507: 0,\n",
       " 1506: 0.5,\n",
       " 1505: 0.047619047619047616,\n",
       " 1504: 0.15384615384615385,\n",
       " 1503: 0.16666666666666666,\n",
       " 1502: 0.3333333333333333,\n",
       " 1501: 0.09090909090909091,\n",
       " 1500: 0.16666666666666666,\n",
       " 1499: 0.1111111111111111,\n",
       " 1498: 0,\n",
       " 1497: 0,\n",
       " 1496: 0.037037037037037035,\n",
       " 1495: 0,\n",
       " 1494: 0.38095238095238093,\n",
       " 1493: 0,\n",
       " 1492: 0.2,\n",
       " 1491: 0.2,\n",
       " 1490: 0.1111111111111111,\n",
       " 1489: 0.3333333333333333,\n",
       " 1488: 0.35555555555555557,\n",
       " 1487: 0.3,\n",
       " 1486: 0.15555555555555556,\n",
       " 1485: 0.12727272727272726,\n",
       " 1484: 0.47619047619047616,\n",
       " 1483: 0,\n",
       " 1482: 0.6071428571428571,\n",
       " 1481: 0,\n",
       " 1480: 0.09523809523809523,\n",
       " 1479: 0,\n",
       " 1478: 1.0,\n",
       " 1477: 0.6,\n",
       " 1476: 0.06386946386946386,\n",
       " 1475: 0.4175824175824176,\n",
       " 1474: 0,\n",
       " 1473: 0,\n",
       " 1472: 0.14035087719298245,\n",
       " 1471: 0.3333333333333333,\n",
       " 1470: 0,\n",
       " 1469: 0.4,\n",
       " 1468: 0.8333333333333334,\n",
       " 1467: 0,\n",
       " 1466: 0,\n",
       " 1465: 0.3333333333333333,\n",
       " 1464: 0.3333333333333333,\n",
       " 1463: 0.3333333333333333,\n",
       " 1462: 0.3333333333333333,\n",
       " 1461: 0,\n",
       " 1460: 0.047619047619047616,\n",
       " 1459: 0,\n",
       " 1458: 0.1282051282051282,\n",
       " 1457: 0.06666666666666667,\n",
       " 1456: 0.13768115942028986,\n",
       " 1455: 0,\n",
       " 1454: 0,\n",
       " 1453: 0.2,\n",
       " 1452: 0.19047619047619047,\n",
       " 1451: 0.13333333333333333,\n",
       " 1450: 0.2,\n",
       " 1449: 0.05555555555555555,\n",
       " 1448: 0,\n",
       " 1447: 0,\n",
       " 1446: 0,\n",
       " 1445: 0.17777777777777778,\n",
       " 1444: 0.6666666666666666,\n",
       " 1443: 0.9,\n",
       " 1442: 0.26666666666666666,\n",
       " 1441: 0,\n",
       " 1440: 0.38095238095238093,\n",
       " 1439: 0.06666666666666667,\n",
       " 1438: 0,\n",
       " 1437: 0.06206896551724138,\n",
       " 1436: 0.3333333333333333,\n",
       " 1435: 0,\n",
       " 1434: 0,\n",
       " 1433: 0.08974358974358974,\n",
       " 1432: 0,\n",
       " 1431: 0,\n",
       " 1430: 0,\n",
       " 1429: 0,\n",
       " 1428: 0,\n",
       " 1427: 0,\n",
       " 1426: 0.1,\n",
       " 1425: 0.17777777777777778,\n",
       " 1424: 1.0,\n",
       " 1423: 0,\n",
       " 1422: 0.2391304347826087,\n",
       " 1421: 0,\n",
       " 1420: 0.12727272727272726,\n",
       " 1419: 1.0,\n",
       " 1418: 0,\n",
       " 1417: 0.17857142857142858,\n",
       " 1416: 0,\n",
       " 1415: 0.08496732026143791,\n",
       " 1414: 0,\n",
       " 1413: 0.26666666666666666,\n",
       " 1412: 0,\n",
       " 1411: 0.16666666666666666,\n",
       " 1410: 0.09420289855072464,\n",
       " 1409: 0.2,\n",
       " 1408: 0,\n",
       " 1407: 0,\n",
       " 1406: 0.047619047619047616,\n",
       " 1405: 0.045454545454545456,\n",
       " 1404: 0.04411764705882353,\n",
       " 1403: 0,\n",
       " 1402: 0.1,\n",
       " 1401: 0.1,\n",
       " 1400: 0.14285714285714285,\n",
       " 1399: 0.05555555555555555,\n",
       " 1398: 0.06666666666666667,\n",
       " 1397: 0,\n",
       " 1396: 0,\n",
       " 1395: 0.19444444444444445,\n",
       " 1394: 0.3333333333333333,\n",
       " 1393: 0,\n",
       " 1392: 0,\n",
       " 1391: 0.12380952380952381,\n",
       " 1390: 0,\n",
       " 1389: 0,\n",
       " 1388: 0,\n",
       " 1387: 0,\n",
       " 1386: 0.3333333333333333,\n",
       " 1385: 0.3333333333333333,\n",
       " 1384: 0.3956043956043956,\n",
       " 1383: 0.5272727272727272,\n",
       " 1382: 0,\n",
       " 1381: 0.2857142857142857,\n",
       " 1380: 0.16666666666666666,\n",
       " 1379: 0,\n",
       " 1378: 0.08333333333333333,\n",
       " 1377: 0.10256410256410256,\n",
       " 1376: 0,\n",
       " 1375: 0,\n",
       " 1374: 0.1,\n",
       " 1373: 0,\n",
       " 1372: 0,\n",
       " 1371: 0,\n",
       " 1370: 0.3,\n",
       " 1369: 0,\n",
       " 1368: 0,\n",
       " 1367: 0,\n",
       " 1366: 0,\n",
       " 1365: 1.0,\n",
       " 1364: 1.0,\n",
       " 1363: 0,\n",
       " 1362: 0.047619047619047616,\n",
       " 1361: 0,\n",
       " 1360: 0.5277777777777778,\n",
       " 1359: 0.1753846153846154,\n",
       " 1358: 0.19444444444444445,\n",
       " 1357: 1.0,\n",
       " 1356: 0,\n",
       " 1355: 0.5,\n",
       " 1354: 0.4666666666666667,\n",
       " 1353: 0.3333333333333333,\n",
       " 1352: 0.5,\n",
       " 1351: 0.6666666666666666,\n",
       " 1350: 0,\n",
       " 1349: 0.20833333333333334,\n",
       " 1348: 0,\n",
       " 1347: 0,\n",
       " 1346: 0,\n",
       " 1345: 0,\n",
       " 1344: 0,\n",
       " 1343: 0.4444444444444444,\n",
       " 1342: 0,\n",
       " 1341: 0.02564102564102564,\n",
       " 1340: 1.0,\n",
       " 1339: 0.20346320346320346,\n",
       " 1338: 0,\n",
       " 1337: 0.14285714285714285,\n",
       " 1336: 0,\n",
       " 1335: 1.0,\n",
       " 1334: 0,\n",
       " 1333: 0.8666666666666667,\n",
       " 1332: 0.1,\n",
       " 1331: 0,\n",
       " 1330: 0,\n",
       " 1329: 0,\n",
       " 1328: 0.09090909090909091,\n",
       " 1327: 0,\n",
       " 1326: 0.16363636363636364,\n",
       " 1325: 0.10294117647058823,\n",
       " 1324: 0.16666666666666666,\n",
       " 1323: 0,\n",
       " 1322: 0,\n",
       " 1321: 0.058823529411764705,\n",
       " 1320: 0.19047619047619047,\n",
       " 1319: 0.10989010989010989,\n",
       " 1318: 0,\n",
       " 1317: 0,\n",
       " 1316: 0.09523809523809523,\n",
       " 1315: 0.013071895424836602,\n",
       " 1314: 0.2,\n",
       " 1313: 0.6666666666666666,\n",
       " 1312: 0.16666666666666666,\n",
       " 1311: 0,\n",
       " 1310: 0.24444444444444444,\n",
       " 1309: 0.1,\n",
       " 1308: 0.6666666666666666,\n",
       " 1307: 0.2,\n",
       " 1306: 1.0,\n",
       " 1305: 0,\n",
       " 1304: 0.1,\n",
       " 1303: 0.3,\n",
       " 1302: 0.030204081632653063,\n",
       " 1301: 0.19047619047619047,\n",
       " 1300: 0,\n",
       " 1299: 0.1111111111111111,\n",
       " 1298: 0,\n",
       " 1297: 0.14285714285714285,\n",
       " 1296: 0.3333333333333333,\n",
       " 1295: 0,\n",
       " 1294: 0.3,\n",
       " 1293: 0,\n",
       " 1292: 0.1,\n",
       " 1291: 0,\n",
       " 1290: 0,\n",
       " 1289: 1.0,\n",
       " 1288: 0.06666666666666667,\n",
       " 1287: 0.1695906432748538,\n",
       " 1286: 0,\n",
       " 1285: 0,\n",
       " 1284: 0,\n",
       " 1283: 0,\n",
       " 1282: 0,\n",
       " 1281: 0,\n",
       " 1280: 0,\n",
       " 1279: 0.07692307692307693,\n",
       " 1278: 0,\n",
       " 1277: 0.3333333333333333,\n",
       " 1276: 0.06324110671936758,\n",
       " 1275: 0.16666666666666666,\n",
       " 1274: 0.16666666666666666,\n",
       " 1273: 0.1,\n",
       " 1272: 0,\n",
       " 1271: 0.2857142857142857,\n",
       " 1270: 0,\n",
       " 1269: 0,\n",
       " 1268: 0,\n",
       " 1267: 0.6666666666666666,\n",
       " 1266: 0,\n",
       " 1265: 0,\n",
       " 1264: 0,\n",
       " 1263: 0.11384615384615385,\n",
       " 1262: 0.16666666666666666,\n",
       " 1261: 0.6666666666666666,\n",
       " 1260: 0.06666666666666667,\n",
       " 1259: 0.16666666666666666,\n",
       " 1258: 1.0,\n",
       " 1257: 0,\n",
       " 1256: 0.06666666666666667,\n",
       " 1255: 0.6,\n",
       " 1254: 0.21818181818181817,\n",
       " 1253: 0,\n",
       " 1252: 0.2857142857142857,\n",
       " 1251: 0.19444444444444445,\n",
       " 1250: 0.12380952380952381,\n",
       " 1249: 0,\n",
       " 1248: 0,\n",
       " 1247: 0,\n",
       " 1246: 0.3333333333333333,\n",
       " 1245: 0.3333333333333333,\n",
       " 1244: 0.3,\n",
       " 1243: 0,\n",
       " 1242: 0.07272727272727272,\n",
       " 1241: 0,\n",
       " 1240: 0.26666666666666666,\n",
       " 1239: 0.38095238095238093,\n",
       " 1238: 0,\n",
       " 1237: 0,\n",
       " 1236: 0,\n",
       " 1235: 0.09090909090909091,\n",
       " 1234: 0.01818181818181818,\n",
       " 1233: 0.19047619047619047,\n",
       " 1232: 1.0,\n",
       " 1231: 0.13333333333333333,\n",
       " 1230: 0,\n",
       " 1229: 0,\n",
       " 1228: 0.4,\n",
       " 1227: 0.32142857142857145,\n",
       " 1226: 0.07575757575757576,\n",
       " 1225: 1.0,\n",
       " 1224: 0.06666666666666667,\n",
       " 1223: 0.09523809523809523,\n",
       " 1222: 0.17857142857142858,\n",
       " 1221: 0,\n",
       " 1220: 0.38095238095238093,\n",
       " 1219: 0.3238095238095238,\n",
       " 1218: 0.19886363636363635,\n",
       " 1217: 0.1,\n",
       " 1216: 0,\n",
       " 1215: 0.13333333333333333,\n",
       " 1214: 0,\n",
       " 1213: 0.06666666666666667,\n",
       " 1212: 0,\n",
       " 1211: 0.3333333333333333,\n",
       " 1210: 1.0,\n",
       " 1209: 0.6666666666666666,\n",
       " 1208: 0,\n",
       " 1207: 0,\n",
       " 1206: 0,\n",
       " 1205: 0.06593406593406594,\n",
       " 1204: 0.2,\n",
       " 1203: 0,\n",
       " 1202: 0.26666666666666666,\n",
       " 1201: 0.3333333333333333,\n",
       " 1200: 0.4666666666666667,\n",
       " 1199: 0.09523809523809523,\n",
       " 1198: 0,\n",
       " 1197: 0,\n",
       " 1196: 0,\n",
       " 1195: 0,\n",
       " 1194: 0.1619047619047619,\n",
       " 1193: 0.3333333333333333,\n",
       " 1192: 0.01818181818181818,\n",
       " 1191: 0.3,\n",
       " 1190: 0,\n",
       " 1189: 1.0,\n",
       " 1188: 0,\n",
       " 1187: 0.047619047619047616,\n",
       " 1186: 0.10256410256410256,\n",
       " 1185: 0.3333333333333333,\n",
       " 1184: 0.3333333333333333,\n",
       " 1183: 0.16666666666666666,\n",
       " 1182: 0,\n",
       " 1181: 0.21428571428571427,\n",
       " 1180: 0.17857142857142858,\n",
       " 1179: 0,\n",
       " 1178: 0,\n",
       " 1177: 0,\n",
       " 1176: 0,\n",
       " 1175: 0.14487179487179488,\n",
       " 1174: 0.6666666666666666,\n",
       " 1173: 0.23809523809523808,\n",
       " 1172: 0.06557377049180328,\n",
       " 1171: 0.3333333333333333,\n",
       " 1170: 0.4,\n",
       " 1169: 0,\n",
       " 1168: 0,\n",
       " 1167: 0,\n",
       " 1166: 1.0,\n",
       " 1165: 0,\n",
       " 1164: 1.0,\n",
       " 1163: 0,\n",
       " 1162: 0.3055555555555556,\n",
       " 1161: 0.06432748538011696,\n",
       " 1160: 0.16666666666666666,\n",
       " 1159: 0,\n",
       " 1158: 0.05714285714285714,\n",
       " 1157: 0.8095238095238095,\n",
       " 1156: 0,\n",
       " 1155: 0,\n",
       " 1154: 0.3333333333333333,\n",
       " 1153: 0.3333333333333333,\n",
       " 1152: 0.05454545454545454,\n",
       " 1151: 0.044444444444444446,\n",
       " 1150: 0,\n",
       " 1149: 0.4,\n",
       " 1148: 0.5,\n",
       " 1147: 0,\n",
       " 1146: 0.16666666666666666,\n",
       " 1145: 0.13333333333333333,\n",
       " 1144: 0,\n",
       " 1143: 0,\n",
       " 1142: 0,\n",
       " 1141: 0,\n",
       " 1140: 0,\n",
       " 1139: 0,\n",
       " 1138: 0.06666666666666667,\n",
       " 1137: 0.04411764705882353,\n",
       " 1136: 0.2,\n",
       " 1135: 0,\n",
       " 1134: 0.05714285714285714,\n",
       " 1133: 0.12727272727272726,\n",
       " 1132: 0,\n",
       " 1131: 0.6666666666666666,\n",
       " 1130: 0,\n",
       " 1129: 0.3333333333333333,\n",
       " 1128: 0,\n",
       " 1127: 0.038461538461538464,\n",
       " 1126: 0.14285714285714285,\n",
       " 1125: 0.5,\n",
       " 1124: 0.07575757575757576,\n",
       " 1123: 0,\n",
       " 1122: 0,\n",
       " 1121: 0,\n",
       " 1120: 0.08888888888888889,\n",
       " 1119: 0,\n",
       " 1118: 0,\n",
       " 1117: 0,\n",
       " 1116: 0,\n",
       " 1115: 0.19047619047619047,\n",
       " 1114: 0,\n",
       " 1113: 0.2,\n",
       " 1112: 0.1,\n",
       " 1111: 0.06666666666666667,\n",
       " 1110: 0.0380952380952381,\n",
       " 1109: 0,\n",
       " 1108: 0.3333333333333333,\n",
       " 1107: 0.3111111111111111,\n",
       " 1106: 0,\n",
       " 1105: 0,\n",
       " 1104: 0.09523809523809523,\n",
       " 1103: 0.16666666666666666,\n",
       " 1102: 0.1,\n",
       " 1101: 0.2,\n",
       " 1100: 0,\n",
       " 1099: 0,\n",
       " 1098: 0.09523809523809523,\n",
       " 1097: 0.06666666666666667,\n",
       " 1096: 0,\n",
       " 1095: 0,\n",
       " 1094: 0,\n",
       " 1093: 0.1,\n",
       " 1092: 0.3333333333333333,\n",
       " 1091: 0.047619047619047616,\n",
       " 1090: 0,\n",
       " 1089: 0,\n",
       " 1088: 0.037037037037037035,\n",
       " 1087: 0.3956043956043956,\n",
       " 1086: 1.0,\n",
       " 1085: 0.26666666666666666,\n",
       " 1084: 0.1,\n",
       " 1083: 0.8333333333333334,\n",
       " 1082: 0,\n",
       " 1081: 0.3333333333333333,\n",
       " 1080: 0.3333333333333333,\n",
       " 1079: 0.21428571428571427,\n",
       " 1078: 0,\n",
       " 1077: 0,\n",
       " 1076: 0.07122507122507123,\n",
       " 1075: 0.13333333333333333,\n",
       " 1074: 0.2,\n",
       " 1073: 0,\n",
       " 1072: 1.0,\n",
       " 1071: 0.07195121951219512,\n",
       " 1070: 0,\n",
       " 1069: 0,\n",
       " 1068: 0,\n",
       " 1067: 0,\n",
       " 1066: 0,\n",
       " 1065: 0,\n",
       " 1064: 0,\n",
       " 1063: 1.0,\n",
       " 1062: 0.2,\n",
       " 1061: 0.13333333333333333,\n",
       " 1060: 0.14285714285714285,\n",
       " 1059: 0.19230769230769232,\n",
       " 1058: 0.06666666666666667,\n",
       " 1057: 0,\n",
       " 1056: 0.11839323467230443,\n",
       " 1055: 0.14285714285714285,\n",
       " 1054: 0.6666666666666666,\n",
       " 1053: 0.06666666666666667,\n",
       " 1052: 0,\n",
       " 1051: 0,\n",
       " 1050: 0.5,\n",
       " 1049: 0,\n",
       " 1048: 0.16666666666666666,\n",
       " 1047: 1.0,\n",
       " 1046: 0,\n",
       " 1045: 0,\n",
       " 1044: 0,\n",
       " 1043: 0,\n",
       " 1042: 0,\n",
       " 1041: 0,\n",
       " 1040: 0.14285714285714285,\n",
       " 1039: 0.2,\n",
       " 1038: 0.05228758169934641,\n",
       " 1037: 0,\n",
       " 1036: 0,\n",
       " 1035: 0.3333333333333333,\n",
       " 1034: 0,\n",
       " 1033: 0,\n",
       " 1032: 0,\n",
       " 1031: 0.3333333333333333,\n",
       " 1030: 1.0,\n",
       " 1029: 0.14285714285714285,\n",
       " 1028: 0.08333333333333333,\n",
       " 1027: 0.4,\n",
       " 1026: 0.20634920634920634,\n",
       " 1025: 0,\n",
       " 1024: 0,\n",
       " 1023: 0.3333333333333333,\n",
       " 1022: 0.19047619047619047,\n",
       " 1021: 0,\n",
       " 1020: 0.16666666666666666,\n",
       " 1019: 0,\n",
       " 1018: 0.6666666666666666,\n",
       " 1017: 0,\n",
       " 1016: 0,\n",
       " 1015: 0.2426470588235294,\n",
       " 1014: 0.16666666666666666,\n",
       " 1013: 0,\n",
       " 1012: 0,\n",
       " 1011: 0.3333333333333333,\n",
       " 1010: 0,\n",
       " 1009: 0,\n",
       " 1008: 0.13949579831932774,\n",
       " 1007: 0.09090909090909091,\n",
       " 1006: 0.2,\n",
       " 1005: 0,\n",
       " 1004: 0.047619047619047616,\n",
       " 1003: 0,\n",
       " 1002: 1.0,\n",
       " 1001: 0.16666666666666666,\n",
       " 1000: 0,\n",
       " 999: 0.02197802197802198,\n",
       " 998: 0.4,\n",
       " 997: 1.0,\n",
       " 996: 0,\n",
       " 995: 0.3333333333333333,\n",
       " 994: 0.030303030303030304,\n",
       " 993: 0,\n",
       " 992: 0,\n",
       " 991: 0,\n",
       " 990: 0.052307692307692305,\n",
       " 989: 0,\n",
       " 988: 0.3333333333333333,\n",
       " 987: 0.3333333333333333,\n",
       " 986: 0.5333333333333333,\n",
       " 985: 0,\n",
       " 984: 0.17846153846153845,\n",
       " 983: 0,\n",
       " ...}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.clustering(data.g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
